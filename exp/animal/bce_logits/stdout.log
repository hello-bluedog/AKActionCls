[03/05 17:15:31][INFO] train_net.py: 411: Train with config:
[03/05 17:15:31][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/train.csv', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': 'exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/05 17:15:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:31][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:31][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:31][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:31][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:31][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:31][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:31][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:15:32][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/05 17:15:32][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/05 17:15:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:15:32][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/05 17:15:32][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/05 17:15:32][INFO] uniformerv2_model.py: 334: Init center: True
[03/05 17:15:33][INFO] misc.py: 183: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/05 17:15:33][INFO] misc.py: 184: Params: 114,552,208
[03/05 17:15:33][INFO] misc.py: 185: Mem: 0.4275493621826172 MB
[03/05 17:18:24][INFO] train_net.py: 411: Train with config:
[03/05 17:18:24][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/train.csv', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': 'exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:18:25][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/05 17:18:25][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/05 17:18:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:18:25][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/05 17:18:25][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/05 17:18:25][INFO] uniformerv2_model.py: 334: Init center: True
[03/05 17:18:26][INFO] misc.py: 183: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/05 17:18:26][INFO] misc.py: 184: Params: 114,552,208
[03/05 17:18:26][INFO] misc.py: 185: Mem: 0.4275493621826172 MB
[03/05 17:25:40][INFO] train_net.py: 411: Train with config:
[03/05 17:25:40][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/train.csv', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': 'exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:25:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:25:40][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/05 17:25:40][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/05 17:25:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:25:41][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:25:41][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:25:41][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:25:41][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/05 17:25:41][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/05 17:25:41][INFO] uniformerv2_model.py: 334: Init center: True
[03/05 17:25:41][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/05 17:25:41][INFO] misc.py: 185: Params: 114,552,208
[03/05 17:25:41][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/05 17:25:41][INFO] misc.py: 187: Flops: 0 G
[03/05 17:25:41][INFO] misc.py: 192: Activations: 0 M
[03/05 17:25:41][INFO] misc.py: 197: nvidia-smi
[03/05 17:25:42][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/05 17:25:42][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/05 17:26:24][INFO] train_net.py: 411: Train with config:
[03/05 17:26:24][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': 'exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/05 17:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:26:25][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/05 17:26:25][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/05 17:26:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:26:25][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/05 17:26:25][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/05 17:26:25][INFO] uniformerv2_model.py: 334: Init center: True
[03/05 17:26:26][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/05 17:26:26][INFO] misc.py: 185: Params: 114,552,208
[03/05 17:26:26][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/05 17:26:26][INFO] misc.py: 187: Flops: 0 G
[03/05 17:26:26][INFO] misc.py: 192: Activations: 0 M
[03/05 17:26:26][INFO] misc.py: 197: nvidia-smi
[03/05 17:26:26][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/05 17:26:26][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/05 17:29:48][INFO] train_net.py: 411: Train with config:
[03/05 17:29:48][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': 'exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:29:48][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/05 17:29:48][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/05 17:29:48][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:29:48][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:29:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:29:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:29:49][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/05 17:29:49][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/05 17:29:49][INFO] uniformerv2_model.py: 334: Init center: True
[03/05 17:29:49][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/05 17:29:49][INFO] misc.py: 185: Params: 114,552,208
[03/05 17:29:49][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/05 17:29:49][INFO] misc.py: 187: Flops: 0 G
[03/05 17:29:49][INFO] misc.py: 192: Activations: 0 M
[03/05 17:29:49][INFO] misc.py: 197: nvidia-smi
[03/05 17:29:50][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/05 17:29:50][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/05 17:30:14][INFO] train_net.py: 411: Train with config:
[03/05 17:30:14][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': 'exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 17:30:14][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 17:30:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 17:30:15][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/05 17:30:15][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/05 17:30:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:30:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:30:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:30:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 17:30:15][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/05 17:30:15][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/05 17:30:15][INFO] uniformerv2_model.py: 334: Init center: True
[03/05 17:30:15][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/05 17:30:15][INFO] misc.py: 185: Params: 114,552,208
[03/05 17:30:15][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/05 17:30:15][INFO] misc.py: 187: Flops: 0 G
[03/05 17:30:15][INFO] misc.py: 192: Activations: 0 M
[03/05 17:30:15][INFO] misc.py: 197: nvidia-smi
[03/05 17:30:16][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/05 17:30:16][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/05 17:30:16][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/train.csv
[03/05 21:17:12][INFO] train_net.py: 411: Train with config:
[03/05 21:17:12][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': 'exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/05 21:17:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/05 21:17:13][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/05 21:17:13][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/05 21:17:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/05 21:17:13][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/05 21:17:13][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/05 21:17:13][INFO] uniformerv2_model.py: 334: Init center: True
[03/05 21:17:14][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/05 21:17:14][INFO] misc.py: 185: Params: 114,552,208
[03/05 21:17:14][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/05 21:17:14][INFO] misc.py: 187: Flops: 0 G
[03/05 21:17:14][INFO] misc.py: 192: Activations: 0 M
[03/05 21:17:14][INFO] misc.py: 197: nvidia-smi
[03/05 21:17:14][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/05 21:17:14][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/05 21:17:14][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/train.csv
[03/06 16:43:28][INFO] train_net.py: 411: Train with config:
[03/06 16:43:28][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 16:43:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:43:29][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 16:43:29][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 16:43:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:43:29][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 16:43:29][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 16:43:29][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 16:43:30][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/06 16:43:30][INFO] misc.py: 185: Params: 114,552,208
[03/06 16:43:30][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/06 16:43:30][INFO] misc.py: 187: Flops: 0 G
[03/06 16:43:30][INFO] misc.py: 192: Activations: 0 M
[03/06 16:43:30][INFO] misc.py: 197: nvidia-smi
[03/06 16:43:31][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 16:43:31][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 16:43:31][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:46:23][INFO] train_net.py: 411: Train with config:
[03/06 16:46:23][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:46:24][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 16:46:24][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 16:46:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:46:24][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 16:46:25][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 16:46:25][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 16:46:25][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/06 16:46:25][INFO] misc.py: 185: Params: 114,552,208
[03/06 16:46:25][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/06 16:46:25][INFO] misc.py: 187: Flops: 0 G
[03/06 16:46:25][INFO] misc.py: 192: Activations: 0 M
[03/06 16:46:25][INFO] misc.py: 197: nvidia-smi
[03/06 16:46:26][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 16:46:26][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 16:46:26][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:46:26][INFO] kinetics_sparse.py: 126: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:49:45][INFO] train_net.py: 411: Train with config:
[03/06 16:49:45][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:49:45][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 16:49:45][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 16:49:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:49:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:49:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:49:46][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 16:49:46][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 16:49:46][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 16:49:47][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 16:49:47][INFO] misc.py: 185: Params: 114,552,208
[03/06 16:49:47][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 16:49:47][INFO] misc.py: 187: Flops: 0 G
[03/06 16:49:47][INFO] misc.py: 192: Activations: 0 M
[03/06 16:49:47][INFO] misc.py: 197: nvidia-smi
[03/06 16:49:48][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 16:49:48][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 16:49:48][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:49:48][INFO] kinetics_sparse.py: 126: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:49:48][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 16:49:48][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:49:48][INFO] kinetics_sparse.py: 126: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:49:48][INFO] train_net.py: 454: Start epoch: 1
[03/06 16:52:57][INFO] train_net.py: 411: Train with config:
[03/06 16:52:57][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:52:57][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 16:52:57][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 16:52:57][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:52:57][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:52:58][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 16:52:58][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 16:52:58][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 16:52:58][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 16:52:58][INFO] misc.py: 185: Params: 114,552,208
[03/06 16:52:58][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 16:52:59][INFO] misc.py: 187: Flops: 0 G
[03/06 16:52:59][INFO] misc.py: 192: Activations: 0 M
[03/06 16:52:59][INFO] misc.py: 197: nvidia-smi
[03/06 16:52:59][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 16:52:59][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 16:52:59][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:53:00][INFO] kinetics_sparse.py: 126: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:53:00][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 16:53:00][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:53:00][INFO] kinetics_sparse.py: 126: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:53:00][INFO] train_net.py: 454: Start epoch: 1
[03/06 16:58:12][INFO] train_net.py: 411: Train with config:
[03/06 16:58:12][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:58:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:58:12][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 16:58:12][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 16:58:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:58:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:58:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:58:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:58:13][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 16:58:13][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 16:58:13][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 16:58:14][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 16:58:14][INFO] misc.py: 185: Params: 114,552,208
[03/06 16:58:14][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 16:58:14][INFO] misc.py: 187: Flops: 0 G
[03/06 16:58:14][INFO] misc.py: 192: Activations: 0 M
[03/06 16:58:14][INFO] misc.py: 197: nvidia-smi
[03/06 16:58:14][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 16:58:14][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 16:58:14][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:58:15][INFO] kinetics_sparse.py: 126: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:58:15][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 16:58:15][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:58:15][INFO] kinetics_sparse.py: 126: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:58:15][INFO] train_net.py: 454: Start epoch: 1
[03/06 16:59:32][INFO] train_net.py: 411: Train with config:
[03/06 16:59:32][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:32][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:33][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:33][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 16:59:33][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 16:59:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 16:59:33][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 16:59:33][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 16:59:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:59:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:59:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:59:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 16:59:33][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 16:59:33][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 16:59:33][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 16:59:34][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 16:59:34][INFO] misc.py: 185: Params: 114,552,208
[03/06 16:59:34][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 16:59:34][INFO] misc.py: 187: Flops: 0 G
[03/06 16:59:34][INFO] misc.py: 192: Activations: 0 M
[03/06 16:59:34][INFO] misc.py: 197: nvidia-smi
[03/06 16:59:35][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 16:59:35][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 16:59:35][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:59:35][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 16:59:35][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 16:59:35][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:59:35][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 16:59:35][INFO] train_net.py: 454: Start epoch: 1
[03/06 17:01:11][INFO] train_net.py: 411: Train with config:
[03/06 17:01:11][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 17:01:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:01:12][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 17:01:12][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 17:01:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:01:12][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 17:01:12][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 17:01:12][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 17:01:13][INFO] misc.py: 184: Model:
Uniformerv2(
  (backbone): VisionTransformer(
    (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dpe): ModuleList(
        (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
      )
      (dec): ModuleList(
        (0-3): 4 x Extractor(
          (drop_path): Identity()
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (dropout): Dropout(p=0.5, inplace=False)
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj): Sequential(
        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=768, out_features=400, bias=True)
      )
      (sigmoid): Sigmoid()
    )
  )
)
[03/06 17:01:13][INFO] misc.py: 185: Params: 114,552,208
[03/06 17:01:13][INFO] misc.py: 186: Mem: 0.4275493621826172 MB
[03/06 17:01:13][INFO] misc.py: 187: Flops: 0 G
[03/06 17:01:13][INFO] misc.py: 192: Activations: 0 M
[03/06 17:01:13][INFO] misc.py: 197: nvidia-smi
[03/06 17:01:14][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 17:01:14][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 17:01:14][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:01:14][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:02:34][INFO] train_net.py: 411: Train with config:
[03/06 17:02:34][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 2, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:02:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:02:34][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 17:02:34][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 17:02:34][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:02:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:02:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:02:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:02:35][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 17:02:35][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 17:02:35][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 17:02:36][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 17:02:36][INFO] misc.py: 185: Params: 114,552,208
[03/06 17:02:36][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 17:02:36][INFO] misc.py: 187: Flops: 0 G
[03/06 17:02:36][INFO] misc.py: 192: Activations: 0 M
[03/06 17:02:36][INFO] misc.py: 197: nvidia-smi
[03/06 17:02:37][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 17:02:37][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 17:02:37][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:02:37][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:02:37][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 17:02:37][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 17:02:37][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 17:02:37][INFO] train_net.py: 454: Start epoch: 1
[03/06 17:07:04][INFO] train_net.py: 411: Train with config:
[03/06 17:07:04][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 2, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:07:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:07:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:07:05][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 17:07:05][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 17:07:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:07:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:07:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:07:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:07:05][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 17:07:05][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 17:07:05][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 17:07:06][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 17:07:06][INFO] misc.py: 185: Params: 114,552,208
[03/06 17:07:06][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 17:07:06][INFO] misc.py: 187: Flops: 0 G
[03/06 17:07:06][INFO] misc.py: 192: Activations: 0 M
[03/06 17:07:06][INFO] misc.py: 197: nvidia-smi
[03/06 17:07:07][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 17:07:07][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 17:07:07][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:07:07][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:07:07][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 17:07:07][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 17:07:07][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 17:07:07][INFO] train_net.py: 454: Start epoch: 1
[03/06 17:10:23][INFO] train_net.py: 411: Train with config:
[03/06 17:10:23][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 2, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 17:10:23][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 17:10:23][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 17:10:23][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 17:10:23][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:10:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:10:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:10:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 17:10:24][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 17:10:24][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 17:10:24][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 17:10:25][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 17:10:25][INFO] misc.py: 185: Params: 114,552,208
[03/06 17:10:25][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 17:10:25][INFO] misc.py: 187: Flops: 0 G
[03/06 17:10:25][INFO] misc.py: 192: Activations: 0 M
[03/06 17:10:25][INFO] misc.py: 197: nvidia-smi
[03/06 17:10:26][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 17:10:26][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 17:10:26][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:10:26][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 17:10:26][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 17:10:26][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 17:10:26][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 17:10:26][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:25:54][INFO] train_net.py: 411: Train with config:
[03/06 18:25:54][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 2, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:25:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:25:55][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:25:55][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:25:55][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:25:55][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:25:55][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:25:55][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:25:56][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:25:56][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:25:56][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:25:56][INFO] misc.py: 187: Flops: 0 G
[03/06 18:25:56][INFO] misc.py: 192: Activations: 0 M
[03/06 18:25:56][INFO] misc.py: 197: nvidia-smi
[03/06 18:25:57][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:25:57][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:25:57][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:25:57][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:25:57][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:25:57][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:25:57][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:25:57][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:27:26][INFO] train_net.py: 411: Train with config:
[03/06 18:27:26][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 2, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:27:26][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:27:26][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:27:26][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:27:26][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:27:27][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:27:27][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:27:27][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:27:27][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:27:27][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:27:28][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:27:28][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:27:28][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:27:28][INFO] misc.py: 187: Flops: 0 G
[03/06 18:27:28][INFO] misc.py: 192: Activations: 0 M
[03/06 18:27:28][INFO] misc.py: 197: nvidia-smi
[03/06 18:27:29][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:27:29][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:27:29][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:27:29][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:27:29][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:27:29][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:27:29][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:27:29][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:29:20][INFO] train_net.py: 411: Train with config:
[03/06 18:29:20][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:29:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:29:21][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:29:21][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:29:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:29:21][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:29:21][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:29:21][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:29:22][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:29:22][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:29:22][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:29:22][INFO] misc.py: 187: Flops: 0 G
[03/06 18:29:22][INFO] misc.py: 192: Activations: 0 M
[03/06 18:29:22][INFO] misc.py: 197: nvidia-smi
[03/06 18:29:23][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:29:23][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:29:23][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:29:23][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:29:23][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:29:23][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:29:23][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:29:23][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:30:16][INFO] train_net.py: 411: Train with config:
[03/06 18:30:16][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 8, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:30:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:30:17][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:30:17][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:30:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:30:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:30:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:30:18][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:30:18][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:30:18][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:30:19][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:30:19][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:30:19][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:30:19][INFO] misc.py: 187: Flops: 0 G
[03/06 18:30:19][INFO] misc.py: 192: Activations: 0 M
[03/06 18:30:19][INFO] misc.py: 197: nvidia-smi
[03/06 18:30:20][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:30:20][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:30:20][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:30:20][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:30:20][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:30:20][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:30:20][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:30:20][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:30:31][INFO] uniformerv2_model.py: 320: torch.Size([32, 3, 8, 224, 224])
[03/06 18:30:31][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:32:15][INFO] train_net.py: 411: Train with config:
[03/06 18:32:15][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:32:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:15][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:15][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:15][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:15][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:32:16][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:32:16][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:32:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:32:16][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:32:17][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:32:17][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:32:17][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:32:17][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:32:17][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:32:18][INFO] misc.py: 187: Flops: 0 G
[03/06 18:32:18][INFO] misc.py: 192: Activations: 0 M
[03/06 18:32:18][INFO] misc.py: 197: nvidia-smi
[03/06 18:32:18][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:32:18][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:32:18][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:32:19][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:32:19][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:32:19][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:32:19][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:32:19][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:34:06][INFO] train_net.py: 411: Train with config:
[03/06 18:34:06][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:06][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:34:06][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:34:06][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:06][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:07][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:34:07][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:34:07][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:34:08][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:34:08][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:34:08][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:34:08][INFO] misc.py: 187: Flops: 0 G
[03/06 18:34:08][INFO] misc.py: 192: Activations: 0 M
[03/06 18:34:08][INFO] misc.py: 197: nvidia-smi
[03/06 18:34:09][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:34:09][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:34:09][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:34:09][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:34:09][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:34:09][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:34:09][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:34:09][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:34:53][INFO] train_net.py: 411: Train with config:
[03/06 18:34:53][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 16, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:34:53][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:53][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:53][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:53][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:53][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:53][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:53][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:53][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:34:54][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:34:54][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:34:54][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:34:54][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:34:54][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:34:54][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:34:55][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:34:55][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:34:55][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:34:55][INFO] misc.py: 187: Flops: 0 G
[03/06 18:34:56][INFO] misc.py: 192: Activations: 0 M
[03/06 18:34:56][INFO] misc.py: 197: nvidia-smi
[03/06 18:34:56][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:34:56][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:34:56][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:34:56][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:34:56][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:34:56][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:34:56][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:34:56][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:35:01][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:01][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:02][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:02][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:03][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:03][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:04][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:04][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:05][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:05][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:06][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:06][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:06][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:06][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:07][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:07][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:08][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:08][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:09][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:09][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 1.02384, "dt_data": 0.66753, "dt_net": 0.35630, "epoch": "1/55", "eta": "23:27:36", "gpu_mem": "5.29G", "iter": "10/1500", "loss": 6.11792, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 100.00000}
[03/06 18:35:10][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:10][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:11][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:11][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:12][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:12][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:13][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:13][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:14][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:14][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:14][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:14][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:15][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:15][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:16][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:16][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:17][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:17][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:18][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:18][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 0.89018, "dt_data": 0.53046, "dt_net": 0.35972, "epoch": "1/55", "eta": "20:23:42", "gpu_mem": "5.29G", "iter": "20/1500", "loss": 5.70898, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 87.50000}
[03/06 18:35:19][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:19][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:20][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:20][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:21][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:21][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:22][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:22][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:23][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:23][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:24][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:24][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:25][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:25][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:26][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:26][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:26][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:26][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:27][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:27][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 0.97479, "dt_data": 0.61547, "dt_net": 0.35931, "epoch": "1/55", "eta": "22:19:51", "gpu_mem": "5.29G", "iter": "30/1500", "loss": 5.46002, "lr": 0.00000, "top1_err": 90.62500, "top5_err": 75.00000}
[03/06 18:35:28][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:28][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:29][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:29][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:30][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:30][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:31][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:31][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:32][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:32][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:33][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:33][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:33][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:33][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:34][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:34][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:35][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:35][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:36][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:36][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 0.82999, "dt_data": 0.39360, "dt_net": 0.43639, "epoch": "1/55", "eta": "19:00:40", "gpu_mem": "5.29G", "iter": "40/1500", "loss": 4.81793, "lr": 0.00000, "top1_err": 87.50000, "top5_err": 62.50000}
[03/06 18:35:37][INFO] uniformerv2_model.py: 320: torch.Size([4, 3, 8, 224, 224])
[03/06 18:35:37][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:35:57][INFO] train_net.py: 411: Train with config:
[03/06 18:35:57][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:35:57][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:35:57][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:35:57][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:35:57][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:35:58][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:35:58][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:35:58][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:35:58][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:36:00][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:36:00][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:36:00][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:36:00][INFO] misc.py: 187: Flops: 0 G
[03/06 18:36:00][INFO] misc.py: 192: Activations: 0 M
[03/06 18:36:00][INFO] misc.py: 197: nvidia-smi
[03/06 18:36:01][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:36:01][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:36:01][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:36:01][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:36:01][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:36:01][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:36:01][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:36:01][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:36:50][INFO] train_net.py: 411: Train with config:
[03/06 18:36:50][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 128, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 400, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/k400/k400_b16_f8x224/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:36:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:36:51][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:36:51][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:36:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:36:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:36:52][INFO] uniformerv2_model.py: 400: load pretrained weights
[03/06 18:36:52][INFO] uniformerv2_model.py: 355: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:36:52][INFO] uniformerv2_model.py: 336: Init center: True
[03/06 18:36:53][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=400, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:36:53][INFO] misc.py: 185: Params: 114,552,208
[03/06 18:36:53][INFO] misc.py: 186: Mem: 0.8542900085449219 MB
[03/06 18:36:53][INFO] misc.py: 187: Flops: 0 G
[03/06 18:36:53][INFO] misc.py: 192: Activations: 0 M
[03/06 18:36:53][INFO] misc.py: 197: nvidia-smi
[03/06 18:36:54][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:36:54][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:36:54][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:36:54][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 18:36:54][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 18:36:54][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:36:54][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 18:36:54][INFO] train_net.py: 454: Start epoch: 1
[03/06 18:37:01][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:01][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:05][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:05][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:09][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:09][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:12][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:12][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:16][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:16][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:20][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:20][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:24][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:24][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:27][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:27][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:30][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:30][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:33][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:33][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:37:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.79006, "dt_data": 2.34994, "dt_net": 0.44011, "epoch": "1/55", "eta": "15:58:37", "gpu_mem": "13.93G", "iter": "10/375", "loss": 6.00092, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 97.65625}
[03/06 18:37:37][INFO] uniformerv2_model.py: 320: torch.Size([16, 3, 8, 224, 224])
[03/06 18:37:37][INFO] uniformerv2_model.py: 321: Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
[03/06 18:47:12][INFO] train_net.py: 411: Train with config:
[03/06 18:47:12][INFO] train_net.py: 412: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 18:47:12][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 18:47:12][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 18:47:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:47:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:47:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:47:13][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 18:47:13][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 18:47:13][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 18:47:13][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 18:47:14][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 18:47:14][INFO] misc.py: 185: Params: 114,352,268
[03/06 18:47:14][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 18:47:14][INFO] misc.py: 187: Flops: 0 G
[03/06 18:47:14][INFO] misc.py: 192: Activations: 0 M
[03/06 18:47:14][INFO] misc.py: 197: nvidia-smi
[03/06 18:47:15][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 18:47:15][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 18:47:15][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:11:06][INFO] train_net.py: 413: Train with config:
[03/06 19:11:06][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:06][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:07][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:11:07][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:11:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:11:07][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:11:07][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:11:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:11:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:11:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:11:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:11:07][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:11:07][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:11:07][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:11:08][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:11:08][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:11:08][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:11:08][INFO] misc.py: 187: Flops: 0 G
[03/06 19:11:08][INFO] misc.py: 192: Activations: 0 M
[03/06 19:11:08][INFO] misc.py: 197: nvidia-smi
[03/06 19:11:09][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:11:09][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 19:11:09][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:11:09][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:11:09][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 19:11:09][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:11:09][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:11:09][INFO] train_net.py: 456: Start epoch: 1
[03/06 19:11:17][INFO] train_net.py:  93: tensor([ 40,   1,   2,  15,   2, 102, 102, 102, 123,  68, 102,  40,  97,   2,
         40,   2], device='cuda:0')
[03/06 19:11:17][INFO] train_net.py:  94: [tensor([[[[[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.4110e-01,
            -9.5117e-01, -9.5853e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.6709e-01,
            -9.6974e-01, -9.7168e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.7168e-01,
            -9.7168e-01, -9.7168e-01],
           ...,
           [-9.4972e-01, -7.0479e-01, -4.1272e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-9.4235e-01, -8.9370e-01, -6.3927e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.0162e+00, -7.6143e-01, -3.6583e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.4110e-01,
            -9.5117e-01, -9.5853e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.6709e-01,
            -9.6974e-01, -9.7168e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.6889e-01,
            -9.7168e-01, -9.7168e-01],
           ...,
           [-8.6894e-01, -9.0993e-01, -7.5555e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-8.4989e-01, -9.5815e-01, -9.0815e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-9.4284e-01, -8.5618e-01, -8.4386e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.4110e-01,
            -9.5117e-01, -9.4355e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.6709e-01,
            -9.6974e-01, -9.6773e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.7168e-01,
            -9.7168e-01, -9.7168e-01],
           ...,
           [-7.7733e-01,  1.0708e+00,  1.3172e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [ 1.3920e+00,  1.3436e+00,  1.3336e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [ 1.1347e+00,  3.5440e-01,  1.3674e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          ...,

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.5853e-01,
            -9.6613e-01, -9.5670e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.7168e-01,
            -9.7168e-01, -9.6773e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.5942e-01,
            -9.7168e-01, -9.6827e-01],
           ...,
           [-3.9920e-01,  4.4467e-02,  6.2399e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-4.8575e-01,  1.4242e-02,  5.8232e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-6.1195e-01, -9.9526e-02,  4.0758e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.5853e-01,
            -9.6613e-01, -9.5670e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.7168e-01,
            -9.7168e-01, -9.6773e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.5824e-01,
            -9.6771e-01, -9.6771e-01],
           ...,
           [-1.2567e+00, -1.2060e+00, -1.1737e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-5.9462e-01, -1.2074e+00, -1.1767e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [ 8.9459e-01, -1.1370e-01, -1.1247e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.5853e-01,
            -9.6613e-01, -9.5670e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.7168e-01,
            -9.7168e-01, -9.6773e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.5824e-01,
            -9.6771e-01, -9.6771e-01],
           ...,
           [-1.1176e+00, -1.0992e+00, -1.0624e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.1460e+00, -1.1406e+00, -1.1209e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.1478e+00, -1.1536e+00, -1.1337e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]]],


         [[[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.9339e-01,
            -1.0035e+00, -1.0108e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0194e+00,
            -1.0220e+00, -1.0240e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0212e+00,
            -1.0240e+00, -1.0240e+00],
           ...,
           [-9.0940e-01, -6.2543e-01, -3.2278e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-9.0230e-01, -8.1293e-01, -5.2353e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-9.0217e-01, -6.3455e-01, -2.2940e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.9339e-01,
            -1.0035e+00, -1.0108e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0194e+00,
            -1.0220e+00, -1.0240e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0228e+00,
            -1.0223e+00, -1.0240e+00],
           ...,
           [-8.6103e-01, -8.4064e-01, -6.5615e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-8.5788e-01, -8.8664e-01, -7.8995e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-8.5603e-01, -7.6235e-01, -7.2576e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -9.9339e-01,
            -1.0035e+00, -9.9584e-01],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0194e+00,
            -1.0220e+00, -1.0200e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0240e+00,
            -1.0240e+00, -1.0240e+00],
           ...,
           [-1.2481e+00, -1.1644e+00, -1.1186e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.1741e+00, -1.1370e+00, -1.1513e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.1796e+00, -1.1870e+00, -1.2071e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          ...,

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0078e+00,
            -1.0184e+00, -1.0090e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0079e+00,
            -1.0185e+00, -1.0200e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0188e+00,
            -1.0166e+00, -1.0206e+00],
           ...,
           [-1.4576e-01,  3.3527e-01,  9.4480e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-2.2890e-01,  3.0090e-01,  9.1884e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-3.6979e-01,  1.7171e-01,  7.5263e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0108e+00,
            -1.0184e+00, -1.0090e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0240e+00,
            -1.0240e+00, -1.0200e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0105e+00,
            -1.0200e+00, -1.0200e+00],
           ...,
           [-1.5434e+00, -1.5452e+00, -1.5362e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.4092e+00, -1.5377e+00, -1.5563e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [ 2.9499e-01, -1.2419e+00, -1.5042e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0108e+00,
            -1.0184e+00, -1.0090e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0240e+00,
            -1.0240e+00, -1.0200e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.0105e+00,
            -1.0200e+00, -1.0200e+00],
           ...,
           [-1.3989e+00, -1.3955e+00, -1.3983e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.4255e+00, -1.4294e+00, -1.4262e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.4254e+00, -1.4347e+00, -1.4300e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]]],


         [[[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1154e+00,
            -1.1255e+00, -1.1328e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1414e+00,
            -1.1440e+00, -1.1460e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1448e+00,
            -1.1443e+00, -1.1460e+00],
           ...,
           [-8.7088e-01, -6.5818e-01, -3.3992e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-8.5765e-01, -8.3481e-01, -5.7138e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-9.5412e-01, -6.8616e-01, -2.7672e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1154e+00,
            -1.1255e+00, -1.1328e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1414e+00,
            -1.1440e+00, -1.1460e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1460e+00,
            -1.1460e+00, -1.1460e+00],
           ...,
           [-7.7323e-01, -8.5553e-01, -7.0726e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-7.6455e-01, -8.7803e-01, -8.1427e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-8.4440e-01, -7.5252e-01, -7.1134e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1154e+00,
            -1.1255e+00, -1.1178e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1414e+00,
            -1.1440e+00, -1.1420e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1460e+00,
            -1.1460e+00, -1.1460e+00],
           ...,
           [-1.3155e+00, -1.2686e+00, -1.2300e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.2172e+00, -1.2242e+00, -1.2597e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.2206e+00, -1.2558e+00, -1.3170e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          ...,

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1328e+00,
            -1.1404e+00, -1.1310e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1460e+00,
            -1.1460e+00, -1.1420e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1337e+00,
            -1.1460e+00, -1.1426e+00],
           ...,
           [-1.4619e-01,  4.3320e-01,  1.1313e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-2.3567e-01,  3.7876e-01,  1.0677e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-3.8233e-01,  1.9960e-01,  8.3715e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1328e+00,
            -1.1404e+00, -1.1310e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1460e+00,
            -1.1460e+00, -1.1420e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1325e+00,
            -1.1420e+00, -1.1420e+00],
           ...,
           [-1.6095e+00, -1.6842e+00, -1.7232e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.4779e+00, -1.6525e+00, -1.7040e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [ 2.9735e-01, -1.3257e+00, -1.6408e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]],

          [[ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1328e+00,
            -1.1404e+00, -1.1310e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1460e+00,
            -1.1460e+00, -1.1420e+00],
           [ 2.1351e-01,  2.1351e-01,  2.1351e-01,  ..., -1.1325e+00,
            -1.1420e+00, -1.1420e+00],
           ...,
           [-1.4292e+00, -1.5171e+00, -1.5405e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.4575e+00, -1.5313e+00, -1.5694e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [-1.4909e+00, -1.5202e+00, -1.5616e+00,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01]]]],



        [[[[ 1.0501e+00,  1.1296e+00,  1.2453e+00,  ...,  2.7591e-01,
             3.6212e-01,  5.0980e-01],
           [ 9.2748e-01,  1.0570e+00,  1.2057e+00,  ...,  3.7431e-01,
             3.9004e-01,  4.1783e-01],
           [ 7.8533e-01,  8.8533e-01,  1.0777e+00,  ...,  3.6579e-01,
             3.4176e-01,  3.0773e-01],
           ...,
           [ 1.8343e+00,  1.8230e+00,  1.8447e+00,  ...,  6.4731e-01,
             7.9859e-01,  6.7383e-01],
           [ 1.6593e+00,  1.7084e+00,  1.7894e+00,  ...,  5.6771e-01,
             7.7165e-01,  8.3255e-01],
           [ 1.3987e+00,  1.5577e+00,  1.7232e+00,  ...,  5.4404e-01,
             6.8036e-01,  7.7124e-01]],

          [[ 1.8519e+00,  1.8405e+00,  1.8564e+00,  ...,  9.2406e-01,
             1.0303e+00,  9.2810e-01],
           [ 1.8059e+00,  1.8345e+00,  1.8717e+00,  ...,  8.0047e-01,
             1.0219e+00,  1.2193e+00],
           [ 1.7717e+00,  1.8239e+00,  1.8679e+00,  ...,  8.2619e-01,
             1.0606e+00,  1.2175e+00],
           ...,
           [ 1.8238e+00,  1.8512e+00,  1.8746e+00,  ...,  4.9447e-01,
             4.7108e-01,  4.5744e-01],
           [ 1.6830e+00,  1.7903e+00,  1.8640e+00,  ...,  4.4040e-01,
             4.0486e-01,  3.7940e-01],
           [ 1.4684e+00,  1.6956e+00,  1.8462e+00,  ...,  4.0974e-01,
             3.6352e-01,  3.1808e-01]],

          [[ 1.1721e+00,  1.2516e+00,  1.3673e+00,  ...,  1.7197e+00,
             1.7063e+00,  1.6950e+00],
           [ 9.7284e-01,  1.0224e+00,  1.1799e+00,  ...,  1.7133e+00,
             1.7117e+00,  1.7103e+00],
           [ 8.3411e-01,  8.9771e-01,  1.0531e+00,  ...,  1.6823e+00,
             1.6706e+00,  1.6706e+00],
           ...,
           [ 9.9759e-01,  1.1248e+00,  1.3332e+00,  ...,  4.5058e-01,
             5.1481e-01,  5.8302e-01],
           [ 7.6766e-01,  9.0672e-01,  1.1255e+00,  ...,  3.9983e-01,
             4.8335e-01,  5.9695e-01],
           [ 6.1438e-01,  7.7342e-01,  9.9004e-01,  ...,  3.9340e-01,
             4.8335e-01,  5.9695e-01]],

          ...,

          [[ 9.8039e-01,  1.0145e+00,  1.0693e+00,  ...,  9.2297e-01,
             1.0994e+00,  1.2244e+00],
           [ 9.4974e-01,  9.5384e-01,  9.8618e-01,  ...,  1.0017e+00,
             1.0421e+00,  1.1171e+00],
           [ 8.7589e-01,  8.4866e-01,  8.5168e-01,  ...,  8.8573e-01,
             9.5129e-01,  1.0467e+00],
           ...,
           [ 7.3615e-01,  9.2694e-01,  1.2176e+00,  ...,  3.6632e-01,
             4.9004e-01,  6.4223e-01],
           [ 5.0622e-01,  6.3570e-01,  9.1080e-01,  ...,  3.9395e-01,
             4.9626e-01,  6.1438e-01],
           [ 3.5294e-01,  4.3246e-01,  6.3585e-01,  ...,  4.5129e-01,
             5.4622e-01,  6.1438e-01]],

          [[ 9.9782e-01,  1.1796e+00,  1.2986e+00,  ...,  7.6393e-01,
             8.5621e-01,  1.0153e+00],
           [ 9.3651e-01,  1.0383e+00,  1.1340e+00,  ...,  1.0542e+00,
             1.0214e+00,  1.0306e+00],
           [ 9.2810e-01,  9.4636e-01,  9.7078e-01,  ...,  1.0369e+00,
             1.0259e+00,  1.0327e+00],
           ...,
           [ 1.1159e+00,  1.3341e+00,  1.5736e+00,  ...,  2.7080e-01,
             4.5650e-01,  6.7001e-01],
           [ 7.2440e-01,  9.9156e-01,  1.3081e+00,  ...,  2.8333e-01,
             4.0224e-01,  5.5307e-01],
           [ 5.0980e-01,  7.3701e-01,  1.0193e+00,  ...,  4.2375e-01,
             5.2350e-01,  6.1438e-01]],

          [[ 8.7582e-01,  1.0235e+00,  1.1682e+00,  ...,  8.4547e-01,
             8.3567e-01,  8.5839e-01],
           [ 7.9918e-01,  9.4686e-01,  1.0851e+00,  ...,  1.0220e+00,
             9.6829e-01,  9.8101e-01],
           [ 8.0260e-01,  8.3227e-01,  8.5987e-01,  ...,  1.0273e+00,
             1.0095e+00,  1.0117e+00],
           ...,
           [ 1.3147e+00,  1.4169e+00,  1.5989e+00,  ...,  1.9487e-01,
             4.1736e-01,  6.4223e-01],
           [ 9.7199e-01,  1.1101e+00,  1.3494e+00,  ...,  2.9173e-01,
             4.5018e-01,  6.1648e-01],
           [ 9.1068e-01,  9.7884e-01,  1.1615e+00,  ...,  3.7877e-01,
             4.9549e-01,  6.3181e-01]]],


         [[[ 1.0675e+00,  1.1471e+00,  1.2627e+00,  ...,  3.2820e-01,
             4.1441e-01,  5.6209e-01],
           [ 9.6024e-01,  1.0797e+00,  1.2231e+00,  ...,  4.2660e-01,
             4.4233e-01,  4.7012e-01],
           [ 8.2018e-01,  9.0883e-01,  1.0951e+00,  ...,  4.1808e-01,
             3.9405e-01,  3.6002e-01],
           ...,
           [ 1.9040e+00,  1.8927e+00,  1.9145e+00,  ...,  7.1703e-01,
             8.6830e-01,  7.4354e-01],
           [ 1.7269e+00,  1.7774e+00,  1.8591e+00,  ...,  6.3533e-01,
             8.3999e-01,  9.0227e-01],
           [ 1.4510e+00,  1.6214e+00,  1.7929e+00,  ...,  5.9633e-01,
             7.3872e-01,  8.4096e-01]],

          [[ 1.8693e+00,  1.8693e+00,  1.8912e+00,  ...,  9.7634e-01,
             1.0826e+00,  9.8039e-01],
           [ 1.8386e+00,  1.8586e+00,  1.8912e+00,  ...,  8.5276e-01,
             1.0741e+00,  1.2716e+00],
           [ 1.8066e+00,  1.8474e+00,  1.8854e+00,  ...,  8.7848e-01,
             1.1129e+00,  1.2698e+00],
           ...,
           [ 1.8936e+00,  1.9209e+00,  1.9443e+00,  ...,  5.2933e-01,
             5.0594e-01,  4.9230e-01],
           [ 1.7506e+00,  1.8593e+00,  1.9338e+00,  ...,  4.7526e-01,
             4.3971e-01,  4.1425e-01],
           [ 1.5207e+00,  1.7593e+00,  1.9160e+00,  ...,  4.4460e-01,
             3.9838e-01,  3.5294e-01]],

          [[ 1.2070e+00,  1.2865e+00,  1.4021e+00,  ...,  1.7720e+00,
             1.7586e+00,  1.7473e+00],
           [ 1.0077e+00,  1.0573e+00,  1.2148e+00,  ...,  1.7656e+00,
             1.7640e+00,  1.7626e+00],
           [ 8.6897e-01,  9.3257e-01,  1.0880e+00,  ...,  1.7346e+00,
             1.7229e+00,  1.7229e+00],
           ...,
           [ 1.0499e+00,  1.1771e+00,  1.3855e+00,  ...,  5.0287e-01,
             5.6710e-01,  6.3531e-01],
           [ 8.1995e-01,  9.5901e-01,  1.1778e+00,  ...,  4.5212e-01,
             5.3564e-01,  6.4924e-01],
           [ 6.6667e-01,  8.2571e-01,  1.0423e+00,  ...,  4.4569e-01,
             5.3564e-01,  6.4924e-01]],

          ...,

          [[ 1.0153e+00,  1.0493e+00,  1.1041e+00,  ...,  9.7526e-01,
             1.1517e+00,  1.2767e+00],
           [ 9.6927e-01,  9.7337e-01,  1.0057e+00,  ...,  1.0540e+00,
             1.0944e+00,  1.1694e+00],
           [ 8.9332e-01,  8.6609e-01,  8.6911e-01,  ...,  9.3802e-01,
             1.0036e+00,  1.0990e+00],
           ...,
           [ 7.8844e-01,  9.6787e-01,  1.2525e+00,  ...,  4.1860e-01,
             5.3626e-01,  6.7709e-01],
           [ 5.5851e-01,  6.7663e-01,  9.4566e-01,  ...,  4.4624e-01,
             5.4248e-01,  6.4924e-01],
           [ 4.0523e-01,  4.7339e-01,  6.7071e-01,  ...,  5.0358e-01,
             5.9244e-01,  6.4924e-01]],

          [[ 1.0153e+00,  1.1857e+00,  1.2986e+00,  ...,  8.1622e-01,
             9.0849e-01,  1.0675e+00],
           [ 9.5394e-01,  1.0644e+00,  1.1646e+00,  ...,  1.1065e+00,
             1.0737e+00,  1.0829e+00],
           [ 9.4553e-01,  9.7515e-01,  1.0056e+00,  ...,  1.0892e+00,
             1.0782e+00,  1.0850e+00],
           ...,
           [ 1.1682e+00,  1.3864e+00,  1.6259e+00,  ...,  3.2309e-01,
             5.0879e-01,  7.2230e-01],
           [ 7.7669e-01,  1.0439e+00,  1.3604e+00,  ...,  3.3352e-01,
             4.5243e-01,  6.0325e-01],
           [ 5.6209e-01,  7.8929e-01,  1.0716e+00,  ...,  4.5861e-01,
             5.5836e-01,  6.4924e-01]],

          [[ 8.9325e-01,  1.0409e+00,  1.1857e+00,  ...,  8.9776e-01,
             8.8796e-01,  9.1068e-01],
           [ 8.1660e-01,  9.6429e-01,  1.1026e+00,  ...,  1.0743e+00,
             1.0206e+00,  1.0333e+00],
           [ 8.2003e-01,  8.4970e-01,  8.7730e-01,  ...,  1.0796e+00,
             1.0618e+00,  1.0640e+00],
           ...,
           [ 1.3669e+00,  1.4692e+00,  1.6512e+00,  ...,  2.4715e-01,
             4.6965e-01,  6.9452e-01],
           [ 1.0243e+00,  1.1624e+00,  1.4017e+00,  ...,  3.4192e-01,
             5.0037e-01,  6.6667e-01],
           [ 9.6296e-01,  1.0311e+00,  1.2138e+00,  ...,  4.1363e-01,
             5.3034e-01,  6.6667e-01]]],


         [[[ 1.1024e+00,  1.1819e+00,  1.2975e+00,  ...,  3.8049e-01,
             4.6670e-01,  6.1438e-01],
           [ 9.9510e-01,  1.1146e+00,  1.2580e+00,  ...,  4.9422e-01,
             5.0995e-01,  5.3774e-01],
           [ 8.5504e-01,  9.4369e-01,  1.1300e+00,  ...,  4.8779e-01,
             4.6377e-01,  4.2974e-01],
           ...,
           [ 1.9214e+00,  1.9101e+00,  1.9319e+00,  ...,  7.3446e-01,
             8.8573e-01,  7.6097e-01],
           [ 1.7443e+00,  1.7948e+00,  1.8765e+00,  ...,  6.5276e-01,
             8.5742e-01,  9.1970e-01],
           [ 1.4684e+00,  1.6388e+00,  1.8103e+00,  ...,  6.1376e-01,
             7.5615e-01,  8.5839e-01]],

          [[ 1.8693e+00,  1.8693e+00,  1.8912e+00,  ...,  1.0286e+00,
             1.1349e+00,  1.0327e+00],
           [ 1.8386e+00,  1.8586e+00,  1.8912e+00,  ...,  9.0505e-01,
             1.1264e+00,  1.3239e+00],
           [ 1.8066e+00,  1.8474e+00,  1.8854e+00,  ...,  9.3076e-01,
             1.1652e+00,  1.3221e+00],
           ...,
           [ 1.9110e+00,  1.9383e+00,  1.9617e+00,  ...,  5.4675e-01,
             5.2337e-01,  5.0973e-01],
           [ 1.7680e+00,  1.8767e+00,  1.9512e+00,  ...,  4.9269e-01,
             4.5714e-01,  4.3168e-01],
           [ 1.5381e+00,  1.7767e+00,  1.9334e+00,  ...,  4.6203e-01,
             4.1581e-01,  3.7037e-01]],

          [[ 1.2244e+00,  1.2926e+00,  1.4021e+00,  ...,  1.8243e+00,
             1.8109e+00,  1.7996e+00],
           [ 1.0098e+00,  1.0680e+00,  1.2301e+00,  ...,  1.8179e+00,
             1.8109e+00,  1.7996e+00],
           [ 8.6897e-01,  9.4393e-01,  1.1054e+00,  ...,  1.7869e+00,
             1.7691e+00,  1.7578e+00],
           ...,
           [ 1.0673e+00,  1.1832e+00,  1.3855e+00,  ...,  5.3773e-01,
             6.0196e-01,  6.7017e-01],
           [ 8.3738e-01,  9.6508e-01,  1.1778e+00,  ...,  4.8698e-01,
             5.7049e-01,  6.8410e-01],
           [ 6.8410e-01,  8.3178e-01,  1.0423e+00,  ...,  4.8055e-01,
             5.7049e-01,  6.8410e-01]],

          ...,

          [[ 1.0327e+00,  1.0668e+00,  1.1215e+00,  ...,  1.0275e+00,
             1.1979e+00,  1.3115e+00],
           [ 1.0020e+00,  1.0061e+00,  1.0385e+00,  ...,  1.1062e+00,
             1.1406e+00,  1.2042e+00],
           [ 9.2818e-01,  9.0095e-01,  9.0397e-01,  ...,  9.9031e-01,
             1.0498e+00,  1.1338e+00],
           ...,
           [ 8.2330e-01,  9.9136e-01,  1.2699e+00,  ...,  4.5346e-01,
             5.7111e-01,  7.1195e-01],
           [ 5.9337e-01,  7.0012e-01,  9.6309e-01,  ...,  4.8109e-01,
             5.7734e-01,  6.8410e-01],
           [ 4.4009e-01,  4.9689e-01,  6.8814e-01,  ...,  5.3844e-01,
             6.2729e-01,  6.8410e-01]],

          [[ 1.0501e+00,  1.2205e+00,  1.3335e+00,  ...,  8.8593e-01,
             9.7214e-01,  1.1198e+00],
           [ 9.8880e-01,  1.0893e+00,  1.1842e+00,  ...,  1.1762e+00,
             1.1320e+00,  1.1198e+00],
           [ 9.8039e-01,  9.9865e-01,  1.0231e+00,  ...,  1.1589e+00,
             1.1358e+00,  1.1198e+00],
           ...,
           [ 1.2031e+00,  1.4099e+00,  1.6433e+00,  ...,  3.5794e-01,
             5.4365e-01,  7.5716e-01],
           [ 8.1154e-01,  1.0687e+00,  1.3799e+00,  ...,  3.6837e-01,
             4.8728e-01,  6.3811e-01],
           [ 5.9695e-01,  8.2415e-01,  1.1064e+00,  ...,  4.9346e-01,
             5.9321e-01,  6.8410e-01]],

          [[ 9.2810e-01,  1.0758e+00,  1.2205e+00,  ...,  9.6748e-01,
             9.5160e-01,  9.6296e-01],
           [ 8.5146e-01,  9.9914e-01,  1.1374e+00,  ...,  1.1440e+00,
             1.0789e+00,  1.0703e+00],
           [ 8.5489e-01,  8.8455e-01,  9.1216e-01,  ...,  1.1493e+00,
             1.1193e+00,  1.0989e+00],
           ...,
           [ 1.4018e+00,  1.4927e+00,  1.6686e+00,  ...,  2.8201e-01,
             5.0451e-01,  7.2938e-01],
           [ 1.0591e+00,  1.1859e+00,  1.4192e+00,  ...,  3.7678e-01,
             5.3523e-01,  7.0153e-01],
           [ 9.9782e-01,  1.0546e+00,  1.2312e+00,  ...,  4.4849e-01,
             5.6520e-01,  7.0153e-01]]]],



        [[[[ 8.9325e-01,  8.8901e-01,  8.7388e-01,  ...,  1.5147e+00,
             1.5345e+00,  1.5381e+00],
           [ 8.8881e-01,  8.7888e-01,  8.4995e-01,  ...,  1.5147e+00,
             1.5310e+00,  1.5378e+00],
           [ 8.5950e-01,  8.3469e-01,  8.1623e-01,  ...,  1.5147e+00,
             1.5207e+00,  1.5300e+00],
           ...,
           [ 2.1756e+00,  2.1756e+00,  2.1756e+00,  ...,  2.1656e+00,
             2.1735e+00,  2.1800e+00],
           [ 2.1839e+00,  2.1960e+00,  2.1960e+00,  ...,  2.1656e+00,
             2.1794e+00,  2.1789e+00],
           [ 2.2002e+00,  2.2164e+00,  2.2164e+00,  ...,  2.1815e+00,
             2.2080e+00,  2.2001e+00]],

          [[ 9.2810e-01,  9.2449e-01,  9.1068e-01,  ...,  1.4912e+00,
             1.5171e+00,  1.5207e+00],
           [ 9.2367e-01,  9.2097e-01,  9.0914e-01,  ...,  1.4912e+00,
             1.5136e+00,  1.5204e+00],
           [ 9.0277e-01,  8.9589e-01,  8.8730e-01,  ...,  1.4912e+00,
             1.5033e+00,  1.5126e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1695e+00,
             2.1571e+00,  2.1504e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1810e+00,
             2.1639e+00,  2.1284e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1835e+00,
             2.1821e+00,  2.1936e+00]],

          [[ 9.6038e-01,  9.4553e-01,  9.4553e-01,  ...,  1.5236e+00,
             1.5225e+00,  1.5192e+00],
           [ 9.4553e-01,  9.4553e-01,  9.4400e-01,  ...,  1.4972e+00,
             1.5033e+00,  1.5033e+00],
           [ 9.3763e-01,  9.3075e-01,  9.2728e-01,  ...,  1.4972e+00,
             1.5033e+00,  1.5033e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4410e+00,  ...,  2.1569e+00,
             2.1629e+00,  2.1792e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4384e+00,  ...,  2.1466e+00,
             2.1584e+00,  2.1895e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4439e+00,  ...,  2.1267e+00,
             2.1334e+00,  2.1661e+00]],

          ...,

          [[ 1.0153e+00,  1.0153e+00,  1.0153e+00,  ...,  1.5410e+00,
             1.5549e+00,  1.5704e+00],
           [ 1.0153e+00,  1.0153e+00,  1.0153e+00,  ...,  1.5147e+00,
             1.5413e+00,  1.5549e+00],
           [ 1.0153e+00,  1.0153e+00,  1.0153e+00,  ...,  1.5147e+00,
             1.5207e+00,  1.5531e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1547e+00,
             2.1364e+00,  2.1632e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1810e+00,
             2.1639e+00,  2.1771e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1884e+00,
             2.1855e+00,  2.1829e+00]],

          [[ 1.0772e+00,  1.0123e+00,  1.0123e+00,  ...,  1.5700e+00,
             1.5838e+00,  1.6172e+00],
           [ 1.0453e+00,  9.8039e-01,  9.8039e-01,  ...,  1.5381e+00,
             1.5519e+00,  1.5638e+00],
           [ 1.0453e+00,  9.8039e-01,  9.8039e-01,  ...,  1.5356e+00,
             1.5461e+00,  1.5737e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1752e+00,
             2.1825e+00,  2.1992e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1656e+00,
             2.1794e+00,  2.1992e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1975e+00,
             2.1860e+00,  2.1992e+00]],

          [[ 1.0850e+00,  1.0850e+00,  1.0850e+00,  ...,  1.5640e+00,
             1.5700e+00,  1.5863e+00],
           [ 1.0850e+00,  1.0850e+00,  1.0850e+00,  ...,  1.5321e+00,
             1.5381e+00,  1.5543e+00],
           [ 1.0850e+00,  1.0850e+00,  1.0850e+00,  ...,  1.5273e+00,
             1.5366e+00,  1.5475e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1595e+00,
             2.1932e+00,  2.2098e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1640e+00,
             2.1932e+00,  2.2167e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1656e+00,
             2.1932e+00,  2.2167e+00]]],


         [[[ 1.2070e+00,  1.2027e+00,  1.1876e+00,  ..., -1.4647e-01,
            -1.6632e-01, -1.6993e-01],
           [ 1.2025e+00,  1.1926e+00,  1.1637e+00,  ..., -1.4647e-01,
            -1.6280e-01, -1.6963e-01],
           [ 1.1748e+00,  1.1706e+00,  1.1521e+00,  ..., -1.4647e-01,
            -1.5251e-01, -1.6185e-01],
           ...,
           [ 1.9665e+00,  1.9665e+00,  1.9665e+00,  ...,  1.3765e+00,
             1.3845e+00,  1.3910e+00],
           [ 1.9748e+00,  1.9869e+00,  1.9869e+00,  ...,  1.3987e+00,
             1.4125e+00,  1.4120e+00],
           [ 1.9910e+00,  2.0072e+00,  2.0072e+00,  ...,  1.4146e+00,
             1.4411e+00,  1.4332e+00]],

          [[ 1.2070e+00,  1.2034e+00,  1.1895e+00,  ..., -1.2302e-01,
            -1.4889e-01, -1.5251e-01],
           [ 1.2025e+00,  1.1998e+00,  1.1880e+00,  ..., -1.2302e-01,
            -1.4537e-01, -1.5220e-01],
           [ 1.1964e+00,  1.1895e+00,  1.1810e+00,  ..., -1.2302e-01,
            -1.3508e-01, -1.4442e-01],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  1.3355e+00,
             1.3470e+00,  1.3466e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  1.3619e+00,
             1.3862e+00,  1.3615e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  1.4121e+00,
             1.4143e+00,  1.4267e+00]],

          [[ 1.2392e+00,  1.2244e+00,  1.2244e+00,  ..., -1.0314e-01,
            -1.4348e-01, -1.5103e-01],
           [ 1.2244e+00,  1.2244e+00,  1.2229e+00,  ..., -7.6758e-02,
            -1.2422e-01, -1.3508e-01],
           [ 1.2165e+00,  1.2096e+00,  1.2061e+00,  ..., -7.6758e-02,
            -1.2422e-01, -1.3508e-01],
           ...,
           [ 2.4115e+00,  2.4022e+00,  2.3962e+00,  ...,  1.3404e+00,
             1.3326e+00,  1.3452e+00],
           [ 2.4258e+00,  2.4096e+00,  2.4036e+00,  ...,  1.3449e+00,
             1.3429e+00,  1.3703e+00],
           [ 2.4269e+00,  2.4222e+00,  2.4091e+00,  ...,  1.3728e+00,
             1.3657e+00,  1.3948e+00]],

          ...,

          [[ 1.2418e+00,  1.2418e+00,  1.2418e+00,  ..., -1.0314e-01,
            -1.1703e-01, -1.3249e-01],
           [ 1.2418e+00,  1.2418e+00,  1.2418e+00,  ..., -7.6758e-02,
            -1.0338e-01, -1.1703e-01],
           [ 1.2418e+00,  1.2418e+00,  1.2418e+00,  ..., -7.6758e-02,
            -8.2789e-02, -1.1523e-01],
           ...,
           [ 2.4077e+00,  2.3821e+00,  2.3821e+00,  ...,  1.3355e+00,
             1.3587e+00,  1.3963e+00],
           [ 2.4072e+00,  2.3747e+00,  2.3747e+00,  ...,  1.3619e+00,
             1.3862e+00,  1.4102e+00],
           [ 2.4072e+00,  2.3747e+00,  2.3747e+00,  ...,  1.3692e+00,
             1.4077e+00,  1.4160e+00]],

          [[ 1.2744e+00,  1.2433e+00,  1.2433e+00,  ..., -4.7930e-02,
            -6.1741e-02, -9.5053e-02],
           [ 1.2755e+00,  1.2593e+00,  1.2593e+00,  ..., -4.7930e-02,
            -6.1741e-02, -7.3616e-02],
           [ 1.2755e+00,  1.2593e+00,  1.2593e+00,  ..., -5.2765e-02,
            -6.3276e-02, -9.0925e-02],
           ...,
           [ 2.3915e+00,  2.3821e+00,  2.3761e+00,  ...,  1.3862e+00,
             1.4110e+00,  1.4323e+00],
           [ 2.3910e+00,  2.3747e+00,  2.3687e+00,  ...,  1.3987e+00,
             1.4125e+00,  1.4323e+00],
           [ 2.3910e+00,  2.3747e+00,  2.3687e+00,  ...,  1.3827e+00,
             1.4092e+00,  1.4323e+00]],

          [[ 1.2767e+00,  1.2767e+00,  1.2767e+00,  ..., -4.1900e-02,
            -4.7930e-02, -6.4153e-02],
           [ 1.2767e+00,  1.2767e+00,  1.2767e+00,  ..., -4.1900e-02,
            -4.7930e-02, -6.4153e-02],
           [ 1.2767e+00,  1.2767e+00,  1.2767e+00,  ..., -3.7066e-02,
            -5.2253e-02, -6.4665e-02],
           ...,
           [ 2.4072e+00,  2.3747e+00,  2.3747e+00,  ...,  1.3404e+00,
             1.3740e+00,  1.3906e+00],
           [ 2.4072e+00,  2.3747e+00,  2.3747e+00,  ...,  1.3449e+00,
             1.3740e+00,  1.3975e+00],
           [ 2.4072e+00,  2.3747e+00,  2.3747e+00,  ...,  1.3464e+00,
             1.3740e+00,  1.3975e+00]]],


         [[[ 1.1895e+00,  1.1853e+00,  1.1702e+00,  ..., -2.8591e-01,
            -3.0575e-01, -3.0937e-01],
           [ 1.1851e+00,  1.1752e+00,  1.1462e+00,  ..., -2.8591e-01,
            -3.0224e-01, -3.0906e-01],
           [ 1.1568e+00,  1.1458e+00,  1.1273e+00,  ..., -2.8591e-01,
            -2.9194e-01, -3.0128e-01],
           ...,
           [ 1.8619e+00,  1.8619e+00,  1.8619e+00,  ...,  4.1972e-01,
             4.2768e-01,  4.0666e-01],
           [ 1.8702e+00,  1.8823e+00,  1.8823e+00,  ...,  1.3290e+00,
             1.3428e+00,  1.3423e+00],
           [ 1.8864e+00,  1.9027e+00,  1.9027e+00,  ...,  1.3449e+00,
             1.3714e+00,  1.3635e+00]],

          [[ 1.2070e+00,  1.2034e+00,  1.1895e+00,  ..., -2.2759e-01,
            -2.5346e-01, -2.5708e-01],
           [ 1.2025e+00,  1.1998e+00,  1.1880e+00,  ..., -2.2759e-01,
            -2.4995e-01, -2.5677e-01],
           [ 1.1890e+00,  1.1822e+00,  1.1736e+00,  ..., -2.2759e-01,
            -2.3965e-01, -2.4899e-01],
           ...,
           [ 2.2179e+00,  2.2142e+00,  2.2004e+00,  ..., -8.0395e-01,
            -8.0742e-01, -8.0496e-01],
           [ 2.2179e+00,  2.2142e+00,  2.2004e+00,  ..., -8.3028e-01,
            -8.4080e-01, -8.1248e-01],
           [ 2.2019e+00,  2.2016e+00,  2.2004e+00,  ...,  1.1611e+00,
             1.1601e+00,  1.1777e+00]],

          [[ 1.2392e+00,  1.2244e+00,  1.2244e+00,  ..., -2.2515e-01,
            -2.5168e-01, -2.5560e-01],
           [ 1.2244e+00,  1.2244e+00,  1.2229e+00,  ..., -1.9876e-01,
            -2.3241e-01, -2.3965e-01],
           [ 1.2165e+00,  1.2096e+00,  1.2061e+00,  ..., -1.9876e-01,
            -2.3241e-01, -2.3965e-01],
           ...,
           [ 2.1601e+00,  2.1508e+00,  2.1448e+00,  ..., -7.2164e-01,
            -7.5529e-01, -7.7875e-01],
           [ 2.1818e+00,  2.1656e+00,  2.1595e+00,  ..., -7.2613e-01,
            -7.6559e-01, -8.0384e-01],
           [ 2.1829e+00,  2.1782e+00,  2.1651e+00,  ..., -7.3810e-01,
            -7.7241e-01, -8.1240e-01]],

          ...,

          [[ 1.2244e+00,  1.2244e+00,  1.2244e+00,  ..., -1.8733e-01,
            -2.0122e-01, -2.1668e-01],
           [ 1.2244e+00,  1.2244e+00,  1.2244e+00,  ..., -1.2905e-01,
            -1.5567e-01, -1.6932e-01],
           [ 1.2244e+00,  1.2244e+00,  1.2244e+00,  ..., -1.2905e-01,
            -1.3508e-01, -1.6752e-01],
           ...,
           [ 2.1307e+00,  2.1307e+00,  2.1307e+00,  ..., -7.6909e-01,
            -7.7842e-01, -8.1240e-01],
           [ 2.1307e+00,  2.1307e+00,  2.1307e+00,  ..., -7.9542e-01,
            -8.0594e-01, -8.2630e-01],
           [ 2.1307e+00,  2.1307e+00,  2.1307e+00,  ..., -8.0275e-01,
            -8.2745e-01, -8.3214e-01]],

          [[ 1.2917e+00,  1.2593e+00,  1.2593e+00,  ..., -1.1765e-01,
            -1.3146e-01, -1.6477e-01],
           [ 1.2917e+00,  1.2593e+00,  1.2593e+00,  ..., -1.1765e-01,
            -1.3146e-01, -1.4333e-01],
           [ 1.2917e+00,  1.2593e+00,  1.2593e+00,  ..., -1.0031e-01,
            -1.1082e-01, -1.3847e-01],
           ...,
           [ 2.1307e+00,  2.1307e+00,  2.1247e+00,  ..., -8.4456e-01,
            -8.6348e-01,  1.1770e+00],
           [ 2.1307e+00,  2.1307e+00,  2.1247e+00,  ..., -8.4967e-01,
            -8.6348e-01,  1.1770e+00],
           [ 2.1307e+00,  2.1307e+00,  2.1247e+00,  ..., -8.4967e-01,
            -8.6348e-01,  1.1770e+00]],

          [[ 1.2941e+00,  1.2941e+00,  1.2941e+00,  ..., -1.1162e-01,
            -1.1765e-01, -1.3387e-01],
           [ 1.2941e+00,  1.2941e+00,  1.2941e+00,  ..., -1.1162e-01,
            -1.1765e-01, -1.3387e-01],
           [ 1.2941e+00,  1.2941e+00,  1.2941e+00,  ..., -1.0678e-01,
            -1.0440e-01, -1.1221e-01],
           ...,
           [ 2.1508e+00,  2.1508e+00,  2.1438e+00,  ..., -7.7393e-01,
            -8.0758e-01, -8.2416e-01],
           [ 2.1656e+00,  2.1656e+00,  2.1535e+00,  ..., -7.7842e-01,
            -8.0758e-01, -8.3104e-01],
           [ 2.1656e+00,  2.1656e+00,  2.1535e+00,  ..., -7.7996e-01,
            -8.0758e-01, -8.3104e-01]]]],



        ...,



        [[[[ 1.3052e+00,  1.3038e+00,  8.7918e-01,  ..., -1.0458e+00,
            -1.0283e+00, -9.5548e-01],
           [ 1.1708e+00,  1.4241e+00,  1.1588e+00,  ..., -1.0156e+00,
            -1.0156e+00, -1.0226e+00],
           [ 8.6549e-01,  1.3791e+00,  1.3259e+00,  ..., -9.7190e-01,
            -9.9253e-01, -1.0492e+00],
           ...,
           [ 3.1842e-01,  3.5294e-01,  3.5294e-01,  ..., -1.6853e-01,
            -2.2144e-01, -2.3688e-01],
           [ 2.8774e-01,  3.3489e-01,  3.3932e-01,  ..., -9.0414e-02,
            -1.2993e-01, -1.2714e-01],
           [ 2.7093e-01,  3.1808e-01,  3.2664e-01,  ..., -2.0362e-02,
            -6.2668e-02, -5.8047e-02]],

          [[ 1.1814e+00,  9.3618e-01,  4.7400e-01,  ..., -1.0864e+00,
            -1.0961e+00, -1.0710e+00],
           [ 1.2962e+00,  1.0622e+00,  4.9835e-01,  ..., -1.0249e+00,
            -1.0434e+00, -1.0901e+00],
           [ 1.3580e+00,  1.2026e+00,  7.4229e-01,  ..., -8.6599e-01,
            -9.7743e-01, -1.0684e+00],
           ...,
           [ 3.1466e-01,  3.1053e-01,  2.6642e-01,  ..., -1.5111e-01,
            -2.0401e-01, -2.5088e-01],
           [ 3.0065e-01,  3.0065e-01,  2.7971e-01,  ..., -7.2985e-02,
            -1.1250e-01, -1.1673e-01],
           [ 3.0065e-01,  2.9634e-01,  2.8465e-01,  ..., -2.9326e-03,
            -4.5238e-02, -3.8091e-02]],

          [[ 1.3065e+00,  1.0112e+00,  3.9040e-01,  ..., -1.0212e+00,
            -1.0244e+00, -1.0274e+00],
           [ 1.3919e+00,  1.2313e+00,  6.7506e-01,  ..., -9.3027e-01,
            -9.8070e-01, -1.0279e+00],
           [ 1.3236e+00,  1.3466e+00,  1.0483e+00,  ..., -8.4500e-01,
            -9.3704e-01, -1.0175e+00],
           ...,
           [ 2.4803e-01,  2.4494e-01,  2.7062e-01,  ..., -1.9278e-01,
            -2.3040e-01, -3.2231e-01],
           [ 2.4117e-01,  2.5801e-01,  2.6596e-01,  ..., -1.1213e-01,
            -1.5081e-01, -2.1528e-01],
           [ 2.3607e-01,  2.8322e-01,  2.8185e-01,  ..., -3.8906e-02,
            -8.6105e-02, -1.3726e-01]],

          ...,

          [[ 4.2376e-01,  7.1940e-01,  8.8735e-01,  ..., -4.6320e-01,
            -3.3000e-01, -2.2148e-01],
           [ 9.2488e-01,  9.2096e-01,  8.6226e-01,  ..., -5.9353e-01,
            -4.0397e-01, -2.7481e-01],
           [ 9.9161e-01,  7.6110e-01,  4.7712e-01,  ..., -7.2443e-01,
            -5.0288e-01, -3.2988e-01],
           ...,
           [ 1.5780e-01,  1.2636e-01,  1.0068e-01,  ..., -2.5394e-01,
            -3.0011e-01, -3.7631e-01],
           [ 1.6593e-01,  1.2636e-01,  1.0068e-01,  ..., -1.7755e-01,
            -2.1150e-01, -2.8467e-01],
           [ 2.0421e-01,  1.6162e-01,  1.1531e-01,  ..., -1.0087e-01,
            -1.2376e-01, -1.9316e-01]],

          [[ 8.0159e-01,  8.1813e-01,  8.2011e-01,  ...,  3.8544e-01,
             3.1844e-01,  2.3642e-01],
           [ 9.1135e-01,  9.3978e-01,  9.5207e-01,  ...,  3.6532e-01,
             2.7076e-01,  1.7999e-01],
           [ 1.0364e+00,  1.0730e+00,  1.0784e+00,  ...,  3.5170e-01,
             2.4634e-01,  1.3663e-01],
           ...,
           [ 1.6295e+00,  1.3436e+00,  1.5932e+00,  ...,  1.2607e+00,
             1.1741e+00,  1.4104e+00],
           [ 1.6897e+00,  1.4973e+00,  1.7144e+00,  ...,  9.7752e-01,
             9.3546e-01,  1.4038e+00],
           [ 1.5531e+00,  1.3704e+00,  1.4652e+00,  ...,  7.1095e-01,
             5.8722e-01,  9.3717e-01]],

          [[ 8.6017e-01,  9.2426e-01,  8.9447e-01,  ...,  4.3192e-01,
             3.5009e-01,  2.7264e-01],
           [ 9.7891e-01,  9.8551e-01,  9.7915e-01,  ...,  4.4710e-01,
             3.3986e-01,  2.4908e-01],
           [ 1.1041e+00,  1.0812e+00,  1.0713e+00,  ...,  4.5596e-01,
             3.2361e-01,  2.0977e-01],
           ...,
           [ 1.8369e+00,  1.4127e+00,  1.6381e+00,  ...,  1.3465e+00,
             1.0994e+00,  1.3359e+00],
           [ 1.8190e+00,  1.5567e+00,  1.7081e+00,  ...,  1.0681e+00,
             8.1792e-01,  1.2989e+00],
           [ 1.6426e+00,  1.3517e+00,  1.3867e+00,  ...,  7.9106e-01,
             5.5220e-01,  8.6172e-01]]],


         [[[ 1.2757e+00,  1.1644e+00,  7.8254e-01,  ..., -1.1335e+00,
            -1.1503e+00, -1.0146e+00],
           [ 1.0892e+00,  1.2931e+00,  1.0458e+00,  ..., -1.0992e+00,
            -1.1376e+00, -1.0969e+00],
           [ 7.2777e-01,  1.2571e+00,  1.1954e+00,  ..., -1.0511e+00,
            -1.1145e+00, -1.1398e+00],
           ...,
           [ 1.3899e-01,  1.2636e-01,  1.2636e-01,  ..., -1.4286e-01,
            -2.2144e-01, -3.1546e-01],
           [ 1.5167e-01,  1.3539e-01,  1.2652e-01,  ..., -4.2092e-02,
            -1.0285e-01, -1.7865e-01],
           [ 1.7522e-01,  1.4379e-01,  1.2667e-01,  ...,  4.9044e-02,
            -1.0380e-02, -8.4346e-02]],

          [[ 1.1482e+00,  9.1875e-01,  4.9081e-01,  ..., -1.1907e+00,
            -1.1832e+00, -1.1581e+00],
           [ 1.2235e+00,  1.0280e+00,  5.0661e-01,  ..., -1.1256e+00,
            -1.1642e+00, -1.1805e+00],
           [ 1.2429e+00,  1.1503e+00,  7.4135e-01,  ..., -9.6294e-01,
            -1.1343e+00, -1.1624e+00],
           ...,
           [ 1.4037e-01,  1.3624e-01,  1.3492e-01,  ..., -2.0370e-01,
            -2.7373e-01, -3.3632e-01],
           [ 1.2636e-01,  1.2636e-01,  1.2606e-01,  ..., -9.8345e-02,
            -1.4611e-01, -1.9862e-01],
           [ 1.2636e-01,  1.2205e-01,  1.1036e-01,  ..., -2.9326e-03,
            -4.5238e-02, -1.1668e-01]],

          [[ 1.3082e+00,  1.0287e+00,  4.1639e-01,  ..., -1.1955e+00,
            -1.1987e+00, -1.1545e+00],
           [ 1.3255e+00,  1.1731e+00,  6.4192e-01,  ..., -1.0835e+00,
            -1.1298e+00, -1.1525e+00],
           [ 1.1842e+00,  1.2072e+00,  9.5162e-01,  ..., -9.7557e-01,
            -1.0590e+00, -1.1395e+00],
           ...,
           [ 1.6088e-01,  1.5780e-01,  1.4068e-01,  ..., -2.1114e-01,
            -3.0011e-01, -3.6059e-01],
           [ 1.6587e-01,  1.2574e-01,  1.1305e-01,  ..., -1.0768e-01,
            -1.8442e-01, -2.5002e-01],
           [ 1.7180e-01,  1.0893e-01,  1.0756e-01,  ..., -1.3229e-02,
            -8.6105e-02, -1.6869e-01]],

          ...,

          [[ 3.7318e-01,  6.8454e-01,  8.6961e-01,  ..., -5.0599e-01,
            -3.3000e-01, -1.7433e-01],
           [ 8.4744e-01,  8.4408e-01,  7.9837e-01,  ..., -6.5313e-01,
            -4.2078e-01, -2.5204e-01],
           [ 8.8533e-01,  6.3910e-01,  3.6368e-01,  ..., -8.0208e-01,
            -5.3774e-01, -3.3331e-01],
           ...,
           [ 4.2640e-02,  7.4074e-02,  9.1193e-02,  ..., -2.3682e-01,
            -3.0011e-01, -4.0774e-01],
           [ 6.8831e-02,  9.2126e-02,  1.0481e-01,  ..., -1.5125e-01,
            -1.9345e-01, -2.9806e-01],
           [ 1.2391e-01,  1.4420e-01,  1.3212e-01,  ..., -6.6008e-02,
            -8.8906e-02, -1.8974e-01]],

          [[-1.6387e-01, -2.1019e-01, -2.0822e-01,  ..., -3.5483e-01,
            -3.9616e-01, -4.3103e-01],
           [-8.8548e-02, -1.3056e-01, -1.1827e-01,  ..., -3.4975e-01,
            -4.1863e-01, -4.6982e-01],
           [-4.6794e-04, -4.2484e-02, -3.7068e-02,  ..., -3.3629e-01,
            -4.1597e-01, -4.9424e-01],
           ...,
           [ 8.3122e-01,  5.7669e-01,  8.4339e-01,  ...,  3.4554e-01,
             2.5032e-01,  4.8666e-01],
           [ 7.9667e-01,  5.9500e-01,  8.5582e-01,  ...,  8.4813e-02,
             2.9768e-02,  4.8995e-01],
           [ 5.7192e-01,  3.4212e-01,  5.0538e-01,  ..., -1.6082e-01,
            -3.0167e-01,  3.2560e-02]],

          [[-2.0986e-01, -2.0864e-01, -2.3843e-01,  ..., -3.6827e-01,
            -3.6450e-01, -3.9480e-01],
           [-1.2143e-01, -1.4738e-01, -1.5375e-01,  ..., -3.4484e-01,
            -3.7474e-01, -4.1836e-01],
           [-2.8815e-02, -5.1746e-02, -6.1625e-02,  ..., -3.2711e-01,
            -3.9099e-01, -4.5767e-01],
           ...,
           [ 8.7997e-01,  4.7150e-01,  7.3972e-01,  ...,  4.6680e-01,
             2.4534e-01,  4.8189e-01],
           [ 7.9699e-01,  6.1550e-01,  8.0970e-01,  ...,  1.8401e-01,
            -3.6114e-02,  4.4485e-01],
           [ 5.5999e-01,  4.1049e-01,  4.8829e-01,  ..., -9.7207e-02,
            -3.0183e-01,  7.6845e-03]]],


         [[[-9.2578e-01, -9.2715e-01, -1.2918e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.0634e+00, -8.4042e-01, -1.0582e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.3723e+00, -9.2155e-01, -9.4047e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9593e+00,
            -1.9644e+00, -1.9012e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9701e+00,
            -1.9530e+00, -1.9125e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          [[-1.0967e+00, -1.2948e+00, -1.6285e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-9.8700e-01, -1.1435e+00, -1.5914e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-9.3064e-01, -9.7609e-01, -1.3337e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9416e+00,
            -1.9295e+00, -1.8664e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9615e+00,
            -1.9362e+00, -1.8957e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -1.9868e+00]],

          [[-1.0136e+00, -1.1674e+00, -1.6599e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8525e-01, -9.7260e-01, -1.4210e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-9.0735e-01, -8.8434e-01, -1.0971e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9576e+00,
            -1.9559e+00, -1.9063e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9658e+00,
            -1.9565e+00, -1.9285e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          ...,

          [[-1.6226e+00, -1.2327e+00, -1.1161e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.2592e+00, -1.1992e+00, -1.2927e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.3405e+00, -1.5396e+00, -1.8269e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9753e+00,
            -1.9809e+00, -1.9555e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9743e+00,
            -1.9733e+00, -1.9529e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9702e+00,
            -1.9828e+00, -1.9472e+00]],

          [[-1.8982e+00, -1.8660e+00, -1.8640e+00,  ..., -1.6012e+00,
            -1.6511e+00, -1.5759e+00],
           [-1.8061e+00, -1.7695e+00, -1.7572e+00,  ..., -1.5703e+00,
            -1.6147e+00, -1.5407e+00],
           [-1.7000e+00, -1.6634e+00, -1.6580e+00,  ..., -1.5291e+00,
            -1.5489e+00, -1.4857e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -9.0843e-01,
            -9.5230e-01, -7.1596e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.1196e+00,
            -1.1277e+00, -6.0242e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3191e+00,
            -1.4171e+00, -9.5717e-01]],

          [[-1.7768e+00, -1.7598e+00, -1.7640e+00,  ..., -1.5547e+00,
            -1.6194e+00, -1.5397e+00],
           [-1.6808e+00, -1.6986e+00, -1.6793e+00,  ..., -1.5519e+00,
            -1.6296e+00, -1.5632e+00],
           [-1.5800e+00, -1.6029e+00, -1.5871e+00,  ..., -1.5563e+00,
            -1.6459e+00, -1.6026e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.1378e-01,
            -1.0096e+00, -7.7301e-01],
           [-1.9756e+00, -2.0000e+00, -2.0000e+00,  ..., -1.0833e+00,
            -1.2910e+00, -7.8564e-01],
           [-1.9924e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3521e+00,
            -1.5567e+00, -1.2001e+00]]]],



        [[[[ 1.0153e+00,  1.1371e+00,  1.1897e+00,  ..., -2.1281e-01,
            -2.0479e-01, -2.0479e-01],
           [ 1.0153e+00,  1.0740e+00,  1.1264e+00,  ..., -1.8365e-01,
            -1.8189e-01, -1.8674e-01],
           [ 1.0153e+00,  1.0153e+00,  1.0673e+00,  ..., -1.5915e-01,
            -1.6240e-01, -1.6993e-01],
           ...,
           [-1.1765e-01, -1.4578e-01, -1.6915e-01,  ...,  1.2973e+00,
             1.2568e+00,  1.1631e+00],
           [-1.4286e-01, -1.5742e-01, -1.6993e-01,  ...,  1.4730e+00,
             1.4753e+00,  1.4267e+00],
           [-1.6993e-01, -1.6993e-01, -1.6993e-01,  ...,  1.5772e+00,
             1.6253e+00,  1.6253e+00]],

          [[ 1.4379e-01,  3.3131e-01,  6.6870e-01,  ..., -2.3024e-01,
            -2.0612e-01, -1.8736e-01],
           [ 1.7989e-01,  3.4799e-01,  6.4172e-01,  ..., -1.8303e-01,
            -1.7350e-01, -1.6931e-01],
           [ 2.1351e-01,  3.6352e-01,  6.0873e-01,  ..., -1.4093e-01,
            -1.4497e-01, -1.5251e-01],
           ...,
           [-5.8512e-02, -9.6016e-02, -1.3381e-01,  ...,  1.3147e+00,
             1.2743e+00,  1.1805e+00],
           [-2.3344e-02, -6.5368e-02, -1.0740e-01,  ...,  1.4905e+00,
             1.4927e+00,  1.4441e+00],
           [ 2.1787e-02, -2.5093e-02, -7.3374e-02,  ...,  1.5946e+00,
             1.6427e+00,  1.6427e+00]],

          [[ 7.1895e-01,  7.9396e-01,  9.8662e-01,  ..., -2.0880e-01,
            -2.1285e-01, -2.2222e-01],
           [ 7.1895e-01,  7.9396e-01,  9.8662e-01,  ..., -1.7477e-01,
            -1.8091e-01, -1.9514e-01],
           [ 6.7445e-01,  7.5866e-01,  9.5845e-01,  ..., -1.4679e-01,
            -1.5487e-01, -1.6993e-01],
           ...,
           [-7.9055e-02, -7.9055e-02, -9.1935e-02,  ...,  1.3039e+00,
             1.2667e+00,  1.1805e+00],
           [-4.8553e-02, -6.6635e-02, -9.8195e-02,  ...,  1.4816e+00,
             1.4878e+00,  1.4441e+00],
           [-3.0501e-02, -6.8005e-02, -1.1625e-01,  ...,  1.5906e+00,
             1.6427e+00,  1.6427e+00]],

          ...,

          [[ 3.8780e-01,  4.5343e-01,  5.6591e-01,  ..., -1.8736e-01,
            -1.7931e-01, -1.6993e-01],
           [ 3.4267e-01,  4.3258e-01,  5.6591e-01,  ..., -1.8736e-01,
            -1.7931e-01, -1.6993e-01],
           [ 3.1777e-01,  4.2108e-01,  5.6591e-01,  ..., -1.8658e-01,
            -1.7931e-01, -1.6993e-01],
           ...,
           [-1.3508e-01, -1.0695e-01, -6.6759e-02,  ..., -1.5803e+00,
            -1.9860e+00, -1.9860e+00],
           [-1.3508e-01, -1.1147e-01, -7.3230e-02,  ..., -8.8333e-01,
            -1.3116e+00, -1.2935e+00],
           [-1.3508e-01, -1.1632e-01, -8.0181e-02,  ..., -1.5025e-01,
            -5.9088e-01, -5.5338e-01]],

          [[ 3.8780e-01,  4.6281e-01,  5.7933e-01,  ..., -1.8736e-01,
            -1.7126e-01, -1.5251e-01],
           [ 3.5170e-01,  4.4613e-01,  5.7933e-01,  ..., -1.8736e-01,
            -1.7126e-01, -1.5251e-01],
           [ 3.3178e-01,  4.2956e-01,  5.6327e-01,  ..., -1.8736e-01,
            -1.7126e-01, -1.5251e-01],
           ...,
           [-6.5359e-02, -2.7855e-02,  2.8401e-02,  ..., -1.5771e+00,
            -1.9860e+00, -1.9860e+00],
           [-9.8972e-02, -5.2427e-02,  1.5459e-02,  ..., -8.8126e-01,
            -1.3077e+00, -1.2851e+00],
           [-1.3508e-01, -7.8820e-02,  1.5575e-03,  ..., -1.5025e-01,
            -5.8283e-01, -5.3595e-01]],

          [[ 8.7582e-01,  8.7582e-01,  8.4376e-01,  ..., -2.0479e-01,
            -1.8869e-01, -1.6993e-01],
           [ 8.7582e-01,  8.7582e-01,  8.4376e-01,  ..., -1.9089e-01,
            -1.7063e-01, -1.5188e-01],
           [ 8.4843e-01,  8.6316e-01,  8.4376e-01,  ..., -1.7795e-01,
            -1.5383e-01, -1.3508e-01],
           ...,
           [-1.3072e-02,  4.3184e-02,  7.9481e-02,  ..., -1.5803e+00,
            -1.9860e+00, -1.9860e+00],
           [-2.9878e-02,  8.2960e-03,  4.6451e-02,  ..., -8.8526e-01,
            -1.3077e+00, -1.2851e+00],
           [-4.7930e-02, -2.9178e-02,  1.0972e-02,  ..., -1.5426e-01,
            -5.8283e-01, -5.3595e-01]]],


         [[[-4.7930e-02,  1.5834e-01,  2.4735e-01,  ..., -1.2626e+00,
            -1.2505e+00, -1.2505e+00],
           [-4.7930e-02,  5.1523e-02,  1.4009e-01,  ..., -1.2015e+00,
            -1.2040e+00, -1.2235e+00],
           [-4.7930e-02, -4.7930e-02,  4.0231e-02,  ..., -1.1551e+00,
            -1.1681e+00, -1.1983e+00],
           ...,
           [-1.0414e+00, -1.1258e+00, -1.1951e+00,  ...,  1.4126e+00,
             1.3185e+00,  1.1005e+00],
           [-1.1170e+00, -1.1607e+00, -1.1983e+00,  ...,  1.7246e+00,
             1.7107e+00,  1.5845e+00],
           [-1.1983e+00, -1.1983e+00, -1.1983e+00,  ...,  1.9246e+00,
             2.0087e+00,  2.0087e+00]],

          [[-1.1634e+00, -8.6337e-01, -3.8125e-01,  ..., -1.2974e+00,
            -1.2532e+00, -1.2157e+00],
           [-1.1273e+00, -8.4668e-01, -4.2691e-01,  ..., -1.2002e+00,
            -1.1873e+00, -1.1886e+00],
           [-1.0937e+00, -8.3115e-01, -4.7965e-01,  ..., -1.1171e+00,
            -1.1333e+00, -1.1634e+00],
           ...,
           [-1.0766e+00, -1.1385e+00, -1.1723e+00,  ...,  1.4507e+00,
             1.3598e+00,  1.1494e+00],
           [-9.9284e-01, -1.0811e+00, -1.1192e+00,  ...,  1.7551e+00,
             1.7414e+00,  1.6200e+00],
           [-8.8453e-01, -9.9704e-01, -1.0456e+00,  ...,  1.9460e+00,
             2.0261e+00,  2.0261e+00]],

          [[ 4.4009e-01,  4.4009e-01,  4.6814e-01,  ..., -1.2566e-01,
            -1.3375e-01, -1.5251e-01],
           [ 4.4009e-01,  4.7408e-01,  5.1679e-01,  ..., -8.2607e-02,
            -9.2795e-02, -1.1640e-01],
           [ 4.1270e-01,  4.8017e-01,  5.3813e-01,  ..., -4.8071e-02,
            -6.0186e-02, -8.2789e-02],
           ...,
           [ 8.4014e-03, -2.1735e-02, -6.3721e-02,  ...,  1.7639e+00,
             1.7015e+00,  1.5568e+00],
           [ 3.9216e-02, -1.1850e-02, -7.3815e-02,  ...,  1.9704e+00,
             1.9599e+00,  1.8774e+00],
           [ 3.9216e-02, -2.6416e-02, -9.8818e-02,  ...,  2.0961e+00,
             2.1481e+00,  2.1481e+00]],

          ...,

          [[ 1.4379e-01,  2.3755e-01,  3.5014e-01,  ..., -1.1765e-01,
            -1.0154e-01, -8.2789e-02],
           [ 9.8662e-02,  2.1670e-01,  3.5014e-01,  ..., -1.1765e-01,
            -1.0154e-01, -8.2789e-02],
           [ 7.3763e-02,  2.0519e-01,  3.5014e-01,  ..., -1.1607e-01,
            -1.0154e-01, -8.2789e-02],
           ...,
           [-8.2789e-02, -8.2789e-02, -9.0803e-02,  ..., -1.5955e+00,
            -1.9860e+00, -1.9860e+00],
           [-8.2789e-02, -9.1830e-02, -9.9881e-02,  ..., -8.4208e-01,
            -1.3161e+00, -1.2935e+00],
           [-8.2789e-02, -1.0154e-01, -1.0963e-01,  ..., -4.7464e-02,
            -6.0026e-01, -5.5338e-01]],

          [[ 1.4379e-01,  2.3755e-01,  3.5415e-01,  ..., -1.1765e-01,
            -1.0154e-01, -8.2789e-02],
           [ 9.8662e-02,  2.1670e-01,  3.5415e-01,  ..., -1.1765e-01,
            -1.0154e-01, -8.2789e-02],
           [ 7.3763e-02,  1.9599e-01,  3.3703e-01,  ..., -1.1765e-01,
            -1.0154e-01, -8.2789e-02],
           ...,
           [ 4.3574e-03,  4.3574e-03, -7.6646e-03,  ..., -1.5947e+00,
            -1.9860e+00, -1.9860e+00],
           [-3.7658e-02, -2.8618e-02, -2.1282e-02,  ..., -8.4208e-01,
            -1.3161e+00, -1.2935e+00],
           [-8.2789e-02, -6.4037e-02, -3.5908e-02,  ..., -4.7464e-02,
            -6.0026e-01, -5.5338e-01]],

          [[ 4.4009e-01,  5.0572e-01,  6.5827e-01,  ..., -1.3508e-01,
            -1.1897e-01, -1.0022e-01],
           [ 4.4009e-01,  5.0572e-01,  6.5827e-01,  ..., -1.2117e-01,
            -1.0092e-01, -8.2166e-02],
           [ 4.4009e-01,  5.0572e-01,  6.5827e-01,  ..., -1.0823e-01,
            -8.4111e-02, -6.5359e-02],
           ...,
           [-1.0022e-01, -5.3338e-02, -2.5094e-02,  ..., -1.5947e+00,
            -1.9860e+00, -1.9860e+00],
           [-1.1702e-01, -8.3706e-02, -5.1653e-02,  ..., -8.4594e-01,
            -1.3161e+00, -1.2935e+00],
           [-1.3508e-01, -1.1632e-01, -8.0181e-02,  ..., -5.5478e-02,
            -6.0026e-01, -5.5338e-01]]],


         [[[ 6.1438e-01,  1.5989e+00,  2.0237e+00,  ..., -1.2491e+00,
            -1.2331e+00, -1.2331e+00],
           [ 6.1438e-01,  1.0890e+00,  1.5118e+00,  ..., -1.1610e+00,
            -1.1637e+00, -1.1880e+00],
           [ 6.1438e-01,  6.1438e-01,  1.0351e+00,  ..., -1.0920e+00,
            -1.1083e+00, -1.1460e+00],
           ...,
           [-1.3028e+00, -1.3403e+00, -1.3405e+00,  ...,  1.3040e-01,
             7.2887e-02, -6.0385e-02],
           [-1.3617e+00, -1.3675e+00, -1.3405e+00,  ...,  1.0545e+00,
             1.2627e+00,  1.1898e+00],
           [-1.4248e+00, -1.3967e+00, -1.3405e+00,  ...,  1.9476e+00,
             2.4444e+00,  2.4444e+00]],

          [[-1.0065e+00, -6.5962e-01,  2.8352e-01,  ..., -1.2840e+00,
            -1.2358e+00, -1.1983e+00],
           [-9.4336e-01, -6.3043e-01,  6.9774e-02,  ..., -1.1528e+00,
            -1.1421e+00, -1.1531e+00],
           [-8.8453e-01, -6.0325e-01, -1.4497e-01,  ..., -1.0417e+00,
            -1.0659e+00, -1.1111e+00],
           ...,
           [-1.2543e+00, -1.3219e+00, -1.3863e+00,  ...,  1.5125e-01,
             9.3740e-02, -3.9532e-02],
           [-1.1923e+00, -1.2719e+00, -1.3402e+00,  ...,  1.0655e+00,
             1.2717e+00,  1.1989e+00],
           [-1.1111e+00, -1.1955e+00, -1.2680e+00,  ...,  1.9516e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 7.7124e-01,  7.7124e-01,  8.1132e-01,  ..., -1.1224e-01,
            -1.2438e-01, -1.5251e-01],
           [ 7.7124e-01,  8.1980e-01,  8.8082e-01,  ..., -4.2108e-02,
            -5.6341e-02, -8.9325e-02],
           [ 7.1304e-01,  8.1969e-01,  9.1130e-01,  ...,  1.5790e-02,
            -3.6397e-04, -3.0501e-02],
           ...,
           [-1.2761e-01, -1.5021e-01, -1.8573e-01,  ...,  8.4198e-01,
             8.0311e-01,  7.1304e-01],
           [-6.6605e-02, -1.2638e-01, -1.9582e-01,  ...,  1.4813e+00,
             1.6265e+00,  1.5779e+00],
           [-3.0501e-02, -1.2426e-01, -2.2082e-01,  ...,  2.0998e+00,
             2.4444e+00,  2.4444e+00]],

          ...,

          [[ 1.6122e-01,  2.5498e-01,  3.7959e-01,  ..., -1.0022e-01,
            -7.6058e-02, -4.7930e-02],
           [ 1.1609e-01,  2.3413e-01,  3.7959e-01,  ..., -1.0022e-01,
            -7.6058e-02, -4.7930e-02],
           [ 9.1192e-02,  2.2262e-01,  3.7959e-01,  ..., -9.7856e-02,
            -7.6058e-02, -4.7930e-02],
           ...,
           [-1.8736e-01, -1.6861e-01, -1.6052e-01,  ..., -1.6221e+00,
            -1.9860e+00, -1.9860e+00],
           [-2.1257e-01, -1.8930e-01, -1.6960e-01,  ..., -9.9517e-01,
            -1.3155e+00, -1.3019e+00],
           [-2.3965e-01, -2.1152e-01, -1.7935e-01,  ..., -3.3057e-01,
            -5.9893e-01, -5.7081e-01]],

          [[ 1.6122e-01,  2.5498e-01,  3.7959e-01,  ..., -1.0022e-01,
            -7.6058e-02, -4.7930e-02],
           [ 1.2512e-01,  2.3830e-01,  3.7959e-01,  ..., -1.0022e-01,
            -7.6058e-02, -4.7930e-02],
           [ 1.0520e-01,  2.1989e-01,  3.5775e-01,  ..., -1.0022e-01,
            -7.6058e-02, -4.7930e-02],
           ...,
           [-4.7930e-02,  2.7078e-02,  7.5474e-02,  ..., -1.6221e+00,
            -1.9860e+00, -1.9860e+00],
           [-7.3140e-02, -2.0734e-02,  3.1433e-02,  ..., -9.9324e-01,
            -1.3155e+00, -1.3019e+00],
           [-1.0022e-01, -7.2090e-02, -1.5872e-02,  ..., -3.2656e-01,
            -5.9893e-01, -5.7081e-01]],

          [[ 9.8039e-01,  9.8039e-01,  1.0405e+00,  ..., -2.0479e-01,
            -1.8869e-01, -1.6993e-01],
           [ 9.8039e-01,  9.8039e-01,  1.0405e+00,  ..., -1.9089e-01,
            -1.6646e-01, -1.4286e-01],
           [ 9.4273e-01,  9.6299e-01,  1.0405e+00,  ..., -1.7795e-01,
            -1.4577e-01, -1.1765e-01],
           ...,
           [-1.6993e-01, -1.2305e-01, -9.0803e-02,  ..., -1.6253e+00,
            -1.9860e+00, -1.9860e+00],
           [-1.8674e-01, -1.5342e-01, -1.1929e-01,  ..., -9.9918e-01,
            -1.3155e+00, -1.3019e+00],
           [-2.0479e-01, -1.8604e-01, -1.4990e-01,  ..., -3.3458e-01,
            -5.9893e-01, -5.7081e-01]]]],



        [[[[-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2241e+00,
            -1.2570e+00, -1.2825e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2438e+00,
            -1.2722e+00, -1.2696e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2522e+00,
            -1.2660e+00, -1.2680e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2060e+00,
            -1.2381e+00, -1.2494e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2163e+00,
            -1.2343e+00, -1.2331e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2247e+00,
            -1.2372e+00, -1.2331e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2060e+00,
            -1.2381e+00, -1.2494e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2163e+00,
            -1.2343e+00, -1.2331e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2247e+00,
            -1.2372e+00, -1.2331e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          ...,

          [[-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2654e+00,
            -1.2737e+00, -1.2680e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2699e+00,
            -1.2680e+00, -1.2680e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2748e+00,
            -1.2680e+00, -1.2680e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2843e+00,
            -1.2843e+00, -1.2843e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2680e+00,
            -1.2680e+00, -1.2680e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2680e+00,
            -1.2680e+00, -1.2680e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2843e+00,
            -1.2843e+00, -1.2997e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2680e+00,
            -1.2680e+00, -1.2834e+00],
           [-1.8257e+00, -1.8257e+00, -1.8257e+00,  ..., -1.2680e+00,
            -1.2680e+00, -1.2834e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]]],


         [[[-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -8.7554e-01,
            -9.0838e-01, -9.3393e-01],
           [-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -8.9523e-01,
            -9.2365e-01, -9.2102e-01],
           [-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -9.0363e-01,
            -9.1743e-01, -9.1939e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -8.9232e-01,
            -9.2434e-01, -9.3569e-01],
           [-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -9.0254e-01,
            -9.2057e-01, -9.1939e-01],
           [-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -9.1095e-01,
            -9.2349e-01, -9.1939e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.7017e+00, -1.6863e+00, -1.6863e+00,  ..., -8.9232e-01,
            -9.2434e-01, -9.3569e-01],
           [-1.7017e+00, -1.6863e+00, -1.6863e+00,  ..., -9.0254e-01,
            -9.2057e-01, -9.1939e-01],
           [-1.7017e+00, -1.6863e+00, -1.6863e+00,  ..., -9.1095e-01,
            -9.2349e-01, -9.1939e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          ...,

          [[-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.1677e-01,
            -9.3569e-01, -9.3569e-01],
           [-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.2135e-01,
            -9.1939e-01, -9.1939e-01],
           [-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.2623e-01,
            -9.1939e-01, -9.1939e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.3569e-01,
            -9.3569e-01, -9.2128e-01],
           [-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.1939e-01,
            -9.1939e-01, -9.1939e-01],
           [-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.1939e-01,
            -9.1939e-01, -9.1939e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.1939e-01,
            -9.1939e-01, -9.3480e-01],
           [-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.1939e-01,
            -9.1939e-01, -9.3480e-01],
           [-1.7037e+00, -1.7037e+00, -1.6936e+00,  ..., -9.1939e-01,
            -9.1939e-01, -9.3480e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]]],


         [[[-1.8606e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6599e+00,
            -1.6927e+00, -1.7038e+00],
           [-1.8606e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6795e+00,
            -1.7080e+00, -1.7053e+00],
           [-1.8606e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6879e+00,
            -1.7017e+00, -1.7037e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8606e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6323e+00,
            -1.6632e+00, -1.6688e+00],
           [-1.8606e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6520e+00,
            -1.6700e+00, -1.6688e+00],
           [-1.8606e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6604e+00,
            -1.6730e+00, -1.6688e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8298e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6323e+00,
            -1.6632e+00, -1.6688e+00],
           [-1.8298e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6520e+00,
            -1.6700e+00, -1.6688e+00],
           [-1.8298e+00, -1.8606e+00, -1.8606e+00,  ..., -1.6604e+00,
            -1.6730e+00, -1.6688e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          ...,

          [[-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.6942e+00,
            -1.7037e+00, -1.7037e+00],
           [-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.7057e+00,
            -1.7037e+00, -1.7037e+00],
           [-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.7105e+00,
            -1.7037e+00, -1.7037e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.7037e+00,
            -1.7037e+00, -1.7037e+00],
           [-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.7037e+00,
            -1.7037e+00, -1.7037e+00],
           [-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.7037e+00,
            -1.7037e+00, -1.7037e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.6688e+00,
            -1.6688e+00, -1.6843e+00],
           [-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.6688e+00,
            -1.6688e+00, -1.6843e+00],
           [-1.8257e+00, -1.8257e+00, -1.8459e+00,  ..., -1.6688e+00,
            -1.6688e+00, -1.6843e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]]]]], device='cuda:0')]
[03/06 19:11:20][INFO] train_net.py:  93: tensor([  2,  78, 102,  78,  99, 123,  68,   1,  40,  78,  47, 104,  40,  15,
         32, 102], device='cuda:0')
[03/06 19:11:20][INFO] train_net.py:  94: [tensor([[[[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.9271e-01,  3.4877e-01,  ...,  1.7801e+00,
             1.7329e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6699e+00,
             1.3819e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1677e+00,
             1.0935e+00,  9.2403e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7774e+00,
             1.7309e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6699e+00,
             1.3819e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1677e+00,
             1.0935e+00,  9.2403e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7949e+00,
             1.7367e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6934e+00,
             1.3924e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1856e+00,
             1.0997e+00,  9.2403e-01]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7895e+00,
             1.7398e+00,  1.8024e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6638e+00,
             1.4093e+00,  1.0480e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1347e+00,
             1.1609e+00,  8.6089e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 6.9433e-01,  6.8867e-01,  3.3671e-01,  ...,  1.7895e+00,
             1.7398e+00,  1.8024e+00],
           [ 5.7363e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6638e+00,
             1.4093e+00,  1.0480e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1347e+00,
             1.1609e+00,  8.6089e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.5352e-01,  7.1998e-01,  3.9336e-01,  ...,  1.8116e+00,
             1.7441e+00,  1.8024e+00],
           [ 6.2986e-01,  4.8024e-01,  5.2782e-01,  ...,  1.6228e+00,
             1.3942e+00,  1.0480e+00],
           [ 1.3406e+00,  9.4744e-01,  9.7841e-01,  ...,  1.0734e+00,
             1.1434e+00,  8.6089e-01]]],


         [[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.9271e-01,  3.4877e-01,  ...,  1.7801e+00,
             1.7329e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6699e+00,
             1.3819e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1677e+00,
             1.0935e+00,  9.2403e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7774e+00,
             1.7309e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6699e+00,
             1.3819e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1677e+00,
             1.0935e+00,  9.2403e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7949e+00,
             1.7367e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6934e+00,
             1.3924e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1856e+00,
             1.0997e+00,  9.2403e-01]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7895e+00,
             1.7398e+00,  1.8024e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6638e+00,
             1.4093e+00,  1.0480e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1347e+00,
             1.1609e+00,  8.6089e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 6.9433e-01,  6.8867e-01,  3.3671e-01,  ...,  1.7895e+00,
             1.7398e+00,  1.8024e+00],
           [ 5.7363e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6638e+00,
             1.4093e+00,  1.0480e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1347e+00,
             1.1609e+00,  8.6089e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.5352e-01,  7.1998e-01,  3.9336e-01,  ...,  1.8116e+00,
             1.7441e+00,  1.8024e+00],
           [ 6.2986e-01,  4.8024e-01,  5.2782e-01,  ...,  1.6228e+00,
             1.3942e+00,  1.0480e+00],
           [ 1.3406e+00,  9.4744e-01,  9.7841e-01,  ...,  1.0734e+00,
             1.1434e+00,  8.6089e-01]]],


         [[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.9271e-01,  3.4877e-01,  ...,  1.7801e+00,
             1.7329e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6699e+00,
             1.3819e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1677e+00,
             1.0935e+00,  9.2403e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7774e+00,
             1.7309e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6699e+00,
             1.3819e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1677e+00,
             1.0935e+00,  9.2403e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7949e+00,
             1.7367e+00,  1.9034e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6934e+00,
             1.3924e+00,  1.1206e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1856e+00,
             1.0997e+00,  9.2403e-01]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.0922e-01,  6.8867e-01,  3.4344e-01,  ...,  1.7895e+00,
             1.7398e+00,  1.8024e+00],
           [ 5.8006e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6638e+00,
             1.4093e+00,  1.0480e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1347e+00,
             1.1609e+00,  8.6089e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 6.9433e-01,  6.8867e-01,  3.3671e-01,  ...,  1.7895e+00,
             1.7398e+00,  1.8024e+00],
           [ 5.7363e-01,  4.2941e-01,  4.9094e-01,  ...,  1.6638e+00,
             1.4093e+00,  1.0480e+00],
           [ 1.3007e+00,  8.8939e-01,  9.4355e-01,  ...,  1.1347e+00,
             1.1609e+00,  8.6089e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 7.5352e-01,  7.1998e-01,  3.9336e-01,  ...,  1.8116e+00,
             1.7441e+00,  1.8024e+00],
           [ 6.2986e-01,  4.8024e-01,  5.2782e-01,  ...,  1.6228e+00,
             1.3942e+00,  1.0480e+00],
           [ 1.3406e+00,  9.4744e-01,  9.7841e-01,  ...,  1.0734e+00,
             1.1434e+00,  8.6089e-01]]]],



        [[[[ 4.4009e-01,  3.9515e-01,  4.9455e-01,  ...,  1.3535e+00,
             1.4556e+00,  1.5904e+00],
           [ 4.4009e-01,  1.0772e+00,  1.1333e+00,  ...,  1.5852e+00,
             1.5714e+00,  1.6527e+00],
           [ 1.1416e+00,  1.3069e+00,  1.3878e+00,  ...,  1.5432e+00,
             1.4197e+00,  1.4454e+00],
           ...,
           [-2.0479e-01, -2.0479e-01, -2.1814e-01,  ...,  1.1029e+00,
             1.0907e+00,  1.0688e+00],
           [-2.0479e-01, -2.0479e-01, -2.1814e-01,  ...,  1.1248e+00,
             1.1437e+00,  1.1603e+00],
           [-2.0479e-01, -2.0479e-01, -2.1814e-01,  ...,  1.1321e+00,
             1.1770e+00,  1.2070e+00]],

          [[ 4.4009e-01,  3.9515e-01,  4.9455e-01,  ...,  1.3535e+00,
             1.4556e+00,  1.5904e+00],
           [ 4.4009e-01,  1.0772e+00,  1.1333e+00,  ...,  1.5852e+00,
             1.5714e+00,  1.6527e+00],
           [ 1.1416e+00,  1.3069e+00,  1.3878e+00,  ...,  1.5432e+00,
             1.4197e+00,  1.4454e+00],
           ...,
           [-2.0479e-01, -2.1977e-01, -2.3557e-01,  ...,  1.1029e+00,
             1.0907e+00,  1.0688e+00],
           [-2.0479e-01, -2.1977e-01, -2.3700e-01,  ...,  1.1248e+00,
             1.1437e+00,  1.1603e+00],
           [-2.0479e-01, -2.1977e-01, -2.4891e-01,  ...,  1.1321e+00,
             1.1770e+00,  1.2070e+00]],

          [[ 4.4009e-01,  3.9515e-01,  4.9455e-01,  ...,  1.3535e+00,
             1.4556e+00,  1.5904e+00],
           [ 4.4009e-01,  1.0772e+00,  1.1333e+00,  ...,  1.5852e+00,
             1.5714e+00,  1.6527e+00],
           [ 1.1416e+00,  1.3069e+00,  1.3878e+00,  ...,  1.5432e+00,
             1.4197e+00,  1.4454e+00],
           ...,
           [-2.0479e-01, -2.1977e-01, -2.3557e-01,  ...,  1.1029e+00,
             1.0907e+00,  1.0688e+00],
           [-2.0479e-01, -2.1977e-01, -2.3700e-01,  ...,  1.1248e+00,
             1.1437e+00,  1.1603e+00],
           [-2.0479e-01, -2.1977e-01, -2.4891e-01,  ...,  1.1321e+00,
             1.1770e+00,  1.2070e+00]],

          ...,

          [[ 3.8780e-01,  3.8780e-01,  4.9455e-01,  ...,  9.3165e-01,
             5.2260e-01,  3.8780e-01],
           [ 3.7224e-01,  1.0543e+00,  1.1297e+00,  ...,  1.1668e+00,
             8.2557e-01,  4.5005e-01],
           [ 1.1148e+00,  1.3005e+00,  1.3871e+00,  ...,  1.1160e+00,
             6.4069e-01,  3.7162e-01],
           ...,
           [-2.0479e-01, -2.1977e-01, -2.3557e-01,  ...,  1.1029e+00,
             1.0907e+00,  1.0688e+00],
           [-2.0479e-01, -2.1977e-01, -2.3700e-01,  ...,  1.1248e+00,
             1.1437e+00,  1.1603e+00],
           [-2.0479e-01, -2.1977e-01, -2.4891e-01,  ...,  1.1321e+00,
             1.1770e+00,  1.2070e+00]],

          [[ 3.8780e-01,  3.8780e-01,  4.9455e-01,  ...,  9.8502e-01,
             5.2260e-01,  3.8780e-01],
           [ 3.7224e-01,  1.0543e+00,  1.1297e+00,  ...,  1.2357e+00,
             8.3895e-01,  4.5005e-01],
           [ 1.1148e+00,  1.3005e+00,  1.3871e+00,  ...,  1.1616e+00,
             6.4336e-01,  3.7162e-01],
           ...,
           [-2.0479e-01, -2.1977e-01, -2.3557e-01,  ...,  1.1029e+00,
             1.0907e+00,  1.0688e+00],
           [-2.0479e-01, -2.1977e-01, -2.3700e-01,  ...,  1.1248e+00,
             1.1437e+00,  1.1603e+00],
           [-2.0479e-01, -2.1977e-01, -2.4891e-01,  ...,  1.1321e+00,
             1.1770e+00,  1.2070e+00]],

          [[ 3.8780e-01,  3.8780e-01,  4.9455e-01,  ...,  9.8502e-01,
             5.2260e-01,  3.8780e-01],
           [ 3.7224e-01,  1.0543e+00,  1.1297e+00,  ...,  1.2357e+00,
             8.3895e-01,  4.5005e-01],
           [ 1.1148e+00,  1.3005e+00,  1.3871e+00,  ...,  1.1616e+00,
             6.4336e-01,  3.7162e-01],
           ...,
           [-2.0479e-01, -2.1977e-01, -2.3557e-01,  ...,  1.1029e+00,
             1.0907e+00,  1.0688e+00],
           [-2.0479e-01, -2.1977e-01, -2.3700e-01,  ...,  1.1248e+00,
             1.1437e+00,  1.1603e+00],
           [-2.0479e-01, -2.1977e-01, -2.4891e-01,  ...,  1.1321e+00,
             1.1770e+00,  1.2070e+00]]],


         [[[ 8.9325e-01,  8.4831e-01,  1.0144e+00,  ...,  6.1520e-01,
             8.1318e-01,  9.6296e-01],
           [ 9.7106e-01,  6.7203e-01,  5.8211e-01,  ...,  7.5161e-01,
             9.3111e-01,  1.0408e+00],
           [ 5.2225e-01,  4.5111e-01,  4.8236e-01,  ...,  6.7715e-01,
             7.4885e-01,  8.7831e-01],
           ...,
           [-7.1024e-01, -7.1024e-01, -7.2358e-01,  ...,  1.0877e-01,
             1.6147e-01,  2.0106e-01],
           [-7.1024e-01, -7.1024e-01, -7.2358e-01,  ...,  1.1389e-01,
             1.3281e-01,  1.4939e-01],
           [-7.1024e-01, -7.1024e-01, -7.2358e-01,  ...,  1.2119e-01,
             1.6612e-01,  1.9608e-01]],

          [[ 8.9325e-01,  8.4831e-01,  1.0144e+00,  ...,  6.1520e-01,
             8.1318e-01,  9.6296e-01],
           [ 9.7106e-01,  6.7203e-01,  5.8211e-01,  ...,  7.5161e-01,
             9.3111e-01,  1.0408e+00],
           [ 5.2225e-01,  4.5111e-01,  4.8236e-01,  ...,  6.7715e-01,
             7.4885e-01,  8.7831e-01],
           ...,
           [-7.1024e-01, -6.8028e-01, -6.8873e-01,  ...,  1.0877e-01,
             1.6147e-01,  2.0106e-01],
           [-7.1024e-01, -6.8028e-01, -6.9016e-01,  ...,  1.1389e-01,
             1.3281e-01,  1.4939e-01],
           [-7.1024e-01, -6.8028e-01, -7.0207e-01,  ...,  1.2119e-01,
             1.6612e-01,  1.9608e-01]],

          [[ 8.9325e-01,  8.4831e-01,  1.0144e+00,  ...,  6.1520e-01,
             8.1318e-01,  9.6296e-01],
           [ 9.7106e-01,  6.7203e-01,  5.8211e-01,  ...,  7.5161e-01,
             9.3111e-01,  1.0408e+00],
           [ 5.2225e-01,  4.5111e-01,  4.8236e-01,  ...,  6.7715e-01,
             7.4885e-01,  8.7831e-01],
           ...,
           [-7.1024e-01, -6.8028e-01, -6.8873e-01,  ...,  1.0877e-01,
             1.6147e-01,  2.0106e-01],
           [-7.1024e-01, -6.8028e-01, -6.9016e-01,  ...,  1.1389e-01,
             1.3281e-01,  1.4939e-01],
           [-7.1024e-01, -6.8028e-01, -7.0207e-01,  ...,  1.2119e-01,
             1.6612e-01,  1.9608e-01]],

          ...,

          [[ 9.4553e-01,  8.5566e-01,  1.0144e+00,  ...,  6.1983e-01,
             1.2143e+00,  1.2593e+00],
           [ 9.7666e-01,  6.5944e-01,  5.7846e-01,  ...,  4.7223e-01,
             6.0547e-01,  1.3993e+00],
           [ 5.0794e-01,  4.2181e-01,  4.7492e-01,  ...,  6.0708e-01,
             1.1601e+00,  1.3302e+00],
           ...,
           [-7.1024e-01, -6.8028e-01, -6.8873e-01,  ...,  1.0877e-01,
             1.6147e-01,  2.0106e-01],
           [-7.1024e-01, -6.8028e-01, -6.9016e-01,  ...,  1.1389e-01,
             1.3281e-01,  1.4939e-01],
           [-7.1024e-01, -6.8028e-01, -7.0207e-01,  ...,  1.2119e-01,
             1.6612e-01,  1.9608e-01]],

          [[ 9.4553e-01,  8.5566e-01,  1.0144e+00,  ...,  6.5468e-01,
             1.2443e+00,  1.2593e+00],
           [ 9.7666e-01,  6.5944e-01,  5.7846e-01,  ...,  5.3919e-01,
             6.2205e-01,  1.3993e+00],
           [ 5.0794e-01,  4.2181e-01,  4.7492e-01,  ...,  6.4165e-01,
             1.1628e+00,  1.3302e+00],
           ...,
           [-7.1024e-01, -6.8028e-01, -6.8873e-01,  ...,  1.0877e-01,
             1.6147e-01,  2.0106e-01],
           [-7.1024e-01, -6.8028e-01, -6.9016e-01,  ...,  1.1389e-01,
             1.3281e-01,  1.4939e-01],
           [-7.1024e-01, -6.8028e-01, -7.0207e-01,  ...,  1.2119e-01,
             1.6612e-01,  1.9608e-01]],

          [[ 9.4553e-01,  8.5566e-01,  1.0144e+00,  ...,  6.5468e-01,
             1.2443e+00,  1.2593e+00],
           [ 9.7666e-01,  6.5944e-01,  5.7846e-01,  ...,  5.3919e-01,
             6.2205e-01,  1.3993e+00],
           [ 5.0794e-01,  4.2181e-01,  4.7492e-01,  ...,  6.4165e-01,
             1.1628e+00,  1.3302e+00],
           ...,
           [-7.1024e-01, -6.8028e-01, -6.8873e-01,  ...,  1.0877e-01,
             1.6147e-01,  2.0106e-01],
           [-7.1024e-01, -6.8028e-01, -6.9016e-01,  ...,  1.1389e-01,
             1.3281e-01,  1.4939e-01],
           [-7.1024e-01, -6.8028e-01, -7.0207e-01,  ...,  1.2119e-01,
             1.6612e-01,  1.9608e-01]]],


         [[[ 6.6667e-01,  6.2173e-01,  7.2113e-01,  ...,  3.6411e-01,
             4.7467e-01,  5.7952e-01],
           [ 5.7330e-01,  2.6089e-01,  9.9565e-01,  ...,  1.7275e-01,
             3.2562e-01,  4.7059e-01],
           [ 1.8052e-02,  1.8052e-02,  2.4967e-01,  ...,  2.5425e-01,
             3.6925e-01,  4.5752e-01],
           ...,
           [-7.7996e-01, -7.7996e-01, -7.7996e-01,  ...,  1.6150e+00,
             1.5667e+00,  1.5394e+00],
           [-7.7435e-01, -7.7756e-01, -7.7666e-01,  ...,  1.6413e+00,
             1.6410e+00,  1.6309e+00],
           [-7.2767e-01, -7.5763e-01, -7.4918e-01,  ...,  1.6294e+00,
             1.6476e+00,  1.6776e+00]],

          [[ 6.6667e-01,  6.2173e-01,  7.2113e-01,  ...,  3.6411e-01,
             4.7467e-01,  5.7952e-01],
           [ 5.7330e-01,  2.6089e-01,  9.9565e-01,  ...,  1.7275e-01,
             3.2562e-01,  4.7059e-01],
           [ 1.8052e-02,  1.8052e-02,  2.4967e-01,  ...,  2.5425e-01,
             3.6925e-01,  4.5752e-01],
           ...,
           [-7.7996e-01, -7.7996e-01, -7.7996e-01,  ...,  1.6150e+00,
             1.5667e+00,  1.5394e+00],
           [-7.7435e-01, -7.7756e-01, -7.7809e-01,  ...,  1.6413e+00,
             1.6410e+00,  1.6309e+00],
           [-7.2767e-01, -7.5763e-01, -7.6253e-01,  ...,  1.6294e+00,
             1.6476e+00,  1.6776e+00]],

          [[ 6.6667e-01,  6.2173e-01,  7.2113e-01,  ...,  3.6411e-01,
             4.7467e-01,  5.7952e-01],
           [ 5.7330e-01,  2.6089e-01,  9.9565e-01,  ...,  1.7275e-01,
             3.2562e-01,  4.7059e-01],
           [ 1.8052e-02,  1.8052e-02,  2.4967e-01,  ...,  2.5425e-01,
             3.6925e-01,  4.5752e-01],
           ...,
           [-7.7996e-01, -7.7996e-01, -7.7996e-01,  ...,  1.6150e+00,
             1.5667e+00,  1.5394e+00],
           [-7.7435e-01, -7.7756e-01, -7.7809e-01,  ...,  1.6413e+00,
             1.6410e+00,  1.6309e+00],
           [-7.2767e-01, -7.5763e-01, -7.6253e-01,  ...,  1.6294e+00,
             1.6476e+00,  1.6776e+00]],

          ...,

          [[ 5.0980e-01,  5.2478e-01,  6.6068e-01,  ...,  1.3581e+00,
             9.6841e-01,  7.8867e-01],
           [ 4.4756e-01,  2.3519e-01,  9.8918e-01,  ...,  1.5006e+00,
             1.3380e+00,  9.4429e-01],
           [-1.8052e-02, -1.1632e-02,  2.4296e-01,  ...,  1.4387e+00,
             1.1651e+00,  9.0570e-01],
           ...,
           [-7.7996e-01, -7.7996e-01, -7.7996e-01,  ...,  1.6150e+00,
             1.5667e+00,  1.5394e+00],
           [-7.7435e-01, -7.7756e-01, -7.7809e-01,  ...,  1.6413e+00,
             1.6410e+00,  1.6309e+00],
           [-7.2767e-01, -7.5763e-01, -7.6253e-01,  ...,  1.6294e+00,
             1.6476e+00,  1.6776e+00]],

          [[ 5.0980e-01,  5.2478e-01,  6.6068e-01,  ...,  1.3510e+00,
             8.9352e-01,  7.8867e-01],
           [ 4.4756e-01,  2.3519e-01,  9.8918e-01,  ...,  6.5951e-01,
             1.2631e+00,  9.4429e-01],
           [-1.8052e-02, -1.1632e-02,  2.4296e-01,  ...,  1.1915e+00,
             1.1026e+00,  9.0570e-01],
           ...,
           [-7.7996e-01, -7.7996e-01, -7.7996e-01,  ...,  1.6150e+00,
             1.5667e+00,  1.5394e+00],
           [-7.7435e-01, -7.7756e-01, -7.7809e-01,  ...,  1.6413e+00,
             1.6410e+00,  1.6309e+00],
           [-7.2767e-01, -7.5763e-01, -7.6253e-01,  ...,  1.6294e+00,
             1.6476e+00,  1.6776e+00]],

          [[ 5.0980e-01,  5.2478e-01,  6.6068e-01,  ...,  1.3510e+00,
             8.9352e-01,  7.8867e-01],
           [ 4.4756e-01,  2.3519e-01,  9.8918e-01,  ...,  6.5951e-01,
             1.2631e+00,  9.4429e-01],
           [-1.8052e-02, -1.1632e-02,  2.4296e-01,  ...,  1.1915e+00,
             1.1026e+00,  9.0570e-01],
           ...,
           [-7.7996e-01, -7.7996e-01, -7.7996e-01,  ...,  1.6150e+00,
             1.5667e+00,  1.5394e+00],
           [-7.7435e-01, -7.7756e-01, -7.7809e-01,  ...,  1.6413e+00,
             1.6410e+00,  1.6309e+00],
           [-7.2767e-01, -7.5763e-01, -7.6253e-01,  ...,  1.6294e+00,
             1.6476e+00,  1.6776e+00]]]],



        [[[[-1.0072e-01, -1.2068e-01, -1.4745e-01,  ...,  5.1859e-02,
             1.0286e-01,  2.4432e-01],
           [-1.1804e-01, -1.3649e-01, -1.5247e-01,  ...,  3.2035e-02,
             6.9746e-02,  2.4332e-01],
           [-5.1215e-02, -1.3809e-01, -1.6974e-01,  ...,  6.1370e-02,
             7.2523e-02,  1.9311e-01],
           ...,
           [ 5.9747e-01,  6.1777e-01,  6.5932e-01,  ...,  6.5861e-01,
             4.8033e-01, -9.5275e-02],
           [ 5.9835e-01,  6.4925e-01,  6.5691e-01,  ...,  2.4015e-01,
             4.8171e-01,  4.0837e-01],
           [ 5.8154e-01,  6.5075e-01,  6.6920e-01,  ...,  1.0695e-01,
            -8.5045e-02,  4.2441e-01]],

          [[-1.0072e-01, -1.1916e-01, -1.3760e-01,  ...,  3.1901e-02,
             1.0135e-01,  2.4432e-01],
           [-1.1804e-01, -1.3648e-01, -1.5492e-01,  ...,  1.4589e-02,
             6.8228e-02,  2.4332e-01],
           [-5.0714e-02, -1.2086e-01, -1.5753e-01,  ...,  4.3940e-02,
             5.5271e-02,  1.7587e-01],
           ...,
           [ 5.9778e-01,  6.2897e-01,  6.0973e-01,  ...,  6.6364e-01,
             4.6442e-01, -1.2963e-01],
           [ 5.8154e-01,  6.4622e-01,  6.2217e-01,  ...,  2.4235e-01,
             4.6576e-01,  3.7402e-01],
           [ 5.8154e-01,  6.4924e-01,  6.5177e-01,  ...,  5.9716e-02,
            -1.0551e-01,  3.9006e-01]],

          [[-3.1513e-02, -6.9911e-02, -1.2523e-01,  ...,  5.1859e-02,
             1.0286e-01,  2.6125e-01],
           [-3.2517e-02, -1.0303e-01, -1.4255e-01,  ...,  3.2035e-02,
             5.3940e-02,  2.4293e-01],
           [ 5.2149e-02, -7.3284e-02, -1.5740e-01,  ...,  3.1901e-02,
             2.2142e-02,  1.5813e-01],
           ...,
           [ 5.9777e-01,  6.3333e-01,  6.5430e-01,  ...,  6.2482e-01,
             4.4475e-01, -1.8069e-01],
           [ 5.8127e-01,  6.3354e-01,  6.5426e-01,  ...,  2.7686e-01,
             5.1692e-01,  3.4306e-01],
           [ 6.1590e-01,  6.6515e-01,  6.4924e-01,  ...,  4.2558e-02,
             2.8401e-03,  5.6284e-01]],

          ...,

          [[-8.3294e-02, -1.0325e-01, -1.4266e-01,  ...,  1.0640e-01,
             2.2032e-01,  3.3248e-01],
           [-6.6484e-02, -1.0175e-01, -1.3037e-01,  ...,  7.6802e-02,
             1.6989e-01,  2.9735e-01],
           [ 1.0674e-03, -9.0502e-02, -1.7699e-01,  ...,  6.1869e-02,
             1.6805e-01,  2.9711e-01],
           ...,
           [ 5.2724e-01,  5.3345e-01,  6.2179e-01,  ...,  6.8828e-01,
             1.5125e-01, -5.2906e-01],
           [ 5.2832e-01,  5.4651e-01,  5.8234e-01,  ...,  2.3408e-01,
             4.6829e-01, -2.8488e-02],
           [ 6.1387e-01,  5.9543e-01,  5.8458e-01,  ..., -9.7294e-03,
             4.6024e-02,  5.3051e-01]],

          [[-1.3710e-01, -2.0631e-01, -2.1211e-01,  ...,  1.6348e-01,
             2.7412e-01,  3.5092e-01],
           [-1.3660e-01, -1.8900e-01, -1.9479e-01,  ...,  1.2885e-01,
             2.5530e-01,  3.5042e-01],
           [-1.5433e-01, -2.2185e-01, -2.1441e-01,  ...,  1.0165e-01,
             2.6791e-01,  3.6765e-01],
           ...,
           [ 5.6273e-01,  5.9695e-01,  6.0704e-01,  ...,  6.2548e-01,
             1.4490e-01, -4.2805e-01],
           [ 5.2949e-01,  5.9707e-01,  6.0465e-01,  ...,  3.1034e-01,
             5.7095e-01,  2.5306e-02],
           [ 5.6361e-01,  6.1438e-01,  6.2197e-01,  ..., -4.7116e-02,
             9.0726e-02,  5.8279e-01]],

          [[-6.5865e-02, -8.7340e-02, -1.3760e-01,  ...,  1.1625e-01,
             2.3775e-01,  3.4991e-01],
           [-6.6870e-02, -1.1895e-01, -1.4012e-01,  ...,  1.0145e-01,
             2.3624e-01,  3.4991e-01],
           [ 1.0618e-03, -8.9196e-02, -1.5987e-01,  ...,  1.0885e-01,
             2.2049e-01,  3.4941e-01],
           ...,
           [ 5.4498e-01,  5.6529e-01,  6.0434e-01,  ...,  6.0821e-01,
             1.4340e-01, -4.2805e-01],
           [ 5.2899e-01,  5.7986e-01,  5.8731e-01,  ...,  3.0760e-01,
             5.7093e-01,  2.5306e-02],
           [ 5.6411e-01,  6.3029e-01,  6.1691e-01,  ..., -8.1975e-02,
             8.7691e-02,  5.8279e-01]]],


         [[[ 4.3857e-01,  3.8477e-01,  3.5547e-01,  ...,  8.0131e-01,
             8.5232e-01,  9.7685e-01],
           [ 4.0495e-01,  3.8477e-01,  3.5045e-01,  ...,  7.8400e-01,
             8.1920e-01,  9.7585e-01],
           [ 4.5493e-01,  3.8477e-01,  3.5291e-01,  ...,  8.1335e-01,
             8.2198e-01,  9.2564e-01],
           ...,
           [ 1.1031e+00,  1.1185e+00,  1.1101e+00,  ...,  9.3747e-01,
             7.5920e-01,  2.1725e-01],
           [ 1.1204e+00,  1.1357e+00,  1.1224e+00,  ...,  5.1952e-01,
             7.6061e-01,  7.0393e-01],
           [ 1.1373e+00,  1.1373e+00,  1.1347e+00,  ...,  4.6059e-01,
             1.9989e-01,  6.8636e-01]],

          [[ 4.5600e-01,  4.0068e-01,  3.5547e-01,  ...,  7.8136e-01,
             8.3489e-01,  9.7635e-01],
           [ 4.2188e-01,  3.8487e-01,  3.5296e-01,  ...,  7.6656e-01,
             8.0177e-01,  9.7534e-01],
           [ 4.3838e-01,  3.8627e-01,  3.6517e-01,  ...,  7.9592e-01,
             8.0455e-01,  9.0840e-01],
           ...,
           [ 1.1029e+00,  1.1168e+00,  1.0952e+00,  ...,  9.4248e-01,
             7.4311e-01,  1.8308e-01],
           [ 1.1031e+00,  1.1184e+00,  1.1075e+00,  ...,  5.1920e-01,
             7.2887e-01,  6.8589e-01],
           [ 1.1373e+00,  1.1357e+00,  1.1148e+00,  ...,  4.1336e-01,
             1.7943e-01,  6.5201e-01]],

          [[ 4.9086e-01,  4.3402e-01,  3.6531e-01,  ...,  8.1874e-01,
             8.5384e-01,  9.9378e-01],
           [ 4.8985e-01,  4.0241e-01,  3.6280e-01,  ...,  8.0143e-01,
             8.0491e-01,  9.5865e-01],
           [ 5.5828e-01,  4.5240e-01,  3.9725e-01,  ...,  7.8658e-01,
             7.8735e-01,  9.0771e-01],
           ...,
           [ 1.0855e+00,  1.1009e+00,  1.0902e+00,  ...,  9.4108e-01,
             7.2683e-01,  1.6569e-01],
           [ 1.0857e+00,  1.1023e+00,  1.1048e+00,  ...,  5.9361e-01,
             8.1456e-01,  6.7286e-01],
           [ 1.1188e+00,  1.0850e+00,  1.0850e+00,  ...,  4.3359e-01,
             2.7490e-01,  8.4120e-01]],

          ...,

          [[ 4.5499e-01,  3.6430e-01,  2.9307e-01,  ...,  8.2100e-01,
             9.1900e-01,  1.0127e+00],
           [ 4.5549e-01,  3.8011e-01,  2.9307e-01,  ...,  7.9391e-01,
             8.8438e-01,  9.6129e-01],
           [ 4.8996e-01,  4.1168e-01,  2.9307e-01,  ...,  7.7899e-01,
             8.6691e-01,  9.9391e-01],
           ...,
           [ 1.1029e+00,  1.1213e+00,  1.1570e+00,  ...,  1.0917e+00,
             5.2030e-01, -6.1882e-02],
           [ 1.1031e+00,  1.1183e+00,  1.1174e+00,  ...,  6.3725e-01,
             8.3721e-01,  4.0465e-01],
           [ 1.1367e+00,  1.1168e+00,  1.0900e+00,  ...,  3.5881e-01,
             3.9613e-01,  8.7909e-01]],

          [[ 3.8578e-01,  3.1657e-01,  3.0318e-01,  ...,  8.9803e-01,
             9.9024e-01,  1.0655e+00],
           [ 3.6897e-01,  3.1657e-01,  3.0569e-01,  ...,  8.6592e-01,
             9.8722e-01,  1.0655e+00],
           [ 3.8559e-01,  3.1657e-01,  3.0821e-01,  ...,  8.1900e-01,
             9.8270e-01,  1.0990e+00],
           ...,
           [ 1.0838e+00,  1.0501e+00,  1.0602e+00,  ...,  1.0141e+00,
             5.1245e-01,  2.2392e-02],
           [ 1.0673e+00,  1.0502e+00,  1.0603e+00,  ...,  7.1336e-01,
             9.3986e-01,  4.5833e-01],
           [ 1.1014e+00,  1.0675e+00,  1.0701e+00,  ...,  2.9894e-01,
             4.3931e-01,  9.1445e-01]],

          [[ 4.3806e-01,  3.6278e-01,  2.8575e-01,  ...,  8.1594e-01,
             9.1900e-01,  9.9580e-01],
           [ 4.3756e-01,  3.4849e-01,  2.9553e-01,  ...,  8.0365e-01,
             9.1749e-01,  1.0126e+00],
           [ 5.0700e-01,  4.3006e-01,  3.2756e-01,  ...,  7.5687e-01,
             8.8151e-01,  1.0787e+00],
           ...,
           [ 1.0845e+00,  1.0691e+00,  1.0925e+00,  ...,  1.0116e+00,
             5.1245e-01,  2.2392e-02],
           [ 1.0846e+00,  1.0692e+00,  1.0900e+00,  ...,  7.1063e-01,
             9.3995e-01,  4.5833e-01],
           [ 1.1019e+00,  1.0850e+00,  1.0850e+00,  ...,  2.6661e-01,
             4.5219e-01,  9.1496e-01]]],


         [[[-4.1597e-01, -4.8821e-01, -5.4353e-01,  ..., -7.6984e-01,
            -6.2084e-01, -4.1950e-01],
           [-4.4959e-01, -4.8821e-01, -5.4353e-01,  ..., -7.7487e-01,
            -6.8406e-01, -4.0470e-01],
           [-3.6464e-01, -4.3801e-01, -5.0656e-01,  ..., -7.0373e-01,
            -6.6125e-01, -4.5431e-01],
           ...,
           [-6.7569e-01, -6.8960e-01, -6.4787e-01,  ..., -3.3486e-01,
            -5.1313e-01, -1.0889e+00],
           [-6.5880e-01, -6.7398e-01, -6.5045e-01,  ..., -7.5254e-01,
            -5.1019e-01, -6.0050e-01],
           [-7.0973e-01, -6.9129e-01, -6.6274e-01,  ..., -7.7210e-01,
            -8.4512e-01, -3.5889e-01]],

          [[-4.5082e-01, -5.2155e-01, -5.6096e-01,  ..., -7.8980e-01,
            -6.2235e-01, -4.1950e-01],
           [-4.8444e-01, -5.2306e-01, -5.7576e-01,  ..., -7.9231e-01,
            -6.8558e-01, -4.0470e-01],
           [-3.3056e-01, -4.0543e-01, -4.9219e-01,  ..., -7.2116e-01,
            -6.7850e-01, -4.7154e-01],
           ...,
           [-6.7588e-01, -6.9112e-01, -6.6529e-01,  ..., -3.2983e-01,
            -5.2904e-01, -1.1231e+00],
           [-6.7561e-01, -6.7549e-01, -6.6779e-01,  ..., -7.5037e-01,
            -5.2603e-01, -6.1792e-01],
           [-7.0973e-01, -6.9129e-01, -6.6779e-01,  ..., -8.2186e-01,
            -8.4967e-01, -3.7581e-01]],

          [[-3.4726e-01, -4.5791e-01, -5.5843e-01,  ..., -8.0723e-01,
            -6.3978e-01, -4.0309e-01],
           [-3.6457e-01, -4.7371e-01, -5.6095e-01,  ..., -8.1225e-01,
            -7.1881e-01, -4.0560e-01],
           [-2.6178e-01, -3.9214e-01, -5.2649e-01,  ..., -8.1479e-01,
            -7.9801e-01, -5.5873e-01],
           ...,
           [-6.5745e-01, -6.3901e-01, -6.1804e-01,  ..., -4.3566e-01,
            -6.3414e-01, -1.2107e+00],
           [-6.5767e-01, -6.3890e-01, -6.1805e-01,  ..., -7.6838e-01,
            -5.4288e-01, -7.0155e-01],
           [-6.9079e-01, -6.2309e-01, -6.2056e-01,  ..., -9.2616e-01,
            -7.8073e-01, -2.3789e-01]],

          ...,

          [[-4.1546e-01, -4.6927e-01, -5.1879e-01,  ..., -7.0040e-01,
            -4.7004e-01, -2.6264e-01],
           [-4.1546e-01, -4.6927e-01, -5.1628e-01,  ..., -7.1771e-01,
            -5.5058e-01, -2.9877e-01],
           [-2.4361e-01, -3.2316e-01, -4.6206e-01,  ..., -7.3006e-01,
            -5.9982e-01, -3.6746e-01],
           ...,
           [-7.1024e-01, -7.0119e-01, -5.8602e-01,  ..., -2.0640e-01,
            -6.4070e-01, -1.4147e+00],
           [-7.1013e-01, -7.0572e-01, -6.3809e-01,  ..., -7.0286e-01,
            -3.2864e-01, -8.9732e-01],
           [-6.9332e-01, -7.1024e-01, -6.9254e-01,  ..., -1.0282e+00,
            -8.2166e-01, -3.2352e-01]],

          [[-4.1799e-01, -5.5641e-01, -5.9076e-01,  ..., -5.4128e-01,
            -3.5940e-01, -2.4268e-01],
           [-4.3379e-01, -5.2480e-01, -5.8574e-01,  ..., -5.6361e-01,
            -4.0832e-01, -2.2738e-01],
           [-4.3340e-01, -5.0585e-01, -5.4874e-01,  ..., -6.4494e-01,
            -4.7909e-01, -3.2969e-01],
           ...,
           [-6.7506e-01, -6.5474e-01, -6.1298e-01,  ..., -2.5877e-01,
            -6.4701e-01, -1.3135e+00],
           [-6.9140e-01, -6.3889e-01, -6.1283e-01,  ..., -5.8596e-01,
            -2.2299e-01, -8.2683e-01],
           [-7.0771e-01, -6.2158e-01, -5.9049e-01,  ..., -9.1858e-01,
            -7.8073e-01, -2.8867e-01]],

          [[-3.2882e-01, -4.0410e-01, -4.9125e-01,  ..., -6.0846e-01,
            -3.8138e-01, -1.7550e-01],
           [-3.2932e-01, -4.1991e-01, -4.9376e-01,  ..., -6.1349e-01,
            -4.1299e-01, -1.5969e-01],
           [-3.1159e-01, -3.9004e-01, -5.0851e-01,  ..., -6.3076e-01,
            -5.2484e-01, -3.9737e-01],
           ...,
           [-6.9230e-01, -6.6783e-01, -5.8101e-01,  ..., -2.6146e-01,
            -6.4703e-01, -1.3135e+00],
           [-6.9241e-01, -6.7063e-01, -6.1308e-01,  ..., -6.0349e-01,
            -2.2451e-01, -8.2683e-01],
           [-7.0822e-01, -6.4052e-01, -6.2788e-01,  ..., -9.5091e-01,
            -7.8377e-01, -2.8867e-01]]]],



        ...,



        [[[[ 2.2527e+00,  2.2527e+00,  2.2527e+00,  ...,  2.2972e+00,
             2.2972e+00,  2.2972e+00],
           [ 2.2527e+00,  2.2527e+00,  2.2527e+00,  ...,  2.2702e+00,
             2.2702e+00,  2.2702e+00],
           [ 2.2179e+00,  2.2527e+00,  2.2527e+00,  ...,  2.2702e+00,
             2.2702e+00,  2.2702e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.0951e+00,
             2.2549e+00,  2.3073e+00],
           [ 2.3917e+00,  2.3916e+00,  2.4444e+00,  ...,  2.3895e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.9214e+00,  2.0631e+00,  2.4382e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 2.3050e+00,  2.3050e+00,  2.3050e+00,  ...,  2.2665e+00,
             2.2928e+00,  2.3098e+00],
           [ 2.2907e+00,  2.3050e+00,  2.3050e+00,  ...,  2.2647e+00,
             2.2702e+00,  2.3121e+00],
           [ 2.2821e+00,  2.3010e+00,  2.3010e+00,  ...,  2.2702e+00,
             2.2959e+00,  2.2702e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.2620e+00,
             2.3882e+00,  2.4142e+00],
           [ 2.2168e+00,  2.3579e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6052e+00,  2.0921e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 2.2179e+00,  2.2527e+00,  2.2527e+00,  ...,  2.2702e+00,
             2.2928e+00,  2.2702e+00],
           [ 2.2179e+00,  2.2527e+00,  2.2527e+00,  ...,  2.2695e+00,
             2.2682e+00,  2.2585e+00],
           [ 2.2179e+00,  2.2179e+00,  2.2469e+00,  ...,  2.2691e+00,
             2.2493e+00,  2.2527e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.2976e+00,
             2.3979e+00,  2.4183e+00],
           [ 2.1577e+00,  2.3483e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6116e+00,  2.0856e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          ...,

          [[ 2.2179e+00,  2.2236e+00,  2.2527e+00,  ...,  2.2779e+00,
             2.2779e+00,  2.2566e+00],
           [ 2.2179e+00,  2.2236e+00,  2.2527e+00,  ...,  2.2817e+00,
             2.2817e+00,  2.2585e+00],
           [ 2.2154e+00,  2.2236e+00,  2.2527e+00,  ...,  2.2702e+00,
             2.2702e+00,  2.2527e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.3181e+00,
             2.4070e+00,  2.4206e+00],
           [ 1.9455e+00,  2.3483e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6127e+00,  2.1534e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 2.1830e+00,  2.2179e+00,  2.2179e+00,  ...,  2.2779e+00,
             2.2779e+00,  2.2566e+00],
           [ 2.1830e+00,  2.2179e+00,  2.2179e+00,  ...,  2.2817e+00,
             2.2817e+00,  2.2585e+00],
           [ 2.1830e+00,  2.2145e+00,  2.2179e+00,  ...,  2.2702e+00,
             2.2702e+00,  2.2527e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.2966e+00,
             2.3984e+00,  2.4133e+00],
           [ 1.9024e+00,  2.3143e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6374e+00,  2.1389e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 2.2179e+00,  2.2179e+00,  2.2179e+00,  ...,  2.2256e+00,
             2.2256e+00,  2.1908e+00],
           [ 2.2179e+00,  2.2179e+00,  2.2179e+00,  ...,  2.2294e+00,
             2.2294e+00,  2.1945e+00],
           [ 2.2179e+00,  2.2145e+00,  2.2179e+00,  ...,  2.2527e+00,
             2.2527e+00,  2.2179e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.3531e+00,
             2.4165e+00,  2.4222e+00],
           [ 1.8826e+00,  2.2996e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6827e+00,  2.1986e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]]],


         [[[ 1.8519e+00,  1.8519e+00,  1.8519e+00,  ...,  1.9525e+00,
             1.9525e+00,  1.9525e+00],
           [ 1.8519e+00,  1.8519e+00,  1.8519e+00,  ...,  1.9390e+00,
             1.9390e+00,  1.9390e+00],
           [ 1.7821e+00,  1.8170e+00,  1.8170e+00,  ...,  1.8693e+00,
             1.8693e+00,  1.8693e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  1.6942e+00,
             1.8540e+00,  1.9064e+00],
           [ 2.3917e+00,  2.4156e+00,  2.4444e+00,  ...,  2.1706e+00,
             2.2889e+00,  2.3511e+00],
           [ 1.8402e+00,  2.0274e+00,  2.4358e+00,  ...,  2.4371e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 1.8170e+00,  1.8170e+00,  1.8170e+00,  ...,  1.9317e+00,
             1.9503e+00,  1.9089e+00],
           [ 1.8027e+00,  1.8170e+00,  1.8170e+00,  ...,  1.9282e+00,
             1.9390e+00,  1.9112e+00],
           [ 1.7707e+00,  1.7801e+00,  1.7801e+00,  ...,  1.8693e+00,
             1.8950e+00,  1.8693e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  1.9830e+00,
             2.1073e+00,  2.2004e+00],
           [ 2.2771e+00,  2.4204e+00,  2.4444e+00,  ...,  2.3895e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6363e+00,  2.1909e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 1.8170e+00,  1.8519e+00,  1.8519e+00,  ...,  1.8693e+00,
             1.8919e+00,  1.8693e+00],
           [ 1.8170e+00,  1.8519e+00,  1.8519e+00,  ...,  1.8686e+00,
             1.8674e+00,  1.8576e+00],
           [ 1.8170e+00,  1.8170e+00,  1.8460e+00,  ...,  1.8683e+00,
             1.8485e+00,  1.8519e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.0023e+00,
             2.1319e+00,  2.2144e+00],
           [ 2.2621e+00,  2.4156e+00,  2.4444e+00,  ...,  2.4115e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6427e+00,  2.1876e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          ...,

          [[ 1.8170e+00,  1.8228e+00,  1.8519e+00,  ...,  1.9429e+00,
             1.9429e+00,  1.9119e+00],
           [ 1.8170e+00,  1.8228e+00,  1.8519e+00,  ...,  1.9448e+00,
             1.9448e+00,  1.9157e+00],
           [ 1.8145e+00,  1.8228e+00,  1.8519e+00,  ...,  1.8693e+00,
             1.8693e+00,  1.8519e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1786e+00,
             2.2933e+00,  2.3570e+00],
           [ 2.0929e+00,  2.4300e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6462e+00,  2.3104e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 1.8519e+00,  1.8693e+00,  1.8693e+00,  ...,  1.9429e+00,
             1.9429e+00,  1.9119e+00],
           [ 1.8519e+00,  1.8693e+00,  1.8693e+00,  ...,  1.9448e+00,
             1.9448e+00,  1.9157e+00],
           [ 1.8519e+00,  1.8676e+00,  1.8693e+00,  ...,  1.8693e+00,
             1.8693e+00,  1.8519e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1406e+00,
             2.2586e+00,  2.2739e+00],
           [ 2.1290e+00,  2.4348e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.6880e+00,  2.3475e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 1.8170e+00,  1.8693e+00,  1.8693e+00,  ...,  1.9642e+00,
             1.9642e+00,  1.9429e+00],
           [ 1.8170e+00,  1.8693e+00,  1.8693e+00,  ...,  1.9679e+00,
             1.9679e+00,  1.9448e+00],
           [ 1.8170e+00,  1.8676e+00,  1.8693e+00,  ...,  1.9041e+00,
             1.9041e+00,  1.8693e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.2117e+00,
             2.3413e+00,  2.3578e+00],
           [ 2.0301e+00,  2.4300e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.7350e+00,  2.3443e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]]],


         [[[ 1.1373e+00,  1.1373e+00,  1.1373e+00,  ...,  1.2166e+00,
             1.2166e+00,  1.2166e+00],
           [ 1.1373e+00,  1.1373e+00,  1.1373e+00,  ...,  1.1895e+00,
             1.1895e+00,  1.1895e+00],
           [ 1.1547e+00,  1.1895e+00,  1.1895e+00,  ...,  1.1547e+00,
             1.1547e+00,  1.1547e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  1.7465e+00,
             1.9080e+00,  1.9689e+00],
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.3215e+00,
             2.4192e+00,  2.4444e+00],
           [ 2.0654e+00,  2.2184e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 1.1373e+00,  1.1373e+00,  1.1373e+00,  ...,  1.1822e+00,
             1.2121e+00,  1.1943e+00],
           [ 1.1230e+00,  1.1373e+00,  1.1373e+00,  ...,  1.1787e+00,
             1.1895e+00,  1.1966e+00],
           [ 1.1667e+00,  1.1855e+00,  1.1855e+00,  ...,  1.1547e+00,
             1.1804e+00,  1.1547e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.0005e+00,
             2.1268e+00,  2.2238e+00],
           [ 2.3347e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.8595e+00,  2.3766e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 9.9782e-01,  1.0675e+00,  1.0675e+00,  ...,  1.1430e+00,
             1.1656e+00,  1.1430e+00],
           [ 9.9782e-01,  1.0675e+00,  1.0675e+00,  ...,  1.1010e+00,
             1.0985e+00,  1.0791e+00],
           [ 1.0501e+00,  1.0501e+00,  1.1284e+00,  ...,  1.1004e+00,
             1.0658e+00,  1.0675e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.0371e+00,
             2.1664e+00,  2.2338e+00],
           [ 2.3369e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.8693e+00,  2.3766e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          ...,

          [[ 1.0501e+00,  1.0530e+00,  1.1332e+00,  ...,  1.1411e+00,
             1.1411e+00,  1.1102e+00],
           [ 1.0501e+00,  1.0530e+00,  1.1332e+00,  ...,  1.1430e+00,
             1.1430e+00,  1.1139e+00],
           [ 1.0476e+00,  1.1082e+00,  1.1373e+00,  ...,  1.1024e+00,
             1.1024e+00,  1.0675e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1447e+00,
             2.2627e+00,  2.3234e+00],
           [ 2.2878e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.8728e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 1.0501e+00,  1.0675e+00,  1.1332e+00,  ...,  1.1973e+00,
             1.1973e+00,  1.1625e+00],
           [ 1.0501e+00,  1.0675e+00,  1.1332e+00,  ...,  1.2011e+00,
             1.2011e+00,  1.1662e+00],
           [ 1.0501e+00,  1.1339e+00,  1.1373e+00,  ...,  1.1547e+00,
             1.1547e+00,  1.1373e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1223e+00,
             2.2241e+00,  2.2403e+00],
           [ 2.2958e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.9083e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]],

          [[ 1.1024e+00,  1.0675e+00,  1.1332e+00,  ...,  1.1973e+00,
             1.1973e+00,  1.1625e+00],
           [ 1.1024e+00,  1.0675e+00,  1.1332e+00,  ...,  1.2011e+00,
             1.2011e+00,  1.1662e+00],
           [ 1.1024e+00,  1.1339e+00,  1.1373e+00,  ...,  1.1547e+00,
             1.1547e+00,  1.1373e+00],
           ...,
           [ 2.4444e+00,  2.4444e+00,  2.4444e+00,  ...,  2.1788e+00,
             2.3065e+00,  2.3249e+00],
           [ 2.2548e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00],
           [ 1.8939e+00,  2.4444e+00,  2.4444e+00,  ...,  2.4444e+00,
             2.4444e+00,  2.4444e+00]]]],



        [[[[-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4946e+00,
            -1.4946e+00, -1.4946e+00],
           [-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4946e+00,
            -1.4946e+00, -1.4946e+00],
           [-1.6556e+00, -1.6556e+00, -1.6589e+00,  ..., -1.4780e+00,
            -1.4803e+00, -1.4846e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.6354e+00,
            -1.7720e+00, -1.8418e+00]],

          [[-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -1.4732e+00,
            -1.4819e+00, -1.4946e+00],
           [-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -1.3725e+00,
            -1.4493e+00, -1.4946e+00],
           [-1.6697e+00, -1.6697e+00, -1.6730e+00,  ..., -1.3792e+00,
            -1.4425e+00, -1.4813e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -6.5659e-01,
            -6.5947e-01, -6.5947e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -4.3488e-01,
            -4.3775e-01, -4.3775e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.7632e-01,
            -1.7920e-01, -1.9234e-01]],

          [[-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -1.4732e+00,
            -1.4810e+00, -1.4919e+00],
           [-1.6863e+00, -1.6863e+00, -1.6863e+00,  ..., -1.3740e+00,
            -1.4248e+00, -1.4248e+00],
           [-1.6697e+00, -1.6697e+00, -1.6697e+00,  ..., -1.3803e+00,
            -1.4215e+00, -1.4215e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.0580e+00,
            -6.2248e-01, -4.1037e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.0543e+00,
            -9.3197e-01, -7.1223e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.2345e+00,
            -1.1887e+00, -1.0818e+00]],

          ...,

          [[-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4585e+00,
            -1.4760e+00, -1.5087e+00],
           [-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4216e+00,
            -1.4210e+00, -1.4248e+00],
           [-1.6556e+00, -1.6556e+00, -1.6556e+00,  ..., -1.3737e+00,
            -1.3897e+00, -1.4215e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -7.0713e-01,
            -4.9119e-01, -3.0140e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.0375e+00,
            -8.0685e-01, -5.7863e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -9.7692e-01,
            -9.6090e-01, -8.2332e-01]],

          [[-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4765e+00,
            -1.5107e+00, -1.5109e+00],
           [-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4597e+00,
            -1.4766e+00, -1.4823e+00],
           [-1.6556e+00, -1.6556e+00, -1.6556e+00,  ..., -1.4434e+00,
            -1.4516e+00, -1.4561e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3847e+00,
            -1.3526e+00, -1.2932e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3148e+00,
            -1.2655e+00, -1.1844e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.2415e+00,
            -1.1828e+00, -1.1206e+00]],

          [[-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4242e+00,
            -1.4882e+00, -1.5105e+00],
           [-1.6688e+00, -1.6688e+00, -1.6688e+00,  ..., -1.4034e+00,
            -1.4558e+00, -1.4718e+00],
           [-1.6556e+00, -1.6556e+00, -1.6556e+00,  ..., -1.3728e+00,
            -1.4191e+00, -1.4531e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.5406e+00,
            -1.5413e+00, -1.5477e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.5644e+00,
            -1.5643e+00, -1.5643e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.5140e+00,
            -1.5022e+00, -1.4804e+00]]],


         [[[-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.6166e+00,
            -1.6166e+00, -1.6166e+00],
           [-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.6166e+00,
            -1.6166e+00, -1.6166e+00],
           [-1.8398e+00, -1.8398e+00, -1.8398e+00,  ..., -1.6133e+00,
            -1.6156e+00, -1.6199e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3993e+00,
            -1.5716e+00, -1.7004e+00]],

          [[-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5797e+00,
            -1.5939e+00, -1.6166e+00],
           [-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5294e+00,
            -1.5939e+00, -1.6166e+00],
           [-1.8398e+00, -1.8398e+00, -1.8398e+00,  ..., -1.5426e+00,
            -1.5961e+00, -1.6166e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -5.1716e-01,
            -5.2615e-01, -5.3747e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.9544e-01,
            -3.0443e-01, -3.1575e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -3.6886e-02,
            -4.5873e-02, -7.0331e-02]],

          [[-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5791e+00,
            -1.5928e+00, -1.6146e+00],
           [-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5134e+00,
            -1.5643e+00, -1.5643e+00],
           [-1.8398e+00, -1.8398e+00, -1.8398e+00,  ..., -1.5297e+00,
            -1.5709e+00, -1.5709e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.1404e-01,
            -4.1440e-01, -6.2294e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.1028e-01,
            -6.8796e-01, -5.1797e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -9.9052e-01,
            -9.4468e-01, -8.3779e-01]],

          ...,

          [[-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5951e+00,
            -1.6037e+00, -1.6146e+00],
           [-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5598e+00,
            -1.5604e+00, -1.5643e+00],
           [-1.8398e+00, -1.8398e+00, -1.8398e+00,  ..., -1.5165e+00,
            -1.5348e+00, -1.5709e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -5.1540e-01,
            -2.9947e-01, -1.8741e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.5995e-01,
            -6.2516e-01, -3.8690e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.0119e-01,
            -7.8050e-01, -6.3160e-01]],

          [[-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5823e+00,
            -1.6164e+00, -1.6167e+00],
           [-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5962e+00,
            -1.6106e+00, -1.6168e+00],
           [-1.8398e+00, -1.8398e+00, -1.8398e+00,  ..., -1.5805e+00,
            -1.5910e+00, -1.5845e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -9.6643e-01,
            -9.4039e-01, -8.9233e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.9773e-01,
            -8.5329e-01, -7.8353e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.2322e-01,
            -7.7058e-01, -7.1977e-01]],

          [[-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5300e+00,
            -1.5939e+00, -1.6163e+00],
           [-1.8431e+00, -1.8431e+00, -1.8431e+00,  ..., -1.5400e+00,
            -1.5892e+00, -1.6059e+00],
           [-1.8398e+00, -1.8398e+00, -1.8398e+00,  ..., -1.5099e+00,
            -1.5536e+00, -1.5784e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3011e+00,
            -1.2933e+00, -1.2863e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3206e+00,
            -1.3142e+00, -1.3028e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.2700e+00,
            -1.2521e+00, -1.2190e+00]]],


         [[[-1.3377e+00, -1.3377e+00, -1.3377e+00,  ..., -1.2680e+00,
            -1.2680e+00, -1.2680e+00],
           [-1.3377e+00, -1.3377e+00, -1.3377e+00,  ..., -1.2680e+00,
            -1.2680e+00, -1.2680e+00],
           [-1.3344e+00, -1.3344e+00, -1.3377e+00,  ..., -1.2746e+00,
            -1.2734e+00, -1.2713e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.9807e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.2811e+00,
            -1.4828e+00, -1.6334e+00]],

          [[-1.3551e+00, -1.3551e+00, -1.3551e+00,  ..., -1.2673e+00,
            -1.2688e+00, -1.2680e+00],
           [-1.3551e+00, -1.3551e+00, -1.3551e+00,  ..., -1.2505e+00,
            -1.2906e+00, -1.2680e+00],
           [-1.3485e+00, -1.3485e+00, -1.3518e+00,  ..., -1.2605e+00,
            -1.2929e+00, -1.2746e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -5.3459e-01,
            -5.5579e-01, -5.8975e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -3.1287e-01,
            -3.3407e-01, -3.6804e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -5.4315e-02,
            -7.5518e-02, -1.2262e-01]],

          [[-1.3551e+00, -1.3551e+00, -1.3551e+00,  ..., -1.2660e+00,
            -1.2680e+00, -1.2680e+00],
           [-1.3551e+00, -1.3551e+00, -1.3551e+00,  ..., -1.2171e+00,
            -1.2680e+00, -1.2680e+00],
           [-1.3485e+00, -1.3485e+00, -1.3485e+00,  ..., -1.2334e+00,
            -1.2734e+00, -1.2713e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.4890e-01,
            -4.5536e-01, -3.3223e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.5931e-01,
            -7.2893e-01, -5.2206e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.0274e+00,
            -9.8565e-01, -8.9008e-01]],

          ...,

          [[-1.3203e+00, -1.3203e+00, -1.3203e+00,  ..., -1.2694e+00,
            -1.2797e+00, -1.3015e+00],
           [-1.3203e+00, -1.3203e+00, -1.3203e+00,  ..., -1.2635e+00,
            -1.2641e+00, -1.2680e+00],
           [-1.3136e+00, -1.3136e+00, -1.3136e+00,  ..., -1.2235e+00,
            -1.2395e+00, -1.2713e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -5.6929e-01,
            -3.6424e-01, -1.6527e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -9.1080e-01,
            -6.7874e-01, -4.5129e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.5203e-01,
            -8.3867e-01, -6.8804e-01]],

          [[-1.3203e+00, -1.3203e+00, -1.3203e+00,  ..., -1.2680e+00,
            -1.3024e+00, -1.3036e+00],
           [-1.3203e+00, -1.3203e+00, -1.3203e+00,  ..., -1.2694e+00,
            -1.2917e+00, -1.3205e+00],
           [-1.3136e+00, -1.3136e+00, -1.3136e+00,  ..., -1.2595e+00,
            -1.2764e+00, -1.2882e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.4298e-01,
            -8.3671e-01, -8.2261e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -7.7302e-01,
            -7.4961e-01, -7.2592e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -6.9972e-01,
            -6.6690e-01, -6.5057e-01]],

          [[-1.3203e+00, -1.3203e+00, -1.3203e+00,  ..., -1.2157e+00,
            -1.2800e+00, -1.3032e+00],
           [-1.3203e+00, -1.3203e+00, -1.3203e+00,  ..., -1.2132e+00,
            -1.2702e+00, -1.3096e+00],
           [-1.3136e+00, -1.3136e+00, -1.3136e+00,  ..., -1.1889e+00,
            -1.2390e+00, -1.2821e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.2966e+00,
            -1.2790e+00, -1.2514e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3204e+00,
            -1.3019e+00, -1.2680e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.2700e+00,
            -1.2399e+00, -1.1841e+00]]]],



        [[[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.6961e-01,
             9.9129e-02, -1.0022e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.1475e-01,
            -3.4405e-03, -2.1895e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.2998e-01,
            -9.1080e-02, -3.3878e-01],
           ...,
           [-6.2076e-01, -6.3811e-01, -6.7110e-01,  ..., -9.0040e-01,
            -9.0040e-01, -9.0040e-01],
           [-5.6660e-01, -6.0116e-01, -6.3586e-01,  ..., -8.6667e-01,
            -8.6708e-01, -8.6664e-01],
           [-4.1394e-01, -4.9700e-01, -5.6536e-01,  ..., -8.5103e-01,
            -8.6629e-01, -8.4967e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.7037e-01,
             3.6220e-01,  1.9608e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.6374e-01,
             2.7739e-01,  1.1127e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.4301e-01,
             2.0611e-01, -7.6252e-03],
           ...,
           [-6.0722e-01, -6.2932e-01, -3.3230e-01,  ..., -7.8048e-01,
            -7.9590e-01, -7.9739e-01],
           [-6.3305e-01, -4.1976e-01, -2.6811e-01,  ..., -7.6206e-01,
            -7.6365e-01, -7.9598e-01],
           [-3.6166e-01, -2.4537e-01, -2.2358e-01,  ..., -7.4510e-01,
            -7.4510e-01, -7.4510e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.6062e-01,
             3.9869e-01,  2.6580e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.9871e-01,
             3.6238e-01,  1.8098e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.3330e-01,
             2.6304e-01,  1.1204e-01],
           ...,
           [-4.6125e-01, -6.4725e-01, -4.3360e-01,  ..., -9.3818e-01,
            -9.5581e-01, -9.8755e-01],
           [-7.2206e-01, -6.2239e-01, -4.4591e-01,  ..., -9.3728e-01,
            -9.5374e-01, -9.5285e-01],
           [-5.1852e-01, -4.1885e-01, -4.3001e-01,  ..., -9.0468e-01,
            -9.3519e-01, -9.0196e-01]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.8840e-01,
             1.3072e-01, -1.3508e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.5315e-01,
             7.5856e-02, -2.7077e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.1107e-01,
            -6.1204e-02, -4.5767e-01],
           ...,
           [-5.8279e-01, -4.8756e-01, -4.8288e-01,  ..., -8.1404e-01,
            -8.1404e-01, -8.1404e-01],
           [-4.6530e-01, -4.6574e-01, -4.6533e-01,  ..., -7.9645e-01,
            -7.9645e-01, -7.9645e-01],
           [-4.3137e-01, -4.4798e-01, -4.3273e-01,  ..., -7.6253e-01,
            -7.6253e-01, -7.6253e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.5082e-01,
             6.1819e-02, -1.8736e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.8297e-01,
            -1.0006e-02, -3.4002e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.3999e-01,
            -1.4831e-01, -5.4404e-01],
           ...,
           [-5.8434e-01, -4.9980e-01, -2.4502e-01,  ..., -8.5026e-01,
            -8.6551e-01, -8.4889e-01],
           [-4.9969e-01, -3.8474e-01, -2.6704e-01,  ..., -8.3314e-01,
            -8.4839e-01, -8.3178e-01],
           [-4.4880e-01, -3.8235e-01, -2.8268e-01,  ..., -8.1618e-01,
            -8.3143e-01, -8.1481e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.4760e-01,
            -2.4510e-02, -2.5708e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  6.2792e-02,
            -1.1250e-01, -4.0974e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.3008e-03,
            -2.3460e-01, -5.9711e-01],
           ...,
           [-4.7666e-01, -3.3160e-01, -2.6163e-01,  ..., -8.1404e-01,
            -8.1318e-01, -7.9583e-01],
           [-3.2680e-01, -2.7741e-01, -2.4284e-01,  ..., -7.9652e-01,
            -7.9573e-01, -7.6206e-01],
           [-3.2680e-01, -2.9357e-01, -2.5980e-01,  ..., -7.6525e-01,
            -7.9493e-01, -7.4510e-01]]],


         [[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.4488e-01,
            -5.8551e-02, -2.7451e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  7.5706e-02,
            -1.4416e-01, -3.7628e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -4.2756e-02,
            -2.6307e-01, -4.9564e-01],
           ...,
           [-6.7227e-01, -6.8962e-01, -7.5403e-01,  ..., -9.1783e-01,
            -9.1783e-01, -9.1783e-01],
           [-6.0053e-01, -6.3553e-01, -6.8632e-01,  ..., -8.8410e-01,
            -8.8451e-01, -8.8406e-01],
           [-4.1394e-01, -5.1362e-01, -5.9886e-01,  ..., -8.6846e-01,
            -8.8371e-01, -8.6710e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.1215e-01,
             1.8791e-01,  2.1787e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.8988e-01,
             1.0230e-01, -7.9987e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.6872e-01,
             3.1780e-02, -1.8270e-01],
           ...,
           [-7.1102e-01, -7.3163e-01, -3.8634e-01,  ..., -7.8048e-01,
            -7.9590e-01, -7.9739e-01],
           [-7.1833e-01, -4.7182e-01, -2.7119e-01,  ..., -7.6206e-01,
            -7.6367e-01, -7.9645e-01],
           [-3.7908e-01, -2.2958e-01, -1.9009e-01,  ..., -7.4510e-01,
            -7.4591e-01, -7.6253e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.5605e-01,
             2.9085e-01,  9.1503e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.9148e-01,
             2.2221e-01,  6.6916e-03],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.9270e-01,
             9.0229e-02, -6.2247e-02],
           ...,
           [-6.5220e-01, -8.3745e-01, -6.3840e-01,  ..., -9.3948e-01,
            -9.7168e-01, -9.8755e-01],
           [-8.9449e-01, -7.7820e-01, -5.8527e-01,  ..., -9.3728e-01,
            -9.5374e-01, -9.5285e-01],
           [-6.2309e-01, -5.0681e-01, -5.1716e-01,  ..., -9.0468e-01,
            -9.3519e-01, -9.0196e-01]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  6.3181e-02,
            -7.7614e-02, -3.2680e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.6606e-02,
            -1.4864e-01, -4.6250e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.5508e-02,
            -2.8537e-01, -6.3274e-01],
           ...,
           [-6.8659e-01, -5.7475e-01, -5.6925e-01,  ..., -8.4889e-01,
            -8.4889e-01, -8.4889e-01],
           [-5.5151e-01, -5.3534e-01, -5.3455e-01,  ..., -8.3131e-01,
            -8.3131e-01, -8.3131e-01],
           [-4.8366e-01, -4.8366e-01, -4.8366e-01,  ..., -7.9739e-01,
            -7.9739e-01, -7.9739e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  4.1667e-02,
            -1.4651e-01, -3.7908e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -4.3145e-02,
            -2.3451e-01, -5.3175e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -8.5286e-02,
            -3.5583e-01, -7.0246e-01],
           ...,
           [-7.0479e-01, -6.0586e-01, -3.9642e-01,  ..., -8.5026e-01,
            -8.6551e-01, -8.4889e-01],
           [-5.8637e-01, -5.0331e-01, -3.8804e-01,  ..., -8.3357e-01,
            -8.4841e-01, -8.3224e-01],
           [-5.1852e-01, -4.3546e-01, -3.6710e-01,  ..., -8.3224e-01,
            -8.3224e-01, -8.3224e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.0621e-02,
            -1.9798e-01, -4.1394e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.1107e-01,
            -2.8598e-01, -5.6660e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.5234e-01,
            -3.9065e-01, -7.2067e-01],
           ...,
           [-4.5923e-01, -3.1343e-01, -2.5877e-01,  ..., -8.3153e-01,
            -8.3139e-01, -8.1404e-01],
           [-3.0890e-01, -2.4290e-01, -2.0752e-01,  ..., -8.1575e-01,
            -8.3059e-01, -7.9692e-01],
           [-2.9194e-01, -2.4210e-01, -2.0752e-01,  ..., -8.0011e-01,
            -8.2979e-01, -7.7996e-01]]],


         [[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.4869e-01,
            -3.1836e-01, -5.0109e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.0356e-01,
            -4.2013e-01, -6.0286e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.7167e-01,
            -4.9110e-01, -7.0557e-01],
           ...,
           [-1.0383e+00, -1.0556e+00, -1.0879e+00,  ..., -1.0747e+00,
            -1.0747e+00, -1.0747e+00],
           [-9.6654e-01, -1.0011e+00, -1.0197e+00,  ..., -1.0409e+00,
            -1.0409e+00, -1.0409e+00],
           [-7.7996e-01, -8.6302e-01, -9.1531e-01,  ..., -1.0240e+00,
            -1.0240e+00, -1.0240e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -8.1427e-02,
            -7.3529e-02, -2.3965e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -7.2416e-02,
            -1.5834e-01, -3.2446e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -9.2721e-02,
            -2.2806e-01, -4.1005e-01],
           ...,
           [-1.0778e+00, -1.0984e+00, -7.6919e-01,  ..., -9.7220e-01,
            -9.8681e-01, -9.7168e-01],
           [-1.1018e+00, -8.5615e-01, -6.7120e-01,  ..., -9.5378e-01,
            -9.5458e-01, -9.7074e-01],
           [-7.6253e-01, -6.4624e-01, -6.0839e-01,  ..., -9.3682e-01,
            -9.3682e-01, -9.3682e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.7511e-01,
            -3.7854e-02, -1.8736e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.8350e-02,
            -9.0331e-02, -2.7218e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.0379e-01,
            -1.9012e-01, -3.4111e-01],
           ...,
           [-9.8257e-01, -1.1693e+00, -9.5498e-01,  ..., -1.0950e+00,
            -1.1127e+00, -1.1444e+00],
           [-1.2096e+00, -1.1261e+00, -9.3436e-01,  ..., -1.0946e+00,
            -1.1110e+00, -1.1097e+00],
           [-9.8911e-01, -8.8943e-01, -8.8453e-01,  ..., -1.0790e+00,
            -1.1087e+00, -1.0588e+00]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.8219e-01,
            -3.3742e-01, -5.5338e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.1611e-01,
            -3.7611e-01, -6.8908e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.4281e-01,
            -5.1195e-01, -8.5932e-01],
           ...,
           [-1.0352e+00, -9.2333e-01, -9.0248e-01,  ..., -1.0058e+00,
            -1.0058e+00, -1.0058e+00],
           [-9.0056e-01, -8.8439e-01, -8.8317e-01,  ..., -9.8817e-01,
            -9.8817e-01, -9.8817e-01],
           [-8.4967e-01, -8.4967e-01, -8.3361e-01,  ..., -9.5425e-01,
            -9.5425e-01, -9.5425e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.1841e-01,
            -3.8971e-01, -6.0566e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.8758e-01,
            -4.7770e-01, -7.5833e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.2929e-01,
            -5.9902e-01, -9.2904e-01],
           ...,
           [-1.0367e+00, -9.3631e-01, -6.8003e-01,  ..., -1.0393e+00,
            -1.0239e+00, -1.0232e+00],
           [-9.3495e-01, -8.1956e-01, -6.8663e-01,  ..., -1.0235e+00,
            -1.0227e+00, -1.0061e+00],
           [-8.6710e-01, -7.8404e-01, -6.9962e-01,  ..., -1.0065e+00,
            -1.0057e+00, -9.8911e-01]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.7206e-01,
            -4.5779e-01, -6.4052e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.7118e-01,
            -5.2961e-01, -7.9318e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.9577e-01,
            -6.1797e-01, -9.4725e-01],
           ...,
           [-8.6010e-01, -7.1430e-01, -6.4501e-01,  ..., -9.7174e-01,
            -9.7238e-01, -9.7090e-01],
           [-7.1024e-01, -6.4424e-01, -6.2492e-01,  ..., -9.7261e-01,
            -9.8745e-01, -9.5378e-01],
           [-7.1024e-01, -6.6040e-01, -6.4188e-01,  ..., -9.5697e-01,
            -9.8666e-01, -9.3682e-01]]]]], device='cuda:0')]
[03/06 19:11:24][INFO] train_net.py:  93: tensor([102,  38,  68,  78,  98,  68,  68,  40, 104, 102,  67,  78, 133, 133,
         16,  78], device='cuda:0')
[03/06 19:11:24][INFO] train_net.py:  94: [tensor([[[[[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -1.9780e+00, -1.8705e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.6116e+00,
            -1.4882e+00, -8.8453e-01],
           [-1.3526e+00, -1.3526e+00, -1.3526e+00,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           ...,
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01]],

          [[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ...,  2.3094e-01,
            -3.0663e-01,  2.3094e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.1697e-01,
            -4.9609e-01,  2.9724e-02],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.3482e-01,
            -8.8453e-01, -7.9088e-01]],

          [[-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [-6.0362e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -1.1655e+00],
           [-7.7809e-02, -8.8453e-01, -8.8453e-01,  ..., -1.5319e+00,
            -1.5319e+00, -1.8704e+00],
           ...,
           [-1.6615e+00, -1.6113e+00, -8.8453e-01,  ..., -1.7116e+00,
            -2.0000e+00, -2.0000e+00],
           [-9.9205e-01, -9.5043e-01, -8.8453e-01,  ..., -1.7607e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          ...,

          [[-8.8453e-01, -7.7702e-01, -7.5506e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -2.8082e-01,  2.3094e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -8.8453e-01, -4.1643e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-1.5319e+00, -9.9436e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [-1.6116e+00, -1.6116e+00, -1.1637e+00,  ..., -8.8453e-01,
            -8.8453e-01, -1.4103e+00],
           [-1.7271e+00, -1.0140e+00, -1.3128e+00,  ..., -8.8453e-01,
            -1.0518e+00, -1.9642e+00]],

          [[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -1.5318e+00],
           ...,
           [-4.1632e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -1.5319e+00, -1.5319e+00],
           [-8.8453e-01, -8.8453e-01, -1.5751e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [ 1.0144e-01,  1.0144e-01,  6.0948e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01]],

          [[-1.5976e+00, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [ 2.3094e-01,  2.3094e-01,  6.0948e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01]]],


         [[[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -1.9780e+00, -1.8705e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.6116e+00,
            -1.4882e+00, -8.8453e-01],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           ...,
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -2.0000e+00, -1.5318e+00],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -1.2730e+00, -1.7988e+00],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -9.7819e-01]],

          [[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-1.6615e+00, -2.0000e+00, -2.0000e+00,  ...,  2.3094e-01,
            -8.8453e-01, -7.7784e-02],
           [-1.1933e+00, -2.0000e+00, -2.0000e+00,  ..., -2.1697e-01,
            -8.8453e-01, -6.0359e-01],
           [-1.1933e+00, -2.0000e+00, -2.0000e+00,  ..., -8.3482e-01,
            -8.8453e-01, -8.8453e-01]],

          [[-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -1.0337e+00,
            -1.2730e+00, -1.2730e+00],
           [-4.1634e-01, -8.8453e-01, -8.8453e-01,  ..., -1.7116e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -8.8453e-01,  ..., -1.7116e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.2730e+00, -1.8767e+00, -1.3324e+00,  ..., -1.7607e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -9.9206e-01, -1.3429e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          ...,

          [[-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-1.2230e+00, -8.8453e-01, -8.8453e-01,  ..., -1.0642e+00,
            -8.8453e-01, -8.8453e-01],
           [-1.8925e+00, -1.0079e+00, -1.1637e+00,  ..., -1.4816e+00,
            -1.6116e+00, -1.6116e+00],
           [-2.0000e+00, -1.8925e+00, -1.9202e+00,  ..., -1.9503e+00,
            -2.0000e+00, -2.0000e+00]],

          [[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -1.5318e+00],
           ...,
           [-4.1632e-01, -8.8453e-01, -8.8453e-01,  ..., -1.1729e+00,
            -1.9206e+00, -1.5319e+00],
           [-8.8453e-01, -8.8453e-01, -1.5751e-01,  ..., -1.1238e+00,
            -1.2071e+00, -8.8453e-01],
           [-8.8453e-01, -8.8453e-01,  2.3094e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01]],

          [[-1.9642e+00, -1.0518e+00, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -1.9064e+00],
           [-1.6913e+00, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -1.6116e+00, -1.0858e+00],
           [-1.2231e+00, -8.8453e-01, -8.8453e-01,  ..., -1.6012e+00,
            -8.8453e-01, -8.8453e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.2631e+00,
            -1.7032e+00, -8.8453e-01]]],


         [[[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -1.9341e+00, -1.6116e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3526e+00,
            -1.2732e+00, -8.8453e-01],
           ...,
           [-8.8453e-01, -8.8453e-01, -8.8453e-01,  ..., -1.8203e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.4103e+00, -8.8453e-01, -8.8453e-01,  ..., -1.5718e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.6913e+00, -8.8453e-01, -1.8705e+00,  ..., -9.6431e-01,
            -2.0000e+00, -2.0000e+00]],

          [[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.6792e-01,
            -8.8453e-01, -8.8453e-01],
           [-1.4742e+00, -2.0000e+00, -2.0000e+00,  ..., -4.9609e-01,
            -8.8453e-01, -8.8453e-01],
           [-1.9063e+00, -2.0000e+00, -2.0000e+00,  ..., -8.8453e-01,
            -8.8453e-01, -1.5976e+00]],

          [[-1.9064e+00, -1.1813e+00, -8.8453e-01,  ..., -8.8453e-01,
            -8.8453e-01, -9.7817e-01],
           [-1.0858e+00, -1.9341e+00, -8.8453e-01,  ..., -1.2730e+00,
            -1.2730e+00, -1.7988e+00],
           [-8.8453e-01, -1.2732e+00, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -1.5717e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -1.8509e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.7271e+00, -1.8327e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          ...,

          [[-9.7817e-01, -8.8453e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.7988e+00, -9.5042e-01, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -1.0738e+00, -8.8453e-01,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -1.3526e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          [[-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-2.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -2.0000e+00,
            -2.0000e+00, -1.5318e+00],
           ...,
           [-4.1632e-01, -1.2732e+00, -8.8453e-01,  ..., -1.7515e+00,
            -2.0000e+00, -1.6615e+00],
           [-8.8453e-01, -1.2071e+00, -1.5751e-01,  ..., -1.2730e+00,
            -1.2730e+00, -9.9204e-01],
           [-8.8453e-01, -8.8453e-01,  2.3094e-01,  ..., -8.8453e-01,
            -1.8705e+00, -1.8705e+00]],

          [[-1.9642e+00, -1.8705e+00, -1.9202e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.6913e+00, -8.8453e-01, -1.3128e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [-1.6913e+00, -8.8453e-01, -1.7116e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -8.8453e-01,
            -8.8453e-01, -8.8453e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.6116e+00,
            -1.4882e+00, -1.4103e+00],
           [-4.1967e-02, -7.5504e-01,  2.3094e-01,  ..., -2.0000e+00,
            -1.9780e+00, -1.9642e+00]]]],



        [[[[ 5.5456e-01,  5.4466e-01,  4.9884e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 5.2972e-01,  5.1132e-01,  4.3053e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 4.9844e-01,  4.7548e-01,  4.2312e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  8.0662e-01,
             5.0306e-01,  1.7640e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.7486e-01,
             7.6277e-01,  1.0184e+00],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  7.9027e-01,
             6.9849e-01,  5.8650e-01]],

          [[ 5.5456e-01,  5.4466e-01,  4.9884e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 5.2972e-01,  5.1132e-01,  4.3053e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 4.9844e-01,  4.7548e-01,  4.2312e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.9985e+00,
             1.4555e+00,  9.7561e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.7030e+00,
             1.2016e+00,  8.5347e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.5400e+00,
             1.1867e+00,  8.4222e-01]],

          [[ 5.5456e-01,  5.4466e-01,  4.9884e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 5.2972e-01,  5.1132e-01,  4.3053e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 4.9844e-01,  4.7548e-01,  4.2312e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  7.5525e-01,
             5.5780e-01,  5.0846e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.8501e-01,
             7.0775e-01,  8.7477e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.3593e-01,
             5.3143e-01,  4.6699e-01]],

          ...,

          [[ 5.5251e-01,  5.1936e-01,  4.8720e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 5.1069e-01,  4.9486e-01,  4.6047e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 4.4411e-01,  4.4545e-01,  4.3235e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.2036e-01,
             4.7557e-01,  4.4647e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  4.5389e-01,
             2.7000e-01,  2.6491e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.6542e-01,
             2.3783e-01,  2.4287e-01]],

          [[ 5.5251e-01,  5.1936e-01,  4.8720e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 5.1069e-01,  4.9486e-01,  4.6047e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 4.4411e-01,  4.4545e-01,  4.3235e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  6.1296e-01,
             4.5452e-01,  4.2348e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.5020e-01,
             3.3282e-01,  2.4750e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.2949e-01,
             2.5453e-01,  1.8888e-01]],

          [[ 5.3750e-01,  5.0213e-01,  4.7461e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 5.1069e-01,  4.9486e-01,  4.6041e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 4.4411e-01,  4.4545e-01,  4.3262e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.5976e-01,
             4.5736e-01,  3.5590e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  4.6899e-01,
             2.6021e-01,  2.6146e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.6213e-01,
             3.4311e-01,  3.4580e-01]]],


         [[[-2.9948e-01, -3.2011e-01, -3.1421e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.2431e-01, -3.3505e-01, -3.5621e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.5559e-01, -3.4787e-01, -3.4489e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.1577e-01,
             1.7671e-01, -1.7014e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  8.6589e-02,
             4.9635e-01,  7.4410e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  4.6956e-01,
             3.7541e-01,  2.5821e-01]],

          [[-2.9948e-01, -3.2011e-01, -3.1421e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.2431e-01, -3.3505e-01, -3.5621e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.5559e-01, -3.4787e-01, -3.4489e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  5.6016e-01,
             2.9412e-01,  1.9139e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.7635e-01,
             1.6153e-01,  5.4155e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.1284e-01,
             8.4056e-02,  4.7582e-03]],

          [[-2.9948e-01, -3.2011e-01, -3.1421e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.2431e-01, -3.3505e-01, -3.5621e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.5559e-01, -3.4787e-01, -3.4489e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.6903e-01,
             2.5239e-01,  2.6472e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.3601e-01,
             4.4078e-01,  5.6718e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  1.1145e-01,
             1.2750e-01,  9.5798e-02]],

          ...,

          [[-3.1077e-01, -3.0152e-01, -3.2726e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.2322e-01, -3.0783e-01, -3.1192e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.6555e-01, -3.4556e-01, -3.4443e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -4.4985e-01,
            -2.3207e-01, -1.3029e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.9005e-01,
            -2.9098e-01, -2.2218e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.3318e-01,
            -2.8814e-01, -2.2645e-01]],

          [[-3.1077e-01, -3.0152e-01, -3.2726e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.2322e-01, -3.0783e-01, -3.1192e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.6555e-01, -3.4556e-01, -3.4443e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -4.8735e-01,
            -2.8265e-01, -1.1671e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.8398e-01,
            -2.7106e-01, -2.0226e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.4561e-01,
            -2.3316e-01, -1.9892e-01]],

          [[-2.9832e-01, -2.7373e-01, -2.9772e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.2322e-01, -3.0783e-01, -3.2397e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-3.6555e-01, -3.4556e-01, -3.4443e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.5963e-01,
            -1.9317e-01, -1.5046e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.3943e-01,
            -2.0439e-01, -1.8807e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -3.1252e-01,
            -1.7629e-01, -1.6036e-01]]],


         [[[-9.7219e-01, -9.8030e-01, -9.4753e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.6452e-01, -9.5829e-01, -9.6610e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.9095e-01, -9.6459e-01, -9.5472e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.1220e-01,
            -1.5118e-01, -5.1668e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.1940e-01,
             2.0370e-01,  4.3740e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  8.0519e-02,
            -1.4367e-02, -9.0059e-02]],

          [[-9.7219e-01, -9.8030e-01, -9.4753e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.6452e-01, -9.5829e-01, -9.6610e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.9095e-01, -9.6459e-01, -9.5472e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  6.8917e-01,
             3.2480e-01, -2.4390e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  4.5999e-01,
             1.4526e-01, -3.5525e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  3.4209e-01,
             6.9941e-02, -8.5701e-02]],

          [[-9.7219e-01, -9.8030e-01, -9.4753e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.6452e-01, -9.5829e-01, -9.6610e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.9095e-01, -9.6459e-01, -9.5472e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  6.6796e-02,
             5.7785e-04, -3.1581e-02],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -1.1196e-01,
             1.3990e-01,  2.2129e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -2.8965e-01,
            -2.7971e-01, -3.0947e-01]],

          ...,

          [[-9.6950e-01, -9.1572e-01, -9.0149e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.7008e-01, -9.5271e-01, -9.3137e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-1.0125e+00, -9.7892e-01, -9.5425e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -5.8768e-01,
            -5.5242e-01, -5.6671e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -5.9584e-01,
            -6.9319e-01, -7.5319e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -6.6355e-01,
            -6.8301e-01, -7.4094e-01]],

          [[-9.6950e-01, -9.1572e-01, -9.0149e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.7008e-01, -9.5271e-01, -9.3137e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-1.0125e+00, -9.7892e-01, -9.4502e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -5.9113e-01,
            -5.6814e-01, -5.3212e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -5.7234e-01,
            -6.3517e-01, -6.9783e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -6.0635e-01,
            -6.4795e-01, -7.2345e-01]],

          [[-9.7799e-01, -9.4351e-01, -9.1846e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-9.6810e-01, -9.5271e-01, -9.3380e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [-1.0125e+00, -9.7892e-01, -9.4502e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -5.6469e-01,
            -5.1261e-01, -5.7225e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -5.7725e-01,
            -6.1238e-01, -6.2692e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ..., -5.4410e-01,
            -4.5112e-01, -5.0216e-01]]]],



        [[[[-6.5359e-02, -7.4735e-02, -8.6796e-02,  ..., -2.3564e-01,
            -2.3965e-01, -2.3965e-01],
           [-5.9602e-02, -7.5172e-02, -9.1230e-02,  ..., -2.2989e-01,
            -2.3389e-01, -2.3389e-01],
           [-4.9953e-02, -7.5905e-02, -9.8660e-02,  ..., -2.2024e-01,
            -2.2425e-01, -2.2425e-01],
           ...,
           [-1.5857e-01, -1.7515e-01, -2.0094e-01,  ..., -2.7004e-01,
            -2.9155e-01, -3.1139e-01],
           [-1.8752e-01, -1.9371e-01, -2.0837e-01,  ..., -2.6782e-01,
            -2.9601e-01, -3.2104e-01],
           [-2.0479e-01, -2.0479e-01, -2.1281e-01,  ..., -2.6650e-01,
            -2.9867e-01, -3.2680e-01]],

          [[-8.2789e-02, -1.0154e-01, -1.2165e-01,  ..., -2.2222e-01,
            -2.3028e-01, -2.3965e-01],
           [-8.2789e-02, -1.0154e-01, -1.2298e-01,  ..., -2.1646e-01,
            -2.2452e-01, -2.3389e-01],
           [-8.2789e-02, -1.0154e-01, -1.2520e-01,  ..., -2.0682e-01,
            -2.1487e-01, -2.2425e-01],
           ...,
           [-1.8939e-01, -2.2580e-01, -2.8019e-01,  ..., -2.7945e-01,
            -3.0898e-01, -3.2882e-01],
           [-1.9904e-01, -2.3026e-01, -2.7576e-01,  ..., -2.7723e-01,
            -3.1344e-01, -3.3847e-01],
           [-2.0479e-01, -2.3292e-01, -2.7311e-01,  ..., -2.7591e-01,
            -3.1610e-01, -3.4423e-01]],

          [[-2.0479e-01, -2.3292e-01, -2.6910e-01,  ..., -2.0479e-01,
            -2.1285e-01, -2.2222e-01],
           [-2.1055e-01, -2.4178e-01, -2.7929e-01,  ..., -1.9904e-01,
            -2.0709e-01, -2.1646e-01],
           [-2.2020e-01, -2.5661e-01, -2.9637e-01,  ..., -1.8939e-01,
            -1.9744e-01, -2.0682e-01],
           ...,
           [-4.4678e-01, -4.7599e-01, -4.9708e-01,  ..., -3.4715e-01,
            -3.6862e-01, -3.7908e-01],
           [-4.3713e-01, -4.7154e-01, -4.9708e-01,  ..., -3.3528e-01,
            -3.6343e-01, -3.7908e-01],
           [-4.3137e-01, -4.6888e-01, -4.9708e-01,  ..., -3.2820e-01,
            -3.6033e-01, -3.7908e-01]],

          ...,

          [[-4.3137e-01, -4.5012e-01, -4.7024e-01,  ..., -1.6993e-01,
            -1.6993e-01, -1.6993e-01],
           [-4.3137e-01, -4.4703e-01, -4.6316e-01,  ..., -1.5842e-01,
            -1.5842e-01, -1.5842e-01],
           [-4.3137e-01, -4.4184e-01, -4.5129e-01,  ..., -1.3912e-01,
            -1.3912e-01, -1.3912e-01],
           ...,
           [-3.5761e-01, -2.9918e-01, -2.2895e-01,  ..., -3.6714e-01,
            -3.1532e-01, -2.6844e-01],
           [-3.3831e-01, -2.6950e-01, -1.9036e-01,  ..., -3.3598e-01,
            -2.8638e-01, -2.3950e-01],
           [-3.2680e-01, -2.5179e-01, -1.6733e-01,  ..., -3.1738e-01,
            -2.6910e-01, -2.2222e-01]],

          [[-4.4880e-01, -4.5818e-01, -4.6623e-01,  ..., -1.5251e-01,
            -1.5251e-01, -1.5251e-01],
           [-4.3729e-01, -4.4666e-01, -4.5472e-01,  ..., -1.4099e-01,
            -1.4099e-01, -1.4099e-01],
           [-4.1799e-01, -4.2737e-01, -4.3542e-01,  ..., -1.2169e-01,
            -1.2169e-01, -1.2169e-01],
           ...,
           [-1.9872e-01, -1.5293e-01, -1.2115e-01,  ..., -3.0388e-01,
            -2.4452e-01, -1.9872e-01],
           [-1.6978e-01, -1.2918e-01, -9.9636e-02,  ..., -2.6529e-01,
            -2.1038e-01, -1.6978e-01],
           [-1.5251e-01, -1.1500e-01, -8.6796e-02,  ..., -2.4226e-01,
            -1.9001e-01, -1.5251e-01]],

          [[-3.9651e-01, -3.7776e-01, -3.5364e-01,  ..., -6.9367e-02,
            -6.5359e-02, -6.5359e-02],
           [-3.7348e-01, -3.5473e-01, -3.3193e-01,  ..., -6.3609e-02,
            -5.6941e-02, -5.3844e-02],
           [-3.3489e-01, -3.1614e-01, -2.9556e-01,  ..., -5.3960e-02,
            -4.2835e-02, -3.4547e-02],
           ...,
           [-1.1967e-01, -1.6329e-01, -2.0876e-01,  ..., -1.4702e-01,
            -9.4772e-02, -5.7268e-02],
           [-1.2932e-01, -1.5736e-01, -1.8947e-01,  ..., -1.0843e-01,
            -5.6178e-02, -1.8674e-02],
           [-1.3508e-01, -1.5383e-01, -1.7795e-01,  ..., -8.5395e-02,
            -3.3147e-02,  4.3574e-03]]],


         [[[-6.0566e-01, -6.0566e-01, -6.0166e-01,  ..., -9.6211e-02,
            -1.0022e-01, -1.0022e-01],
           [-6.0566e-01, -6.0257e-01, -5.9722e-01,  ..., -9.1777e-02,
            -9.4460e-02, -9.4460e-02],
           [-6.0566e-01, -5.9738e-01, -5.8979e-01,  ..., -8.4347e-02,
            -8.4812e-02, -8.4812e-02],
           ...,
           [ 3.3147e-02,  3.5323e-02,  2.5636e-02,  ..., -6.4894e-02,
            -8.2401e-02, -1.0224e-01],
           [ 4.2019e-03,  1.6759e-02,  1.8206e-02,  ..., -6.2676e-02,
            -8.6859e-02, -1.1189e-01],
           [-1.3072e-02,  5.6802e-03,  1.3772e-02,  ..., -6.1352e-02,
            -8.9519e-02, -1.1765e-01]],

          [[-5.8824e-01, -5.8824e-01, -4.1993e-01,  ..., -8.2789e-02,
            -9.0842e-02, -1.0022e-01],
           [-5.8824e-01, -5.8824e-01, -4.2125e-01,  ..., -7.7031e-02,
            -8.2424e-02, -8.8702e-02],
           [-5.8824e-01, -5.8824e-01, -4.2347e-01,  ..., -6.7382e-02,
            -6.8317e-02, -6.9405e-02],
           ...,
           [ 1.9764e-02,  3.1881e-03, -3.1085e-02,  ..., -7.4309e-02,
            -1.0695e-01, -1.3508e-01],
           [ 1.0115e-02,  3.9204e-03, -2.1437e-02,  ..., -7.2091e-02,
            -1.0695e-01, -1.3508e-01],
           [ 4.3574e-03,  4.3574e-03, -1.5679e-02,  ..., -7.0767e-02,
            -1.0695e-01, -1.3508e-01]],

          [[ 7.4074e-02,  5.5322e-02,  2.7194e-02,  ..., -6.5359e-02,
            -7.3413e-02, -8.2789e-02],
           [ 7.4074e-02,  5.2225e-02,  2.1436e-02,  ..., -5.9602e-02,
            -6.4994e-02, -7.1273e-02],
           [ 7.4074e-02,  4.7034e-02,  1.1788e-02,  ..., -4.9953e-02,
            -5.0888e-02, -5.1976e-02],
           ...,
           [-1.8534e-01, -2.1456e-01, -2.3564e-01,  ..., -1.6931e-01,
            -1.9433e-01, -2.0479e-01],
           [-1.7569e-01, -2.1010e-01, -2.3564e-01,  ..., -1.5966e-01,
            -1.8914e-01, -2.0479e-01],
           [-1.6993e-01, -2.0744e-01, -2.3564e-01,  ..., -1.5391e-01,
            -1.8604e-01, -2.0479e-01]],

          ...,

          [[-1.1765e-01, -1.2702e-01, -1.3908e-01,  ..., -3.4508e-02,
            -3.0501e-02, -3.0501e-02],
           [-1.1189e-01, -1.2127e-01, -1.3333e-01,  ..., -2.2992e-02,
            -1.8985e-02, -1.8985e-02],
           [-1.0224e-01, -1.1162e-01, -1.2368e-01,  ..., -3.6959e-03,
             3.1130e-04,  3.1130e-04],
           ...,
           [-9.6172e-02, -3.8828e-02,  9.9978e-03,  ..., -1.7188e-01,
            -1.2360e-01, -7.6720e-02],
           [-7.6875e-02, -1.4341e-02, -5.8664e-02,  ..., -1.4294e-01,
            -9.4655e-02, -4.7775e-02],
           [-6.5359e-02,  2.7267e-04, -9.9640e-02,  ..., -1.2566e-01,
            -7.7381e-02, -3.0501e-02]],

          [[-1.3508e-01, -1.4445e-01, -1.5251e-01,  ..., -1.3072e-02,
            -1.3072e-02, -1.3072e-02],
           [-1.1780e-01, -1.2718e-01, -1.3656e-01,  ..., -1.5561e-03,
            -1.5561e-03, -1.5561e-03],
           [-8.8858e-02, -9.8234e-02, -1.0983e-01,  ...,  1.7740e-02,
             1.7740e-02,  1.7740e-02],
           ...,
           [ 4.5285e-02,  4.1018e-02,  3.4275e-02,  ..., -1.0815e-01,
            -4.4741e-02,  1.0426e-02],
           [ 7.4230e-02, -1.7398e-01, -3.8581e-01,  ..., -6.9561e-02,
            -1.0606e-02,  3.9371e-02],
           [ 9.1503e-02, -3.0229e-01, -6.3652e-01,  ..., -4.6530e-02,
             9.7651e-03,  5.6645e-02]],

          [[-1.0022e-01, -9.0842e-02, -7.4774e-02,  ...,  3.9216e-02,
             4.7269e-02,  5.6645e-02],
           [-7.7186e-02, -6.7810e-02, -5.3066e-02,  ...,  4.9408e-02,
             5.8785e-02,  6.8161e-02],
           [-3.8593e-02, -2.9217e-02, -1.6692e-02,  ...,  6.6486e-02,
             7.8081e-02,  8.7457e-02],
           ...,
           [ 1.0691e-01,  6.3294e-02,  1.7818e-02,  ...,  2.7737e-02,
            -2.5720e-01, -6.1173e-01],
           [ 9.7261e-02,  6.9217e-02,  3.7114e-02,  ...,  6.8548e-02,
            -2.4982e-01, -6.4068e-01],
           [ 9.1503e-02,  7.2751e-02,  4.8630e-02,  ...,  9.2904e-02,
            -2.4541e-01, -6.5795e-01]]],


         [[[-6.5795e-01, -6.6733e-01, -6.6737e-01,  ...,  3.9216e-02,
             3.1163e-02,  2.1787e-02],
           [-6.6371e-01, -6.6689e-01, -6.6293e-01,  ...,  4.4974e-02,
             3.6920e-02,  2.7544e-02],
           [-6.7336e-01, -6.6616e-01, -6.5550e-01,  ...,  5.4622e-02,
             4.6569e-02,  3.7193e-02],
           ...,
           [ 1.3772e-01,  1.3990e-01,  1.2620e-01,  ...,  8.1530e-04,
            -1.2684e-02, -3.2524e-02],
           [ 1.0878e-01,  1.2133e-01,  1.1877e-01,  ...,  3.0336e-03,
            -1.7142e-02, -4.2172e-02],
           [ 9.1503e-02,  1.1026e-01,  1.1434e-01,  ...,  4.3574e-03,
            -1.9802e-02, -4.7930e-02]],

          [[-6.4052e-01, -6.4052e-01, -6.3251e-01,  ...,  4.3223e-02,
             3.9216e-02,  3.9216e-02],
           [-6.4052e-01, -6.4052e-01, -6.3251e-01,  ...,  4.7657e-02,
             4.4974e-02,  4.4974e-02],
           [-6.4052e-01, -6.4052e-01, -6.3251e-01,  ...,  5.5087e-02,
             5.4622e-02,  5.4622e-02],
           ...,
           [ 1.0893e-01,  9.9557e-02,  6.8390e-02,  ...,  4.8225e-03,
            -1.9802e-02, -4.7930e-02],
           [ 1.0893e-01,  9.9557e-02,  7.2826e-02,  ...,  7.0407e-03,
            -1.9802e-02, -4.7930e-02],
           [ 1.0893e-01,  9.9557e-02,  7.5474e-02,  ...,  8.3645e-03,
            -1.9802e-02, -4.7930e-02]],

          [[-6.0566e-01, -2.1187e-01,  1.1434e-01,  ...,  5.6645e-02,
             4.8592e-02,  3.9216e-02],
           [-5.9991e-01, -2.1541e-01,  1.0282e-01,  ...,  6.2403e-02,
             5.4350e-02,  4.4974e-02],
           [-5.9026e-01, -2.2133e-01,  8.3527e-02,  ...,  7.2051e-02,
             6.3998e-02,  5.4622e-02],
           ...,
           [-8.0766e-02, -1.0061e-01, -1.1364e-01,  ..., -1.3399e-01,
            -1.5142e-01, -1.5251e-01],
           [-7.1117e-02, -9.6148e-02, -1.1364e-01,  ..., -1.2212e-01,
            -1.4623e-01, -1.5251e-01],
           [-6.5359e-02, -9.3487e-02, -1.1364e-01,  ..., -1.1504e-01,
            -1.4313e-01, -1.5251e-01]],

          ...,

          [[-3.0501e-02, -4.9253e-02, -6.5359e-02,  ...,  7.4074e-02,
             7.4074e-02,  7.4074e-02],
           [-3.0501e-02, -4.6156e-02, -5.9602e-02,  ...,  8.5590e-02,
             8.5590e-02,  8.5590e-02],
           [-3.0501e-02, -4.0965e-02, -4.9953e-02,  ...,  1.0489e-01,
             1.0489e-01,  1.0489e-01],
           ...,
           [ 2.3809e-02, -3.1808e-01, -6.3177e-01,  ..., -1.4103e-01,
            -8.8741e-02, -4.1861e-02],
           [ 3.3458e-02, -3.2919e-01, -6.6071e-01,  ..., -1.1208e-01,
            -5.9796e-02, -1.2916e-02],
           [ 3.9216e-02, -3.3582e-01, -6.7799e-01,  ..., -9.4810e-02,
            -4.2522e-02,  4.3574e-03]],

          [[-6.5359e-02, -7.4735e-02, -8.6796e-02,  ...,  7.8081e-02,
             7.4074e-02,  7.4074e-02],
           [-5.3844e-02, -6.3220e-02, -7.5280e-02,  ...,  8.9597e-02,
             8.5590e-02,  8.5590e-02],
           [-3.4547e-02, -4.3923e-02, -5.5984e-02,  ...,  1.0889e-01,
             1.0489e-01,  1.0489e-01],
           ...,
           [-6.4659e-01, -6.8410e-01, -7.1230e-01,  ..., -9.0725e-02,
            -2.7312e-02,  2.7855e-02],
           [-6.7554e-01, -7.1304e-01, -7.4125e-01,  ..., -5.2132e-02,
             6.8231e-03,  5.6800e-02],
           [-6.9281e-01, -7.3031e-01, -7.5852e-01,  ..., -2.9100e-02,
             2.7194e-02,  7.4074e-02]],

          [[-4.7930e-02, -3.8554e-02, -2.2486e-02,  ...,  1.0893e-01,
            -2.2125e-01, -6.0566e-01],
           [-1.9141e-02, -1.2862e-02, -7.7882e-04,  ..., -1.2714e-01,
            -3.5090e-01, -6.1142e-01],
           [ 2.9101e-02,  3.0189e-02,  3.5596e-02,  ..., -5.2272e-01,
            -5.6816e-01, -6.2107e-01],
           ...,
           [-7.0822e-01, -6.6460e-01, -4.7744e-01,  ..., -4.8571e-03,
            -2.9330e-01, -6.2916e-01],
           [-6.9857e-01, -6.7052e-01, -5.8547e-01,  ..., -2.8576e-01,
            -5.0910e-01, -6.5811e-01],
           [-6.9281e-01, -6.7406e-01, -6.4994e-01,  ..., -4.5339e-01,
            -6.3788e-01, -6.7538e-01]]]],



        ...,



        [[[[ 7.7124e-01,  7.2701e-01,  6.8009e-01,  ...,  6.8456e-01,
             7.4444e-01,  7.8867e-01],
           [ 7.7124e-01,  7.2701e-01,  7.3879e-01,  ...,  6.8051e-01,
             7.2864e-01,  7.7288e-01],
           [ 7.4183e-01,  6.9760e-01,  6.9359e-01,  ...,  6.6538e-01,
             7.1457e-01,  7.7124e-01],
           ...,
           [-1.5795e-02, -1.5311e-01, -3.5543e-01,  ...,  1.1166e-01,
             1.1166e-01,  1.1166e-01],
           [-3.3769e-02, -1.9735e-01, -3.8137e-01,  ...,  1.2473e-01,
             1.2473e-01,  1.2473e-01],
           [-6.5359e-02, -2.4230e-01, -4.1702e-01,  ...,  1.0893e-01,
             1.0893e-01,  1.0893e-01]],

          [[ 7.5381e-01,  7.3907e-01,  7.3638e-01,  ...,  3.2256e-01,
             3.3551e-01,  3.3551e-01],
           [ 7.3802e-01,  7.0991e-01,  6.6957e-01,  ...,  3.3835e-01,
             3.5131e-01,  3.5131e-01],
           [ 7.3638e-01,  7.0689e-01,  6.6266e-01,  ...,  3.3999e-01,
             3.5294e-01,  3.5294e-01],
           ...,
           [-1.7266e-01, -1.7266e-01, -1.7063e-01,  ...,  1.6908e-01,
             1.4840e-01,  1.4379e-01],
           [-1.9063e-01, -1.9063e-01, -1.7768e-01,  ...,  1.6490e-01,
             1.7542e-01,  1.4869e-01],
           [-2.2222e-01, -2.2222e-01, -2.0927e-01,  ...,  1.5721e-01,
             1.9608e-01,  1.9608e-01]],

          [[ 4.7495e-01,  6.3714e-01,  7.5735e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [ 9.1721e-01,  9.0569e-01,  8.8862e-01,  ...,  2.4104e-01,
             2.2930e-01,  2.2930e-01],
           [ 8.8943e-01,  8.4750e-01,  8.5768e-01,  ...,  2.7708e-01,
             2.6826e-01,  2.3094e-01],
           ...,
           [-5.7353e-01, -5.6662e-01, -4.0382e-01,  ...,  5.4936e-02,
             9.2065e-02,  1.7593e-01],
           [-5.8333e-01, -5.2113e-01, -3.1547e-01,  ...,  9.7620e-02,
             1.0614e-01,  1.5959e-01],
           [-5.3595e-01, -3.0003e-01, -6.2749e-02,  ...,  1.5675e-01,
             1.4379e-01,  1.4379e-01]],

          ...,

          [[ 8.2353e-01,  7.2031e-01,  6.7561e-01,  ...,  2.6580e-01,
             2.7385e-01,  3.1808e-01],
           [ 7.9194e-01,  7.8226e-01,  7.4285e-01,  ...,  2.6580e-01,
             2.6655e-01,  2.7070e-01],
           [ 6.8573e-01,  7.7282e-01,  7.8260e-01,  ...,  2.5109e-01,
             2.5109e-01,  2.5109e-01],
           ...,
           [ 1.0621e-01,  1.2095e-01,  1.4955e-01,  ...,  2.8428e-01,
             2.9563e-01,  2.9793e-01],
           [ 9.3137e-02,  1.0788e-01,  1.3405e-01,  ...,  2.6659e-01,
             2.6659e-01,  2.7996e-01],
           [ 1.0893e-01,  1.2368e-01,  1.2636e-01,  ...,  2.7428e-01,
             2.4837e-01,  2.4837e-01]],

          [[ 7.0153e-01,  6.8678e-01,  6.1932e-01,  ...,  2.1351e-01,
             2.1351e-01,  2.1351e-01],
           [ 6.0675e-01,  5.9201e-01,  5.7151e-01,  ...,  2.0945e-01,
             1.9771e-01,  1.9771e-01],
           [ 5.8224e-01,  5.9238e-01,  5.7034e-01,  ...,  1.9810e-01,
             1.9834e-01,  2.1078e-01],
           ...,
           [ 3.1264e-01,  2.9789e-01,  2.2557e-01,  ..., -4.4110e-01,
            -3.3524e-01, -4.9564e-02],
           [ 2.8649e-01,  2.7313e-01,  2.4357e-01,  ..., -4.8756e-01,
            -3.7988e-01, -1.5087e-01],
           [ 3.1808e-01,  3.1808e-01,  2.7922e-01,  ..., -4.0453e-01,
            -2.9727e-01, -1.3508e-01]],

          [[ 5.7952e-01,  5.9427e-01,  5.9695e-01,  ...,  2.0055e-01,
             2.1351e-01,  2.1351e-01],
           [ 5.9532e-01,  5.8334e-01,  5.9290e-01,  ...,  1.8476e-01,
             1.9771e-01,  1.9771e-01],
           [ 6.1166e-01,  5.9691e-01,  5.8532e-01,  ...,  1.9405e-01,
             1.9381e-01,  1.8137e-01],
           ...,
           [ 3.2353e-01,  3.2123e-01,  3.2971e-01,  ...,  8.6857e-02,
            -1.5085e-02, -2.3257e-01],
           [ 3.5458e-01,  3.3983e-01,  3.2419e-01,  ..., -5.5953e-02,
             1.6989e-02, -8.7146e-02],
           [ 3.7037e-01,  3.5563e-01,  3.3999e-01,  ..., -9.9284e-02,
             9.7262e-03,  3.9216e-02]]],


         [[[ 1.2244e+00,  1.1949e+00,  1.1636e+00,  ...,  1.2249e+00,
             1.2821e+00,  1.3115e+00],
           [ 1.2402e+00,  1.1973e+00,  1.2106e+00,  ...,  1.2208e+00,
             1.2663e+00,  1.2958e+00],
           [ 1.2271e+00,  1.1829e+00,  1.2007e+00,  ...,  1.2057e+00,
             1.2522e+00,  1.2941e+00],
           ...,
           [ 4.5479e-01,  3.1748e-01,  7.6290e-02,  ...,  5.8224e-01,
             5.8224e-01,  5.8224e-01],
           [ 4.3682e-01,  2.7324e-01,  5.0348e-02,  ...,  5.9532e-01,
             5.9532e-01,  5.9532e-01],
           [ 4.0523e-01,  2.2829e-01,  1.4703e-02,  ...,  5.7952e-01,
             5.7952e-01,  5.7952e-01]],

          [[ 1.2593e+00,  1.2445e+00,  1.2548e+00,  ...,  8.1057e-01,
             8.3158e-01,  8.7582e-01],
           [ 1.2277e+00,  1.1996e+00,  1.1957e+00,  ...,  8.2637e-01,
             8.4738e-01,  8.9161e-01],
           [ 1.2244e+00,  1.1949e+00,  1.1895e+00,  ...,  8.2800e-01,
             8.4901e-01,  8.9325e-01],
           ...,
           [ 2.9793e-01,  2.9793e-01,  2.9995e-01,  ...,  6.7180e-01,
             6.5154e-01,  6.4924e-01],
           [ 2.7996e-01,  2.7996e-01,  2.9291e-01,  ...,  6.5128e-01,
             6.6423e-01,  6.5087e-01],
           [ 2.4837e-01,  2.4837e-01,  2.6132e-01,  ...,  6.2780e-01,
             6.6667e-01,  6.6667e-01]],

          [[ 8.7582e-01,  1.0380e+00,  1.1323e+00,  ...,  7.1895e-01,
             7.1895e-01,  7.1895e-01],
           [ 1.3339e+00,  1.3090e+00,  1.2753e+00,  ...,  7.4649e-01,
             7.3475e-01,  7.3475e-01],
           [ 1.3960e+00,  1.3517e+00,  1.3048e+00,  ...,  7.8253e-01,
             7.7371e-01,  7.3638e-01],
           ...,
           [-2.5327e-01, -2.5741e-01, -3.9952e-02,  ...,  5.2755e-01,
             5.5275e-01,  5.8224e-01],
           [-3.1699e-01, -1.7047e-01,  6.3496e-02,  ...,  5.8200e-01,
             5.7488e-01,  6.0022e-01],
           [-2.2222e-01,  5.7932e-02,  3.1622e-01,  ...,  6.4924e-01,
             6.4655e-01,  6.3181e-01]],

          ...,

          [[ 1.4161e+00,  1.3129e+00,  1.2293e+00,  ...,  7.1895e-01,
             7.2701e-01,  7.7124e-01],
           [ 1.3529e+00,  1.3566e+00,  1.2925e+00,  ...,  7.0721e-01,
             7.1971e-01,  7.2386e-01],
           [ 1.2435e+00,  1.3204e+00,  1.3352e+00,  ...,  7.1693e-01,
             7.1895e-01,  7.1895e-01],
           ...,
           [ 5.9967e-01,  6.1442e-01,  6.1710e-01,  ...,  7.3744e-01,
             7.5415e-01,  7.8595e-01],
           [ 6.1275e-01,  6.2749e-01,  6.3260e-01,  ...,  7.1975e-01,
             7.2512e-01,  7.6797e-01],
           [ 5.9695e-01,  6.1170e-01,  6.4029e-01,  ...,  7.2744e-01,
             7.0689e-01,  7.3638e-01]],

          [[ 1.2593e+00,  1.2445e+00,  1.2030e+00,  ...,  7.1895e-01,
             7.1895e-01,  7.1895e-01],
           [ 1.1487e+00,  1.1473e+00,  1.1434e+00,  ...,  7.1490e-01,
             7.0316e-01,  7.0316e-01],
           [ 1.1078e+00,  1.1078e+00,  1.1188e+00,  ...,  7.0355e-01,
             7.0379e-01,  7.1623e-01],
           ...,
           [ 7.8050e-01,  7.6806e-01,  6.9616e-01,  ...,  2.9488e-02,
             1.3534e-01,  4.2102e-01],
           [ 7.4292e-01,  7.4154e-01,  7.1416e-01,  ..., -1.6971e-02,
             9.0712e-02,  3.1972e-01],
           [ 8.0610e-01,  7.9136e-01,  7.4980e-01,  ...,  6.6060e-02,
             1.7332e-01,  3.3551e-01]],

          [[ 1.1024e+00,  1.1171e+00,  1.1457e+00,  ...,  7.0600e-01,
             7.1895e-01,  7.1895e-01],
           [ 1.1182e+00,  1.1062e+00,  1.1417e+00,  ...,  6.9020e-01,
             7.0316e-01,  7.0316e-01],
           [ 1.1345e+00,  1.1198e+00,  1.1341e+00,  ...,  6.9950e-01,
             6.9926e-01,  6.8682e-01],
           ...,
           [ 8.2898e-01,  8.2667e-01,  8.0237e-01,  ...,  4.9423e-01,
             4.0322e-01,  1.8573e-01],
           [ 8.6002e-01,  8.4528e-01,  8.2964e-01,  ...,  3.6235e-01,
             4.3529e-01,  3.3115e-01],
           [ 8.7582e-01,  8.6107e-01,  8.4543e-01,  ...,  3.1902e-01,
             4.2803e-01,  4.5752e-01]]],


         [[[ 1.3290e+00,  1.2995e+00,  1.2553e+00,  ...,  1.3294e+00,
             1.3947e+00,  1.4684e+00],
           [ 1.3448e+00,  1.3019e+00,  1.3022e+00,  ...,  1.3254e+00,
             1.3789e+00,  1.4526e+00],
           [ 1.3464e+00,  1.3022e+00,  1.3071e+00,  ...,  1.3103e+00,
             1.3648e+00,  1.4510e+00],
           ...,
           [ 4.3736e-01,  3.0005e-01,  7.1817e-02,  ...,  6.2978e-01,
             6.3181e-01,  6.3181e-01],
           [ 4.1939e-01,  2.5581e-01,  4.5874e-02,  ...,  6.1680e-01,
             6.2854e-01,  6.2854e-01],
           [ 3.8780e-01,  2.1086e-01,  1.0229e-02,  ...,  5.9695e-01,
             5.9695e-01,  5.9695e-01]],

          [[ 1.3464e+00,  1.3317e+00,  1.3290e+00,  ...,  8.9772e-01,
             9.2141e-01,  9.8039e-01],
           [ 1.3306e+00,  1.3025e+00,  1.2739e+00,  ...,  9.1352e-01,
             9.3721e-01,  9.9619e-01],
           [ 1.3437e+00,  1.3142e+00,  1.2938e+00,  ...,  9.1515e-01,
             9.3884e-01,  9.9782e-01],
           ...,
           [ 3.1536e-01,  3.1536e-01,  3.1738e-01,  ...,  7.0736e-01,
             6.8870e-01,  6.8410e-01],
           [ 2.9739e-01,  2.9739e-01,  3.1034e-01,  ...,  6.9183e-01,
             7.1409e-01,  6.8736e-01],
           [ 2.6580e-01,  2.6580e-01,  2.7875e-01,  ...,  6.8009e-01,
             7.1895e-01,  7.1895e-01]],

          [[ 9.1068e-01,  1.0581e+00,  1.1886e+00,  ...,  7.5381e-01,
             7.5381e-01,  7.5381e-01],
           [ 1.3687e+00,  1.3425e+00,  1.3357e+00,  ...,  7.8135e-01,
             7.6961e-01,  7.6961e-01],
           [ 1.4161e+00,  1.3843e+00,  1.3874e+00,  ...,  8.1738e-01,
             8.0856e-01,  7.7124e-01],
           ...,
           [-2.1296e-01, -2.3185e-01, -8.1695e-03,  ...,  5.8256e-01,
             6.0466e-01,  6.1710e-01],
           [-2.4891e-01, -1.1575e-01,  1.0283e-01,  ...,  6.5335e-01,
             6.4161e-01,  6.4161e-01],
           [-1.6993e-01,  1.1022e-01,  3.5555e-01,  ...,  7.3638e-01,
             7.3638e-01,  7.3638e-01]],

          ...,

          [[ 1.5033e+00,  1.4001e+00,  1.3035e+00,  ...,  8.2800e-01,
             8.5170e-01,  9.1068e-01],
           [ 1.4559e+00,  1.4462e+00,  1.3667e+00,  ...,  8.1221e-01,
             8.3104e-01,  8.6329e-01],
           [ 1.3775e+00,  1.4645e+00,  1.4355e+00,  ...,  8.1773e-01,
             8.1419e-01,  8.4368e-01],
           ...,
           [ 6.1983e-01,  6.3457e-01,  6.3726e-01,  ...,  8.4201e-01,
             8.5605e-01,  8.7309e-01],
           [ 6.4760e-01,  6.6235e-01,  6.6746e-01,  ...,  8.2432e-01,
             8.2701e-01,  8.5512e-01],
           [ 6.3181e-01,  6.4655e-01,  6.7515e-01,  ...,  8.3201e-01,
             8.0878e-01,  8.2353e-01]],

          [[ 1.3987e+00,  1.3839e+00,  1.2906e+00,  ...,  7.5381e-01,
             7.5381e-01,  7.5381e-01],
           [ 1.3039e+00,  1.2892e+00,  1.2310e+00,  ...,  7.4976e-01,
             7.3802e-01,  7.3802e-01],
           [ 1.2647e+00,  1.2624e+00,  1.2539e+00,  ...,  7.3841e-01,
             7.3865e-01,  7.5109e-01],
           ...,
           [ 8.3551e-01,  8.2077e-01,  7.4845e-01,  ...,  8.1776e-02,
             1.8763e-01,  4.7331e-01],
           [ 8.0937e-01,  7.9601e-01,  7.6645e-01,  ...,  3.5317e-02,
             1.4300e-01,  3.7200e-01],
           [ 8.4096e-01,  8.4096e-01,  8.0209e-01,  ...,  1.1835e-01,
             2.2561e-01,  3.8780e-01]],

          [[ 1.2767e+00,  1.2767e+00,  1.2896e+00,  ...,  7.4086e-01,
             7.5381e-01,  7.5381e-01],
           [ 1.2767e+00,  1.2633e+00,  1.2856e+00,  ...,  7.2506e-01,
             7.3802e-01,  7.3802e-01],
           [ 1.2914e+00,  1.2766e+00,  1.2780e+00,  ...,  7.3436e-01,
             7.3412e-01,  7.2168e-01],
           ...,
           [ 8.6383e-01,  8.6153e-01,  8.4816e-01,  ...,  5.6394e-01,
             4.7293e-01,  2.5545e-01],
           [ 8.9488e-01,  8.8014e-01,  8.6450e-01,  ...,  4.3206e-01,
             5.0501e-01,  4.0087e-01],
           [ 9.1068e-01,  8.9593e-01,  8.8029e-01,  ...,  3.8873e-01,
             4.9774e-01,  5.2723e-01]]]],



        [[[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.8883e+00,  1.5798e+00,  1.4756e+00,  ..., -1.4597e+00,
            -1.4597e+00, -1.4769e+00],
           [ 1.9499e+00,  1.8502e+00,  1.7221e+00,  ..., -1.4597e+00,
            -1.4597e+00, -1.4769e+00],
           [ 1.4933e+00,  2.1278e+00,  2.2224e+00,  ..., -1.4597e+00,
            -1.4597e+00, -1.4769e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.8883e+00,  1.5798e+00,  1.4756e+00,  ..., -1.4597e+00,
            -1.4597e+00, -1.4769e+00],
           [ 1.9499e+00,  1.8502e+00,  1.7221e+00,  ..., -1.4597e+00,
            -1.4597e+00, -1.4769e+00],
           [ 1.4933e+00,  2.1278e+00,  2.2224e+00,  ..., -1.4597e+00,
            -1.4597e+00, -1.4769e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [-4.8199e-01, -1.5519e-01, -1.3071e-01,  ..., -1.2453e+00,
            -1.2644e+00, -1.2651e+00],
           [-6.5430e-01, -2.5281e-01, -2.6486e-02,  ..., -1.2785e+00,
            -1.2986e+00, -1.2993e+00],
           [-5.7458e-01, -5.8813e-01, -4.2184e-01,  ..., -1.2651e+00,
            -1.3015e+00, -1.3028e+00]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 5.2716e-01,  7.3346e-01,  7.9435e-01,  ..., -1.1454e+00,
            -1.1598e+00, -1.1462e+00],
           [ 3.7131e-01,  5.7183e-01,  7.6198e-01,  ..., -1.1807e+00,
            -1.1790e+00, -1.1619e+00],
           [ 2.2165e-01,  4.9042e-01,  8.2248e-01,  ..., -1.1675e+00,
            -1.1640e+00, -1.1468e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.4220e-01,  3.8873e-02, -3.7883e-03,  ..., -1.1278e+00,
            -1.1312e+00, -1.1257e+00],
           [ 4.2642e-01,  5.5592e-02, -2.9189e-01,  ..., -1.1466e+00,
            -1.1743e+00, -1.1756e+00],
           [ 4.8833e-01,  2.6417e-01, -3.4586e-02,  ..., -1.1786e+00,
            -1.1646e+00, -1.1640e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 8.7768e-01,  1.0205e+00,  1.0096e+00,  ..., -1.1111e+00,
            -1.1446e+00, -1.1460e+00],
           [ 1.0508e+00,  1.1097e+00,  1.0759e+00,  ..., -1.1111e+00,
            -1.1596e+00, -1.1616e+00],
           [ 1.1181e+00,  1.1184e+00,  1.0849e+00,  ..., -1.1111e+00,
            -1.1451e+00, -1.1466e+00]]],


         [[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.1534e+00,  8.4645e-01,  7.1258e-01,  ..., -1.7386e+00,
            -1.7386e+00, -1.7558e+00],
           [ 1.1708e+00,  1.0679e+00,  8.6128e-01,  ..., -1.7386e+00,
            -1.7386e+00, -1.7558e+00],
           [ 7.0898e-01,  1.3407e+00,  1.3678e+00,  ..., -1.7386e+00,
            -1.7386e+00, -1.7558e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.1534e+00,  8.4645e-01,  7.1258e-01,  ..., -1.7386e+00,
            -1.7386e+00, -1.7558e+00],
           [ 1.1708e+00,  1.0679e+00,  8.6128e-01,  ..., -1.7386e+00,
            -1.7386e+00, -1.7558e+00],
           [ 7.0898e-01,  1.3407e+00,  1.3678e+00,  ..., -1.7386e+00,
            -1.7386e+00, -1.7558e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [-1.0254e+00, -7.1281e-01, -6.8552e-01,  ..., -1.5939e+00,
            -1.5795e+00, -1.5788e+00],
           [-1.1946e+00, -7.9612e-01, -5.9885e-01,  ..., -1.6271e+00,
            -1.6138e+00, -1.6131e+00],
           [-1.1149e+00, -1.1292e+00, -9.8012e-01,  ..., -1.6136e+00,
            -1.6166e+00, -1.6166e+00]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [-2.2522e-01, -1.9728e-02,  2.1828e-02,  ..., -1.4648e+00,
            -1.4236e+00, -1.4076e+00],
           [-3.3090e-01, -1.1372e-01,  1.0484e-01,  ..., -1.4485e+00,
            -1.4407e+00, -1.4079e+00],
           [-4.7551e-01, -2.0476e-01,  1.6075e-01,  ..., -1.4458e+00,
            -1.4423e+00, -1.4245e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [-5.5205e-01, -6.5771e-01, -7.5713e-01,  ..., -1.4830e+00,
            -1.4800e+00, -1.4743e+00],
           [-2.7074e-01, -6.4179e-01, -9.9548e-01,  ..., -1.4785e+00,
            -1.5072e+00, -1.5085e+00],
           [-2.0884e-01, -4.3367e-01, -7.4977e-01,  ..., -1.5097e+00,
            -1.4958e+00, -1.4951e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 6.2242e-03,  1.4908e-01,  1.3718e-01,  ..., -1.4248e+00,
            -1.3914e+00, -1.3900e+00],
           [ 1.3256e-01,  2.0693e-01,  1.7293e-01,  ..., -1.4248e+00,
            -1.3914e+00, -1.3900e+00],
           [ 1.9458e-01,  2.1211e-01,  1.7857e-01,  ..., -1.4248e+00,
            -1.4075e+00, -1.4068e+00]]],


         [[[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.9144e+00,  1.5948e+00,  1.5018e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [ 1.6224e+00,  1.5229e+00,  1.4406e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [ 1.1441e+00,  1.7801e+00,  1.9086e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.9144e+00,  1.5948e+00,  1.5018e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [ 1.6224e+00,  1.5229e+00,  1.4406e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00],
           [ 1.1441e+00,  1.7801e+00,  1.9086e+00,  ..., -2.0000e+00,
            -2.0000e+00, -2.0000e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [-1.2693e+00, -9.4802e-01, -9.8863e-01,  ..., -1.9076e+00,
            -1.9099e+00, -1.9099e+00],
           [-1.3759e+00, -9.7784e-01, -8.3360e-01,  ..., -1.9408e+00,
            -1.9442e+00, -1.9442e+00],
           [-1.2555e+00, -1.2732e+00, -1.2056e+00,  ..., -1.9274e+00,
            -1.9470e+00, -1.9477e+00]],

          ...,

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [-1.9324e-01,  1.6648e-02,  9.4267e-02,  ..., -1.7419e+00,
            -1.7692e+00, -1.7562e+00],
           [-2.6468e-01, -4.7365e-02,  1.7456e-01,  ..., -1.7431e+00,
            -1.7871e+00, -1.7564e+00],
           [-4.0580e-01, -1.3437e-01,  2.4618e-01,  ..., -1.7421e+00,
            -1.7726e+00, -1.7729e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [-6.7698e-01, -7.7832e-01, -7.7359e-01,  ..., -1.7417e+00,
            -1.7776e+00, -1.7735e+00],
           [-3.6139e-01, -7.2886e-01, -9.9606e-01,  ..., -1.7556e+00,
            -1.7726e+00, -1.7734e+00],
           [-2.7937e-01, -5.1799e-01, -7.6544e-01,  ..., -1.7886e+00,
            -1.7741e+00, -1.7734e+00]],

          [[ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           ...,
           [ 1.4566e-01,  2.8852e-01,  2.7661e-01,  ..., -1.7908e+00,
            -1.8243e+00, -1.8257e+00],
           [ 2.7200e-01,  3.4636e-01,  3.1236e-01,  ..., -1.7908e+00,
            -1.8394e+00, -1.8414e+00],
           [ 3.3402e-01,  3.5154e-01,  3.1800e-01,  ..., -1.7908e+00,
            -1.8249e+00, -1.8263e+00]]]],



        [[[[-1.9692e+00, -1.9716e+00, -1.9482e+00,  ..., -1.7174e+00,
            -1.7953e+00, -1.7918e+00],
           [-1.9826e+00, -1.9928e+00, -1.9606e+00,  ..., -1.8906e+00,
            -1.9517e+00, -1.8978e+00],
           [-1.9657e+00, -1.9766e+00, -1.9997e+00,  ..., -2.0000e+00,
            -1.9988e+00, -1.9714e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.7936e+00, -1.9365e+00, -1.9677e+00,  ..., -1.7625e+00,
            -1.7294e+00, -1.7506e+00],
           [-1.9221e+00, -1.6272e+00, -1.4495e+00,  ..., -1.6170e+00,
            -1.8872e+00, -1.8571e+00],
           [-1.5133e+00, -1.3094e+00, -1.1911e+00,  ..., -1.9999e+00,
            -1.9649e+00, -1.9162e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.4676e+00, -1.0554e+00, -1.2579e+00,  ..., -1.7601e+00,
            -1.4582e+00, -1.4070e+00],
           [-3.5900e-01, -7.8138e-01, -1.5241e+00,  ..., -1.7868e+00,
            -1.6400e+00, -1.9077e+00],
           [-7.3227e-01, -1.4367e+00, -1.9478e+00,  ..., -1.6477e+00,
            -1.7781e+00, -1.9885e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          ...,

          [[-1.8100e+00, -1.7935e+00, -1.8806e+00,  ..., -1.5442e+00,
            -1.5217e+00, -1.7725e+00],
           [-1.8350e+00, -1.8005e+00, -1.8705e+00,  ..., -1.5155e+00,
            -1.5121e+00, -1.8725e+00],
           [-1.8295e+00, -1.8601e+00, -1.9179e+00,  ..., -1.5888e+00,
            -1.7804e+00, -1.6163e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.6012e+00, -1.7156e+00, -1.6307e+00,  ..., -1.4879e+00,
            -1.6804e+00, -1.6646e+00],
           [-1.5900e+00, -1.6393e+00, -1.7520e+00,  ..., -1.9051e+00,
            -1.8207e+00, -1.4634e+00],
           [-1.7574e+00, -1.7424e+00, -1.8499e+00,  ..., -1.8403e+00,
            -1.5438e+00, -1.6519e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.7295e+00, -1.6593e+00, -1.7130e+00,  ..., -1.6427e+00,
            -1.7437e+00, -1.5977e+00],
           [-1.6402e+00, -1.7180e+00, -1.8193e+00,  ..., -1.9308e+00,
            -1.5646e+00, -1.5555e+00],
           [-1.6826e+00, -1.8001e+00, -1.7683e+00,  ..., -1.6402e+00,
            -1.5927e+00, -1.9084e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]]],


         [[[-1.9518e+00, -1.9723e+00, -1.9524e+00,  ..., -1.7305e+00,
            -1.7937e+00, -1.7878e+00],
           [-1.9773e+00, -1.9835e+00, -1.9655e+00,  ..., -1.8785e+00,
            -1.9374e+00, -1.8901e+00],
           [-1.9600e+00, -1.9591e+00, -1.9823e+00,  ..., -1.9969e+00,
            -1.9743e+00, -1.9388e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.7171e+00, -1.8945e+00, -1.9553e+00,  ..., -1.7625e+00,
            -1.7294e+00, -1.7754e+00],
           [-1.8698e+00, -1.5749e+00, -1.3853e+00,  ..., -1.6170e+00,
            -1.8972e+00, -1.8662e+00],
           [-1.4610e+00, -1.2571e+00, -1.1531e+00,  ..., -1.9999e+00,
            -1.9792e+00, -1.9488e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.3411e+00, -9.2669e-01, -1.1516e+00,  ..., -1.7122e+00,
            -1.4026e+00, -1.3126e+00],
           [-2.7289e-01, -7.1695e-01, -1.4480e+00,  ..., -1.7397e+00,
            -1.5603e+00, -1.8355e+00],
           [-6.3454e-01, -1.3465e+00, -1.8344e+00,  ..., -1.6043e+00,
            -1.7415e+00, -1.9759e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          ...,

          [[-1.7577e+00, -1.7413e+00, -1.8283e+00,  ..., -1.5093e+00,
            -1.4773e+00, -1.7235e+00],
           [-1.7730e+00, -1.7554e+00, -1.8184e+00,  ..., -1.4686e+00,
            -1.4719e+00, -1.8366e+00],
           [-1.8330e+00, -1.8586e+00, -1.8745e+00,  ..., -1.5766e+00,
            -1.7389e+00, -1.5635e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.5195e+00, -1.6074e+00, -1.5509e+00,  ..., -1.4527e+00,
            -1.6281e+00, -1.6230e+00],
           [-1.5377e+00, -1.5941e+00, -1.7237e+00,  ..., -1.8938e+00,
            -1.7684e+00, -1.4014e+00],
           [-1.7131e+00, -1.7462e+00, -1.8474e+00,  ..., -1.7881e+00,
            -1.4938e+00, -1.5963e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.5914e+00, -1.5771e+00, -1.6473e+00,  ..., -1.6036e+00,
            -1.6914e+00, -1.5454e+00],
           [-1.5879e+00, -1.6728e+00, -1.7792e+00,  ..., -1.8785e+00,
            -1.5173e+00, -1.4958e+00],
           [-1.6877e+00, -1.8147e+00, -1.7686e+00,  ..., -1.5907e+00,
            -1.5508e+00, -1.8573e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]]],


         [[[-1.8612e+00, -1.8448e+00, -1.8089e+00,  ..., -1.5643e+00,
            -1.6253e+00, -1.6410e+00],
           [-1.8746e+00, -1.8646e+00, -1.8332e+00,  ..., -1.7755e+00,
            -1.8388e+00, -1.7922e+00],
           [-1.9017e+00, -1.9345e+00, -1.9017e+00,  ..., -1.9533e+00,
            -1.9533e+00, -1.9231e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.6726e+00, -1.7991e+00, -1.9176e+00,  ..., -1.6019e+00,
            -1.5059e+00, -1.5173e+00],
           [-1.7487e+00, -1.4190e+00, -1.2282e+00,  ..., -1.4145e+00,
            -1.6638e+00, -1.6034e+00],
           [-1.3019e+00, -1.1019e+00, -1.0018e+00,  ..., -1.9346e+00,
            -1.8093e+00, -1.8193e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.1760e+00, -7.1826e-01, -9.2104e-01,  ..., -1.5553e+00,
            -1.2485e+00, -1.1658e+00],
           [-8.1999e-02, -4.9038e-01, -1.2279e+00,  ..., -1.5950e+00,
            -1.4514e+00, -1.7821e+00],
           [-4.6025e-01, -1.1825e+00, -1.6659e+00,  ..., -1.5489e+00,
            -1.7332e+00, -1.9828e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          ...,

          [[-1.5660e+00, -1.5789e+00, -1.6754e+00,  ..., -1.1863e+00,
            -1.1654e+00, -1.4187e+00],
           [-1.6161e+00, -1.5985e+00, -1.6906e+00,  ..., -1.2324e+00,
            -1.2024e+00, -1.5588e+00],
           [-1.6626e+00, -1.7251e+00, -1.7526e+00,  ..., -1.3731e+00,
            -1.5370e+00, -1.3694e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.3493e+00, -1.4530e+00, -1.3943e+00,  ..., -1.2439e+00,
            -1.4452e+00, -1.4668e+00],
           [-1.3809e+00, -1.4373e+00, -1.5669e+00,  ..., -1.6969e+00,
            -1.5910e+00, -1.2488e+00],
           [-1.5636e+00, -1.6073e+00, -1.7108e+00,  ..., -1.6025e+00,
            -1.3529e+00, -1.4625e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]],

          [[-1.4453e+00, -1.4124e+00, -1.4902e+00,  ..., -1.3854e+00,
            -1.5085e+00, -1.3886e+00],
           [-1.4311e+00, -1.5231e+00, -1.6345e+00,  ..., -1.6992e+00,
            -1.3573e+00, -1.3390e+00],
           [-1.5483e+00, -1.6770e+00, -1.6292e+00,  ..., -1.4597e+00,
            -1.4152e+00, -1.7033e+00],
           ...,
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01],
           [ 2.3094e-01,  2.3094e-01,  2.3094e-01,  ...,  2.3094e-01,
             2.3094e-01,  2.3094e-01]]]]], device='cuda:0')]
[03/06 19:13:03][INFO] train_net.py: 414: Train with config:
[03/06 19:13:03][INFO] train_net.py: 415: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:13:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:13:04][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:13:04][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:13:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:13:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:13:05][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:13:05][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:13:05][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:13:06][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:13:06][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:13:06][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:13:06][INFO] misc.py: 187: Flops: 0 G
[03/06 19:13:06][INFO] misc.py: 192: Activations: 0 M
[03/06 19:13:06][INFO] misc.py: 197: nvidia-smi
[03/06 19:13:06][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:13:06][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 19:13:06][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:13:07][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:13:07][INFO] kinetics_sparse.py:  78: Constructing Kinetics val...
[03/06 19:13:07][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:13:07][INFO] kinetics_sparse.py: 127: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:13:07][INFO] train_net.py: 457: Start epoch: 1
[03/06 19:13:14][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:14][INFO] train_net.py:  94: tensor([ 40,   1,   2,  15,   2, 102, 102, 102, 123,  68, 102,  40,  97,   2,
         40,   2], device='cuda:0')
[03/06 19:13:17][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:17][INFO] train_net.py:  94: tensor([  2,  78, 102,  78,  99, 123,  68,   1,  40,  78,  47, 104,  40,  15,
         32, 102], device='cuda:0')
[03/06 19:13:22][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:22][INFO] train_net.py:  94: tensor([102,  38,  68,  78,  98,  68,  68,  40, 104, 102,  67,  78, 133, 133,
         16,  78], device='cuda:0')
[03/06 19:13:25][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:25][INFO] train_net.py:  94: tensor([102, 102, 114,  40,  15,  68,  48, 114,   2,  38, 104,  38,   5,   2,
         98, 133], device='cuda:0')
[03/06 19:13:28][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:28][INFO] train_net.py:  94: tensor([ 78, 102, 128,  68,  40,  40, 102,  38, 102,  28,   2,  68, 112,  68,
         78,   2], device='cuda:0')
[03/06 19:13:32][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:32][INFO] train_net.py:  94: tensor([ 68, 102,  68,  48, 102,  68, 104, 123,  84,  26,  68,  48,  78, 104,
        104,  13], device='cuda:0')
[03/06 19:13:37][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:37][INFO] train_net.py:  94: tensor([102,  67,  68,  68,   2,  48,  68, 123,  68, 102,  15,  38,  48,   2,
        133,  40], device='cuda:0')
[03/06 19:13:40][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:40][INFO] train_net.py:  94: tensor([ 40,  40, 102,  40,  52, 102, 102,  52, 104,   2,  78, 128,  16,   2,
        102, 133], device='cuda:0')
[03/06 19:13:44][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:44][INFO] train_net.py:  94: tensor([133,  68,  68, 102,  58,  52, 133, 104,   1,  40, 102,  68,  20,  15,
        123, 102], device='cuda:0')
[03/06 19:13:47][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:47][INFO] train_net.py:  94: tensor([135,  58,  40,  68, 123,  78,  80, 102,  68,  52,  32, 123, 133,  15,
        127,  68], device='cuda:0')
[03/06 19:13:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30545, "dt_data": 2.78456, "dt_net": 0.52089, "epoch": "1/55", "eta": "18:55:41", "gpu_mem": "13.93G", "iter": "10/375", "loss": 4.91161, "lr": 0.00000, "top1_err": 97.65625, "top5_err": 89.84375}
[03/06 19:13:52][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:52][INFO] train_net.py:  94: tensor([ 68, 102, 133, 123,  69, 114,  40, 102, 133,  78, 133,  68,  78, 133,
         40,  78], device='cuda:0')
[03/06 19:13:56][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:13:56][INFO] train_net.py:  94: tensor([ 47,  40,  38,  36,  68, 133, 102,  78,  52, 133,   2, 128,  40, 133,
        102,  40], device='cuda:0')
[03/06 19:14:00][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:14:00][INFO] train_net.py:  94: tensor([ 38, 120,   8,   2,  69,  38,  68,  45,  68,  58, 108,  40,  40, 133,
        102, 102], device='cuda:0')
[03/06 19:29:27][INFO] train_net.py: 414: Train with config:
[03/06 19:29:27][INFO] train_net.py: 415: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:29:28][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:29:28][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:29:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:29:28][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:29:28][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:29:28][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:29:29][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:29:29][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:29:29][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:29:29][INFO] misc.py: 187: Flops: 0 G
[03/06 19:29:29][INFO] misc.py: 192: Activations: 0 M
[03/06 19:29:29][INFO] misc.py: 197: nvidia-smi
[03/06 19:29:30][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:29:30][INFO] kinetics_sparse.py:  78: Constructing Kinetics train...
[03/06 19:29:30][INFO] kinetics_sparse.py: 104: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:30:03][INFO] train_net.py: 414: Train with config:
[03/06 19:30:03][INFO] train_net.py: 415: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:30:04][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:30:04][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:30:04][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:30:05][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:30:05][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:30:05][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:30:05][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:30:05][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:30:06][INFO] misc.py: 187: Flops: 0 G
[03/06 19:30:06][INFO] misc.py: 192: Activations: 0 M
[03/06 19:30:06][INFO] misc.py: 197: nvidia-smi
[03/06 19:30:06][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:30:06][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 19:30:06][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:31:40][INFO] train_net.py: 414: Train with config:
[03/06 19:31:40][INFO] train_net.py: 415: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:40][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:41][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:41][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:41][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:41][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:31:41][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:31:41][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:31:41][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:31:41][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:31:41][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:31:41][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:31:41][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:31:41][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:31:41][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:31:41][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:31:41][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:31:42][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:31:42][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:31:42][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:31:42][INFO] misc.py: 187: Flops: 0 G
[03/06 19:31:42][INFO] misc.py: 192: Activations: 0 M
[03/06 19:31:42][INFO] misc.py: 197: nvidia-smi
[03/06 19:31:43][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:31:43][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 19:31:43][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:32:04][INFO] train_net.py: 414: Train with config:
[03/06 19:32:04][INFO] train_net.py: 415: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:32:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:32:05][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:32:05][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:32:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:32:05][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:32:06][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:32:06][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:32:07][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:32:07][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:32:07][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:32:07][INFO] misc.py: 187: Flops: 0 G
[03/06 19:32:07][INFO] misc.py: 192: Activations: 0 M
[03/06 19:32:07][INFO] misc.py: 197: nvidia-smi
[03/06 19:32:07][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:32:07][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 19:32:07][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:32:08][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:32:08][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 19:32:08][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:32:08][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:32:08][INFO] train_net.py: 457: Start epoch: 1
[03/06 19:33:38][INFO] train_net.py: 414: Train with config:
[03/06 19:33:38][INFO] train_net.py: 415: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logits', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:33:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:33:39][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:33:39][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:33:39][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:33:39][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:33:40][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:33:40][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:33:40][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:33:40][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:33:40][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:33:41][INFO] misc.py: 187: Flops: 0 G
[03/06 19:33:41][INFO] misc.py: 192: Activations: 0 M
[03/06 19:33:41][INFO] misc.py: 197: nvidia-smi
[03/06 19:33:41][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:33:41][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 19:33:41][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:33:42][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:33:42][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 19:33:42][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:33:42][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:33:42][INFO] train_net.py: 457: Start epoch: 1
[03/06 19:34:35][INFO] train_net.py: 414: Train with config:
[03/06 19:34:35][INFO] train_net.py: 415: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 19:34:35][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 19:34:35][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 19:34:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:34:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:34:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:34:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 19:34:36][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 19:34:36][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 19:34:36][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 19:34:37][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 19:34:37][INFO] misc.py: 185: Params: 114,352,268
[03/06 19:34:37][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 19:34:37][INFO] misc.py: 187: Flops: 0 G
[03/06 19:34:37][INFO] misc.py: 192: Activations: 0 M
[03/06 19:34:37][INFO] misc.py: 197: nvidia-smi
[03/06 19:34:38][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 19:34:38][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 19:34:38][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:34:38][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 19:34:38][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 19:34:38][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:34:38][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 19:34:38][INFO] train_net.py: 457: Start epoch: 1
[03/06 19:34:45][INFO] train_net.py:  93: labels:::::-----------------
[03/06 19:34:45][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 20:17:03][INFO] train_net.py: 413: Train with config:
[03/06 20:17:03][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:03][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 20:17:03][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 20:17:03][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:03][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:04][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 20:17:04][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 20:17:04][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 20:17:05][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 20:17:05][INFO] misc.py: 185: Params: 114,352,268
[03/06 20:17:05][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 20:17:05][INFO] misc.py: 187: Flops: 0 G
[03/06 20:17:05][INFO] misc.py: 192: Activations: 0 M
[03/06 20:17:05][INFO] misc.py: 197: nvidia-smi
[03/06 20:17:06][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 20:17:06][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 20:17:06][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:17:06][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:17:06][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 20:17:06][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:17:06][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:17:06][INFO] train_net.py: 456: Start epoch: 1
[03/06 20:17:14][INFO] train_net.py:  93: labels:::::-----------------
[03/06 20:17:14][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 20:17:50][INFO] train_net.py: 413: Train with config:
[03/06 20:17:50][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:17:50][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 20:17:50][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 20:17:50][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:50][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:17:51][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 20:17:51][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 20:17:51][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 20:17:52][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 20:17:52][INFO] misc.py: 185: Params: 114,352,268
[03/06 20:17:52][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 20:17:52][INFO] misc.py: 187: Flops: 0 G
[03/06 20:17:52][INFO] misc.py: 192: Activations: 0 M
[03/06 20:17:52][INFO] misc.py: 197: nvidia-smi
[03/06 20:17:53][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 20:17:53][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 20:17:53][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:17:53][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:17:53][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 20:17:53][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:17:53][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:17:53][INFO] train_net.py: 456: Start epoch: 1
[03/06 20:18:01][INFO] train_net.py:  93: labels:::::-----------------
[03/06 20:18:01][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 20:20:16][INFO] train_net.py: 413: Train with config:
[03/06 20:20:16][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 20:20:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:20:17][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 20:20:17][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 20:20:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:20:17][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 20:20:17][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 20:20:17][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 20:20:18][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 20:20:18][INFO] misc.py: 185: Params: 114,352,268
[03/06 20:20:18][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 20:20:18][INFO] misc.py: 187: Flops: 0 G
[03/06 20:20:18][INFO] misc.py: 192: Activations: 0 M
[03/06 20:20:18][INFO] misc.py: 197: nvidia-smi
[03/06 20:20:19][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 20:20:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 20:20:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:20:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:20:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 20:20:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:20:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:20:19][INFO] train_net.py: 456: Start epoch: 1
[03/06 20:20:27][INFO] train_net.py:  93: labels:::::-----------------
[03/06 20:20:27][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 20:26:17][INFO] train_net.py: 413: Train with config:
[03/06 20:26:17][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 20:26:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:26:18][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 20:26:18][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 20:26:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:26:18][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 20:26:19][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 20:26:19][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 20:26:19][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 20:26:19][INFO] misc.py: 185: Params: 114,352,268
[03/06 20:26:19][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 20:26:19][INFO] misc.py: 187: Flops: 0 G
[03/06 20:26:20][INFO] misc.py: 192: Activations: 0 M
[03/06 20:26:20][INFO] misc.py: 197: nvidia-smi
[03/06 20:26:20][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 20:26:20][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 20:26:20][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:26:21][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:26:21][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 20:26:21][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:26:21][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:26:21][INFO] train_net.py: 456: Start epoch: 1
[03/06 20:26:28][INFO] train_net.py:  93: labels:::::-----------------
[03/06 20:26:28][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 20:27:26][INFO] train_net.py: 413: Train with config:
[03/06 20:27:26][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 20:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:26][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:26][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:26][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 20:27:27][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 20:27:27][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 20:27:27][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 20:27:27][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 20:27:28][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 20:27:28][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 20:27:28][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 20:27:28][INFO] misc.py: 185: Params: 114,352,268
[03/06 20:27:28][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 20:27:28][INFO] misc.py: 187: Flops: 0 G
[03/06 20:27:28][INFO] misc.py: 192: Activations: 0 M
[03/06 20:27:28][INFO] misc.py: 197: nvidia-smi
[03/06 20:27:29][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 20:27:29][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 20:27:29][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:27:29][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 20:27:29][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 20:27:29][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:27:29][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 20:27:29][INFO] train_net.py: 456: Start epoch: 1
[03/06 20:27:37][INFO] train_net.py:  93: labels:::::-----------------
[03/06 20:27:37][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:00:37][INFO] train_net.py: 413: Train with config:
[03/06 21:00:37][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:00:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:00:38][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:00:38][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:00:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:00:38][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:00:38][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:00:38][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:00:39][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:00:39][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:00:39][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:00:40][INFO] misc.py: 187: Flops: 0 G
[03/06 21:00:40][INFO] misc.py: 192: Activations: 0 M
[03/06 21:00:40][INFO] misc.py: 197: nvidia-smi
[03/06 21:00:40][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:00:40][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:00:40][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:00:41][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:00:41][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:00:41][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:00:41][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:00:41][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:00:48][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:00:48][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:01:19][INFO] train_net.py: 413: Train with config:
[03/06 21:01:19][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:01:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:01:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:01:20][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:01:20][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:01:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:01:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:01:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:01:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:01:20][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:01:20][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:01:20][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:01:21][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:01:21][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:01:21][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:01:21][INFO] misc.py: 187: Flops: 0 G
[03/06 21:01:21][INFO] misc.py: 192: Activations: 0 M
[03/06 21:01:21][INFO] misc.py: 197: nvidia-smi
[03/06 21:01:22][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:01:22][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:01:22][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:01:22][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:01:22][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:01:22][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:01:22][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:01:22][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:01:30][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:01:30][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:05:01][INFO] train_net.py: 413: Train with config:
[03/06 21:05:01][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:05:01][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:01][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:05:02][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:05:02][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:05:02][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:05:02][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:05:03][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:05:03][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:05:03][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:05:03][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:05:03][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:05:04][INFO] misc.py: 187: Flops: 0 G
[03/06 21:05:04][INFO] misc.py: 192: Activations: 0 M
[03/06 21:05:04][INFO] misc.py: 197: nvidia-smi
[03/06 21:05:04][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:05:04][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:05:04][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:05:05][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:05:05][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:05:05][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:05:05][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:05:05][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:05:12][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:05:12][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:06:45][INFO] train_net.py: 413: Train with config:
[03/06 21:06:45][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:06:45][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:06:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:06:46][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:06:46][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:06:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:06:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:06:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:06:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:06:46][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:06:46][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:06:46][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:06:47][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:06:47][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:06:47][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:06:47][INFO] misc.py: 187: Flops: 0 G
[03/06 21:06:47][INFO] misc.py: 192: Activations: 0 M
[03/06 21:06:47][INFO] misc.py: 197: nvidia-smi
[03/06 21:06:48][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:06:48][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:06:48][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:06:48][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:06:48][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:06:48][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:06:48][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:06:48][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:06:55][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:06:55][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:11:43][INFO] train_net.py: 413: Train with config:
[03/06 21:11:43][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:11:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:11:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:11:44][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:11:44][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:11:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:11:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:11:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:11:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:11:44][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:11:44][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:11:44][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:11:45][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:11:45][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:11:45][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:11:45][INFO] misc.py: 187: Flops: 0 G
[03/06 21:11:45][INFO] misc.py: 192: Activations: 0 M
[03/06 21:11:45][INFO] misc.py: 197: nvidia-smi
[03/06 21:11:46][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:11:46][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:11:46][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:11:46][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:11:46][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:11:46][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:11:46][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:11:46][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:11:54][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:11:54][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:12:51][INFO] train_net.py: 413: Train with config:
[03/06 21:12:51][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:12:51][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:12:51][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:12:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:12:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:12:52][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:12:52][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:12:52][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:12:53][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:12:53][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:12:53][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:12:53][INFO] misc.py: 187: Flops: 0 G
[03/06 21:12:53][INFO] misc.py: 192: Activations: 0 M
[03/06 21:12:53][INFO] misc.py: 197: nvidia-smi
[03/06 21:12:54][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:12:54][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:12:54][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:12:54][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:12:54][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:12:54][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:12:54][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:12:54][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:13:01][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:13:01][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:14:19][INFO] train_net.py: 413: Train with config:
[03/06 21:14:19][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:14:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:19][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:19][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:14:20][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:14:20][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:14:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:14:20][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:14:20][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:14:20][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:14:21][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:14:21][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:14:21][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:14:21][INFO] misc.py: 187: Flops: 0 G
[03/06 21:14:21][INFO] misc.py: 192: Activations: 0 M
[03/06 21:14:21][INFO] misc.py: 197: nvidia-smi
[03/06 21:14:22][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:14:22][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:14:22][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:14:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:14:23][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:14:23][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:14:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:14:23][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:14:30][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:14:30][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:15:10][INFO] train_net.py: 413: Train with config:
[03/06 21:15:10][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:10][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:15:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:15:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:15:11][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:15:11][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:15:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:15:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:15:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:15:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:15:11][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:15:11][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:15:11][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:15:12][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:15:12][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:15:12][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:15:12][INFO] misc.py: 187: Flops: 0 G
[03/06 21:15:12][INFO] misc.py: 192: Activations: 0 M
[03/06 21:15:12][INFO] misc.py: 197: nvidia-smi
[03/06 21:15:13][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:15:13][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:15:13][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:15:13][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:15:13][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:15:13][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:15:13][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:15:13][INFO] train_net.py: 456: Start epoch: 1
[03/06 21:15:20][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:15:20][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:22:17][INFO] train_net.py: 415: Train with config:
[03/06 21:22:17][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:22:18][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:22:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:22:18][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:22:18][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:22:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:22:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:22:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:22:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:22:18][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:22:18][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:22:18][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:22:19][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:22:19][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:22:19][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:22:19][INFO] misc.py: 187: Flops: 0 G
[03/06 21:22:19][INFO] misc.py: 192: Activations: 0 M
[03/06 21:22:19][INFO] misc.py: 197: nvidia-smi
[03/06 21:22:20][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:22:20][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:22:20][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:22:20][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:22:20][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:22:20][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:22:20][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:22:20][INFO] train_net.py: 458: Start epoch: 1
[03/06 21:22:27][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:22:27][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:23:36][INFO] train_net.py: 415: Train with config:
[03/06 21:23:36][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:23:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:23:37][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:23:37][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:23:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:23:37][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:23:38][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:23:38][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:23:38][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:23:38][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:23:38][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:23:39][INFO] misc.py: 187: Flops: 0 G
[03/06 21:23:39][INFO] misc.py: 192: Activations: 0 M
[03/06 21:23:39][INFO] misc.py: 197: nvidia-smi
[03/06 21:23:39][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:23:39][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:23:39][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:23:40][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:23:40][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:23:40][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:23:40][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:23:40][INFO] train_net.py: 458: Start epoch: 1
[03/06 21:23:47][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:23:47][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:24:27][INFO] train_net.py: 415: Train with config:
[03/06 21:24:27][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:24:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:27][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:24:28][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:24:28][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:24:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:24:28][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:24:28][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:24:28][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:24:29][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:24:29][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:24:29][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:24:29][INFO] misc.py: 187: Flops: 0 G
[03/06 21:24:29][INFO] misc.py: 192: Activations: 0 M
[03/06 21:24:29][INFO] misc.py: 197: nvidia-smi
[03/06 21:24:30][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:24:30][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:24:30][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:24:30][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:24:30][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:24:30][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:24:30][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:24:30][INFO] train_net.py: 458: Start epoch: 1
[03/06 21:24:38][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:24:38][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:25:04][INFO] train_net.py: 415: Train with config:
[03/06 21:25:04][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:25:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:25:05][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:25:05][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:25:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:25:05][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:25:05][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:25:05][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:25:06][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:25:06][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:25:06][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:25:06][INFO] misc.py: 187: Flops: 0 G
[03/06 21:25:06][INFO] misc.py: 192: Activations: 0 M
[03/06 21:25:06][INFO] misc.py: 197: nvidia-smi
[03/06 21:25:07][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:25:07][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:25:07][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:25:07][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:25:07][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:25:07][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:25:07][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:25:07][INFO] train_net.py: 458: Start epoch: 1
[03/06 21:25:15][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:25:15][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:27:55][INFO] train_net.py: 415: Train with config:
[03/06 21:27:55][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:27:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:55][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:55][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:55][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:27:56][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:27:56][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:27:56][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:27:56][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:27:57][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:27:57][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:27:57][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:27:57][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:27:57][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:27:58][INFO] misc.py: 187: Flops: 0 G
[03/06 21:27:58][INFO] misc.py: 192: Activations: 0 M
[03/06 21:27:58][INFO] misc.py: 197: nvidia-smi
[03/06 21:27:58][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:27:58][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:27:58][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:27:58][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:27:58][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:27:58][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:27:58][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:27:58][INFO] train_net.py: 458: Start epoch: 1
[03/06 21:28:06][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:28:06][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:16][INFO] train_net.py: 415: Train with config:
[03/06 21:29:16][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:29:16][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:29:16][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:29:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:29:16][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:29:17][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:29:17][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:29:18][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:29:18][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:29:18][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:29:18][INFO] misc.py: 187: Flops: 0 G
[03/06 21:29:18][INFO] misc.py: 192: Activations: 0 M
[03/06 21:29:18][INFO] misc.py: 197: nvidia-smi
[03/06 21:29:18][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:29:18][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:29:18][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:29:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:29:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:29:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:29:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:29:19][INFO] train_net.py: 458: Start epoch: 1
[03/06 21:29:26][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:26][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:29][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:29][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:33][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:33][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:36][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:36][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:40][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:40][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:44][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:44][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:48][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:48][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:51][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:51][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:55][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:55][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:58][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:29:58][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:29:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28680, "dt_data": 2.82126, "dt_net": 0.46554, "epoch": "1/55", "eta": "18:49:17", "gpu_mem": "13.92G", "iter": "10/375", "loss": 0.71461, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:30:02][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:02][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:06][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:06][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:09][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:09][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:13][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:13][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:17][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:17][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:21][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:21][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:25][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:25][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:29][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:29][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:33][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:33][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:36][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:36][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48825, "dt_data": 3.02378, "dt_net": 0.46447, "epoch": "1/55", "eta": "19:57:55", "gpu_mem": "13.92G", "iter": "20/375", "loss": 0.58333, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:30:41][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:41][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:44][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:44][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:48][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:48][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:52][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:52][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:30:56][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:30:56][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:00][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:00][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:03][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:03][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:07][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:07][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:11][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:11][INFO] train_net.py:  94: tensor([[0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:15][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:15][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.30108, "dt_data": 3.84245, "dt_net": 0.45863, "epoch": "1/55", "eta": "1 day, 0:36:20", "gpu_mem": "13.92G", "iter": "30/375", "loss": 0.47508, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:31:18][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:18][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:22][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:22][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:26][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:26][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:30][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:30][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:34][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:34][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:38][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:38][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:41][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:41][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:45][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:45][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:47][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:47][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:51][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:51][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:31:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43246, "dt_data": 2.96892, "dt_net": 0.46353, "epoch": "1/55", "eta": "19:37:37", "gpu_mem": "13.92G", "iter": "40/375", "loss": 0.39898, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:31:56][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:31:56][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:00][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:00][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:03][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:03][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:07][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:07][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:11][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:11][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:15][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:15][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:19][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:19][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:23][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:23][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:27][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:27][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:31][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:31][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64120, "dt_data": 3.18378, "dt_net": 0.45742, "epoch": "1/55", "eta": "20:48:37", "gpu_mem": "13.92G", "iter": "50/375", "loss": 0.33866, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:32:35][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:35][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:39][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:39][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:42][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:42][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:46][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:46][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:50][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:50][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:53][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:53][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:32:58][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:32:58][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:01][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:01][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:05][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:05][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:09][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:09][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91041, "dt_data": 3.44869, "dt_net": 0.46172, "epoch": "1/55", "eta": "22:20:17", "gpu_mem": "13.92G", "iter": "60/375", "loss": 0.31677, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:33:13][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:13][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:16][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:16][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:20][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:20][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:23][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:23][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:27][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:27][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:33:31][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:33:31][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:04][INFO] train_net.py: 415: Train with config:
[03/06 21:34:04][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:34:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:04][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:34:05][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:34:05][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:34:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:34:05][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:34:05][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:34:05][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:34:06][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:34:06][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:34:06][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:34:06][INFO] misc.py: 187: Flops: 0 G
[03/06 21:34:06][INFO] misc.py: 192: Activations: 0 M
[03/06 21:34:06][INFO] misc.py: 197: nvidia-smi
[03/06 21:34:07][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:34:07][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:34:07][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:34:07][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:34:07][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:34:07][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:34:07][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:34:07][INFO] train_net.py: 458: Start epoch: 1
[03/06 21:34:15][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:15][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:18][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:18][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:22][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:22][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:26][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:26][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:29][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:29][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:33][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:33][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:38][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:38][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:41][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:41][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:45][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:45][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:48][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:48][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19756, "dt_data": 2.73346, "dt_net": 0.46411, "epoch": "1/55", "eta": "18:18:37", "gpu_mem": "13.92G", "iter": "10/375", "loss": 0.71461, "lr": 0.00000, "mAP": 0.54018, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:34:52][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:52][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:56][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:56][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:34:59][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:34:59][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:03][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:03][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:06][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:06][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:09][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:09][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:13][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:13][INFO] train_net.py:  94: tensor([[0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:17][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:17][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:20][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:20][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:23][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:23][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17416, "dt_data": 2.71557, "dt_net": 0.45859, "epoch": "1/55", "eta": "18:10:03", "gpu_mem": "13.92G", "iter": "20/375", "loss": 0.58334, "lr": 0.00000, "mAP": 0.54320, "top1_err": 0.00000, "top5_err": 0.00000}
[03/06 21:35:28][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:28][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:35:30][INFO] train_net.py:  93: labels:::::-----------------
[03/06 21:35:30][INFO] train_net.py:  94: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)
[03/06 21:36:52][INFO] train_net.py: 412: Train with config:
[03/06 21:36:52][INFO] train_net.py: 413: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:36:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:36:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:36:53][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:36:53][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:36:53][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:36:53][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:36:53][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:36:53][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:36:53][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:36:53][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:36:53][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:36:54][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:36:54][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:36:54][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:36:54][INFO] misc.py: 187: Flops: 0 G
[03/06 21:36:54][INFO] misc.py: 192: Activations: 0 M
[03/06 21:36:54][INFO] misc.py: 197: nvidia-smi
[03/06 21:36:55][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:36:55][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:36:55][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:36:55][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:36:55][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:36:55][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:36:55][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:36:55][INFO] train_net.py: 455: Start epoch: 1
[03/06 21:38:36][INFO] train_net.py: 412: Train with config:
[03/06 21:38:36][INFO] train_net.py: 413: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/06 21:38:36][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/06 21:38:36][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/06 21:38:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/06 21:38:36][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/06 21:38:37][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/06 21:38:37][INFO] uniformerv2_model.py: 334: Init center: True
[03/06 21:38:37][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/06 21:38:37][INFO] misc.py: 185: Params: 114,352,268
[03/06 21:38:37][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/06 21:38:37][INFO] misc.py: 187: Flops: 0 G
[03/06 21:38:37][INFO] misc.py: 192: Activations: 0 M
[03/06 21:38:37][INFO] misc.py: 197: nvidia-smi
[03/06 21:38:38][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/06 21:38:38][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/06 21:38:38][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:38:38][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/06 21:38:38][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/06 21:38:38][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:38:38][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/06 21:38:38][INFO] train_net.py: 455: Start epoch: 1
[03/07 09:29:52][INFO] train_net.py: 412: Train with config:
[03/07 09:29:52][INFO] train_net.py: 413: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:29:52][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 09:29:52][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 09:29:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:29:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:29:53][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 09:29:53][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 09:29:53][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 09:29:54][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 09:29:54][INFO] misc.py: 185: Params: 114,352,268
[03/07 09:29:54][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 09:29:54][INFO] misc.py: 187: Flops: 0 G
[03/07 09:29:54][INFO] misc.py: 192: Activations: 0 M
[03/07 09:29:54][INFO] misc.py: 197: nvidia-smi
[03/07 09:29:55][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 09:29:55][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 09:29:55][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:29:55][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:29:55][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 09:29:55][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:29:55][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:29:55][INFO] train_net.py: 455: Start epoch: 1
[03/07 09:37:43][INFO] train_net.py: 413: Train with config:
[03/07 09:37:43][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 09:37:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:43][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:37:44][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 09:37:44][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 09:37:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:37:44][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 09:37:44][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 09:37:44][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 09:37:45][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 09:37:45][INFO] misc.py: 185: Params: 114,352,268
[03/07 09:37:45][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 09:37:45][INFO] misc.py: 187: Flops: 0 G
[03/07 09:37:45][INFO] misc.py: 192: Activations: 0 M
[03/07 09:37:45][INFO] misc.py: 197: nvidia-smi
[03/07 09:37:46][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 09:37:46][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 09:37:46][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:37:46][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:37:46][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 09:37:46][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:37:46][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:37:46][INFO] train_net.py: 456: Start epoch: 1
[03/07 09:39:17][INFO] train_net.py: 413: Train with config:
[03/07 09:39:17][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:39:17][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 09:39:17][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 09:39:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:39:17][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 09:39:18][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 09:39:18][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 09:39:19][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 09:39:19][INFO] misc.py: 185: Params: 114,352,268
[03/07 09:39:19][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 09:39:19][INFO] misc.py: 187: Flops: 0 G
[03/07 09:39:19][INFO] misc.py: 192: Activations: 0 M
[03/07 09:39:19][INFO] misc.py: 197: nvidia-smi
[03/07 09:39:19][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 09:39:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 09:39:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:39:20][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:39:20][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 09:39:20][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:39:20][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:39:20][INFO] train_net.py: 456: Start epoch: 1
[03/07 09:41:07][INFO] train_net.py: 413: Train with config:
[03/07 09:41:07][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 09:41:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:07][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:07][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:07][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:07][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:07][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 09:41:08][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 09:41:08][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 09:41:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 09:41:08][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 09:41:08][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 09:41:08][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 09:41:09][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 09:41:09][INFO] misc.py: 185: Params: 114,352,268
[03/07 09:41:09][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 09:41:09][INFO] misc.py: 187: Flops: 0 G
[03/07 09:41:09][INFO] misc.py: 192: Activations: 0 M
[03/07 09:41:09][INFO] misc.py: 197: nvidia-smi
[03/07 09:41:10][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 09:41:10][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 09:41:10][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:41:10][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 09:41:10][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 09:41:10][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:41:10][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 09:41:10][INFO] train_net.py: 456: Start epoch: 1
[03/07 09:41:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29935, "dt_data": 2.85019, "dt_net": 0.44916, "epoch": "1/55", "eta": "18:53:36", "gpu_mem": "14.00G", "iter": "10/375", "loss": 0.71461, "lr": 0.00000, "mAP": 0.01180, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:42:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22618, "dt_data": 2.77859, "dt_net": 0.44759, "epoch": "1/55", "eta": "18:27:55", "gpu_mem": "14.00G", "iter": "20/375", "loss": 0.58334, "lr": 0.00000, "mAP": 0.00977, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:43:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84082, "dt_data": 3.39628, "dt_net": 0.44454, "epoch": "1/55", "eta": "21:58:21", "gpu_mem": "14.00G", "iter": "30/375", "loss": 0.47510, "lr": 0.00000, "mAP": 0.00818, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:43:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04752, "dt_data": 2.60090, "dt_net": 0.44661, "epoch": "1/55", "eta": "17:25:33", "gpu_mem": "14.00G", "iter": "40/375", "loss": 0.39899, "lr": 0.00000, "mAP": 0.00454, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:44:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03341, "dt_data": 2.58784, "dt_net": 0.44557, "epoch": "1/55", "eta": "17:20:12", "gpu_mem": "14.00G", "iter": "50/375", "loss": 0.33867, "lr": 0.00000, "mAP": 0.00446, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:44:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41160, "dt_data": 2.96707, "dt_net": 0.44453, "epoch": "1/55", "eta": "19:29:19", "gpu_mem": "14.00G", "iter": "60/375", "loss": 0.31678, "lr": 0.00000, "mAP": 0.00223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:45:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59704, "dt_data": 3.15323, "dt_net": 0.44381, "epoch": "1/55", "eta": "20:32:17", "gpu_mem": "14.00G", "iter": "70/375", "loss": 0.29889, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:45:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89839, "dt_data": 3.45150, "dt_net": 0.44689, "epoch": "1/55", "eta": "22:14:52", "gpu_mem": "14.00G", "iter": "80/375", "loss": 0.28867, "lr": 0.00000, "mAP": 0.00268, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:46:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.14733, "dt_data": 3.70027, "dt_net": 0.44706, "epoch": "1/55", "eta": "23:39:25", "gpu_mem": "14.00G", "iter": "90/375", "loss": 0.28663, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 09:47:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34292, "dt_data": 1.09710, "dt_net": 2.24582, "epoch": "1/55", "eta": "19:03:33", "gpu_mem": "14.00G", "iter": "100/375", "loss": 0.28262, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:13:44][INFO] train_net.py: 413: Train with config:
[03/07 10:13:44][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:13:44][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:13:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:13:45][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:13:45][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:13:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:13:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:13:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:13:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:13:45][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:13:45][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:13:45][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:13:46][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:13:46][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:13:46][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:13:46][INFO] misc.py: 187: Flops: 0 G
[03/07 10:13:46][INFO] misc.py: 192: Activations: 0 M
[03/07 10:13:46][INFO] misc.py: 197: nvidia-smi
[03/07 10:13:47][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:13:47][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:13:47][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:13:47][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:13:47][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:13:47][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:13:47][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:13:47][INFO] train_net.py: 456: Start epoch: 1
[03/07 10:14:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29513, "dt_data": 2.86722, "dt_net": 0.42791, "epoch": "1/55", "eta": "18:52:09", "gpu_mem": "14.06G", "iter": "10/375", "loss": 0.71461, "lr": 0.00000, "mAP": 0.01180, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:15:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06929, "dt_data": 2.64213, "dt_net": 0.42716, "epoch": "1/55", "eta": "17:34:02", "gpu_mem": "14.06G", "iter": "20/375", "loss": 0.58333, "lr": 0.00000, "mAP": 0.00982, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:15:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91485, "dt_data": 3.49181, "dt_net": 0.42304, "epoch": "1/55", "eta": "22:23:46", "gpu_mem": "14.06G", "iter": "30/375", "loss": 0.47508, "lr": 0.00000, "mAP": 0.00818, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:16:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95069, "dt_data": 2.52394, "dt_net": 0.42675, "epoch": "1/55", "eta": "16:52:19", "gpu_mem": "14.06G", "iter": "40/375", "loss": 0.39900, "lr": 0.00000, "mAP": 0.00454, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:16:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03405, "dt_data": 2.60759, "dt_net": 0.42645, "epoch": "1/55", "eta": "17:20:25", "gpu_mem": "14.06G", "iter": "50/375", "loss": 0.33868, "lr": 0.00000, "mAP": 0.00446, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:17:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39058, "dt_data": 2.96434, "dt_net": 0.42624, "epoch": "1/55", "eta": "19:22:07", "gpu_mem": "14.06G", "iter": "60/375", "loss": 0.31678, "lr": 0.00000, "mAP": 0.00223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:17:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36130, "dt_data": 2.93401, "dt_net": 0.42729, "epoch": "1/55", "eta": "19:11:31", "gpu_mem": "14.06G", "iter": "70/375", "loss": 0.29889, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:18:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73477, "dt_data": 3.30728, "dt_net": 0.42749, "epoch": "1/55", "eta": "21:18:50", "gpu_mem": "14.06G", "iter": "80/375", "loss": 0.28867, "lr": 0.00000, "mAP": 0.00223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:18:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95605, "dt_data": 3.52762, "dt_net": 0.42843, "epoch": "1/55", "eta": "22:33:57", "gpu_mem": "14.06G", "iter": "90/375", "loss": 0.28624, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:19:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52817, "dt_data": 3.10296, "dt_net": 0.42521, "epoch": "1/55", "eta": "20:06:55", "gpu_mem": "14.06G", "iter": "100/375", "loss": 0.28234, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:20:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24369, "dt_data": 2.81739, "dt_net": 0.42630, "epoch": "1/55", "eta": "18:29:04", "gpu_mem": "14.06G", "iter": "110/375", "loss": 0.28110, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:20:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45435, "dt_data": 3.02906, "dt_net": 0.42529, "epoch": "1/55", "eta": "19:40:31", "gpu_mem": "14.06G", "iter": "120/375", "loss": 0.27862, "lr": 0.00000, "mAP": 0.00223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:21:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64746, "dt_data": 3.21766, "dt_net": 0.42980, "epoch": "1/55", "eta": "20:45:54", "gpu_mem": "14.06G", "iter": "130/375", "loss": 0.27706, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:21:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.46609, "dt_data": 3.00861, "dt_net": 1.45748, "epoch": "1/55", "eta": "1 day, 1:24:47", "gpu_mem": "14.06G", "iter": "140/375", "loss": 0.27353, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:22:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.21200, "dt_data": 3.07021, "dt_net": 1.14179, "epoch": "1/55", "eta": "23:57:20", "gpu_mem": "14.06G", "iter": "150/375", "loss": 0.27333, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:23:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.08814, "dt_data": 0.39537, "dt_net": 3.69276, "epoch": "1/55", "eta": "23:14:23", "gpu_mem": "14.06G", "iter": "160/375", "loss": 0.26900, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:23:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29598, "dt_data": 0.02503, "dt_net": 3.27095, "epoch": "1/55", "eta": "18:43:39", "gpu_mem": "14.06G", "iter": "170/375", "loss": 0.26746, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:24:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38883, "dt_data": 1.74682, "dt_net": 1.64201, "epoch": "1/55", "eta": "19:14:44", "gpu_mem": "14.06G", "iter": "180/375", "loss": 0.26732, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:25:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51095, "dt_data": 1.71618, "dt_net": 1.79477, "epoch": "1/55", "eta": "19:55:46", "gpu_mem": "14.06G", "iter": "190/375", "loss": 0.26371, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:25:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58810, "dt_data": 1.92159, "dt_net": 1.66651, "epoch": "1/55", "eta": "20:21:27", "gpu_mem": "14.06G", "iter": "200/375", "loss": 0.26334, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:26:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94588, "dt_data": 3.52104, "dt_net": 0.42484, "epoch": "1/55", "eta": "22:22:35", "gpu_mem": "14.06G", "iter": "210/375", "loss": 0.26011, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:27:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.21909, "dt_data": 3.79238, "dt_net": 0.42671, "epoch": "1/55", "eta": "23:54:50", "gpu_mem": "14.06G", "iter": "220/375", "loss": 0.25615, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:27:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.35710, "dt_data": 3.93059, "dt_net": 0.42651, "epoch": "1/55", "eta": "1 day, 0:41:03", "gpu_mem": "14.06G", "iter": "230/375", "loss": 0.25432, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:28:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.28823, "dt_data": 3.86215, "dt_net": 0.42608, "epoch": "1/55", "eta": "1 day, 0:16:55", "gpu_mem": "14.06G", "iter": "240/375", "loss": 0.25305, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:28:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76626, "dt_data": 3.33930, "dt_net": 0.42696, "epoch": "1/55", "eta": "21:18:57", "gpu_mem": "14.06G", "iter": "250/375", "loss": 0.25189, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:29:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.85980, "dt_data": 4.43331, "dt_net": 0.42649, "epoch": "1/55", "eta": "1 day, 3:29:29", "gpu_mem": "14.06G", "iter": "260/375", "loss": 0.24804, "lr": 0.00000, "mAP": 0.00045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:30:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93090, "dt_data": 3.50623, "dt_net": 0.42467, "epoch": "1/55", "eta": "22:13:33", "gpu_mem": "14.06G", "iter": "270/375", "loss": 0.24502, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:30:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09629, "dt_data": 3.67107, "dt_net": 0.42521, "epoch": "1/55", "eta": "23:08:59", "gpu_mem": "14.06G", "iter": "280/375", "loss": 0.24362, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:31:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.50128, "dt_data": 4.07632, "dt_net": 0.42496, "epoch": "1/55", "eta": "1 day, 1:25:33", "gpu_mem": "14.06G", "iter": "290/375", "loss": 0.23998, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:32:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26769, "dt_data": 2.84325, "dt_net": 0.42444, "epoch": "1/55", "eta": "18:26:55", "gpu_mem": "14.06G", "iter": "300/375", "loss": 0.24007, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:32:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53853, "dt_data": 3.11355, "dt_net": 0.42497, "epoch": "1/55", "eta": "19:58:05", "gpu_mem": "14.06G", "iter": "310/375", "loss": 0.23802, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:33:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.31966, "dt_data": 3.89383, "dt_net": 0.42582, "epoch": "1/55", "eta": "1 day, 0:21:50", "gpu_mem": "14.06G", "iter": "320/375", "loss": 0.23401, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:33:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95564, "dt_data": 3.52889, "dt_net": 0.42676, "epoch": "1/55", "eta": "22:17:59", "gpu_mem": "14.06G", "iter": "330/375", "loss": 0.23303, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:34:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72849, "dt_data": 2.30298, "dt_net": 0.42550, "epoch": "1/55", "eta": "15:22:27", "gpu_mem": "14.06G", "iter": "340/375", "loss": 0.23080, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:35:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45568, "dt_data": 1.12556, "dt_net": 2.33012, "epoch": "1/55", "eta": "19:27:43", "gpu_mem": "14.06G", "iter": "350/375", "loss": 0.22613, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:35:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79622, "dt_data": 1.07866, "dt_net": 2.71756, "epoch": "1/55", "eta": "21:22:10", "gpu_mem": "14.06G", "iter": "360/375", "loss": 0.22922, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:36:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16011, "dt_data": 0.02508, "dt_net": 3.13503, "epoch": "1/55", "eta": "17:46:48", "gpu_mem": "14.06G", "iter": "370/375", "loss": 0.22424, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:36:41][INFO] logging.py:  99: json_stats: {"RAM": "20.83/251.55G", "_type": "train_epoch", "dt": 0.00033, "dt_data": 0.00033, "dt_net": 3.31961, "epoch": "1/55", "eta": "0:00:06", "gpu_mem": "14.06G", "loss": 0.29119, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:36:41][INFO] train_net.py: 494: Epoch 0 takes 1373.66s. Epochs from 0 to 0 take 1373.66s in average and 1373.66s in median.
[03/07 10:36:41][INFO] train_net.py: 500: For epoch 0, each iteraction takes 3.66s in average. From epoch 0 to 0, each iteraction takes 3.66s in average.
[03/07 10:45:20][INFO] train_net.py: 412: Train with config:
[03/07 10:45:20][INFO] train_net.py: 413: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:45:20][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:45:20][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:45:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:45:20][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:45:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:45:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:45:21][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:45:21][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:45:21][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:45:22][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:45:22][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:45:22][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:45:22][INFO] misc.py: 187: Flops: 0 G
[03/07 10:45:22][INFO] misc.py: 192: Activations: 0 M
[03/07 10:45:22][INFO] misc.py: 197: nvidia-smi
[03/07 10:45:23][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:45:23][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:45:23][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:45:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:45:23][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:45:23][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:45:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:45:23][INFO] train_net.py: 455: Start epoch: 1
[03/07 10:47:22][INFO] train_net.py: 413: Train with config:
[03/07 10:47:22][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:47:22][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:47:22][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:47:22][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:47:22][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:47:23][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:47:23][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:47:23][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:47:23][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:47:23][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:47:24][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:47:24][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:47:24][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:47:24][INFO] misc.py: 187: Flops: 0 G
[03/07 10:47:24][INFO] misc.py: 192: Activations: 0 M
[03/07 10:47:24][INFO] misc.py: 197: nvidia-smi
[03/07 10:47:25][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:47:25][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:47:25][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:47:25][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:47:25][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:47:25][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:47:25][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:47:25][INFO] train_net.py: 456: Start epoch: 1
[03/07 10:48:03][INFO] train_net.py: 413: Train with config:
[03/07 10:48:03][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:48:03][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:48:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:48:04][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:48:04][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:48:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:48:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:48:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:48:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:48:04][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:48:04][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:48:04][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:48:05][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:48:05][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:48:05][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:48:05][INFO] misc.py: 187: Flops: 0 G
[03/07 10:48:05][INFO] misc.py: 192: Activations: 0 M
[03/07 10:48:05][INFO] misc.py: 197: nvidia-smi
[03/07 10:48:06][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:48:06][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:48:06][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:48:06][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:48:06][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:48:06][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:48:06][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:48:06][INFO] train_net.py: 456: Start epoch: 1
[03/07 10:48:12][INFO] train_net.py: 266: [tensor(0.0082, device='cuda:0')]
[03/07 10:49:11][INFO] train_net.py: 413: Train with config:
[03/07 10:49:11][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:49:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:11][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:12][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:49:12][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:49:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:12][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:49:12][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:49:12][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:49:13][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:49:13][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:49:13][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:49:13][INFO] misc.py: 187: Flops: 0 G
[03/07 10:49:13][INFO] misc.py: 192: Activations: 0 M
[03/07 10:49:13][INFO] misc.py: 197: nvidia-smi
[03/07 10:49:14][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:49:14][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:49:14][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:49:14][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:49:14][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:49:14][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:49:14][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:49:14][INFO] train_net.py: 456: Start epoch: 1
[03/07 10:49:20][INFO] train_net.py: 266: [tensor(0.0082, device='cuda:0')]
[03/07 10:49:37][INFO] train_net.py: 413: Train with config:
[03/07 10:49:37][INFO] train_net.py: 414: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:49:37][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:49:37][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:49:37][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:49:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:49:38][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:49:38][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:49:38][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:49:39][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:49:39][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:49:39][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:49:39][INFO] misc.py: 187: Flops: 0 G
[03/07 10:49:39][INFO] misc.py: 192: Activations: 0 M
[03/07 10:49:39][INFO] misc.py: 197: nvidia-smi
[03/07 10:49:40][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:49:40][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:49:40][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:49:40][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:49:40][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:49:40][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:49:40][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:49:40][INFO] train_net.py: 456: Start epoch: 1
[03/07 10:49:46][INFO] train_net.py: 266: [tensor(0.0082, device='cuda:0')]
[03/07 10:50:28][INFO] train_net.py: 415: Train with config:
[03/07 10:50:28][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:28][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:50:29][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:50:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:50:29][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:50:29][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:50:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:50:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:50:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:50:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:50:29][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:50:29][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:50:29][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:50:30][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:50:30][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:50:30][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:50:30][INFO] misc.py: 187: Flops: 0 G
[03/07 10:50:30][INFO] misc.py: 192: Activations: 0 M
[03/07 10:50:30][INFO] misc.py: 197: nvidia-smi
[03/07 10:50:31][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:50:31][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:50:31][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:50:31][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:50:31][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:50:31][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:50:31][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:50:31][INFO] train_net.py: 458: Start epoch: 1
[03/07 10:50:37][INFO] train_net.py: 266: [tensor(0.0082, device='cuda:0')]
[03/07 10:52:34][INFO] train_net.py: 415: Train with config:
[03/07 10:52:34][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:34][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:52:35][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:52:35][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:52:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:52:35][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:52:35][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:52:35][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:52:36][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:52:36][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:52:36][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:52:36][INFO] misc.py: 187: Flops: 0 G
[03/07 10:52:36][INFO] misc.py: 192: Activations: 0 M
[03/07 10:52:36][INFO] misc.py: 197: nvidia-smi
[03/07 10:52:37][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:52:37][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:52:37][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:52:37][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:52:37][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:52:37][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:52:37][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:52:37][INFO] train_net.py: 458: Start epoch: 1
[03/07 10:52:43][INFO] train_net.py: 266: [tensor(0.0082, device='cuda:0')]
[03/07 10:52:45][INFO] train_net.py: 266: [tensor(0.0083, device='cuda:0')]
[03/07 10:52:47][INFO] train_net.py: 266: [tensor(0.0102, device='cuda:0')]
[03/07 10:52:49][INFO] train_net.py: 266: [tensor(0.0101, device='cuda:0')]
[03/07 10:52:51][INFO] train_net.py: 266: [tensor(0.0085, device='cuda:0')]
[03/07 10:52:54][INFO] train_net.py: 266: [tensor(0.0115, device='cuda:0')]
[03/07 10:52:56][INFO] train_net.py: 266: [tensor(0.0153, device='cuda:0')]
[03/07 10:52:58][INFO] train_net.py: 266: [tensor(0.0149, device='cuda:0')]
[03/07 10:53:01][INFO] train_net.py: 266: [tensor(0.0156, device='cuda:0')]
[03/07 10:53:03][INFO] train_net.py: 266: [tensor(0.0107, device='cuda:0')]
[03/07 10:54:00][INFO] train_net.py: 415: Train with config:
[03/07 10:54:00][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:54:00][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:00][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:00][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:00][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:00][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:00][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:00][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:00][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:54:01][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:54:01][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:54:01][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:54:01][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:54:01][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:54:01][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:54:02][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:54:02][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:54:02][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:54:02][INFO] misc.py: 187: Flops: 0 G
[03/07 10:54:02][INFO] misc.py: 192: Activations: 0 M
[03/07 10:54:02][INFO] misc.py: 197: nvidia-smi
[03/07 10:54:03][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:54:03][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:54:03][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:54:03][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:54:03][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:54:03][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:54:03][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:54:03][INFO] train_net.py: 458: Start epoch: 1
[03/07 10:55:09][INFO] train_net.py: 415: Train with config:
[03/07 10:55:09][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': True, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 10:55:09][INFO] uniformerv2_model.py:  75: No L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 10:55:09][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 10:55:09][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 10:55:10][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:55:10][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:55:10][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:55:10][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 10:55:10][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 10:55:10][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 10:55:10][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 10:55:11][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 10:55:11][INFO] misc.py: 185: Params: 114,352,268
[03/07 10:55:11][INFO] misc.py: 186: Mem: 0.8526897430419922 MB
[03/07 10:55:11][INFO] misc.py: 187: Flops: 0 G
[03/07 10:55:11][INFO] misc.py: 192: Activations: 0 M
[03/07 10:55:11][INFO] misc.py: 197: nvidia-smi
[03/07 10:55:12][INFO] optimizer.py:  71: bn 0, non bn 72, zero 147
[03/07 10:55:12][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 10:55:12][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:55:12][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 10:55:12][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 10:55:12][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:55:12][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 10:55:12][INFO] train_net.py: 458: Start epoch: 1
[03/07 10:55:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:37", "gpu_mem": "2.31G", "iter": "10/96", "mAP": 0.01042, "time_diff": 1.82768, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:55:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:14", "gpu_mem": "2.31G", "iter": "20/96", "mAP": 0.00889, "time_diff": 1.76680, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:56:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:15", "gpu_mem": "2.31G", "iter": "30/96", "mAP": 0.01099, "time_diff": 2.05467, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:56:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:12", "gpu_mem": "2.31G", "iter": "40/96", "mAP": 0.00956, "time_diff": 2.36910, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:57:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:50", "gpu_mem": "2.31G", "iter": "50/96", "mAP": 0.00944, "time_diff": 2.39915, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:57:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:33", "gpu_mem": "2.31G", "iter": "60/96", "mAP": 0.01012, "time_diff": 2.60186, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:57:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:57", "gpu_mem": "2.31G", "iter": "70/96", "mAP": 0.01086, "time_diff": 2.21809, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:58:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:30", "gpu_mem": "2.31G", "iter": "80/96", "mAP": 0.01074, "time_diff": 1.89906, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:58:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:14", "gpu_mem": "2.31G", "iter": "90/96", "mAP": 0.01020, "time_diff": 2.45646, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:58:36][INFO] logging.py:  99: json_stats: {"RAM": "19.94/251.55G", "_type": "val_epoch", "epoch": "1/55", "gpu_mem": "2.31G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:59:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72700, "dt_data": 0.57020, "dt_net": 2.15681, "epoch": "1/55", "eta": "15:36:57", "gpu_mem": "14.07G", "iter": "10/375", "loss": 0.71619, "lr": 0.00000, "mAP": 0.01296, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 10:59:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64848, "dt_data": 0.98315, "dt_net": 2.66533, "epoch": "1/55", "eta": "20:52:57", "gpu_mem": "14.07G", "iter": "20/375", "loss": 0.58287, "lr": 0.00000, "mAP": 0.01085, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:00:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92989, "dt_data": 1.67462, "dt_net": 2.25527, "epoch": "1/55", "eta": "22:28:56", "gpu_mem": "14.07G", "iter": "30/375", "loss": 0.47583, "lr": 0.00000, "mAP": 0.00677, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:00:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28657, "dt_data": 0.41266, "dt_net": 2.87391, "epoch": "1/55", "eta": "18:47:33", "gpu_mem": "14.07G", "iter": "40/375", "loss": 0.40163, "lr": 0.00000, "mAP": 0.00424, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:01:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24252, "dt_data": 0.40507, "dt_net": 2.83745, "epoch": "1/55", "eta": "18:31:54", "gpu_mem": "14.07G", "iter": "50/375", "loss": 0.34019, "lr": 0.00000, "mAP": 0.00298, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:02:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24160, "dt_data": 1.33873, "dt_net": 1.90287, "epoch": "1/55", "eta": "18:31:03", "gpu_mem": "14.07G", "iter": "60/375", "loss": 0.31658, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:02:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03642, "dt_data": 2.63284, "dt_net": 0.40358, "epoch": "1/55", "eta": "17:20:13", "gpu_mem": "14.07G", "iter": "70/375", "loss": 0.29894, "lr": 0.00000, "mAP": 0.00268, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:03:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75161, "dt_data": 3.34638, "dt_net": 0.40523, "epoch": "1/55", "eta": "21:24:36", "gpu_mem": "14.07G", "iter": "80/375", "loss": 0.28961, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:03:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72280, "dt_data": 2.31783, "dt_net": 0.40497, "epoch": "1/55", "eta": "15:31:52", "gpu_mem": "14.07G", "iter": "90/375", "loss": 0.28648, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:04:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25899, "dt_data": 2.85487, "dt_net": 0.40412, "epoch": "1/55", "eta": "18:34:50", "gpu_mem": "14.07G", "iter": "100/375", "loss": 0.28209, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:04:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34599, "dt_data": 2.94160, "dt_net": 0.40438, "epoch": "1/55", "eta": "19:04:02", "gpu_mem": "14.07G", "iter": "110/375", "loss": 0.28149, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:05:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49486, "dt_data": 1.31613, "dt_net": 2.17873, "epoch": "1/55", "eta": "19:54:22", "gpu_mem": "14.07G", "iter": "120/375", "loss": 0.27849, "lr": 0.00000, "mAP": 0.00223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:06:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74807, "dt_data": 0.02501, "dt_net": 3.72306, "epoch": "1/55", "eta": "21:20:16", "gpu_mem": "14.07G", "iter": "130/375", "loss": 0.27749, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:06:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07821, "dt_data": 0.02504, "dt_net": 3.05317, "epoch": "1/55", "eta": "17:30:57", "gpu_mem": "14.07G", "iter": "140/375", "loss": 0.27363, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:07:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.98418, "dt_data": 1.01122, "dt_net": 2.97296, "epoch": "1/55", "eta": "22:39:36", "gpu_mem": "14.07G", "iter": "150/375", "loss": 0.27345, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:07:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22754, "dt_data": 1.08034, "dt_net": 2.14720, "epoch": "1/55", "eta": "18:20:51", "gpu_mem": "14.07G", "iter": "160/375", "loss": 0.26890, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:08:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46277, "dt_data": 0.02514, "dt_net": 3.43764, "epoch": "1/55", "eta": "19:40:31", "gpu_mem": "14.07G", "iter": "170/375", "loss": 0.26757, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:08:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95751, "dt_data": 0.02506, "dt_net": 3.93246, "epoch": "1/55", "eta": "22:28:31", "gpu_mem": "14.07G", "iter": "180/375", "loss": 0.26751, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:09:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.11285, "dt_data": 0.02502, "dt_net": 4.08783, "epoch": "1/55", "eta": "23:20:46", "gpu_mem": "14.07G", "iter": "190/375", "loss": 0.26379, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:10:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52853, "dt_data": 0.02509, "dt_net": 3.50343, "epoch": "1/55", "eta": "20:01:10", "gpu_mem": "14.07G", "iter": "200/375", "loss": 0.26334, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:10:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70352, "dt_data": 0.02505, "dt_net": 3.67847, "epoch": "1/55", "eta": "21:00:07", "gpu_mem": "14.07G", "iter": "210/375", "loss": 0.26021, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:11:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89173, "dt_data": 0.27592, "dt_net": 3.61581, "epoch": "1/55", "eta": "22:03:30", "gpu_mem": "14.07G", "iter": "220/375", "loss": 0.25618, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:11:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68386, "dt_data": 0.02502, "dt_net": 2.65884, "epoch": "1/55", "eta": "15:12:17", "gpu_mem": "14.07G", "iter": "230/375", "loss": 0.25442, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:12:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98391, "dt_data": 1.02403, "dt_net": 1.95987, "epoch": "1/55", "eta": "16:53:46", "gpu_mem": "14.07G", "iter": "240/375", "loss": 0.25308, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:12:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91289, "dt_data": 2.03591, "dt_net": 0.87697, "epoch": "1/55", "eta": "16:29:10", "gpu_mem": "14.07G", "iter": "250/375", "loss": 0.25186, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:13:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53501, "dt_data": 3.12981, "dt_net": 0.40520, "epoch": "1/55", "eta": "19:59:50", "gpu_mem": "14.07G", "iter": "260/375", "loss": 0.24808, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:14:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34232, "dt_data": 2.93877, "dt_net": 0.40355, "epoch": "1/55", "eta": "18:53:52", "gpu_mem": "14.07G", "iter": "270/375", "loss": 0.24514, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:14:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90396, "dt_data": 3.49768, "dt_net": 0.40628, "epoch": "1/55", "eta": "22:03:46", "gpu_mem": "14.07G", "iter": "280/375", "loss": 0.24365, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:15:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10357, "dt_data": 2.69836, "dt_net": 0.40521, "epoch": "1/55", "eta": "17:31:51", "gpu_mem": "14.07G", "iter": "290/375", "loss": 0.24001, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:15:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36668, "dt_data": 2.96068, "dt_net": 0.40600, "epoch": "1/55", "eta": "19:00:27", "gpu_mem": "14.07G", "iter": "300/375", "loss": 0.24024, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:16:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83346, "dt_data": 3.42731, "dt_net": 0.40614, "epoch": "1/55", "eta": "21:37:56", "gpu_mem": "14.07G", "iter": "310/375", "loss": 0.23813, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:16:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33878, "dt_data": 2.93547, "dt_net": 0.40331, "epoch": "1/55", "eta": "18:49:53", "gpu_mem": "14.07G", "iter": "320/375", "loss": 0.23416, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:17:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04882, "dt_data": 2.64574, "dt_net": 0.40308, "epoch": "1/55", "eta": "17:11:15", "gpu_mem": "14.07G", "iter": "330/375", "loss": 0.23298, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:18:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22503, "dt_data": 2.82108, "dt_net": 0.40395, "epoch": "1/55", "eta": "18:10:19", "gpu_mem": "14.07G", "iter": "340/375", "loss": 0.23091, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:18:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21253, "dt_data": 2.80852, "dt_net": 0.40401, "epoch": "1/55", "eta": "18:05:34", "gpu_mem": "14.07G", "iter": "350/375", "loss": 0.22612, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:19:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.29999, "dt_data": 3.89473, "dt_net": 0.40526, "epoch": "1/55", "eta": "1 day, 0:12:19", "gpu_mem": "14.07G", "iter": "360/375", "loss": 0.22926, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:19:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.44792, "dt_data": 2.04400, "dt_net": 0.40392, "epoch": "1/55", "eta": "13:46:22", "gpu_mem": "14.07G", "iter": "370/375", "loss": 0.22428, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:20:05][INFO] logging.py:  99: json_stats: {"RAM": "26.01/251.55G", "_type": "train_epoch", "dt": 0.00036, "dt_data": 0.00036, "dt_net": 0.40507, "epoch": "1/55", "eta": "0:00:06", "gpu_mem": "14.07G", "loss": 0.29134, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:20:05][INFO] train_net.py: 497: Epoch 0 takes 1492.72s. Epochs from 0 to 0 take 1492.72s in average and 1492.72s in median.
[03/07 11:20:05][INFO] train_net.py: 503: For epoch 0, each iteraction takes 3.98s in average. From epoch 0 to 0, each iteraction takes 3.98s in average.
[03/07 11:20:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:19", "gpu_mem": "14.07G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.62020, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:20:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:08", "gpu_mem": "14.07G", "iter": "20/96", "mAP": 0.00000, "time_diff": 1.68494, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:20:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:38", "gpu_mem": "14.07G", "iter": "30/96", "mAP": 0.00000, "time_diff": 1.49854, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:21:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:24", "gpu_mem": "14.07G", "iter": "40/96", "mAP": 0.00000, "time_diff": 1.51028, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:21:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:14", "gpu_mem": "14.07G", "iter": "50/96", "mAP": 0.00000, "time_diff": 1.62475, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:21:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:57", "gpu_mem": "14.07G", "iter": "60/96", "mAP": 0.00000, "time_diff": 1.60956, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:22:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:48", "gpu_mem": "14.07G", "iter": "70/96", "mAP": 0.00000, "time_diff": 1.87380, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:22:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:24", "gpu_mem": "14.07G", "iter": "80/96", "mAP": 0.00000, "time_diff": 1.52051, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:22:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:09", "gpu_mem": "14.07G", "iter": "90/96", "mAP": 0.00000, "time_diff": 1.57665, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:22:47][INFO] logging.py:  99: json_stats: {"RAM": "26.27/251.55G", "_type": "val_epoch", "epoch": "1/55", "gpu_mem": "14.07G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:23:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:02:30", "gpu_mem": "14.07G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.74502, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:23:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:55", "gpu_mem": "14.07G", "iter": "20/96", "mAP": 0.00000, "time_diff": 1.51872, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:23:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:36", "gpu_mem": "14.07G", "iter": "30/96", "mAP": 0.00000, "time_diff": 1.46010, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:23:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:47", "gpu_mem": "14.07G", "iter": "40/96", "mAP": 0.00000, "time_diff": 1.91117, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:24:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:21", "gpu_mem": "14.07G", "iter": "50/96", "mAP": 0.00000, "time_diff": 1.78037, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:24:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:04", "gpu_mem": "14.07G", "iter": "60/96", "mAP": 0.00000, "time_diff": 1.78153, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:24:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:43", "gpu_mem": "14.07G", "iter": "70/96", "mAP": 0.00000, "time_diff": 1.68046, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:25:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:25", "gpu_mem": "14.07G", "iter": "80/96", "mAP": 0.00000, "time_diff": 1.57804, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:25:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:11", "gpu_mem": "14.07G", "iter": "90/96", "mAP": 0.00000, "time_diff": 1.86659, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:25:28][INFO] logging.py:  99: json_stats: {"RAM": "27.07/251.55G", "_type": "val_epoch", "epoch": "2/55", "gpu_mem": "14.07G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:26:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60253, "dt_data": 1.03261, "dt_net": 2.56991, "epoch": "2/55", "eta": "20:15:15", "gpu_mem": "14.07G", "iter": "10/375", "loss": 0.22119, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:26:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55617, "dt_data": 2.28409, "dt_net": 1.27208, "epoch": "2/55", "eta": "19:59:01", "gpu_mem": "14.07G", "iter": "20/375", "loss": 0.22138, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:27:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68255, "dt_data": 3.27723, "dt_net": 0.40531, "epoch": "2/55", "eta": "20:41:01", "gpu_mem": "14.07G", "iter": "30/375", "loss": 0.21491, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:27:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.20724, "dt_data": 3.80307, "dt_net": 0.40416, "epoch": "2/55", "eta": "23:37:08", "gpu_mem": "14.07G", "iter": "40/375", "loss": 0.20918, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:28:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34062, "dt_data": 2.93549, "dt_net": 0.40513, "epoch": "2/55", "eta": "18:44:40", "gpu_mem": "14.07G", "iter": "50/375", "loss": 0.20932, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:28:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51465, "dt_data": 3.10956, "dt_net": 0.40509, "epoch": "2/55", "eta": "19:42:40", "gpu_mem": "14.07G", "iter": "60/375", "loss": 0.20791, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:29:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52825, "dt_data": 3.12463, "dt_net": 0.40362, "epoch": "2/55", "eta": "19:46:40", "gpu_mem": "14.07G", "iter": "70/375", "loss": 0.20574, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:30:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71837, "dt_data": 3.31579, "dt_net": 0.40258, "epoch": "2/55", "eta": "20:49:59", "gpu_mem": "14.07G", "iter": "80/375", "loss": 0.20422, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:30:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.77982, "dt_data": 2.37451, "dt_net": 0.40530, "epoch": "2/55", "eta": "15:34:01", "gpu_mem": "14.07G", "iter": "90/375", "loss": 0.20068, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:31:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22484, "dt_data": 2.81888, "dt_net": 0.40596, "epoch": "2/55", "eta": "18:03:00", "gpu_mem": "14.07G", "iter": "100/375", "loss": 0.19818, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:31:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.86587, "dt_data": 2.45991, "dt_net": 0.40596, "epoch": "2/55", "eta": "16:01:58", "gpu_mem": "14.07G", "iter": "110/375", "loss": 0.19851, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:32:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80668, "dt_data": 3.40334, "dt_net": 0.40334, "epoch": "2/55", "eta": "21:17:08", "gpu_mem": "14.07G", "iter": "120/375", "loss": 0.19440, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:32:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85012, "dt_data": 3.44702, "dt_net": 0.40310, "epoch": "2/55", "eta": "21:31:04", "gpu_mem": "14.07G", "iter": "130/375", "loss": 0.19341, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:33:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67372, "dt_data": 3.27082, "dt_net": 0.40289, "epoch": "2/55", "eta": "20:31:18", "gpu_mem": "14.07G", "iter": "140/375", "loss": 0.19022, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:34:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11255, "dt_data": 2.70853, "dt_net": 0.40402, "epoch": "2/55", "eta": "17:22:42", "gpu_mem": "14.07G", "iter": "150/375", "loss": 0.18962, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:34:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16509, "dt_data": 2.76133, "dt_net": 0.40375, "epoch": "2/55", "eta": "17:39:46", "gpu_mem": "14.07G", "iter": "160/375", "loss": 0.18629, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:35:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.52525, "dt_data": 4.12256, "dt_net": 0.40269, "epoch": "2/55", "eta": "1 day, 1:14:27", "gpu_mem": "14.07G", "iter": "170/375", "loss": 0.18511, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:35:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18443, "dt_data": 2.78170, "dt_net": 0.40274, "epoch": "2/55", "eta": "17:45:11", "gpu_mem": "14.07G", "iter": "180/375", "loss": 0.18089, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:36:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25223, "dt_data": 2.84747, "dt_net": 0.40476, "epoch": "2/55", "eta": "18:07:19", "gpu_mem": "14.07G", "iter": "190/375", "loss": 0.17824, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:36:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97366, "dt_data": 3.56809, "dt_net": 0.40556, "epoch": "2/55", "eta": "22:07:51", "gpu_mem": "14.07G", "iter": "200/375", "loss": 0.17770, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:37:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13432, "dt_data": 2.73082, "dt_net": 0.40350, "epoch": "2/55", "eta": "17:26:51", "gpu_mem": "14.07G", "iter": "210/375", "loss": 0.17470, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:38:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67346, "dt_data": 3.26744, "dt_net": 0.40601, "epoch": "2/55", "eta": "20:26:19", "gpu_mem": "14.07G", "iter": "220/375", "loss": 0.17200, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:38:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.47486, "dt_data": 4.07351, "dt_net": 0.40135, "epoch": "2/55", "eta": "1 day, 0:53:06", "gpu_mem": "14.07G", "iter": "230/375", "loss": 0.16979, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:39:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99258, "dt_data": 2.58794, "dt_net": 0.40464, "epoch": "2/55", "eta": "16:38:01", "gpu_mem": "14.07G", "iter": "240/375", "loss": 0.16655, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:39:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68070, "dt_data": 3.27670, "dt_net": 0.40400, "epoch": "2/55", "eta": "20:26:54", "gpu_mem": "14.07G", "iter": "250/375", "loss": 0.16742, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:40:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53067, "dt_data": 3.12329, "dt_net": 0.40738, "epoch": "2/55", "eta": "19:36:18", "gpu_mem": "14.07G", "iter": "260/375", "loss": 0.16352, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:40:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22186, "dt_data": 2.81474, "dt_net": 0.40712, "epoch": "2/55", "eta": "17:52:52", "gpu_mem": "14.07G", "iter": "270/375", "loss": 0.15817, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:41:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83145, "dt_data": 3.42722, "dt_net": 0.40422, "epoch": "2/55", "eta": "21:15:13", "gpu_mem": "14.07G", "iter": "280/375", "loss": 0.15984, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:42:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11665, "dt_data": 2.71163, "dt_net": 0.40501, "epoch": "2/55", "eta": "17:16:48", "gpu_mem": "14.07G", "iter": "290/375", "loss": 0.15570, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:42:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23685, "dt_data": 2.83351, "dt_net": 0.40334, "epoch": "2/55", "eta": "17:56:15", "gpu_mem": "14.07G", "iter": "300/375", "loss": 0.15748, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:43:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88787, "dt_data": 2.48219, "dt_net": 0.40568, "epoch": "2/55", "eta": "15:59:44", "gpu_mem": "14.07G", "iter": "310/375", "loss": 0.15410, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:43:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28297, "dt_data": 2.87922, "dt_net": 0.40376, "epoch": "2/55", "eta": "18:10:29", "gpu_mem": "14.07G", "iter": "320/375", "loss": 0.15006, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:44:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09383, "dt_data": 3.68964, "dt_net": 0.40418, "epoch": "2/55", "eta": "22:39:09", "gpu_mem": "14.07G", "iter": "330/375", "loss": 0.14866, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:44:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.54229, "dt_data": 4.13580, "dt_net": 0.40649, "epoch": "2/55", "eta": "1 day, 1:07:16", "gpu_mem": "14.07G", "iter": "340/375", "loss": 0.14950, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:45:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05037, "dt_data": 2.64779, "dt_net": 0.40258, "epoch": "2/55", "eta": "16:51:42", "gpu_mem": "14.07G", "iter": "350/375", "loss": 0.14492, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:46:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17546, "dt_data": 2.58754, "dt_net": 0.58792, "epoch": "2/55", "eta": "17:32:39", "gpu_mem": "14.07G", "iter": "360/375", "loss": 0.14417, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:46:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53893, "dt_data": 1.08810, "dt_net": 2.45083, "epoch": "2/55", "eta": "19:32:33", "gpu_mem": "14.07G", "iter": "370/375", "loss": 0.14112, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:46:55][INFO] logging.py:  99: json_stats: {"RAM": "27.27/251.55G", "_type": "train_epoch", "dt": 0.00030, "dt_data": 0.00030, "dt_net": 2.54760, "epoch": "2/55", "eta": "0:00:05", "gpu_mem": "14.07G", "loss": 0.17929, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:46:55][INFO] train_net.py: 497: Epoch 1 takes 1446.47s. Epochs from 0 to 1 take 1469.60s in average and 1469.60s in median.
[03/07 11:46:55][INFO] train_net.py: 503: For epoch 1, each iteraction takes 3.86s in average. From epoch 0 to 1, each iteraction takes 3.92s in average.
[03/07 11:47:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:02:13", "gpu_mem": "14.07G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.55418, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:47:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:02:09", "gpu_mem": "14.07G", "iter": "20/96", "mAP": 0.00000, "time_diff": 1.70319, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:47:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:38", "gpu_mem": "14.07G", "iter": "30/96", "mAP": 0.00000, "time_diff": 1.49865, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:48:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:25", "gpu_mem": "14.07G", "iter": "40/96", "mAP": 0.00000, "time_diff": 1.52359, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:48:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:18", "gpu_mem": "14.07G", "iter": "50/96", "mAP": 0.00000, "time_diff": 1.71179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:48:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:58", "gpu_mem": "14.07G", "iter": "60/96", "mAP": 0.00000, "time_diff": 1.61720, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:48:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:49", "gpu_mem": "14.07G", "iter": "70/96", "mAP": 0.00000, "time_diff": 1.91032, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:49:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:23", "gpu_mem": "14.07G", "iter": "80/96", "mAP": 0.00000, "time_diff": 1.44763, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:49:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:09", "gpu_mem": "14.07G", "iter": "90/96", "mAP": 0.00000, "time_diff": 1.52952, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:49:38][INFO] logging.py:  99: json_stats: {"RAM": "26.27/251.55G", "_type": "val_epoch", "epoch": "2/55", "gpu_mem": "14.07G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:50:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:02:33", "gpu_mem": "14.07G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.78607, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:50:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:59", "gpu_mem": "14.07G", "iter": "20/96", "mAP": 0.00000, "time_diff": 1.57466, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:50:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:48", "gpu_mem": "14.07G", "iter": "30/96", "mAP": 0.00000, "time_diff": 1.64645, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:50:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:45", "gpu_mem": "14.07G", "iter": "40/96", "mAP": 0.00000, "time_diff": 1.88009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:51:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:28", "gpu_mem": "14.07G", "iter": "50/96", "mAP": 0.00000, "time_diff": 1.92064, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:51:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:12", "gpu_mem": "14.07G", "iter": "60/96", "mAP": 0.00000, "time_diff": 2.01689, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:51:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:00:40", "gpu_mem": "14.07G", "iter": "70/96", "mAP": 0.00000, "time_diff": 1.56226, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:51:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:00:26", "gpu_mem": "14.07G", "iter": "80/96", "mAP": 0.00000, "time_diff": 1.64546, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:52:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:00:11", "gpu_mem": "14.07G", "iter": "90/96", "mAP": 0.00000, "time_diff": 1.92993, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:52:24][INFO] logging.py:  99: json_stats: {"RAM": "26.74/251.55G", "_type": "val_epoch", "epoch": "3/55", "gpu_mem": "14.07G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:53:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36952, "dt_data": 2.96624, "dt_net": 0.40328, "epoch": "3/55", "eta": "18:35:35", "gpu_mem": "14.07G", "iter": "10/375", "loss": 0.13959, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:53:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88201, "dt_data": 2.47784, "dt_net": 0.40417, "epoch": "3/55", "eta": "15:53:42", "gpu_mem": "14.07G", "iter": "20/375", "loss": 0.13908, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:54:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34792, "dt_data": 2.65278, "dt_net": 0.69513, "epoch": "3/55", "eta": "18:27:19", "gpu_mem": "14.07G", "iter": "30/375", "loss": 0.13663, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:54:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60815, "dt_data": 0.02510, "dt_net": 3.58305, "epoch": "3/55", "eta": "19:52:47", "gpu_mem": "14.07G", "iter": "40/375", "loss": 0.13313, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 11:55:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12787, "dt_data": 1.13265, "dt_net": 1.99522, "epoch": "3/55", "eta": "17:13:30", "gpu_mem": "14.07G", "iter": "50/375", "loss": 0.13480, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:43:51][INFO] train_net.py: 415: Train with config:
[03/07 18:43:51][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:43:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:43:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:43:52][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 18:43:52][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 18:43:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:43:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:43:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:43:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:43:52][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 18:43:52][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 18:43:52][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 18:43:53][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 18:43:53][INFO] misc.py: 185: Params: 133,343,372
[03/07 18:43:53][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/07 18:43:53][INFO] misc.py: 187: Flops: 0 G
[03/07 18:43:53][INFO] misc.py: 192: Activations: 0 M
[03/07 18:43:53][INFO] misc.py: 197: nvidia-smi
[03/07 18:43:54][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/07 18:43:54][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/07 18:43:54][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.0.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.1.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.2.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.3.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.4.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.5.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.6.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.7.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.8.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.9.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.10.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra1.pos_embed.3.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.0.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.0.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.0.running_mean not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.0.running_var not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.0.num_batches_tracked not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.1.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.1.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.2.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.2.bias not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.3.weight not loaded.
[03/07 18:43:55][INFO] checkpoint_amp.py: 391: Network weights backbone.transformer.resblocks.11.lmhra2.pos_embed.3.bias not loaded.
[03/07 18:45:20][INFO] train_net.py: 415: Train with config:
[03/07 18:45:20][INFO] train_net.py: 416: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/07 18:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:20][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:20][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:20][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/07 18:45:21][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/07 18:45:21][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/07 18:45:21][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/07 18:45:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/07 18:45:21][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/07 18:45:21][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/07 18:45:21][INFO] uniformerv2_model.py: 334: Init center: True
[03/07 18:45:22][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/07 18:45:22][INFO] misc.py: 185: Params: 133,343,372
[03/07 18:45:22][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/07 18:45:22][INFO] misc.py: 187: Flops: 0 G
[03/07 18:45:22][INFO] misc.py: 192: Activations: 0 M
[03/07 18:45:22][INFO] misc.py: 197: nvidia-smi
[03/07 18:45:23][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/07 18:45:23][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/07 18:45:23][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 18:45:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/07 18:45:23][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/07 18:45:23][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 18:45:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/07 18:45:23][INFO] train_net.py: 458: Start epoch: 1
[03/07 18:46:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54730, "dt_data": 0.10327, "dt_net": 3.44403, "epoch": "1/55", "eta": "20:18:47", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.68755, "lr": 0.00000, "mAP": 0.01143, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:46:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36816, "dt_data": 2.81275, "dt_net": 0.55540, "epoch": "1/55", "eta": "19:16:40", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.54518, "lr": 0.00000, "mAP": 0.00810, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:47:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64079, "dt_data": 1.04553, "dt_net": 2.59526, "epoch": "1/55", "eta": "20:49:42", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.44105, "lr": 0.00000, "mAP": 0.00573, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:47:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51206, "dt_data": 0.02501, "dt_net": 3.48706, "epoch": "1/55", "eta": "20:04:55", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.36864, "lr": 0.00000, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:48:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14002, "dt_data": 0.02501, "dt_net": 3.11501, "epoch": "1/55", "eta": "17:56:45", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.32474, "lr": 0.00000, "mAP": 0.00313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:48:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70324, "dt_data": 0.02502, "dt_net": 3.67822, "epoch": "1/55", "eta": "21:09:17", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.30959, "lr": 0.00000, "mAP": 0.00134, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:49:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13200, "dt_data": 0.02505, "dt_net": 3.10694, "epoch": "1/55", "eta": "17:52:58", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.29698, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:50:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77846, "dt_data": 0.02498, "dt_net": 3.75348, "epoch": "1/55", "eta": "21:33:48", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.28923, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:50:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89801, "dt_data": 2.73714, "dt_net": 1.16086, "epoch": "1/55", "eta": "22:14:05", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.28762, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:51:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21262, "dt_data": 0.02503, "dt_net": 3.18759, "epoch": "1/55", "eta": "18:18:59", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.28242, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:51:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10866, "dt_data": 2.55791, "dt_net": 0.55075, "epoch": "1/55", "eta": "17:42:54", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.28261, "lr": 0.00000, "mAP": 0.00045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:52:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04569, "dt_data": 2.49193, "dt_net": 0.55375, "epoch": "1/55", "eta": "17:20:51", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.28009, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:52:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74633, "dt_data": 2.07462, "dt_net": 0.67171, "epoch": "1/55", "eta": "15:38:06", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.27919, "lr": 0.00000, "mAP": 0.00313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:53:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33394, "dt_data": 1.93408, "dt_net": 1.39985, "epoch": "1/55", "eta": "18:58:15", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.27985, "lr": 0.00000, "mAP": 0.00022, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:54:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.62692, "dt_data": 1.50634, "dt_net": 1.12057, "epoch": "1/55", "eta": "14:56:26", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.27596, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:54:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56113, "dt_data": 2.94205, "dt_net": 0.61908, "epoch": "1/55", "eta": "20:14:38", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.27281, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:55:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72036, "dt_data": 2.06621, "dt_net": 1.65415, "epoch": "1/55", "eta": "21:08:19", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.26857, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:55:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74921, "dt_data": 0.02500, "dt_net": 2.72421, "epoch": "1/55", "eta": "15:36:47", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.26946, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:56:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.19214, "dt_data": 0.02503, "dt_net": 4.16711, "epoch": "1/55", "eta": "23:47:46", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.26974, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:56:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.17157, "dt_data": 0.02503, "dt_net": 4.14653, "epoch": "1/55", "eta": "23:40:04", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.26690, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:57:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88019, "dt_data": 0.02508, "dt_net": 3.85511, "epoch": "1/55", "eta": "22:00:14", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.26341, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:58:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57621, "dt_data": 0.02509, "dt_net": 3.55111, "epoch": "1/55", "eta": "20:16:12", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.26245, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:58:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75544, "dt_data": 0.02509, "dt_net": 2.73034, "epoch": "1/55", "eta": "15:36:37", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.25674, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:59:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.69388, "dt_data": 0.02515, "dt_net": 2.66873, "epoch": "1/55", "eta": "15:15:14", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.25540, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 18:59:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69308, "dt_data": 0.02505, "dt_net": 3.66803, "epoch": "1/55", "eta": "20:54:06", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.25076, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:00:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.35202, "dt_data": 0.02500, "dt_net": 2.32702, "epoch": "1/55", "eta": "13:18:18", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.25154, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:00:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55495, "dt_data": 0.02501, "dt_net": 3.52993, "epoch": "1/55", "eta": "20:06:00", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.25278, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:01:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09036, "dt_data": 0.63386, "dt_net": 3.45650, "epoch": "1/55", "eta": "23:06:58", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.24687, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:02:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03728, "dt_data": 1.15860, "dt_net": 1.87867, "epoch": "1/55", "eta": "17:09:23", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.24718, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:02:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18641, "dt_data": 1.42819, "dt_net": 1.75822, "epoch": "1/55", "eta": "17:59:23", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.24297, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:03:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57761, "dt_data": 1.60767, "dt_net": 1.96994, "epoch": "1/55", "eta": "20:11:19", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.24036, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:03:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04305, "dt_data": 0.77768, "dt_net": 2.26537, "epoch": "1/55", "eta": "17:09:49", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.24037, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:04:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82430, "dt_data": 0.02559, "dt_net": 3.79871, "epoch": "1/55", "eta": "21:33:34", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.23853, "lr": 0.00000, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:04:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75909, "dt_data": 0.02540, "dt_net": 2.73368, "epoch": "1/55", "eta": "15:32:48", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.23372, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:05:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84906, "dt_data": 0.02525, "dt_net": 2.82380, "epoch": "1/55", "eta": "16:02:44", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.23083, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:05:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27599, "dt_data": 0.02505, "dt_net": 3.25094, "epoch": "1/55", "eta": "18:26:27", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.23049, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:06:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00138, "dt_data": 0.02528, "dt_net": 2.97609, "epoch": "1/55", "eta": "16:53:12", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.22538, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:06:51][INFO] logging.py:  99: json_stats: {"RAM": "22.86/251.55G", "_type": "train_epoch", "dt": 0.00030, "dt_data": 0.00030, "dt_net": 3.32111, "epoch": "1/55", "eta": "0:00:05", "gpu_mem": "17.37G", "loss": 0.28961, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:06:51][INFO] train_net.py: 497: Epoch 0 takes 1287.45s. Epochs from 0 to 0 take 1287.45s in average and 1287.45s in median.
[03/07 19:06:51][INFO] train_net.py: 503: For epoch 0, each iteraction takes 3.43s in average. From epoch 0 to 0, each iteraction takes 3.43s in average.
[03/07 19:07:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:19", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.61835, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:07:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:08", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.00000, "time_diff": 1.69155, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:07:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:50", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.00000, "time_diff": 1.68159, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:08:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:54", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.00000, "time_diff": 2.03651, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:08:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:26", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.00000, "time_diff": 1.89086, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:08:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:02", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.00000, "time_diff": 1.73049, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:08:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:46", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.00000, "time_diff": 1.78075, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:09:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.00000, "time_diff": 1.52657, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:09:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.00000, "time_diff": 1.59056, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:09:44][INFO] logging.py:  99: json_stats: {"RAM": "28.42/251.55G", "_type": "val_epoch", "epoch": "1/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:10:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50971, "dt_data": 2.89840, "dt_net": 0.61131, "epoch": "2/55", "eta": "19:43:56", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.22384, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:10:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68733, "dt_data": 3.13713, "dt_net": 0.55020, "epoch": "2/55", "eta": "20:43:14", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.22349, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:11:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45578, "dt_data": 1.90271, "dt_net": 1.55306, "epoch": "2/55", "eta": "19:24:35", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.21775, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:12:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75495, "dt_data": 1.26059, "dt_net": 2.49435, "epoch": "2/55", "eta": "21:04:47", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.21623, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:12:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76120, "dt_data": 0.02512, "dt_net": 3.73608, "epoch": "2/55", "eta": "21:06:16", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.21259, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:13:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94443, "dt_data": 1.05275, "dt_net": 2.89168, "epoch": "2/55", "eta": "22:07:18", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.21004, "lr": 0.00000, "mAP": 0.00045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:13:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.08731, "dt_data": 2.90412, "dt_net": 1.18318, "epoch": "2/55", "eta": "22:54:41", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.21058, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:14:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02573, "dt_data": 3.47602, "dt_net": 0.54971, "epoch": "2/55", "eta": "22:33:18", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.20617, "lr": 0.00000, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:14:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40378, "dt_data": 2.60257, "dt_net": 0.80120, "epoch": "2/55", "eta": "19:03:40", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.20386, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:15:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81916, "dt_data": 1.18759, "dt_net": 1.63156, "epoch": "2/55", "eta": "15:46:46", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.20023, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:16:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36272, "dt_data": 0.02507, "dt_net": 3.33765, "epoch": "2/55", "eta": "18:48:45", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.20103, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:16:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33397, "dt_data": 0.02505, "dt_net": 3.30892, "epoch": "2/55", "eta": "18:38:32", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.20075, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:17:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82294, "dt_data": 0.02516, "dt_net": 3.79777, "epoch": "2/55", "eta": "21:21:57", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.19444, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:17:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.17468, "dt_data": 0.02506, "dt_net": 4.14962, "epoch": "2/55", "eta": "23:19:12", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.19282, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:18:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43228, "dt_data": 0.02517, "dt_net": 3.40711, "epoch": "2/55", "eta": "19:09:48", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.18915, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:18:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40181, "dt_data": 0.02506, "dt_net": 3.37675, "epoch": "2/55", "eta": "18:59:02", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.18732, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:19:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42334, "dt_data": 0.84602, "dt_net": 2.57731, "epoch": "2/55", "eta": "19:05:40", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.18722, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:19:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42017, "dt_data": 0.02505, "dt_net": 3.39512, "epoch": "2/55", "eta": "19:04:02", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.18240, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:20:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.11247, "dt_data": 0.02518, "dt_net": 4.08729, "epoch": "2/55", "eta": "22:54:56", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.18027, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:21:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80831, "dt_data": 0.02503, "dt_net": 2.78328, "epoch": "2/55", "eta": "15:38:26", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.17857, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:21:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91769, "dt_data": 0.02519, "dt_net": 3.89250, "epoch": "2/55", "eta": "21:48:30", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.17667, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:22:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.32085, "dt_data": 0.54368, "dt_net": 3.77716, "epoch": "2/55", "eta": "1 day, 0:02:26", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.17632, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:22:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13017, "dt_data": 0.02524, "dt_net": 3.10493, "epoch": "2/55", "eta": "17:24:25", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.17189, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:23:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07645, "dt_data": 0.02507, "dt_net": 3.05138, "epoch": "2/55", "eta": "17:05:59", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.16770, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:23:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15496, "dt_data": 0.02519, "dt_net": 3.12977, "epoch": "2/55", "eta": "17:31:39", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.16888, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:24:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75420, "dt_data": 0.02504, "dt_net": 3.72915, "epoch": "2/55", "eta": "20:50:46", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.16392, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:25:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.21119, "dt_data": 0.02511, "dt_net": 4.18608, "epoch": "2/55", "eta": "23:22:19", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.16037, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:25:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74512, "dt_data": 0.02532, "dt_net": 3.71979, "epoch": "2/55", "eta": "20:46:30", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.16088, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:26:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08373, "dt_data": 0.02544, "dt_net": 3.05829, "epoch": "2/55", "eta": "17:05:51", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.15918, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:26:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57450, "dt_data": 0.02506, "dt_net": 3.54944, "epoch": "2/55", "eta": "19:48:31", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.15797, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:27:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43003, "dt_data": 0.02499, "dt_net": 3.40503, "epoch": "2/55", "eta": "18:59:54", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.15667, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:27:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.04352, "dt_data": 0.02513, "dt_net": 4.01839, "epoch": "2/55", "eta": "22:23:07", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.15095, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:28:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43473, "dt_data": 0.02521, "dt_net": 3.40952, "epoch": "2/55", "eta": "19:00:19", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.15057, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:29:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66566, "dt_data": 0.02522, "dt_net": 3.64044, "epoch": "2/55", "eta": "20:16:23", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.15061, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:29:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90266, "dt_data": 0.02509, "dt_net": 3.87757, "epoch": "2/55", "eta": "21:34:22", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.14406, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:30:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76334, "dt_data": 0.02513, "dt_net": 3.73821, "epoch": "2/55", "eta": "20:47:32", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.14542, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:30:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40207, "dt_data": 0.02501, "dt_net": 3.37706, "epoch": "2/55", "eta": "18:47:13", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.14279, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:31:08][INFO] logging.py:  99: json_stats: {"RAM": "28.45/251.55G", "_type": "train_epoch", "dt": 0.00031, "dt_data": 0.00031, "dt_net": 3.25676, "epoch": "2/55", "eta": "0:00:05", "gpu_mem": "17.37G", "loss": 0.18118, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:31:08][INFO] train_net.py: 497: Epoch 1 takes 1282.43s. Epochs from 0 to 1 take 1284.94s in average and 1284.94s in median.
[03/07 19:31:08][INFO] train_net.py: 503: For epoch 1, each iteraction takes 3.42s in average. From epoch 0 to 1, each iteraction takes 3.43s in average.
[03/07 19:31:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:02:21", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.64109, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:31:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:02:08", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.00000, "time_diff": 1.69540, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:32:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:36", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.00000, "time_diff": 1.46641, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:32:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:41", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.00000, "time_diff": 1.82107, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:32:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:29", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.00000, "time_diff": 1.93860, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:32:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:01:02", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.00000, "time_diff": 1.72921, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:33:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:48", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.00000, "time_diff": 1.88149, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:33:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.00000, "time_diff": 1.52675, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:33:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.00000, "time_diff": 1.56778, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:33:55][INFO] logging.py:  99: json_stats: {"RAM": "29.02/251.55G", "_type": "val_epoch", "epoch": "2/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00015, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:34:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31275, "dt_data": 2.75927, "dt_net": 0.55348, "epoch": "3/55", "eta": "18:16:47", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.14073, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:35:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53348, "dt_data": 2.98219, "dt_net": 0.55129, "epoch": "3/55", "eta": "19:29:17", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.14133, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:35:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85883, "dt_data": 1.92605, "dt_net": 0.93278, "epoch": "3/55", "eta": "15:45:33", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.13544, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:36:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91592, "dt_data": 1.33815, "dt_net": 1.57777, "epoch": "3/55", "eta": "16:03:57", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.13524, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:36:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10537, "dt_data": 0.02509, "dt_net": 3.08029, "epoch": "3/55", "eta": "17:06:04", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.13515, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:37:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77243, "dt_data": 0.02503, "dt_net": 3.74740, "epoch": "3/55", "eta": "20:45:50", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.12957, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:38:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57347, "dt_data": 0.02518, "dt_net": 3.54829, "epoch": "3/55", "eta": "19:39:32", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.12980, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:38:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93883, "dt_data": 0.02511, "dt_net": 2.91372, "epoch": "3/55", "eta": "16:09:34", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.12929, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:39:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41448, "dt_data": 1.21707, "dt_net": 2.19741, "epoch": "3/55", "eta": "18:45:55", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.12411, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:39:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40561, "dt_data": 0.02502, "dt_net": 3.38059, "epoch": "3/55", "eta": "18:42:26", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.12556, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:40:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48864, "dt_data": 2.93618, "dt_net": 0.55246, "epoch": "3/55", "eta": "19:09:12", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.12454, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:40:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12078, "dt_data": 2.56975, "dt_net": 0.55103, "epoch": "3/55", "eta": "17:07:31", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.12204, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:41:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06091, "dt_data": 2.50780, "dt_net": 0.55310, "epoch": "3/55", "eta": "16:47:17", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.12365, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:41:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91053, "dt_data": 2.35653, "dt_net": 0.55400, "epoch": "3/55", "eta": "15:57:19", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.11896, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:42:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40658, "dt_data": 2.85980, "dt_net": 0.54678, "epoch": "3/55", "eta": "18:39:54", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.11815, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:43:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.45486, "dt_data": 1.90433, "dt_net": 0.55053, "epoch": "3/55", "eta": "13:26:37", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.11769, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:43:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84717, "dt_data": 2.40389, "dt_net": 1.44328, "epoch": "3/55", "eta": "21:03:28", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.11703, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:44:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68327, "dt_data": 3.12998, "dt_net": 0.55329, "epoch": "3/55", "eta": "20:09:02", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.11281, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:44:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.32045, "dt_data": 3.76601, "dt_net": 0.55444, "epoch": "3/55", "eta": "23:37:28", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.11433, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:45:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49511, "dt_data": 2.94524, "dt_net": 0.54987, "epoch": "3/55", "eta": "19:06:06", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.11096, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:45:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10945, "dt_data": 2.55935, "dt_net": 0.55010, "epoch": "3/55", "eta": "16:59:07", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.11161, "lr": 0.00001, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:46:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42557, "dt_data": 2.87740, "dt_net": 0.54816, "epoch": "3/55", "eta": "18:42:09", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.11027, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:46:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80946, "dt_data": 2.25637, "dt_net": 0.55310, "epoch": "3/55", "eta": "15:19:51", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.10795, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:47:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92819, "dt_data": 2.37536, "dt_net": 0.55283, "epoch": "3/55", "eta": "15:58:15", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.10462, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:48:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26263, "dt_data": 2.70646, "dt_net": 0.55616, "epoch": "3/55", "eta": "17:47:09", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.10633, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:48:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36829, "dt_data": 2.81068, "dt_net": 0.55760, "epoch": "3/55", "eta": "18:21:08", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.10251, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:49:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32073, "dt_data": 2.77006, "dt_net": 0.55066, "epoch": "3/55", "eta": "18:05:02", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.10387, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:49:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92094, "dt_data": 0.49015, "dt_net": 3.43078, "epoch": "3/55", "eta": "21:20:30", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.10076, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:50:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.55472, "dt_data": 0.02501, "dt_net": 2.52971, "epoch": "3/55", "eta": "13:53:54", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.09962, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:50:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92898, "dt_data": 0.02515, "dt_net": 2.90383, "epoch": "3/55", "eta": "15:55:34", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.10034, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:51:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12299, "dt_data": 0.27113, "dt_net": 2.85186, "epoch": "3/55", "eta": "16:58:21", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.09908, "lr": 0.00001, "mAP": 0.00045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:51:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91109, "dt_data": 0.02507, "dt_net": 2.88602, "epoch": "3/55", "eta": "15:48:46", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.09750, "lr": 0.00001, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:52:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91674, "dt_data": 0.02503, "dt_net": 2.89172, "epoch": "3/55", "eta": "15:50:07", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.09641, "lr": 0.00001, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:53:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74927, "dt_data": 0.02514, "dt_net": 2.72413, "epoch": "3/55", "eta": "14:55:07", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.09338, "lr": 0.00001, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:53:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77367, "dt_data": 0.02514, "dt_net": 3.74853, "epoch": "3/55", "eta": "20:28:00", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.09257, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:54:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24461, "dt_data": 0.02504, "dt_net": 3.21958, "epoch": "3/55", "eta": "17:35:18", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.09475, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:54:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40586, "dt_data": 0.02520, "dt_net": 3.38065, "epoch": "3/55", "eta": "18:27:11", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.09313, "lr": 0.00001, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:55:05][INFO] logging.py:  99: json_stats: {"RAM": "29.01/251.55G", "_type": "train_epoch", "dt": 0.00031, "dt_data": 0.00031, "dt_net": 3.94593, "epoch": "3/55", "eta": "0:00:05", "gpu_mem": "17.37G", "loss": 0.11376, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:55:05][INFO] train_net.py: 497: Epoch 2 takes 1265.14s. Epochs from 0 to 2 take 1278.34s in average and 1282.43s in median.
[03/07 19:55:05][INFO] train_net.py: 503: For epoch 2, each iteraction takes 3.37s in average. From epoch 0 to 2, each iteraction takes 3.41s in average.
[03/07 19:55:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:02:20", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.63657, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:55:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.00000, "time_diff": 1.70835, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:55:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:45", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.00000, "time_diff": 1.59476, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:56:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:32", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.00000, "time_diff": 1.65234, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:56:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:01:23", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.00000, "time_diff": 1.82269, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:56:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:00:59", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.00000, "time_diff": 1.65128, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:57:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:00:44", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.00000, "time_diff": 1.72446, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:57:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:00:26", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.00000, "time_diff": 1.64762, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:57:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.00000, "time_diff": 1.64773, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:57:51][INFO] logging.py:  99: json_stats: {"RAM": "29.16/251.55G", "_type": "val_epoch", "epoch": "3/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:58:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64802, "dt_data": 3.09671, "dt_net": 0.55130, "epoch": "4/55", "eta": "19:44:59", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.09075, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:59:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72861, "dt_data": 2.17817, "dt_net": 0.55044, "epoch": "4/55", "eta": "14:45:53", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.09208, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 19:59:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63197, "dt_data": 3.08150, "dt_net": 0.55047, "epoch": "4/55", "eta": "19:38:34", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.08827, "lr": 0.00001, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:00:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54924, "dt_data": 2.51903, "dt_net": 1.03021, "epoch": "4/55", "eta": "19:11:08", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.09010, "lr": 0.00001, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:00:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70290, "dt_data": 2.13146, "dt_net": 1.57144, "epoch": "4/55", "eta": "20:00:21", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.08877, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:01:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17979, "dt_data": 0.03862, "dt_net": 3.14117, "epoch": "4/55", "eta": "17:10:15", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.08896, "lr": 0.00001, "mAP": 0.00045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:01:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31861, "dt_data": 2.76783, "dt_net": 0.55078, "epoch": "4/55", "eta": "17:54:40", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.08565, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:02:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46321, "dt_data": 2.90998, "dt_net": 0.55322, "epoch": "4/55", "eta": "18:40:55", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.08498, "lr": 0.00001, "mAP": 0.00089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:03:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25134, "dt_data": 2.69944, "dt_net": 0.55190, "epoch": "4/55", "eta": "17:31:48", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.08507, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:03:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54807, "dt_data": 2.99470, "dt_net": 0.55336, "epoch": "4/55", "eta": "19:07:12", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.08389, "lr": 0.00001, "mAP": 0.00268, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:04:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41691, "dt_data": 2.86728, "dt_net": 0.54962, "epoch": "4/55", "eta": "18:24:13", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.08425, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:04:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53993, "dt_data": 2.98986, "dt_net": 0.55007, "epoch": "4/55", "eta": "19:03:23", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.08144, "lr": 0.00001, "mAP": 0.00268, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:05:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83035, "dt_data": 3.27615, "dt_net": 0.55420, "epoch": "4/55", "eta": "20:36:33", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.08132, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:05:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67645, "dt_data": 3.12289, "dt_net": 0.55356, "epoch": "4/55", "eta": "19:46:16", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.08246, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:06:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16763, "dt_data": 2.61473, "dt_net": 0.55290, "epoch": "4/55", "eta": "17:01:33", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.08205, "lr": 0.00001, "mAP": 0.00268, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:07:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.12712, "dt_data": 3.57779, "dt_net": 0.54932, "epoch": "4/55", "eta": "22:10:18", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.07944, "lr": 0.00001, "mAP": 0.00223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:07:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.14256, "dt_data": 3.59024, "dt_net": 0.55231, "epoch": "4/55", "eta": "22:14:35", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.07568, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:08:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74500, "dt_data": 2.19133, "dt_net": 0.55366, "epoch": "4/55", "eta": "14:43:53", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.07909, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:08:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48993, "dt_data": 2.93739, "dt_net": 0.55253, "epoch": "4/55", "eta": "18:43:10", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.07673, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:09:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43535, "dt_data": 2.88265, "dt_net": 0.55270, "epoch": "4/55", "eta": "18:25:02", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.07773, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:09:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87433, "dt_data": 3.32446, "dt_net": 0.54987, "epoch": "4/55", "eta": "20:45:35", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.07753, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:10:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33481, "dt_data": 2.78740, "dt_net": 0.54740, "epoch": "4/55", "eta": "17:51:35", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.07845, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:10:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82788, "dt_data": 0.02512, "dt_net": 2.80276, "epoch": "4/55", "eta": "15:08:13", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.07846, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:11:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17593, "dt_data": 0.02518, "dt_net": 3.15075, "epoch": "4/55", "eta": "16:59:28", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.07598, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:12:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70531, "dt_data": 0.02515, "dt_net": 3.68016, "epoch": "4/55", "eta": "19:48:47", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.07413, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:12:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81492, "dt_data": 0.02502, "dt_net": 2.78990, "epoch": "4/55", "eta": "15:02:39", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.07332, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:13:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70961, "dt_data": 0.02512, "dt_net": 3.68449, "epoch": "4/55", "eta": "19:48:55", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.07385, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:13:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84089, "dt_data": 0.02519, "dt_net": 2.81570, "epoch": "4/55", "eta": "15:10:01", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.07384, "lr": 0.00001, "mAP": 0.00313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:14:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95598, "dt_data": 2.40439, "dt_net": 0.55159, "epoch": "4/55", "eta": "15:46:24", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.07032, "lr": 0.00001, "mAP": 0.00536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:14:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59994, "dt_data": 3.04926, "dt_net": 0.55067, "epoch": "4/55", "eta": "19:11:58", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.07269, "lr": 0.00001, "mAP": 0.00179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:15:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33189, "dt_data": 0.02503, "dt_net": 3.30686, "epoch": "4/55", "eta": "17:45:39", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.07154, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:15:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21931, "dt_data": 0.02509, "dt_net": 3.19423, "epoch": "4/55", "eta": "17:09:06", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.06821, "lr": 0.00001, "mAP": 0.00208, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:16:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64365, "dt_data": 0.02498, "dt_net": 3.61867, "epoch": "4/55", "eta": "19:24:08", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.07173, "lr": 0.00001, "mAP": 0.00446, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:17:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98730, "dt_data": 0.02521, "dt_net": 2.96209, "epoch": "4/55", "eta": "15:53:56", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.06866, "lr": 0.00001, "mAP": 0.00580, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:17:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16811, "dt_data": 2.61704, "dt_net": 0.55106, "epoch": "4/55", "eta": "16:51:09", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.06635, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:18:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71363, "dt_data": 3.16178, "dt_net": 0.55185, "epoch": "4/55", "eta": "19:44:38", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.06850, "lr": 0.00001, "mAP": 0.00565, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:18:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03126, "dt_data": 2.48330, "dt_net": 0.54795, "epoch": "4/55", "eta": "16:06:27", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.06898, "lr": 0.00001, "mAP": 0.00565, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:18:59][INFO] logging.py:  99: json_stats: {"RAM": "29.28/251.55G", "_type": "train_epoch", "dt": 0.00026, "dt_data": 0.00026, "dt_net": 0.55022, "epoch": "4/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.07864, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:18:59][INFO] train_net.py: 497: Epoch 3 takes 1261.44s. Epochs from 0 to 3 take 1274.12s in average and 1273.79s in median.
[03/07 20:18:59][INFO] train_net.py: 503: For epoch 3, each iteraction takes 3.36s in average. From epoch 0 to 3, each iteraction takes 3.40s in average.
[03/07 20:19:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:02:19", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.01250, "time_diff": 1.62189, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:19:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:02:12", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.00863, "time_diff": 1.73795, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:19:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:01:42", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.01161, "time_diff": 1.55655, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:20:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:01:29", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.00893, "time_diff": 1.60613, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:20:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:01:31", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.01071, "time_diff": 1.99004, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:20:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:01:07", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.01250, "time_diff": 1.86453, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:21:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:00:43", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.01042, "time_diff": 1.65773, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:21:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.01161, "time_diff": 1.54508, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:21:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.00781, "time_diff": 1.66651, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:21:45][INFO] logging.py:  99: json_stats: {"RAM": "28.86/251.55G", "_type": "val_epoch", "epoch": "4/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:22:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92498, "dt_data": 3.36802, "dt_net": 0.55696, "epoch": "5/55", "eta": "20:50:26", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.06816, "lr": 0.00001, "mAP": 0.00313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:23:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73531, "dt_data": 3.18475, "dt_net": 0.55056, "epoch": "5/55", "eta": "19:49:23", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.06650, "lr": 0.00001, "mAP": 0.00536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:23:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42138, "dt_data": 2.87089, "dt_net": 0.55049, "epoch": "5/55", "eta": "18:08:51", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.06775, "lr": 0.00001, "mAP": 0.00357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:24:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34571, "dt_data": 2.78921, "dt_net": 0.55650, "epoch": "5/55", "eta": "17:44:12", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.06601, "lr": 0.00001, "mAP": 0.00536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:24:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49043, "dt_data": 2.93347, "dt_net": 0.55696, "epoch": "5/55", "eta": "18:29:40", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.06682, "lr": 0.00001, "mAP": 0.00759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:25:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56686, "dt_data": 3.01557, "dt_net": 0.55130, "epoch": "5/55", "eta": "18:53:22", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.06746, "lr": 0.00001, "mAP": 0.00491, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:25:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.78752, "dt_data": 2.73363, "dt_net": 1.05388, "epoch": "5/55", "eta": "20:02:51", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.06666, "lr": 0.00001, "mAP": 0.00536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:26:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31566, "dt_data": 0.02510, "dt_net": 3.29056, "epoch": "5/55", "eta": "17:32:26", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.06767, "lr": 0.00001, "mAP": 0.00804, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:27:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18618, "dt_data": 0.02504, "dt_net": 3.16114, "epoch": "5/55", "eta": "16:50:48", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.06291, "lr": 0.00001, "mAP": 0.00536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:27:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28994, "dt_data": 0.02512, "dt_net": 3.26482, "epoch": "5/55", "eta": "17:23:11", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.06448, "lr": 0.00001, "mAP": 0.00670, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:28:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20834, "dt_data": 0.02506, "dt_net": 3.18328, "epoch": "5/55", "eta": "16:56:46", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.06194, "lr": 0.00001, "mAP": 0.00580, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:28:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89646, "dt_data": 0.02501, "dt_net": 2.87145, "epoch": "5/55", "eta": "15:17:27", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.06410, "lr": 0.00001, "mAP": 0.00580, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:29:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94749, "dt_data": 0.02522, "dt_net": 2.92227, "epoch": "5/55", "eta": "15:33:07", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.06284, "lr": 0.00001, "mAP": 0.00982, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:29:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.35718, "dt_data": 0.02499, "dt_net": 4.33219, "epoch": "5/55", "eta": "22:58:41", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.06130, "lr": 0.00001, "mAP": 0.00848, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:30:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.99768, "dt_data": 0.02504, "dt_net": 3.97264, "epoch": "5/55", "eta": "21:04:16", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.06535, "lr": 0.00001, "mAP": 0.00744, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:30:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16285, "dt_data": 0.02529, "dt_net": 3.13756, "epoch": "5/55", "eta": "16:39:43", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.06117, "lr": 0.00001, "mAP": 0.00714, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:31:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22098, "dt_data": 0.02519, "dt_net": 3.19578, "epoch": "5/55", "eta": "16:57:33", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.05998, "lr": 0.00001, "mAP": 0.00625, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:32:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88474, "dt_data": 0.02506, "dt_net": 2.85968, "epoch": "5/55", "eta": "15:10:51", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.06082, "lr": 0.00001, "mAP": 0.00871, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:32:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82415, "dt_data": 0.20572, "dt_net": 3.61843, "epoch": "5/55", "eta": "20:06:50", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.06188, "lr": 0.00001, "mAP": 0.00893, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:33:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32327, "dt_data": 0.02501, "dt_net": 3.29826, "epoch": "5/55", "eta": "17:28:12", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.06320, "lr": 0.00001, "mAP": 0.00982, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:33:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59404, "dt_data": 0.02504, "dt_net": 3.56900, "epoch": "5/55", "eta": "18:53:01", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.06014, "lr": 0.00001, "mAP": 0.00804, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:34:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17912, "dt_data": 0.02505, "dt_net": 3.15406, "epoch": "5/55", "eta": "16:41:41", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.06054, "lr": 0.00001, "mAP": 0.01161, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:34:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01844, "dt_data": 0.02516, "dt_net": 2.99328, "epoch": "5/55", "eta": "15:50:33", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.05815, "lr": 0.00001, "mAP": 0.00759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:35:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00163, "dt_data": 0.95197, "dt_net": 2.04965, "epoch": "5/55", "eta": "15:44:45", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.05973, "lr": 0.00001, "mAP": 0.01310, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:36:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88357, "dt_data": 2.33399, "dt_net": 0.54958, "epoch": "5/55", "eta": "15:07:07", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.06108, "lr": 0.00001, "mAP": 0.00982, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:36:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66443, "dt_data": 3.11687, "dt_net": 0.54756, "epoch": "5/55", "eta": "19:12:09", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.06049, "lr": 0.00001, "mAP": 0.00625, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:37:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42913, "dt_data": 2.87450, "dt_net": 0.55463, "epoch": "5/55", "eta": "17:57:36", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.06033, "lr": 0.00001, "mAP": 0.00759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:37:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67577, "dt_data": 3.12620, "dt_net": 0.54956, "epoch": "5/55", "eta": "19:14:29", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.05981, "lr": 0.00001, "mAP": 0.01161, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:38:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54756, "dt_data": 2.99350, "dt_net": 0.55406, "epoch": "5/55", "eta": "18:33:38", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.05770, "lr": 0.00001, "mAP": 0.00759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:38:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10639, "dt_data": 2.19845, "dt_net": 0.90794, "epoch": "5/55", "eta": "16:14:37", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.06138, "lr": 0.00001, "mAP": 0.01027, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:39:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17978, "dt_data": 0.54173, "dt_net": 2.63805, "epoch": "5/55", "eta": "16:37:07", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.05897, "lr": 0.00001, "mAP": 0.00759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:40:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53220, "dt_data": 0.02504, "dt_net": 3.50716, "epoch": "5/55", "eta": "18:27:02", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.05701, "lr": 0.00001, "mAP": 0.01116, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:40:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56564, "dt_data": 0.02521, "dt_net": 3.54043, "epoch": "5/55", "eta": "18:36:56", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.05861, "lr": 0.00001, "mAP": 0.01295, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:41:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25723, "dt_data": 0.02499, "dt_net": 3.23223, "epoch": "5/55", "eta": "16:59:47", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.05790, "lr": 0.00001, "mAP": 0.00938, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:41:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89352, "dt_data": 0.02511, "dt_net": 2.86841, "epoch": "5/55", "eta": "15:05:25", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.05860, "lr": 0.00001, "mAP": 0.01116, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:42:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26569, "dt_data": 2.01221, "dt_net": 1.25348, "epoch": "5/55", "eta": "17:01:20", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.05694, "lr": 0.00001, "mAP": 0.01116, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:42:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48332, "dt_data": 0.66557, "dt_net": 2.81775, "epoch": "5/55", "eta": "18:08:49", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.05458, "lr": 0.00001, "mAP": 0.01696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:43:07][INFO] logging.py:  99: json_stats: {"RAM": "28.81/251.55G", "_type": "train_epoch", "dt": 0.00028, "dt_data": 0.00028, "dt_net": 3.24753, "epoch": "5/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.06183, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:43:07][INFO] train_net.py: 497: Epoch 4 takes 1276.52s. Epochs from 0 to 4 take 1274.60s in average and 1276.52s in median.
[03/07 20:43:07][INFO] train_net.py: 503: For epoch 4, each iteraction takes 3.40s in average. From epoch 0 to 4, each iteraction takes 3.40s in average.
[03/07 20:43:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:02:17", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.01384, "time_diff": 1.60282, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:43:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:02:08", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.01161, "time_diff": 1.68759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:44:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:01:56", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.01429, "time_diff": 1.76267, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:44:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:01:41", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.01042, "time_diff": 1.81694, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:44:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:01:18", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.01399, "time_diff": 1.70402, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:44:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:01:00", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.01384, "time_diff": 1.68778, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:45:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:00:47", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.01161, "time_diff": 1.84227, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:45:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:00:26", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.01116, "time_diff": 1.65301, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:45:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.00938, "time_diff": 1.60708, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:45:54][INFO] logging.py:  99: json_stats: {"RAM": "29.60/251.55G", "_type": "val_epoch", "epoch": "5/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:46:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52700, "dt_data": 2.97260, "dt_net": 0.55440, "epoch": "6/55", "eta": "18:21:35", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.05445, "lr": 0.00001, "mAP": 0.01071, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:47:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38820, "dt_data": 2.83602, "dt_net": 0.55218, "epoch": "6/55", "eta": "17:37:41", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.05661, "lr": 0.00001, "mAP": 0.01643, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:47:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25528, "dt_data": 2.70372, "dt_net": 0.55156, "epoch": "6/55", "eta": "16:55:38", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.05372, "lr": 0.00001, "mAP": 0.00938, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:48:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26466, "dt_data": 2.39496, "dt_net": 0.86970, "epoch": "6/55", "eta": "16:58:01", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.05668, "lr": 0.00001, "mAP": 0.01295, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:48:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85562, "dt_data": 1.93435, "dt_net": 1.92127, "epoch": "6/55", "eta": "20:01:40", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.05481, "lr": 0.00001, "mAP": 0.01057, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:49:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58116, "dt_data": 0.02502, "dt_net": 3.55614, "epoch": "6/55", "eta": "18:35:31", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.05533, "lr": 0.00001, "mAP": 0.01652, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:49:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66910, "dt_data": 0.02505, "dt_net": 3.64406, "epoch": "6/55", "eta": "19:02:18", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.05265, "lr": 0.00001, "mAP": 0.01518, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:50:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57277, "dt_data": 0.02502, "dt_net": 3.54775, "epoch": "6/55", "eta": "18:31:43", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.05393, "lr": 0.00001, "mAP": 0.01875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:50:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42761, "dt_data": 0.02507, "dt_net": 3.40254, "epoch": "6/55", "eta": "17:45:59", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.05451, "lr": 0.00001, "mAP": 0.01205, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:51:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24035, "dt_data": 0.02516, "dt_net": 3.21519, "epoch": "6/55", "eta": "16:47:12", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.05388, "lr": 0.00001, "mAP": 0.01696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:52:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91834, "dt_data": 0.02502, "dt_net": 3.89331, "epoch": "6/55", "eta": "20:17:17", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.05497, "lr": 0.00001, "mAP": 0.00759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:52:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18219, "dt_data": 0.02510, "dt_net": 3.15709, "epoch": "6/55", "eta": "16:28:04", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.05444, "lr": 0.00001, "mAP": 0.01920, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:53:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82981, "dt_data": 0.02505, "dt_net": 2.80476, "epoch": "6/55", "eta": "14:38:11", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.05462, "lr": 0.00001, "mAP": 0.01979, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:53:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62156, "dt_data": 0.02512, "dt_net": 3.59644, "epoch": "6/55", "eta": "18:43:17", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.05453, "lr": 0.00001, "mAP": 0.01637, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:54:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08995, "dt_data": 0.02500, "dt_net": 3.06494, "epoch": "6/55", "eta": "15:57:53", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.05302, "lr": 0.00001, "mAP": 0.01429, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:54:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75355, "dt_data": 0.02512, "dt_net": 3.72843, "epoch": "6/55", "eta": "19:22:58", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.05378, "lr": 0.00001, "mAP": 0.01577, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:55:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46416, "dt_data": 0.02502, "dt_net": 3.43913, "epoch": "6/55", "eta": "17:52:44", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.05188, "lr": 0.00001, "mAP": 0.01875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:56:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68611, "dt_data": 0.02507, "dt_net": 2.66104, "epoch": "6/55", "eta": "13:51:21", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.05338, "lr": 0.00001, "mAP": 0.02262, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:56:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85447, "dt_data": 0.02495, "dt_net": 2.82951, "epoch": "6/55", "eta": "14:42:58", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.05163, "lr": 0.00001, "mAP": 0.01652, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:57:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75398, "dt_data": 0.02507, "dt_net": 2.72891, "epoch": "6/55", "eta": "14:11:26", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.05465, "lr": 0.00001, "mAP": 0.01696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:57:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09291, "dt_data": 0.02511, "dt_net": 3.06780, "epoch": "6/55", "eta": "15:55:42", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.05192, "lr": 0.00001, "mAP": 0.01979, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:58:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36898, "dt_data": 0.02501, "dt_net": 3.34397, "epoch": "6/55", "eta": "17:20:27", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.05128, "lr": 0.00001, "mAP": 0.02321, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:58:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02464, "dt_data": 0.02500, "dt_net": 3.99963, "epoch": "6/55", "eta": "20:42:16", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.05275, "lr": 0.00001, "mAP": 0.01786, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 20:59:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37901, "dt_data": 0.02500, "dt_net": 3.35401, "epoch": "6/55", "eta": "17:22:25", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.05090, "lr": 0.00001, "mAP": 0.01652, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:00:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72151, "dt_data": 0.02504, "dt_net": 3.69647, "epoch": "6/55", "eta": "19:07:27", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.05259, "lr": 0.00001, "mAP": 0.01830, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:00:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62649, "dt_data": 0.02516, "dt_net": 3.60132, "epoch": "6/55", "eta": "18:37:33", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.05094, "lr": 0.00001, "mAP": 0.01339, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:01:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59008, "dt_data": 0.02505, "dt_net": 3.56503, "epoch": "6/55", "eta": "18:25:44", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.05101, "lr": 0.00001, "mAP": 0.01503, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:01:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38395, "dt_data": 0.02510, "dt_net": 3.35884, "epoch": "6/55", "eta": "17:21:41", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.05209, "lr": 0.00001, "mAP": 0.01533, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:02:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.79615, "dt_data": 0.02504, "dt_net": 2.77111, "epoch": "6/55", "eta": "14:20:16", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.04932, "lr": 0.00001, "mAP": 0.02054, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:02:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87055, "dt_data": 0.02512, "dt_net": 2.84543, "epoch": "6/55", "eta": "14:42:41", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.05028, "lr": 0.00001, "mAP": 0.02068, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:03:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97049, "dt_data": 0.02507, "dt_net": 2.94542, "epoch": "6/55", "eta": "15:12:55", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.05266, "lr": 0.00001, "mAP": 0.02113, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:03:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46113, "dt_data": 2.25056, "dt_net": 1.21057, "epoch": "6/55", "eta": "17:43:08", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.05006, "lr": 0.00001, "mAP": 0.02054, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:04:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30019, "dt_data": 0.02513, "dt_net": 3.27506, "epoch": "6/55", "eta": "16:53:09", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.04820, "lr": 0.00001, "mAP": 0.01696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:05:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34595, "dt_data": 0.02500, "dt_net": 3.32095, "epoch": "6/55", "eta": "17:06:38", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.04928, "lr": 0.00001, "mAP": 0.01875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:05:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48945, "dt_data": 0.02507, "dt_net": 3.46438, "epoch": "6/55", "eta": "17:50:05", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.04903, "lr": 0.00001, "mAP": 0.01696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:06:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47380, "dt_data": 0.02502, "dt_net": 3.44878, "epoch": "6/55", "eta": "17:44:43", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.04720, "lr": 0.00001, "mAP": 0.02351, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:06:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74280, "dt_data": 0.02505, "dt_net": 3.71775, "epoch": "6/55", "eta": "19:06:32", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.04991, "lr": 0.00001, "mAP": 0.01347, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:06:57][INFO] logging.py:  99: json_stats: {"RAM": "29.25/251.55G", "_type": "train_epoch", "dt": 0.00029, "dt_data": 0.00029, "dt_net": 3.54924, "epoch": "6/55", "eta": "0:00:05", "gpu_mem": "17.37G", "loss": 0.05255, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:06:57][INFO] train_net.py: 497: Epoch 5 takes 1257.88s. Epochs from 0 to 5 take 1271.81s in average and 1270.83s in median.
[03/07 21:06:57][INFO] train_net.py: 503: For epoch 5, each iteraction takes 3.35s in average. From epoch 0 to 5, each iteraction takes 3.39s in average.
[03/07 21:07:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:02:21", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.03251, "time_diff": 1.64866, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:07:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:02:18", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.02798, "time_diff": 1.81753, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:07:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:01:52", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.03028, "time_diff": 1.70381, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:08:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:01:42", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.03226, "time_diff": 1.83554, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:08:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:01:10", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.02987, "time_diff": 1.53984, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:08:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:00:59", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.02993, "time_diff": 1.65756, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:09:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:00:50", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.03289, "time_diff": 1.93303, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:09:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.03074, "time_diff": 1.59237, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:09:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/55", "eta": "0:00:10", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.02954, "time_diff": 1.66818, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:09:45][INFO] logging.py:  99: json_stats: {"RAM": "29.13/251.55G", "_type": "val_epoch", "epoch": "6/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:10:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37638, "dt_data": 2.82244, "dt_net": 0.55394, "epoch": "7/55", "eta": "17:13:27", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.04954, "lr": 0.00001, "mAP": 0.02783, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:10:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03082, "dt_data": 2.47588, "dt_net": 0.55494, "epoch": "7/55", "eta": "15:27:10", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.04842, "lr": 0.00001, "mAP": 0.02411, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:11:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10741, "dt_data": 2.55224, "dt_net": 0.55517, "epoch": "7/55", "eta": "15:50:05", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.05002, "lr": 0.00001, "mAP": 0.02155, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:12:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.81070, "dt_data": 3.26063, "dt_net": 0.55007, "epoch": "7/55", "eta": "19:24:29", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.04909, "lr": 0.00001, "mAP": 0.02113, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:12:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07183, "dt_data": 2.51860, "dt_net": 0.55323, "epoch": "7/55", "eta": "15:38:11", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.04922, "lr": 0.00001, "mAP": 0.01917, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:13:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75809, "dt_data": 3.20667, "dt_net": 0.55141, "epoch": "7/55", "eta": "19:07:09", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.04968, "lr": 0.00001, "mAP": 0.02589, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:13:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91765, "dt_data": 3.36466, "dt_net": 0.55298, "epoch": "7/55", "eta": "19:55:12", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.04899, "lr": 0.00001, "mAP": 0.01629, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:14:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.00237, "dt_data": 3.45270, "dt_net": 0.54967, "epoch": "7/55", "eta": "20:20:23", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.04873, "lr": 0.00001, "mAP": 0.01957, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:14:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44100, "dt_data": 2.89433, "dt_net": 0.54667, "epoch": "7/55", "eta": "17:28:38", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.04813, "lr": 0.00001, "mAP": 0.02284, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:15:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04428, "dt_data": 2.49897, "dt_net": 0.54531, "epoch": "7/55", "eta": "15:27:14", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.04539, "lr": 0.00001, "mAP": 0.01875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:15:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29965, "dt_data": 2.74556, "dt_net": 0.55408, "epoch": "7/55", "eta": "16:44:28", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.05018, "lr": 0.00001, "mAP": 0.01533, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:16:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17930, "dt_data": 2.62747, "dt_net": 0.55183, "epoch": "7/55", "eta": "16:07:18", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.04785, "lr": 0.00001, "mAP": 0.02515, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:17:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11082, "dt_data": 1.37655, "dt_net": 1.73427, "epoch": "7/55", "eta": "15:45:56", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.04794, "lr": 0.00001, "mAP": 0.02062, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:17:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39583, "dt_data": 0.02517, "dt_net": 3.37066, "epoch": "7/55", "eta": "17:12:03", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.04612, "lr": 0.00001, "mAP": 0.02065, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:18:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02465, "dt_data": 0.02505, "dt_net": 2.99961, "epoch": "7/55", "eta": "15:18:44", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.04903, "lr": 0.00001, "mAP": 0.02113, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:18:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54395, "dt_data": 0.02505, "dt_net": 3.51890, "epoch": "7/55", "eta": "17:55:53", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.04735, "lr": 0.00001, "mAP": 0.01637, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:19:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88529, "dt_data": 0.02507, "dt_net": 3.86021, "epoch": "7/55", "eta": "19:38:51", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.04587, "lr": 0.00001, "mAP": 0.02760, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:19:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74074, "dt_data": 0.02521, "dt_net": 3.71553, "epoch": "7/55", "eta": "18:54:22", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.04672, "lr": 0.00001, "mAP": 0.02500, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:20:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.66480, "dt_data": 0.02503, "dt_net": 2.63977, "epoch": "7/55", "eta": "13:27:39", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.04750, "lr": 0.00001, "mAP": 0.02173, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:21:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96209, "dt_data": 0.02514, "dt_net": 2.93694, "epoch": "7/55", "eta": "14:57:15", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.04603, "lr": 0.00001, "mAP": 0.02545, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:21:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22268, "dt_data": 0.02505, "dt_net": 3.19764, "epoch": "7/55", "eta": "16:15:40", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.04627, "lr": 0.00001, "mAP": 0.02426, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:22:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.15758, "dt_data": 0.02503, "dt_net": 4.13255, "epoch": "7/55", "eta": "20:58:00", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.04745, "lr": 0.00001, "mAP": 0.02693, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:22:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.54232, "dt_data": 0.02509, "dt_net": 4.51723, "epoch": "7/55", "eta": "22:53:40", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.04748, "lr": 0.00001, "mAP": 0.02098, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:23:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82110, "dt_data": 0.02512, "dt_net": 3.79598, "epoch": "7/55", "eta": "19:14:55", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.04468, "lr": 0.00001, "mAP": 0.02143, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:23:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80257, "dt_data": 0.02522, "dt_net": 2.77735, "epoch": "7/55", "eta": "14:06:36", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.04858, "lr": 0.00001, "mAP": 0.02336, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:24:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54946, "dt_data": 0.02503, "dt_net": 3.52443, "epoch": "7/55", "eta": "17:51:38", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.04502, "lr": 0.00001, "mAP": 0.02411, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:24:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51456, "dt_data": 0.02519, "dt_net": 3.48937, "epoch": "7/55", "eta": "17:40:31", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.04539, "lr": 0.00001, "mAP": 0.02268, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:25:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44625, "dt_data": 0.02506, "dt_net": 3.42119, "epoch": "7/55", "eta": "17:19:19", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.04583, "lr": 0.00001, "mAP": 0.02381, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:26:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09005, "dt_data": 0.02510, "dt_net": 3.06494, "epoch": "7/55", "eta": "15:31:23", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.04736, "lr": 0.00001, "mAP": 0.03065, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:26:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52797, "dt_data": 0.02503, "dt_net": 3.50294, "epoch": "7/55", "eta": "17:42:48", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.04809, "lr": 0.00001, "mAP": 0.01860, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:27:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49569, "dt_data": 0.02503, "dt_net": 3.47066, "epoch": "7/55", "eta": "17:32:29", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.04500, "lr": 0.00001, "mAP": 0.03051, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:27:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12024, "dt_data": 0.02513, "dt_net": 3.09510, "epoch": "7/55", "eta": "15:38:55", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.04845, "lr": 0.00001, "mAP": 0.02396, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:28:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89235, "dt_data": 0.02501, "dt_net": 3.86733, "epoch": "7/55", "eta": "19:30:37", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.04668, "lr": 0.00001, "mAP": 0.02954, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:28:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82026, "dt_data": 0.02513, "dt_net": 3.79513, "epoch": "7/55", "eta": "19:08:18", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.04368, "lr": 0.00001, "mAP": 0.02098, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:29:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75548, "dt_data": 0.02500, "dt_net": 3.73049, "epoch": "7/55", "eta": "18:48:12", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.04982, "lr": 0.00001, "mAP": 0.03378, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:30:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46212, "dt_data": 0.02509, "dt_net": 3.43702, "epoch": "7/55", "eta": "17:19:30", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.04569, "lr": 0.00001, "mAP": 0.02202, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:30:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59839, "dt_data": 0.02522, "dt_net": 2.57317, "epoch": "7/55", "eta": "12:59:44", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.04447, "lr": 0.00001, "mAP": 0.02545, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:30:53][INFO] logging.py:  99: json_stats: {"RAM": "29.40/251.55G", "_type": "train_epoch", "dt": 0.00026, "dt_data": 0.00026, "dt_net": 2.07809, "epoch": "7/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.04754, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:30:53][INFO] train_net.py: 497: Epoch 6 takes 1262.58s. Epochs from 0 to 6 take 1270.49s in average and 1265.14s in median.
[03/07 21:30:53][INFO] train_net.py: 503: For epoch 6, each iteraction takes 3.37s in average. From epoch 0 to 6, each iteraction takes 3.39s in average.
[03/07 21:31:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:02:20", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.03125, "time_diff": 1.63587, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:31:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:02:19", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.03162, "time_diff": 1.83106, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:31:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:01:54", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.03524, "time_diff": 1.73998, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:32:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:01:37", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.03472, "time_diff": 1.73878, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:32:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:01:16", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.03274, "time_diff": 1.65334, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:32:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:00:54", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.03073, "time_diff": 1.51771, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:32:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:00:44", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.03479, "time_diff": 1.73070, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:33:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:00:26", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.03289, "time_diff": 1.66942, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:33:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.02470, "time_diff": 1.54617, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:33:40][INFO] logging.py:  99: json_stats: {"RAM": "29.45/251.55G", "_type": "val_epoch", "epoch": "7/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:34:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11944, "dt_data": 2.57030, "dt_net": 0.54913, "epoch": "8/55", "eta": "15:35:18", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.04593, "lr": 0.00001, "mAP": 0.02068, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:34:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13593, "dt_data": 1.64645, "dt_net": 1.48948, "epoch": "8/55", "eta": "15:39:43", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.04431, "lr": 0.00001, "mAP": 0.02374, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:35:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46427, "dt_data": 1.42410, "dt_net": 2.04016, "epoch": "8/55", "eta": "17:17:32", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.04528, "lr": 0.00001, "mAP": 0.02254, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:35:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17254, "dt_data": 1.67185, "dt_net": 1.50069, "epoch": "8/55", "eta": "15:49:38", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.04481, "lr": 0.00001, "mAP": 0.02269, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:36:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52450, "dt_data": 0.27211, "dt_net": 3.25239, "epoch": "8/55", "eta": "17:34:24", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.04718, "lr": 0.00001, "mAP": 0.02902, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:37:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08368, "dt_data": 1.32610, "dt_net": 1.75757, "epoch": "8/55", "eta": "15:22:01", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.04351, "lr": 0.00001, "mAP": 0.02202, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:37:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58910, "dt_data": 1.87577, "dt_net": 1.71333, "epoch": "8/55", "eta": "17:52:32", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.04730, "lr": 0.00001, "mAP": 0.02902, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:38:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50763, "dt_data": 0.02509, "dt_net": 3.48254, "epoch": "8/55", "eta": "17:27:36", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.04469, "lr": 0.00001, "mAP": 0.03810, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:38:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32211, "dt_data": 0.02502, "dt_net": 3.29709, "epoch": "8/55", "eta": "16:31:39", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.04434, "lr": 0.00001, "mAP": 0.03021, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:39:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09454, "dt_data": 0.02499, "dt_net": 3.06955, "epoch": "8/55", "eta": "15:23:12", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.04554, "lr": 0.00001, "mAP": 0.02813, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:39:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91582, "dt_data": 1.27521, "dt_net": 2.64060, "epoch": "8/55", "eta": "19:27:33", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.04344, "lr": 0.00001, "mAP": 0.02403, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:40:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67355, "dt_data": 0.02509, "dt_net": 3.64846, "epoch": "8/55", "eta": "18:14:43", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.04446, "lr": 0.00001, "mAP": 0.02902, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:41:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.69160, "dt_data": 0.02516, "dt_net": 2.66643, "epoch": "8/55", "eta": "13:21:38", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.04339, "lr": 0.00001, "mAP": 0.02247, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:41:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71970, "dt_data": 0.02502, "dt_net": 3.69468, "epoch": "8/55", "eta": "18:27:13", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.04450, "lr": 0.00001, "mAP": 0.02961, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:42:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19972, "dt_data": 0.30417, "dt_net": 2.89555, "epoch": "8/55", "eta": "15:51:54", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.04418, "lr": 0.00001, "mAP": 0.02321, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:42:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34506, "dt_data": 0.99677, "dt_net": 2.34828, "epoch": "8/55", "eta": "16:34:35", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.04324, "lr": 0.00001, "mAP": 0.02750, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:43:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97549, "dt_data": 0.02516, "dt_net": 3.95032, "epoch": "8/55", "eta": "19:41:22", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.04590, "lr": 0.00001, "mAP": 0.03080, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:43:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29467, "dt_data": 0.02515, "dt_net": 3.26952, "epoch": "8/55", "eta": "16:18:30", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.04334, "lr": 0.00001, "mAP": 0.02515, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:44:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68699, "dt_data": 0.02510, "dt_net": 3.66189, "epoch": "8/55", "eta": "18:14:25", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.04640, "lr": 0.00001, "mAP": 0.02679, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:45:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51627, "dt_data": 1.26633, "dt_net": 2.24994, "epoch": "8/55", "eta": "17:23:09", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.04393, "lr": 0.00001, "mAP": 0.03251, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:45:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47621, "dt_data": 0.02499, "dt_net": 3.45122, "epoch": "8/55", "eta": "17:10:41", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.04455, "lr": 0.00001, "mAP": 0.02946, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:46:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97576, "dt_data": 0.02503, "dt_net": 3.95073, "epoch": "8/55", "eta": "19:38:09", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.04381, "lr": 0.00001, "mAP": 0.02932, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:46:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34630, "dt_data": 0.02501, "dt_net": 3.32129, "epoch": "8/55", "eta": "16:31:03", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.04324, "lr": 0.00001, "mAP": 0.02530, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:47:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61003, "dt_data": 0.06646, "dt_net": 3.54357, "epoch": "8/55", "eta": "17:48:34", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.04152, "lr": 0.00001, "mAP": 0.02612, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:47:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52123, "dt_data": 0.02501, "dt_net": 3.49621, "epoch": "8/55", "eta": "17:21:41", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.04378, "lr": 0.00001, "mAP": 0.02567, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:48:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13467, "dt_data": 0.02509, "dt_net": 3.10957, "epoch": "8/55", "eta": "15:26:49", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.04180, "lr": 0.00001, "mAP": 0.03646, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:49:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00295, "dt_data": 0.02498, "dt_net": 2.97797, "epoch": "8/55", "eta": "14:47:22", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.04590, "lr": 0.00001, "mAP": 0.02665, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:49:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59327, "dt_data": 0.02501, "dt_net": 3.56826, "epoch": "8/55", "eta": "17:41:12", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.04543, "lr": 0.00001, "mAP": 0.03497, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:50:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84710, "dt_data": 0.02501, "dt_net": 3.82209, "epoch": "8/55", "eta": "18:55:32", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.04415, "lr": 0.00001, "mAP": 0.03118, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:50:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09993, "dt_data": 0.02501, "dt_net": 3.07492, "epoch": "8/55", "eta": "15:14:28", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.04333, "lr": 0.00001, "mAP": 0.03348, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:51:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97352, "dt_data": 0.02507, "dt_net": 2.94845, "epoch": "8/55", "eta": "14:36:41", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.04596, "lr": 0.00001, "mAP": 0.02946, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:51:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25717, "dt_data": 0.02505, "dt_net": 3.23212, "epoch": "8/55", "eta": "15:59:46", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.04316, "lr": 0.00001, "mAP": 0.03170, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:52:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21047, "dt_data": 0.02517, "dt_net": 3.18530, "epoch": "8/55", "eta": "15:45:29", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.04541, "lr": 0.00001, "mAP": 0.03378, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:53:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.24657, "dt_data": 0.02512, "dt_net": 4.22145, "epoch": "8/55", "eta": "20:49:54", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.04296, "lr": 0.00001, "mAP": 0.03527, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:53:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93622, "dt_data": 0.02501, "dt_net": 2.91121, "epoch": "8/55", "eta": "14:23:44", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.04152, "lr": 0.00001, "mAP": 0.03452, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:54:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.14314, "dt_data": 0.02510, "dt_net": 4.11804, "epoch": "8/55", "eta": "20:18:04", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.04232, "lr": 0.00001, "mAP": 0.03237, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:54:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83085, "dt_data": 0.02524, "dt_net": 3.80561, "epoch": "8/55", "eta": "18:45:37", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.04206, "lr": 0.00001, "mAP": 0.02024, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:55:03][INFO] logging.py:  99: json_stats: {"RAM": "29.26/251.55G", "_type": "train_epoch", "dt": 0.00032, "dt_data": 0.00032, "dt_net": 3.40396, "epoch": "8/55", "eta": "0:00:05", "gpu_mem": "17.37G", "loss": 0.04430, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:55:03][INFO] train_net.py: 497: Epoch 7 takes 1278.05s. Epochs from 0 to 7 take 1271.44s in average and 1270.83s in median.
[03/07 21:55:03][INFO] train_net.py: 503: For epoch 7, each iteraction takes 3.41s in average. From epoch 0 to 7, each iteraction takes 3.39s in average.
[03/07 21:55:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:02:26", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.03068, "time_diff": 1.69784, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:55:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:02:25", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.03137, "time_diff": 1.91369, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:55:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:01:44", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.03414, "time_diff": 1.57910, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:56:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:01:33", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.03496, "time_diff": 1.66408, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:56:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:01:05", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.03189, "time_diff": 1.42267, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:56:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:00:58", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.03719, "time_diff": 1.62484, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:57:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:00:46", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.03521, "time_diff": 1.80421, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:57:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.03573, "time_diff": 1.62243, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:57:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.03052, "time_diff": 1.99134, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:57:51][INFO] logging.py:  99: json_stats: {"RAM": "29.04/251.55G", "_type": "val_epoch", "epoch": "8/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:58:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90961, "dt_data": 3.35976, "dt_net": 0.54985, "epoch": "9/55", "eta": "19:07:47", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.04247, "lr": 0.00001, "mAP": 0.03628, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:59:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99561, "dt_data": 2.44215, "dt_net": 0.55345, "epoch": "9/55", "eta": "14:38:57", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.04289, "lr": 0.00001, "mAP": 0.02396, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 21:59:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86703, "dt_data": 3.31872, "dt_net": 0.54830, "epoch": "9/55", "eta": "18:54:00", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.04197, "lr": 0.00001, "mAP": 0.02991, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:00:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56027, "dt_data": 1.95157, "dt_net": 1.60870, "epoch": "9/55", "eta": "17:23:27", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.04237, "lr": 0.00001, "mAP": 0.03750, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:00:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57510, "dt_data": 1.44981, "dt_net": 2.12529, "epoch": "9/55", "eta": "17:27:12", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.04081, "lr": 0.00001, "mAP": 0.03348, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:01:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39146, "dt_data": 0.02507, "dt_net": 3.36639, "epoch": "9/55", "eta": "16:32:51", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.04500, "lr": 0.00001, "mAP": 0.03140, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:01:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12726, "dt_data": 1.41243, "dt_net": 1.71482, "epoch": "9/55", "eta": "15:14:58", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.04312, "lr": 0.00001, "mAP": 0.03765, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:02:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74915, "dt_data": 0.02518, "dt_net": 3.72397, "epoch": "9/55", "eta": "18:16:18", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.04379, "lr": 0.00001, "mAP": 0.03308, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:02:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07138, "dt_data": 0.02502, "dt_net": 3.04636, "epoch": "9/55", "eta": "14:57:36", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.04131, "lr": 0.00001, "mAP": 0.03839, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:03:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49864, "dt_data": 0.43386, "dt_net": 3.06478, "epoch": "9/55", "eta": "17:01:53", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.04379, "lr": 0.00001, "mAP": 0.03482, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:04:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90368, "dt_data": 0.02506, "dt_net": 3.87862, "epoch": "9/55", "eta": "18:59:33", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.04205, "lr": 0.00001, "mAP": 0.02723, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:04:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61386, "dt_data": 0.02505, "dt_net": 3.58881, "epoch": "9/55", "eta": "17:34:20", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.04191, "lr": 0.00001, "mAP": 0.03408, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:05:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97419, "dt_data": 0.02498, "dt_net": 2.94921, "epoch": "9/55", "eta": "14:27:13", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.04051, "lr": 0.00001, "mAP": 0.03616, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:05:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83571, "dt_data": 0.02502, "dt_net": 2.81069, "epoch": "9/55", "eta": "13:46:22", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.04224, "lr": 0.00001, "mAP": 0.03063, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:06:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87493, "dt_data": 0.46323, "dt_net": 2.41169, "epoch": "9/55", "eta": "13:57:19", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.04078, "lr": 0.00001, "mAP": 0.03214, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:06:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.90151, "dt_data": 1.72127, "dt_net": 1.18024, "epoch": "9/55", "eta": "14:04:34", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.04216, "lr": 0.00001, "mAP": 0.03378, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:07:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14587, "dt_data": 1.85137, "dt_net": 1.29450, "epoch": "9/55", "eta": "15:15:11", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.04141, "lr": 0.00001, "mAP": 0.03192, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:07:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83333, "dt_data": 1.90105, "dt_net": 0.93228, "epoch": "9/55", "eta": "13:43:47", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.04102, "lr": 0.00001, "mAP": 0.02932, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:08:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.41734, "dt_data": 0.02497, "dt_net": 2.39237, "epoch": "9/55", "eta": "11:42:26", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.04081, "lr": 0.00001, "mAP": 0.02560, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:09:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.76195, "dt_data": 0.02504, "dt_net": 2.73690, "epoch": "9/55", "eta": "13:22:06", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.04319, "lr": 0.00001, "mAP": 0.03799, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:09:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33953, "dt_data": 1.00474, "dt_net": 2.33479, "epoch": "9/55", "eta": "16:09:17", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.04084, "lr": 0.00001, "mAP": 0.03036, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:10:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.78968, "dt_data": 0.16063, "dt_net": 3.62905, "epoch": "9/55", "eta": "18:19:19", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.04176, "lr": 0.00001, "mAP": 0.03792, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:10:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11216, "dt_data": 0.02517, "dt_net": 3.08698, "epoch": "9/55", "eta": "15:02:15", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.04090, "lr": 0.00001, "mAP": 0.02932, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:11:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97874, "dt_data": 0.02500, "dt_net": 2.95374, "epoch": "9/55", "eta": "14:23:05", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.04060, "lr": 0.00001, "mAP": 0.02872, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:11:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20852, "dt_data": 0.02500, "dt_net": 3.18352, "epoch": "9/55", "eta": "15:29:08", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.04307, "lr": 0.00001, "mAP": 0.03304, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:12:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.78843, "dt_data": 0.02502, "dt_net": 2.76341, "epoch": "9/55", "eta": "13:27:01", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.04182, "lr": 0.00001, "mAP": 0.02478, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:13:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83613, "dt_data": 0.02502, "dt_net": 3.81111, "epoch": "9/55", "eta": "18:29:36", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.04001, "lr": 0.00001, "mAP": 0.03765, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:13:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84300, "dt_data": 0.02531, "dt_net": 2.81769, "epoch": "9/55", "eta": "13:41:51", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.04044, "lr": 0.00001, "mAP": 0.02976, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:14:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73648, "dt_data": 0.02511, "dt_net": 3.71136, "epoch": "9/55", "eta": "17:59:31", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.04143, "lr": 0.00001, "mAP": 0.03661, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:14:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54857, "dt_data": 0.02502, "dt_net": 3.52354, "epoch": "9/55", "eta": "17:04:38", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.04055, "lr": 0.00001, "mAP": 0.02589, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:15:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93302, "dt_data": 0.02508, "dt_net": 3.90793, "epoch": "9/55", "eta": "18:55:00", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.04144, "lr": 0.00001, "mAP": 0.03378, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:15:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69693, "dt_data": 1.54389, "dt_net": 2.15303, "epoch": "9/55", "eta": "17:46:15", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.04073, "lr": 0.00001, "mAP": 0.03192, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:16:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86882, "dt_data": 0.02501, "dt_net": 3.84380, "epoch": "9/55", "eta": "18:35:11", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.04429, "lr": 0.00001, "mAP": 0.03065, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:17:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68366, "dt_data": 0.02519, "dt_net": 2.65847, "epoch": "9/55", "eta": "12:53:07", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03948, "lr": 0.00001, "mAP": 0.02857, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:17:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00811, "dt_data": 0.06672, "dt_net": 2.94139, "epoch": "9/55", "eta": "14:26:05", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.04059, "lr": 0.00001, "mAP": 0.03155, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:18:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44781, "dt_data": 2.89608, "dt_net": 0.55173, "epoch": "9/55", "eta": "16:32:06", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.04065, "lr": 0.00001, "mAP": 0.03810, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:18:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09358, "dt_data": 2.54100, "dt_net": 0.55258, "epoch": "9/55", "eta": "14:49:39", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.04154, "lr": 0.00001, "mAP": 0.03140, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:19:07][INFO] logging.py:  99: json_stats: {"RAM": "29.07/251.55G", "_type": "train_epoch", "dt": 0.00028, "dt_data": 0.00028, "dt_net": 1.09747, "epoch": "9/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.04188, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:19:07][INFO] train_net.py: 497: Epoch 8 takes 1270.50s. Epochs from 0 to 8 take 1271.33s in average and 1270.50s in median.
[03/07 22:19:07][INFO] train_net.py: 503: For epoch 8, each iteraction takes 3.39s in average. From epoch 0 to 8, each iteraction takes 3.39s in average.
[03/07 22:19:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:02:14", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.03603, "time_diff": 1.56087, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:19:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:02:15", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.03254, "time_diff": 1.78159, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:20:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:01:41", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.04427, "time_diff": 1.54053, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:20:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:01:44", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.03923, "time_diff": 1.86328, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:20:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:01:13", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.04150, "time_diff": 1.60800, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:20:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:00:59", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.03774, "time_diff": 1.66176, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:21:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:00:51", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.04208, "time_diff": 1.96683, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:21:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.04268, "time_diff": 1.54124, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:21:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.03583, "time_diff": 1.55397, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:21:51][INFO] logging.py:  99: json_stats: {"RAM": "28.77/251.55G", "_type": "val_epoch", "epoch": "9/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:22:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40999, "dt_data": 2.85931, "dt_net": 0.55069, "epoch": "10/55", "eta": "16:19:48", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.04217, "lr": 0.00001, "mAP": 0.03601, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:23:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01368, "dt_data": 2.45431, "dt_net": 0.55936, "epoch": "10/55", "eta": "14:25:25", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.04024, "lr": 0.00001, "mAP": 0.03147, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:23:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03992, "dt_data": 2.49095, "dt_net": 0.54897, "epoch": "10/55", "eta": "14:32:27", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.04232, "lr": 0.00001, "mAP": 0.03341, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:24:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48498, "dt_data": 2.93286, "dt_net": 0.55212, "epoch": "10/55", "eta": "16:39:36", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.04154, "lr": 0.00001, "mAP": 0.03586, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:24:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22069, "dt_data": 2.67080, "dt_net": 0.54988, "epoch": "10/55", "eta": "15:23:15", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.04123, "lr": 0.00001, "mAP": 0.03438, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:25:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39870, "dt_data": 2.84408, "dt_net": 0.55461, "epoch": "10/55", "eta": "16:13:43", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03915, "lr": 0.00001, "mAP": 0.03423, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:25:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75977, "dt_data": 3.20689, "dt_net": 0.55288, "epoch": "10/55", "eta": "17:56:32", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03931, "lr": 0.00001, "mAP": 0.03475, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:26:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79334, "dt_data": 3.24173, "dt_net": 0.55161, "epoch": "10/55", "eta": "18:05:31", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.04179, "lr": 0.00001, "mAP": 0.03958, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:26:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88618, "dt_data": 2.33994, "dt_net": 0.54623, "epoch": "10/55", "eta": "13:45:26", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.04142, "lr": 0.00001, "mAP": 0.03558, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:27:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22300, "dt_data": 2.66925, "dt_net": 0.55376, "epoch": "10/55", "eta": "15:21:14", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.04133, "lr": 0.00001, "mAP": 0.04182, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:28:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58927, "dt_data": 0.99148, "dt_net": 2.59778, "epoch": "10/55", "eta": "17:05:20", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.04040, "lr": 0.00001, "mAP": 0.03095, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:28:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28727, "dt_data": 0.35802, "dt_net": 2.92925, "epoch": "10/55", "eta": "15:38:30", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.04114, "lr": 0.00001, "mAP": 0.03185, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:29:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.86644, "dt_data": 2.16792, "dt_net": 0.69851, "epoch": "10/55", "eta": "13:37:53", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.04007, "lr": 0.00001, "mAP": 0.03125, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:29:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35218, "dt_data": 2.80679, "dt_net": 0.54539, "epoch": "10/55", "eta": "15:55:55", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03980, "lr": 0.00001, "mAP": 0.04092, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:30:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09871, "dt_data": 0.20354, "dt_net": 2.89516, "epoch": "10/55", "eta": "14:43:07", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.04177, "lr": 0.00001, "mAP": 0.03467, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:30:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56385, "dt_data": 0.50209, "dt_net": 3.06176, "epoch": "10/55", "eta": "16:55:06", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.04015, "lr": 0.00001, "mAP": 0.03988, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:31:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20841, "dt_data": 0.37773, "dt_net": 2.83068, "epoch": "10/55", "eta": "15:13:19", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.04050, "lr": 0.00001, "mAP": 0.03497, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:32:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67500, "dt_data": 0.02504, "dt_net": 3.64996, "epoch": "10/55", "eta": "17:25:32", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.04070, "lr": 0.00001, "mAP": 0.03341, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:32:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.55571, "dt_data": 0.02502, "dt_net": 2.53069, "epoch": "10/55", "eta": "12:06:40", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03799, "lr": 0.00001, "mAP": 0.03341, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:33:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42520, "dt_data": 0.02503, "dt_net": 3.40017, "epoch": "10/55", "eta": "16:13:19", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03943, "lr": 0.00001, "mAP": 0.03826, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:33:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16195, "dt_data": 0.02504, "dt_net": 3.13691, "epoch": "10/55", "eta": "14:57:59", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03930, "lr": 0.00001, "mAP": 0.03643, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:34:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26303, "dt_data": 0.02507, "dt_net": 3.23796, "epoch": "10/55", "eta": "15:26:09", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.04022, "lr": 0.00001, "mAP": 0.03705, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:34:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80140, "dt_data": 0.02521, "dt_net": 2.77619, "epoch": "10/55", "eta": "13:14:39", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03985, "lr": 0.00001, "mAP": 0.04134, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:35:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89753, "dt_data": 0.02496, "dt_net": 3.87256, "epoch": "10/55", "eta": "18:24:56", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03931, "lr": 0.00001, "mAP": 0.03624, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:36:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.36653, "dt_data": 0.02505, "dt_net": 4.34148, "epoch": "10/55", "eta": "20:37:10", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.04069, "lr": 0.00001, "mAP": 0.03006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:36:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18574, "dt_data": 0.02498, "dt_net": 3.16075, "epoch": "10/55", "eta": "15:02:05", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.03966, "lr": 0.00001, "mAP": 0.03845, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:37:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.01456, "dt_data": 0.02513, "dt_net": 3.98943, "epoch": "10/55", "eta": "18:56:07", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03949, "lr": 0.00001, "mAP": 0.03259, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:37:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36354, "dt_data": 0.02502, "dt_net": 3.33851, "epoch": "10/55", "eta": "15:51:19", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03841, "lr": 0.00001, "mAP": 0.03068, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:38:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68334, "dt_data": 0.25016, "dt_net": 3.43318, "epoch": "10/55", "eta": "17:21:09", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.04074, "lr": 0.00001, "mAP": 0.03940, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:38:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34573, "dt_data": 0.94244, "dt_net": 2.40328, "epoch": "10/55", "eta": "15:45:10", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.04016, "lr": 0.00001, "mAP": 0.03609, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:39:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.65699, "dt_data": 0.02512, "dt_net": 2.63187, "epoch": "10/55", "eta": "12:30:09", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.04062, "lr": 0.00001, "mAP": 0.04115, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:40:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24819, "dt_data": 0.02499, "dt_net": 3.22320, "epoch": "10/55", "eta": "15:16:31", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03899, "lr": 0.00001, "mAP": 0.03519, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:40:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30316, "dt_data": 0.02509, "dt_net": 3.27807, "epoch": "10/55", "eta": "15:31:29", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03932, "lr": 0.00001, "mAP": 0.03720, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:41:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83530, "dt_data": 0.02503, "dt_net": 3.81027, "epoch": "10/55", "eta": "18:00:54", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.04086, "lr": 0.00001, "mAP": 0.03958, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:41:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.49815, "dt_data": 0.02515, "dt_net": 4.47300, "epoch": "10/55", "eta": "21:06:58", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.04000, "lr": 0.00001, "mAP": 0.03720, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:42:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93906, "dt_data": 0.02500, "dt_net": 2.91405, "epoch": "10/55", "eta": "13:47:20", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03753, "lr": 0.00001, "mAP": 0.03125, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:42:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96563, "dt_data": 0.02508, "dt_net": 2.94054, "epoch": "10/55", "eta": "13:54:19", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03888, "lr": 0.00001, "mAP": 0.04226, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:43:04][INFO] logging.py:  99: json_stats: {"RAM": "28.69/251.55G", "_type": "train_epoch", "dt": 0.00028, "dt_data": 0.00028, "dt_net": 1.27901, "epoch": "10/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.04022, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:43:04][INFO] train_net.py: 497: Epoch 9 takes 1267.93s. Epochs from 0 to 9 take 1270.99s in average and 1269.21s in median.
[03/07 22:43:04][INFO] train_net.py: 503: For epoch 9, each iteraction takes 3.38s in average. From epoch 0 to 9, each iteraction takes 3.39s in average.
[03/07 22:43:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:02:16", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.03978, "time_diff": 1.58398, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:43:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:02:19", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.03513, "time_diff": 1.83598, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:43:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:01:48", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.04068, "time_diff": 1.64189, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:44:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:01:34", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.03951, "time_diff": 1.68792, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:44:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:01:18", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.04131, "time_diff": 1.70673, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:44:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:01:06", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.04182, "time_diff": 1.84418, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:45:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:00:49", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.04219, "time_diff": 1.89811, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:45:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:00:30", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.04140, "time_diff": 1.89646, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:45:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/55", "eta": "0:00:12", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.03661, "time_diff": 2.05812, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:45:58][INFO] logging.py:  99: json_stats: {"RAM": "29.15/251.55G", "_type": "val_epoch", "epoch": "10/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:46:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19327, "dt_data": 2.64002, "dt_net": 0.55325, "epoch": "11/55", "eta": "14:57:34", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03725, "lr": 0.00001, "mAP": 0.03482, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:47:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85615, "dt_data": 2.30330, "dt_net": 0.55284, "epoch": "11/55", "eta": "13:22:20", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03910, "lr": 0.00001, "mAP": 0.04018, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:47:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15009, "dt_data": 2.59827, "dt_net": 0.55182, "epoch": "11/55", "eta": "14:44:23", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03847, "lr": 0.00001, "mAP": 0.05086, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:48:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24811, "dt_data": 2.69850, "dt_net": 0.54961, "epoch": "11/55", "eta": "15:11:21", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.04008, "lr": 0.00001, "mAP": 0.02961, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:48:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42079, "dt_data": 1.94634, "dt_net": 1.47445, "epoch": "11/55", "eta": "15:59:14", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03776, "lr": 0.00001, "mAP": 0.03549, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:49:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49531, "dt_data": 1.52538, "dt_net": 1.96992, "epoch": "11/55", "eta": "16:19:33", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03828, "lr": 0.00001, "mAP": 0.04196, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:49:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82483, "dt_data": 0.02512, "dt_net": 2.79971, "epoch": "11/55", "eta": "13:11:11", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03949, "lr": 0.00001, "mAP": 0.03810, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:50:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99290, "dt_data": 1.41850, "dt_net": 1.57440, "epoch": "11/55", "eta": "13:57:45", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03815, "lr": 0.00001, "mAP": 0.03951, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:51:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42796, "dt_data": 0.02499, "dt_net": 3.40297, "epoch": "11/55", "eta": "15:58:58", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03834, "lr": 0.00001, "mAP": 0.03891, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:51:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07209, "dt_data": 0.68372, "dt_net": 2.38836, "epoch": "11/55", "eta": "14:18:54", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03846, "lr": 0.00001, "mAP": 0.04382, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:52:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25865, "dt_data": 0.02519, "dt_net": 3.23345, "epoch": "11/55", "eta": "15:10:31", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03868, "lr": 0.00001, "mAP": 0.03140, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:52:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06502, "dt_data": 0.02502, "dt_net": 3.04000, "epoch": "11/55", "eta": "14:15:54", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03980, "lr": 0.00001, "mAP": 0.04152, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:53:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45088, "dt_data": 0.57345, "dt_net": 2.87743, "epoch": "11/55", "eta": "16:03:05", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03905, "lr": 0.00001, "mAP": 0.03705, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:53:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68213, "dt_data": 0.02497, "dt_net": 3.65715, "epoch": "11/55", "eta": "17:07:00", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03857, "lr": 0.00001, "mAP": 0.03356, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:54:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68063, "dt_data": 0.02510, "dt_net": 3.65553, "epoch": "11/55", "eta": "17:05:58", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03999, "lr": 0.00001, "mAP": 0.04591, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:54:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96534, "dt_data": 0.02546, "dt_net": 2.93987, "epoch": "11/55", "eta": "13:46:05", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03911, "lr": 0.00001, "mAP": 0.04100, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:55:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04594, "dt_data": 0.02498, "dt_net": 3.02095, "epoch": "11/55", "eta": "14:08:02", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.03947, "lr": 0.00001, "mAP": 0.03869, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:56:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85366, "dt_data": 0.02499, "dt_net": 2.82866, "epoch": "11/55", "eta": "13:14:01", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03726, "lr": 0.00001, "mAP": 0.04003, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:56:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83372, "dt_data": 0.02502, "dt_net": 3.80870, "epoch": "11/55", "eta": "17:46:05", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03692, "lr": 0.00001, "mAP": 0.03735, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:57:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92054, "dt_data": 0.02505, "dt_net": 2.89549, "epoch": "11/55", "eta": "13:31:39", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03762, "lr": 0.00001, "mAP": 0.03854, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:57:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01918, "dt_data": 0.02515, "dt_net": 2.99402, "epoch": "11/55", "eta": "13:58:34", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03790, "lr": 0.00001, "mAP": 0.03847, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:58:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.65000, "dt_data": 0.02510, "dt_net": 2.62490, "epoch": "11/55", "eta": "12:15:35", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03962, "lr": 0.00001, "mAP": 0.03899, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:58:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02806, "dt_data": 0.02497, "dt_net": 4.00309, "epoch": "11/55", "eta": "18:37:27", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03941, "lr": 0.00001, "mAP": 0.04568, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:59:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.44184, "dt_data": 0.02508, "dt_net": 4.41675, "epoch": "11/55", "eta": "20:31:29", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03869, "lr": 0.00001, "mAP": 0.03911, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 22:59:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54855, "dt_data": 0.43989, "dt_net": 3.10866, "epoch": "11/55", "eta": "16:23:14", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03968, "lr": 0.00001, "mAP": 0.03952, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:00:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20307, "dt_data": 2.28081, "dt_net": 0.92225, "epoch": "11/55", "eta": "14:46:58", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.04013, "lr": 0.00001, "mAP": 0.04092, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:00:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35936, "dt_data": 1.86951, "dt_net": 1.48985, "epoch": "11/55", "eta": "15:29:42", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03713, "lr": 0.00001, "mAP": 0.04646, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:01:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53239, "dt_data": 1.15528, "dt_net": 2.37710, "epoch": "11/55", "eta": "16:16:59", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03844, "lr": 0.00001, "mAP": 0.04583, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:02:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84202, "dt_data": 0.02515, "dt_net": 2.81688, "epoch": "11/55", "eta": "13:05:34", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03522, "lr": 0.00001, "mAP": 0.04234, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:02:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41328, "dt_data": 0.02505, "dt_net": 3.38823, "epoch": "11/55", "eta": "15:42:55", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03680, "lr": 0.00001, "mAP": 0.04063, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:03:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43721, "dt_data": 0.02500, "dt_net": 3.41221, "epoch": "11/55", "eta": "15:48:57", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03798, "lr": 0.00001, "mAP": 0.03859, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:03:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62542, "dt_data": 0.02501, "dt_net": 3.60040, "epoch": "11/55", "eta": "16:40:18", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03762, "lr": 0.00001, "mAP": 0.03348, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:04:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56111, "dt_data": 0.02504, "dt_net": 3.53606, "epoch": "11/55", "eta": "16:21:58", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03614, "lr": 0.00001, "mAP": 0.04226, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:05:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91578, "dt_data": 0.02501, "dt_net": 3.89077, "epoch": "11/55", "eta": "17:59:07", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03783, "lr": 0.00001, "mAP": 0.03598, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:05:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13094, "dt_data": 0.02499, "dt_net": 3.10595, "epoch": "11/55", "eta": "14:22:18", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03669, "lr": 0.00001, "mAP": 0.03973, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:06:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07320, "dt_data": 0.02513, "dt_net": 3.04807, "epoch": "11/55", "eta": "14:05:53", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03908, "lr": 0.00001, "mAP": 0.04583, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:06:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99784, "dt_data": 0.02498, "dt_net": 2.97285, "epoch": "11/55", "eta": "13:44:39", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03685, "lr": 0.00001, "mAP": 0.03638, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:06:59][INFO] logging.py:  99: json_stats: {"RAM": "29.55/251.55G", "_type": "train_epoch", "dt": 0.00032, "dt_data": 0.00032, "dt_net": 3.59658, "epoch": "11/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.03850, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:06:59][INFO] train_net.py: 497: Epoch 10 takes 1254.52s. Epochs from 0 to 10 take 1269.50s in average and 1267.93s in median.
[03/07 23:06:59][INFO] train_net.py: 503: For epoch 10, each iteraction takes 3.35s in average. From epoch 0 to 10, each iteraction takes 3.39s in average.
[03/07 23:07:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:02:28", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.04280, "time_diff": 1.72526, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:07:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:02:11", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.04007, "time_diff": 1.73313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:07:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:01:46", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.04546, "time_diff": 1.60856, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:08:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:01:39", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.04391, "time_diff": 1.78451, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:08:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:01:07", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.04048, "time_diff": 1.47702, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:08:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:01:00", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.04501, "time_diff": 1.68550, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:09:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.04644, "time_diff": 1.74234, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:09:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:00:23", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.04446, "time_diff": 1.47538, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:09:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.04159, "time_diff": 1.65104, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:09:46][INFO] logging.py:  99: json_stats: {"RAM": "28.85/251.55G", "_type": "val_epoch", "epoch": "11/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:10:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82000, "dt_data": 2.27398, "dt_net": 0.54602, "epoch": "12/55", "eta": "12:55:01", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03706, "lr": 0.00001, "mAP": 0.04238, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:10:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43988, "dt_data": 0.98728, "dt_net": 2.45260, "epoch": "12/55", "eta": "15:44:49", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03666, "lr": 0.00001, "mAP": 0.04598, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:11:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05353, "dt_data": 0.02509, "dt_net": 3.02843, "epoch": "12/55", "eta": "13:58:11", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03723, "lr": 0.00001, "mAP": 0.04442, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:12:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23375, "dt_data": 0.02500, "dt_net": 3.20875, "epoch": "12/55", "eta": "14:47:07", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.03942, "lr": 0.00001, "mAP": 0.03512, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:12:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68098, "dt_data": 0.02500, "dt_net": 3.65597, "epoch": "12/55", "eta": "16:49:12", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03629, "lr": 0.00001, "mAP": 0.04442, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:13:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66322, "dt_data": 0.02501, "dt_net": 3.63822, "epoch": "12/55", "eta": "16:43:43", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03778, "lr": 0.00001, "mAP": 0.03914, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:13:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82018, "dt_data": 0.02502, "dt_net": 2.79516, "epoch": "12/55", "eta": "12:52:15", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03760, "lr": 0.00001, "mAP": 0.04479, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:14:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18206, "dt_data": 0.02506, "dt_net": 3.15699, "epoch": "12/55", "eta": "14:30:49", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03575, "lr": 0.00001, "mAP": 0.03799, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:14:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89675, "dt_data": 0.02500, "dt_net": 2.87174, "epoch": "12/55", "eta": "13:12:15", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03769, "lr": 0.00001, "mAP": 0.03839, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:15:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85997, "dt_data": 0.02511, "dt_net": 3.83486, "epoch": "12/55", "eta": "17:35:03", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03729, "lr": 0.00001, "mAP": 0.04801, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:16:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29314, "dt_data": 1.16910, "dt_net": 2.12404, "epoch": "12/55", "eta": "14:59:34", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03835, "lr": 0.00001, "mAP": 0.03638, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:16:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87637, "dt_data": 1.21329, "dt_net": 2.66308, "epoch": "12/55", "eta": "17:38:14", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03635, "lr": 0.00001, "mAP": 0.04063, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:17:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21117, "dt_data": 0.88536, "dt_net": 2.32581, "epoch": "12/55", "eta": "14:36:06", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03533, "lr": 0.00001, "mAP": 0.04182, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:17:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24422, "dt_data": 0.90844, "dt_net": 2.33578, "epoch": "12/55", "eta": "14:44:35", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03666, "lr": 0.00001, "mAP": 0.04390, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:18:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54091, "dt_data": 2.15156, "dt_net": 1.38935, "epoch": "12/55", "eta": "16:04:53", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03741, "lr": 0.00001, "mAP": 0.04673, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:18:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83475, "dt_data": 0.24248, "dt_net": 3.59226, "epoch": "12/55", "eta": "17:24:19", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03686, "lr": 0.00001, "mAP": 0.04592, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:19:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94059, "dt_data": 0.27549, "dt_net": 3.66510, "epoch": "12/55", "eta": "17:52:29", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.03684, "lr": 0.00001, "mAP": 0.03937, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:19:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.69191, "dt_data": 0.84319, "dt_net": 1.84871, "epoch": "12/55", "eta": "12:12:11", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03694, "lr": 0.00001, "mAP": 0.03750, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:20:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61580, "dt_data": 0.02512, "dt_net": 3.59068, "epoch": "12/55", "eta": "16:22:53", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03647, "lr": 0.00001, "mAP": 0.04063, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:21:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.17022, "dt_data": 0.02498, "dt_net": 2.14523, "epoch": "12/55", "eta": "9:49:34", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03815, "lr": 0.00001, "mAP": 0.03571, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:21:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87993, "dt_data": 2.29604, "dt_net": 1.58388, "epoch": "12/55", "eta": "17:33:23", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03753, "lr": 0.00001, "mAP": 0.04487, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:22:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44180, "dt_data": 1.61189, "dt_net": 1.82991, "epoch": "12/55", "eta": "15:33:52", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03782, "lr": 0.00001, "mAP": 0.04281, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:22:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14076, "dt_data": 0.02515, "dt_net": 3.11561, "epoch": "12/55", "eta": "14:11:40", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03772, "lr": 0.00001, "mAP": 0.05223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:23:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41365, "dt_data": 0.02517, "dt_net": 3.38848, "epoch": "12/55", "eta": "15:25:05", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03622, "lr": 0.00001, "mAP": 0.03446, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:23:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61917, "dt_data": 0.02827, "dt_net": 3.59089, "epoch": "12/55", "eta": "16:20:11", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03621, "lr": 0.00001, "mAP": 0.04561, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:24:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22566, "dt_data": 0.02501, "dt_net": 3.20065, "epoch": "12/55", "eta": "14:33:04", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.03725, "lr": 0.00001, "mAP": 0.03603, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:24:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34186, "dt_data": 0.02496, "dt_net": 3.31690, "epoch": "12/55", "eta": "15:03:58", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03773, "lr": 0.00001, "mAP": 0.03772, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:25:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.19472, "dt_data": 0.02505, "dt_net": 4.16967, "epoch": "12/55", "eta": "18:53:58", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03612, "lr": 0.00001, "mAP": 0.05054, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:26:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85695, "dt_data": 0.02499, "dt_net": 3.83196, "epoch": "12/55", "eta": "17:22:01", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03571, "lr": 0.00001, "mAP": 0.03591, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:26:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10101, "dt_data": 0.02526, "dt_net": 3.07575, "epoch": "12/55", "eta": "13:57:16", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03668, "lr": 0.00001, "mAP": 0.03943, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:27:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60351, "dt_data": 0.02504, "dt_net": 3.57846, "epoch": "12/55", "eta": "16:12:20", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03519, "lr": 0.00001, "mAP": 0.03676, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:27:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24614, "dt_data": 0.02508, "dt_net": 3.22106, "epoch": "12/55", "eta": "14:35:22", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03649, "lr": 0.00001, "mAP": 0.04866, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:28:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18623, "dt_data": 0.02550, "dt_net": 3.16073, "epoch": "12/55", "eta": "14:18:41", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03763, "lr": 0.00001, "mAP": 0.04315, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:28:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48200, "dt_data": 0.02499, "dt_net": 3.45701, "epoch": "12/55", "eta": "15:37:49", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03738, "lr": 0.00001, "mAP": 0.04792, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:29:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28038, "dt_data": 0.02502, "dt_net": 3.25536, "epoch": "12/55", "eta": "14:42:58", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03658, "lr": 0.00001, "mAP": 0.04302, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:30:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07959, "dt_data": 0.02500, "dt_net": 3.05459, "epoch": "12/55", "eta": "13:48:24", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03582, "lr": 0.00001, "mAP": 0.04427, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:30:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38044, "dt_data": 0.02518, "dt_net": 3.35526, "epoch": "12/55", "eta": "15:08:46", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03664, "lr": 0.00001, "mAP": 0.04048, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:30:57][INFO] logging.py:  99: json_stats: {"RAM": "28.77/251.55G", "_type": "train_epoch", "dt": 0.00029, "dt_data": 0.00029, "dt_net": 2.67473, "epoch": "12/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.03701, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:30:57][INFO] train_net.py: 497: Epoch 11 takes 1264.65s. Epochs from 0 to 11 take 1269.09s in average and 1266.53s in median.
[03/07 23:30:57][INFO] train_net.py: 503: For epoch 11, each iteraction takes 3.37s in average. From epoch 0 to 11, each iteraction takes 3.38s in average.
[03/07 23:31:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:02:07", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.04644, "time_diff": 1.48209, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:31:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.04379, "time_diff": 1.71414, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:31:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:01:43", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.05030, "time_diff": 1.56613, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:32:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:01:27", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.04731, "time_diff": 1.57040, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:32:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:01:15", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.04747, "time_diff": 1.64625, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:32:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:01:01", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.04629, "time_diff": 1.71592, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:33:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:00:50", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.04634, "time_diff": 1.93585, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:33:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.04948, "time_diff": 1.57655, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:33:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.04565, "time_diff": 1.61164, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:33:45][INFO] logging.py:  99: json_stats: {"RAM": "29.25/251.55G", "_type": "val_epoch", "epoch": "12/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:34:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73169, "dt_data": 3.17916, "dt_net": 0.55253, "epoch": "13/55", "eta": "16:42:16", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03490, "lr": 0.00001, "mAP": 0.04085, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:34:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43211, "dt_data": 2.88317, "dt_net": 0.54894, "epoch": "13/55", "eta": "15:21:14", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03418, "lr": 0.00001, "mAP": 0.04792, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:35:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79060, "dt_data": 1.41760, "dt_net": 2.37300, "epoch": "13/55", "eta": "16:56:49", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03658, "lr": 0.00001, "mAP": 0.05007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:36:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49850, "dt_data": 0.25234, "dt_net": 3.24615, "epoch": "13/55", "eta": "15:37:53", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.03489, "lr": 0.00001, "mAP": 0.04449, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:36:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24832, "dt_data": 1.13336, "dt_net": 2.11495, "epoch": "13/55", "eta": "14:30:16", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03597, "lr": 0.00001, "mAP": 0.04688, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:37:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28381, "dt_data": 0.02504, "dt_net": 3.25876, "epoch": "13/55", "eta": "14:39:14", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03688, "lr": 0.00001, "mAP": 0.04643, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:37:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94624, "dt_data": 0.02509, "dt_net": 3.92115, "epoch": "13/55", "eta": "17:35:56", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03671, "lr": 0.00001, "mAP": 0.03810, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:38:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97851, "dt_data": 0.02503, "dt_net": 3.95347, "epoch": "13/55", "eta": "17:43:55", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03561, "lr": 0.00001, "mAP": 0.04792, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:38:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88121, "dt_data": 0.02509, "dt_net": 3.85612, "epoch": "13/55", "eta": "17:17:15", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03612, "lr": 0.00001, "mAP": 0.04121, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:39:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75281, "dt_data": 0.02502, "dt_net": 2.72779, "epoch": "13/55", "eta": "12:15:13", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03794, "lr": 0.00001, "mAP": 0.04103, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:40:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87938, "dt_data": 0.02502, "dt_net": 3.85436, "epoch": "13/55", "eta": "17:15:28", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03596, "lr": 0.00001, "mAP": 0.03921, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:40:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.58294, "dt_data": 0.02502, "dt_net": 2.55791, "epoch": "13/55", "eta": "11:28:59", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03519, "lr": 0.00001, "mAP": 0.03557, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:41:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25565, "dt_data": 0.42621, "dt_net": 2.82943, "epoch": "13/55", "eta": "14:27:54", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03681, "lr": 0.00001, "mAP": 0.05156, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:41:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36082, "dt_data": 2.75344, "dt_net": 0.60738, "epoch": "13/55", "eta": "14:55:22", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03517, "lr": 0.00001, "mAP": 0.04644, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:42:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31492, "dt_data": 2.13206, "dt_net": 1.18286, "epoch": "13/55", "eta": "14:42:35", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03504, "lr": 0.00001, "mAP": 0.04487, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:42:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56570, "dt_data": 1.67482, "dt_net": 1.89088, "epoch": "13/55", "eta": "15:48:46", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03602, "lr": 0.00001, "mAP": 0.04131, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:43:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64754, "dt_data": 3.09329, "dt_net": 0.55425, "epoch": "13/55", "eta": "16:09:56", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.03605, "lr": 0.00001, "mAP": 0.04673, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:44:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.36273, "dt_data": 3.81338, "dt_net": 0.54935, "epoch": "13/55", "eta": "19:19:23", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03592, "lr": 0.00001, "mAP": 0.04658, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:44:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42472, "dt_data": 2.87859, "dt_net": 0.54613, "epoch": "13/55", "eta": "15:09:32", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03422, "lr": 0.00001, "mAP": 0.04472, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:45:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24290, "dt_data": 2.69055, "dt_net": 0.55235, "epoch": "13/55", "eta": "14:20:43", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03541, "lr": 0.00001, "mAP": 0.03996, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:45:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.86765, "dt_data": 2.31460, "dt_net": 0.55304, "epoch": "13/55", "eta": "12:40:38", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03552, "lr": 0.00001, "mAP": 0.04841, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:46:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83323, "dt_data": 3.27964, "dt_net": 0.55359, "epoch": "13/55", "eta": "16:56:07", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03709, "lr": 0.00001, "mAP": 0.03891, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:46:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10475, "dt_data": 2.55091, "dt_net": 0.55384, "epoch": "13/55", "eta": "13:42:30", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03558, "lr": 0.00001, "mAP": 0.04598, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:47:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24736, "dt_data": 2.70141, "dt_net": 0.54594, "epoch": "13/55", "eta": "14:19:44", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03526, "lr": 0.00001, "mAP": 0.04609, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:47:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88021, "dt_data": 3.32818, "dt_net": 0.55203, "epoch": "13/55", "eta": "17:06:38", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03605, "lr": 0.00001, "mAP": 0.04702, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:48:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15290, "dt_data": 2.18819, "dt_net": 0.96471, "epoch": "13/55", "eta": "13:53:40", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.03521, "lr": 0.00001, "mAP": 0.04070, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:48:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45324, "dt_data": 1.00261, "dt_net": 2.45063, "epoch": "13/55", "eta": "15:12:31", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03762, "lr": 0.00001, "mAP": 0.05007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:49:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43025, "dt_data": 1.62624, "dt_net": 1.80401, "epoch": "13/55", "eta": "15:05:52", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03800, "lr": 0.00001, "mAP": 0.04323, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:50:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72189, "dt_data": 0.07928, "dt_net": 3.64261, "epoch": "13/55", "eta": "16:22:16", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03276, "lr": 0.00001, "mAP": 0.03726, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:50:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51513, "dt_data": 2.96494, "dt_net": 0.55018, "epoch": "13/55", "eta": "15:27:06", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03501, "lr": 0.00001, "mAP": 0.04417, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:51:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69501, "dt_data": 3.14790, "dt_net": 0.54711, "epoch": "13/55", "eta": "16:13:56", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03576, "lr": 0.00001, "mAP": 0.04862, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:51:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.90322, "dt_data": 2.35159, "dt_net": 0.55163, "epoch": "13/55", "eta": "12:44:45", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03499, "lr": 0.00001, "mAP": 0.04810, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:52:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56280, "dt_data": 3.01203, "dt_net": 0.55077, "epoch": "13/55", "eta": "15:37:54", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03396, "lr": 0.00001, "mAP": 0.04583, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:52:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99575, "dt_data": 2.44673, "dt_net": 0.54901, "epoch": "13/55", "eta": "13:08:07", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03439, "lr": 0.00001, "mAP": 0.05015, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:53:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12327, "dt_data": 2.57286, "dt_net": 0.55040, "epoch": "13/55", "eta": "13:41:09", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03631, "lr": 0.00001, "mAP": 0.05057, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:53:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75877, "dt_data": 0.78866, "dt_net": 1.97011, "epoch": "13/55", "eta": "12:04:52", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03587, "lr": 0.00001, "mAP": 0.04137, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:54:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31333, "dt_data": 2.76129, "dt_net": 0.55204, "epoch": "13/55", "eta": "14:30:01", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03470, "lr": 0.00001, "mAP": 0.03914, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:54:38][INFO] logging.py:  99: json_stats: {"RAM": "26.79/251.55G", "_type": "train_epoch", "dt": 0.00025, "dt_data": 0.00025, "dt_net": 0.55157, "epoch": "13/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.03577, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:54:38][INFO] train_net.py: 497: Epoch 12 takes 1246.65s. Epochs from 0 to 12 take 1267.37s in average and 1265.14s in median.
[03/07 23:54:38][INFO] train_net.py: 503: For epoch 12, each iteraction takes 3.32s in average. From epoch 0 to 12, each iteraction takes 3.38s in average.
[03/07 23:54:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:02:18", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.04814, "time_diff": 1.61014, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:55:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:02:19", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.04948, "time_diff": 1.83341, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:55:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:01:40", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.05216, "time_diff": 1.52687, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:55:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:01:33", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.05089, "time_diff": 1.67478, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:56:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:01:13", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.04702, "time_diff": 1.59296, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:56:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:00:53", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05064, "time_diff": 1.49391, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:56:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:00:48", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.04789, "time_diff": 1.87222, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:56:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05112, "time_diff": 1.60128, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:57:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.04997, "time_diff": 1.44500, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:57:21][INFO] logging.py:  99: json_stats: {"RAM": "27.40/251.55G", "_type": "val_epoch", "epoch": "13/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:58:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95460, "dt_data": 3.40334, "dt_net": 0.55126, "epoch": "14/55", "eta": "17:17:25", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03522, "lr": 0.00001, "mAP": 0.04888, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:58:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61626, "dt_data": 3.06973, "dt_net": 0.54652, "epoch": "14/55", "eta": "15:48:03", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03528, "lr": 0.00001, "mAP": 0.04915, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:59:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59358, "dt_data": 2.04391, "dt_net": 0.54967, "epoch": "14/55", "eta": "11:19:31", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03679, "lr": 0.00001, "mAP": 0.05231, "top1_err": 0.00000, "top5_err": 0.00000}
[03/07 23:59:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11762, "dt_data": 2.56713, "dt_net": 0.55049, "epoch": "14/55", "eta": "13:36:17", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.03570, "lr": 0.00001, "mAP": 0.04784, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:00:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.40689, "dt_data": 1.85591, "dt_net": 0.55099, "epoch": "14/55", "eta": "10:29:48", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03410, "lr": 0.00001, "mAP": 0.04570, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:00:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58243, "dt_data": 3.02927, "dt_net": 0.55315, "epoch": "14/55", "eta": "15:36:48", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03446, "lr": 0.00001, "mAP": 0.04568, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:01:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36518, "dt_data": 2.81328, "dt_net": 0.55190, "epoch": "14/55", "eta": "14:39:26", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03328, "lr": 0.00001, "mAP": 0.04784, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:01:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60659, "dt_data": 3.05476, "dt_net": 0.55182, "epoch": "14/55", "eta": "15:41:55", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03438, "lr": 0.00001, "mAP": 0.05246, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:02:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68876, "dt_data": 2.13611, "dt_net": 0.55265, "epoch": "14/55", "eta": "11:41:45", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03285, "lr": 0.00001, "mAP": 0.04807, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:02:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67940, "dt_data": 3.12835, "dt_net": 0.55105, "epoch": "14/55", "eta": "15:59:42", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03632, "lr": 0.00001, "mAP": 0.03836, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:03:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84034, "dt_data": 2.28862, "dt_net": 0.55172, "epoch": "14/55", "eta": "12:20:22", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03395, "lr": 0.00001, "mAP": 0.04734, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:04:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61607, "dt_data": 3.06708, "dt_net": 0.54899, "epoch": "14/55", "eta": "15:41:59", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03381, "lr": 0.00001, "mAP": 0.04650, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:04:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08705, "dt_data": 2.53569, "dt_net": 0.55136, "epoch": "14/55", "eta": "13:23:39", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03436, "lr": 0.00001, "mAP": 0.05183, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:05:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57437, "dt_data": 3.02254, "dt_net": 0.55183, "epoch": "14/55", "eta": "15:29:55", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03477, "lr": 0.00001, "mAP": 0.04360, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:05:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45192, "dt_data": 2.89874, "dt_net": 0.55318, "epoch": "14/55", "eta": "14:57:29", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03325, "lr": 0.00001, "mAP": 0.05232, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:06:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54446, "dt_data": 2.99190, "dt_net": 0.55256, "epoch": "14/55", "eta": "15:20:58", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03387, "lr": 0.00001, "mAP": 0.04263, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:06:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.36008, "dt_data": 3.80871, "dt_net": 0.55137, "epoch": "14/55", "eta": "18:52:10", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.03435, "lr": 0.00001, "mAP": 0.04851, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:07:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58826, "dt_data": 3.03791, "dt_net": 0.55034, "epoch": "14/55", "eta": "15:31:09", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03406, "lr": 0.00001, "mAP": 0.04732, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:07:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36770, "dt_data": 2.81596, "dt_net": 0.55175, "epoch": "14/55", "eta": "14:33:21", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03239, "lr": 0.00001, "mAP": 0.04387, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:08:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.22888, "dt_data": 3.67742, "dt_net": 0.55146, "epoch": "14/55", "eta": "18:15:59", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03388, "lr": 0.00001, "mAP": 0.04417, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:09:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04811, "dt_data": 2.49740, "dt_net": 0.55070, "epoch": "14/55", "eta": "13:09:27", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03474, "lr": 0.00001, "mAP": 0.04598, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:09:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86300, "dt_data": 3.31122, "dt_net": 0.55178, "epoch": "14/55", "eta": "16:39:52", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03638, "lr": 0.00001, "mAP": 0.05312, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:10:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31205, "dt_data": 2.75866, "dt_net": 0.55339, "epoch": "14/55", "eta": "14:16:43", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03512, "lr": 0.00001, "mAP": 0.04940, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:10:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00613, "dt_data": 2.45403, "dt_net": 0.55210, "epoch": "14/55", "eta": "12:57:05", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03466, "lr": 0.00001, "mAP": 0.04613, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:11:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40965, "dt_data": 2.85636, "dt_net": 0.55328, "epoch": "14/55", "eta": "14:40:49", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03397, "lr": 0.00001, "mAP": 0.04725, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:11:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55094, "dt_data": 0.69676, "dt_net": 2.85418, "epoch": "14/55", "eta": "15:16:44", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.03409, "lr": 0.00001, "mAP": 0.04635, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:12:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07633, "dt_data": 0.36338, "dt_net": 2.71295, "epoch": "14/55", "eta": "13:13:41", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03465, "lr": 0.00001, "mAP": 0.05045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:12:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16061, "dt_data": 2.47342, "dt_net": 0.68720, "epoch": "14/55", "eta": "13:34:54", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03392, "lr": 0.00001, "mAP": 0.04660, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:13:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42133, "dt_data": 1.43227, "dt_net": 1.98906, "epoch": "14/55", "eta": "14:41:33", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03507, "lr": 0.00001, "mAP": 0.05390, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:14:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.16075, "dt_data": 0.02508, "dt_net": 4.13567, "epoch": "14/55", "eta": "17:51:23", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03287, "lr": 0.00001, "mAP": 0.04290, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:14:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.65380, "dt_data": 0.02504, "dt_net": 2.62875, "epoch": "14/55", "eta": "11:22:54", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03386, "lr": 0.00001, "mAP": 0.04238, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:15:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37920, "dt_data": 1.28042, "dt_net": 2.09877, "epoch": "14/55", "eta": "14:29:01", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03315, "lr": 0.00001, "mAP": 0.04933, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:15:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50478, "dt_data": 0.02507, "dt_net": 3.47971, "epoch": "14/55", "eta": "15:00:43", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03534, "lr": 0.00001, "mAP": 0.04978, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:16:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89827, "dt_data": 0.02505, "dt_net": 2.87321, "epoch": "14/55", "eta": "12:24:22", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03512, "lr": 0.00001, "mAP": 0.05042, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:16:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73301, "dt_data": 2.44233, "dt_net": 1.29068, "epoch": "14/55", "eta": "15:58:08", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03533, "lr": 0.00001, "mAP": 0.04814, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:17:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38917, "dt_data": 2.80452, "dt_net": 0.58465, "epoch": "14/55", "eta": "14:29:19", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03442, "lr": 0.00001, "mAP": 0.05923, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:18:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81286, "dt_data": 0.02516, "dt_net": 2.78770, "epoch": "14/55", "eta": "12:01:01", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03296, "lr": 0.00001, "mAP": 0.04799, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:18:18][INFO] logging.py:  99: json_stats: {"RAM": "27.67/251.55G", "_type": "train_epoch", "dt": 0.00041, "dt_data": 0.00041, "dt_net": 3.91971, "epoch": "14/55", "eta": "0:00:05", "gpu_mem": "17.37G", "loss": 0.03454, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:18:18][INFO] train_net.py: 497: Epoch 13 takes 1250.93s. Epochs from 0 to 13 take 1266.19s in average and 1264.90s in median.
[03/08 00:18:18][INFO] train_net.py: 503: For epoch 13, each iteraction takes 3.34s in average. From epoch 0 to 13, each iteraction takes 3.38s in average.
[03/08 00:18:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:02:11", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.04696, "time_diff": 1.52414, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:18:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:02:39", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.04433, "time_diff": 2.10088, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:19:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:01:53", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.04740, "time_diff": 1.71842, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:19:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:01:26", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.04520, "time_diff": 1.54651, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:19:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:01:17", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.04826, "time_diff": 1.68142, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:20:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:00:58", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.04838, "time_diff": 1.63409, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:20:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.04924, "time_diff": 1.76182, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:20:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:00:22", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.04869, "time_diff": 1.38594, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:20:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/55", "eta": "0:00:10", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.04256, "time_diff": 1.75436, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:21:07][INFO] logging.py:  99: json_stats: {"RAM": "27.96/251.55G", "_type": "val_epoch", "epoch": "14/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:21:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52707, "dt_data": 2.97209, "dt_net": 0.55498, "epoch": "15/55", "eta": "15:03:13", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03462, "lr": 0.00001, "mAP": 0.05205, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:22:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42304, "dt_data": 2.68157, "dt_net": 0.74147, "epoch": "15/55", "eta": "14:36:00", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03324, "lr": 0.00001, "mAP": 0.04226, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:22:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22002, "dt_data": 2.66815, "dt_net": 0.55186, "epoch": "15/55", "eta": "13:43:31", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03346, "lr": 0.00001, "mAP": 0.05260, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:23:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.36275, "dt_data": 3.81167, "dt_net": 0.55108, "epoch": "15/55", "eta": "18:35:02", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.03265, "lr": 0.00001, "mAP": 0.04182, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:24:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94631, "dt_data": 2.39342, "dt_net": 0.55289, "epoch": "15/55", "eta": "12:32:32", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03255, "lr": 0.00001, "mAP": 0.05647, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:24:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05201, "dt_data": 0.93290, "dt_net": 2.11912, "epoch": "15/55", "eta": "12:59:01", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03520, "lr": 0.00001, "mAP": 0.04427, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:25:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13787, "dt_data": 0.42428, "dt_net": 2.71359, "epoch": "15/55", "eta": "13:20:25", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03404, "lr": 0.00001, "mAP": 0.04851, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:25:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08838, "dt_data": 0.02512, "dt_net": 3.06326, "epoch": "15/55", "eta": "13:07:16", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03298, "lr": 0.00001, "mAP": 0.04818, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:26:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39839, "dt_data": 0.02508, "dt_net": 3.37331, "epoch": "15/55", "eta": "14:25:44", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03354, "lr": 0.00001, "mAP": 0.04894, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:26:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51156, "dt_data": 0.02512, "dt_net": 3.48644, "epoch": "15/55", "eta": "14:53:59", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03430, "lr": 0.00001, "mAP": 0.05015, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:27:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80081, "dt_data": 0.02508, "dt_net": 3.77572, "epoch": "15/55", "eta": "16:06:59", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03404, "lr": 0.00001, "mAP": 0.05253, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:28:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00908, "dt_data": 0.02514, "dt_net": 2.98393, "epoch": "15/55", "eta": "12:45:03", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03148, "lr": 0.00001, "mAP": 0.04725, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:28:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47229, "dt_data": 0.02500, "dt_net": 3.44729, "epoch": "15/55", "eta": "14:42:15", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03477, "lr": 0.00001, "mAP": 0.05192, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:29:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21334, "dt_data": 0.02501, "dt_net": 3.18833, "epoch": "15/55", "eta": "13:35:55", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03237, "lr": 0.00001, "mAP": 0.05126, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:29:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97558, "dt_data": 0.02506, "dt_net": 2.95051, "epoch": "15/55", "eta": "12:35:03", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03227, "lr": 0.00001, "mAP": 0.04848, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:30:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07283, "dt_data": 0.02496, "dt_net": 3.04787, "epoch": "15/55", "eta": "12:59:13", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03274, "lr": 0.00001, "mAP": 0.04942, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:30:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40461, "dt_data": 0.02501, "dt_net": 3.37959, "epoch": "15/55", "eta": "14:22:47", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.03462, "lr": 0.00001, "mAP": 0.04702, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:31:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62777, "dt_data": 0.02509, "dt_net": 3.60268, "epoch": "15/55", "eta": "15:18:43", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03319, "lr": 0.00001, "mAP": 0.04107, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:31:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.29013, "dt_data": 0.02513, "dt_net": 2.26500, "epoch": "15/55", "eta": "9:39:35", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03370, "lr": 0.00001, "mAP": 0.04696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:32:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61150, "dt_data": 0.02504, "dt_net": 3.58646, "epoch": "15/55", "eta": "15:13:24", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03490, "lr": 0.00001, "mAP": 0.04741, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:33:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36767, "dt_data": 0.02516, "dt_net": 3.34252, "epoch": "15/55", "eta": "14:11:10", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03319, "lr": 0.00001, "mAP": 0.05054, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:33:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75448, "dt_data": 0.02503, "dt_net": 2.72945, "epoch": "15/55", "eta": "11:35:44", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03547, "lr": 0.00001, "mAP": 0.04196, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:34:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59036, "dt_data": 0.02504, "dt_net": 2.56532, "epoch": "15/55", "eta": "10:53:50", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03335, "lr": 0.00001, "mAP": 0.05848, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:34:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30051, "dt_data": 0.02505, "dt_net": 3.27546, "epoch": "15/55", "eta": "13:52:33", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03427, "lr": 0.00001, "mAP": 0.04960, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:35:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46273, "dt_data": 0.02529, "dt_net": 3.43744, "epoch": "15/55", "eta": "14:32:53", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03266, "lr": 0.00001, "mAP": 0.05168, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:35:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.21694, "dt_data": 1.30435, "dt_net": 2.91259, "epoch": "15/55", "eta": "17:42:19", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.03332, "lr": 0.00001, "mAP": 0.04793, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:36:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69580, "dt_data": 0.02501, "dt_net": 3.67079, "epoch": "15/55", "eta": "15:30:25", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03289, "lr": 0.00001, "mAP": 0.05201, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:36:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.37265, "dt_data": 0.02511, "dt_net": 2.34754, "epoch": "15/55", "eta": "9:56:55", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03320, "lr": 0.00001, "mAP": 0.04622, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:37:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94888, "dt_data": 2.08082, "dt_net": 0.86806, "epoch": "15/55", "eta": "12:21:23", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03468, "lr": 0.00001, "mAP": 0.04598, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:38:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31536, "dt_data": 2.69831, "dt_net": 0.61705, "epoch": "15/55", "eta": "13:52:59", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03322, "lr": 0.00001, "mAP": 0.04807, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:38:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24896, "dt_data": 2.70036, "dt_net": 0.54860, "epoch": "15/55", "eta": "13:35:45", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03421, "lr": 0.00001, "mAP": 0.05528, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:39:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17631, "dt_data": 2.62111, "dt_net": 0.55520, "epoch": "15/55", "eta": "13:16:59", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03541, "lr": 0.00001, "mAP": 0.06388, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:39:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46560, "dt_data": 2.60663, "dt_net": 0.85897, "epoch": "15/55", "eta": "14:28:59", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03320, "lr": 0.00001, "mAP": 0.04368, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:40:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.62804, "dt_data": 1.24328, "dt_net": 3.38476, "epoch": "15/55", "eta": "19:19:42", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03280, "lr": 0.00001, "mAP": 0.05022, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:40:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.03273, "dt_data": 3.48021, "dt_net": 0.55252, "epoch": "15/55", "eta": "16:49:51", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03272, "lr": 0.00001, "mAP": 0.05327, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:41:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07975, "dt_data": 2.52719, "dt_net": 0.55256, "epoch": "15/55", "eta": "12:50:42", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03212, "lr": 0.00001, "mAP": 0.05199, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:42:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.58150, "dt_data": 2.02878, "dt_net": 0.55271, "epoch": "15/55", "eta": "10:45:35", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03345, "lr": 0.00001, "mAP": 0.04521, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:42:18][INFO] logging.py:  99: json_stats: {"RAM": "28.06/251.55G", "_type": "train_epoch", "dt": 0.00027, "dt_data": 0.00027, "dt_net": 0.54966, "epoch": "15/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.03365, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:42:18][INFO] train_net.py: 497: Epoch 14 takes 1264.12s. Epochs from 0 to 14 take 1266.05s in average and 1264.65s in median.
[03/08 00:42:18][INFO] train_net.py: 503: For epoch 14, each iteraction takes 3.37s in average. From epoch 0 to 14, each iteraction takes 3.38s in average.
[03/08 00:42:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:02:33", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05156, "time_diff": 1.78212, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:42:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05134, "time_diff": 1.71173, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:43:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:01:38", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.05751, "time_diff": 1.49036, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:43:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:01:33", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.05428, "time_diff": 1.67286, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:43:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:01:13", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.05064, "time_diff": 1.58962, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:44:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:01:04", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05150, "time_diff": 1.80036, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:44:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:00:48", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.05402, "time_diff": 1.84952, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:44:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05238, "time_diff": 1.58540, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:44:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05175, "time_diff": 1.47015, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:45:02][INFO] logging.py:  99: json_stats: {"RAM": "27.50/251.55G", "_type": "val_epoch", "epoch": "15/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:45:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93078, "dt_data": 3.37691, "dt_net": 0.55388, "epoch": "16/55", "eta": "16:22:02", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03116, "lr": 0.00001, "mAP": 0.05618, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:46:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97931, "dt_data": 2.42662, "dt_net": 0.55269, "epoch": "16/55", "eta": "12:23:50", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03147, "lr": 0.00001, "mAP": 0.05379, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:46:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11759, "dt_data": 2.56685, "dt_net": 0.55073, "epoch": "16/55", "eta": "12:57:50", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03312, "lr": 0.00001, "mAP": 0.04963, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:47:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.62868, "dt_data": 2.08184, "dt_net": 0.54684, "epoch": "16/55", "eta": "10:55:25", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.03208, "lr": 0.00001, "mAP": 0.05693, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:47:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.90928, "dt_data": 2.35986, "dt_net": 0.54941, "epoch": "16/55", "eta": "12:04:53", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03231, "lr": 0.00001, "mAP": 0.05670, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:48:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.78015, "dt_data": 1.60226, "dt_net": 1.17788, "epoch": "16/55", "eta": "11:32:15", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03289, "lr": 0.00001, "mAP": 0.05618, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:49:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.78570, "dt_data": 0.07033, "dt_net": 3.71536, "epoch": "16/55", "eta": "15:42:00", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03389, "lr": 0.00001, "mAP": 0.04978, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:49:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21365, "dt_data": 0.08861, "dt_net": 3.12504, "epoch": "16/55", "eta": "13:19:07", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03298, "lr": 0.00001, "mAP": 0.04672, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:50:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89369, "dt_data": 1.62033, "dt_net": 2.27336, "epoch": "16/55", "eta": "16:07:34", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03397, "lr": 0.00001, "mAP": 0.05094, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:50:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44597, "dt_data": 0.02497, "dt_net": 3.42100, "epoch": "16/55", "eta": "14:15:44", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03619, "lr": 0.00001, "mAP": 0.05179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:51:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.00819, "dt_data": 0.02503, "dt_net": 3.98315, "epoch": "16/55", "eta": "16:34:41", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03224, "lr": 0.00001, "mAP": 0.04405, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:51:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22254, "dt_data": 0.02501, "dt_net": 3.19753, "epoch": "16/55", "eta": "13:19:11", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03210, "lr": 0.00001, "mAP": 0.05086, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:52:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.15724, "dt_data": 0.02502, "dt_net": 4.13222, "epoch": "16/55", "eta": "17:10:18", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03258, "lr": 0.00001, "mAP": 0.05499, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:53:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.44643, "dt_data": 0.73448, "dt_net": 1.71195, "epoch": "16/55", "eta": "10:05:53", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03306, "lr": 0.00001, "mAP": 0.04680, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:53:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73742, "dt_data": 0.83233, "dt_net": 2.90509, "epoch": "16/55", "eta": "15:25:00", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03219, "lr": 0.00001, "mAP": 0.05632, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:54:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55828, "dt_data": 0.02498, "dt_net": 3.53330, "epoch": "16/55", "eta": "14:40:04", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03368, "lr": 0.00001, "mAP": 0.05563, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:54:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12498, "dt_data": 0.02501, "dt_net": 3.09996, "epoch": "16/55", "eta": "12:52:23", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.03355, "lr": 0.00001, "mAP": 0.05045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:55:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54490, "dt_data": 0.40422, "dt_net": 3.14068, "epoch": "16/55", "eta": "14:35:35", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03276, "lr": 0.00001, "mAP": 0.04554, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:55:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64516, "dt_data": 1.22517, "dt_net": 2.41999, "epoch": "16/55", "eta": "14:59:44", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03405, "lr": 0.00001, "mAP": 0.05235, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:56:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.29685, "dt_data": 1.27579, "dt_net": 3.02106, "epoch": "16/55", "eta": "17:39:53", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03098, "lr": 0.00001, "mAP": 0.04759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:57:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26398, "dt_data": 0.02514, "dt_net": 3.23884, "epoch": "16/55", "eta": "13:24:34", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03062, "lr": 0.00001, "mAP": 0.05335, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:57:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75485, "dt_data": 0.02504, "dt_net": 3.72980, "epoch": "16/55", "eta": "15:24:56", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03241, "lr": 0.00001, "mAP": 0.05604, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:58:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83474, "dt_data": 0.02498, "dt_net": 2.80977, "epoch": "16/55", "eta": "11:37:49", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03179, "lr": 0.00001, "mAP": 0.04628, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:58:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38065, "dt_data": 0.88557, "dt_net": 2.49507, "epoch": "16/55", "eta": "13:51:38", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03396, "lr": 0.00001, "mAP": 0.05104, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:59:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56247, "dt_data": 1.41744, "dt_net": 2.14503, "epoch": "16/55", "eta": "14:35:46", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03413, "lr": 0.00001, "mAP": 0.05156, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 00:59:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41313, "dt_data": 0.02511, "dt_net": 3.38802, "epoch": "16/55", "eta": "13:58:29", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.03488, "lr": 0.00001, "mAP": 0.04613, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:00:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72325, "dt_data": 0.02503, "dt_net": 2.69822, "epoch": "16/55", "eta": "11:08:33", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03327, "lr": 0.00001, "mAP": 0.03891, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:00:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19720, "dt_data": 0.02507, "dt_net": 3.17213, "epoch": "16/55", "eta": "13:04:22", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03232, "lr": 0.00001, "mAP": 0.05557, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:01:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.24052, "dt_data": 0.48080, "dt_net": 3.75972, "epoch": "16/55", "eta": "17:19:38", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03042, "lr": 0.00001, "mAP": 0.05290, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:01:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.66414, "dt_data": 0.02520, "dt_net": 2.63894, "epoch": "16/55", "eta": "10:52:42", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03218, "lr": 0.00001, "mAP": 0.04933, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:02:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80252, "dt_data": 0.02526, "dt_net": 3.77726, "epoch": "16/55", "eta": "15:30:58", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03098, "lr": 0.00001, "mAP": 0.04808, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:03:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20833, "dt_data": 0.02498, "dt_net": 3.18335, "epoch": "16/55", "eta": "13:04:58", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03179, "lr": 0.00001, "mAP": 0.05193, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:03:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43193, "dt_data": 0.02497, "dt_net": 3.40695, "epoch": "16/55", "eta": "13:59:06", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03186, "lr": 0.00001, "mAP": 0.04935, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:04:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13987, "dt_data": 0.02507, "dt_net": 3.11479, "epoch": "16/55", "eta": "12:47:10", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03105, "lr": 0.00001, "mAP": 0.04685, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:04:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69539, "dt_data": 0.02507, "dt_net": 3.67031, "epoch": "16/55", "eta": "15:02:17", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03198, "lr": 0.00001, "mAP": 0.06049, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:05:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47832, "dt_data": 0.02514, "dt_net": 3.45318, "epoch": "16/55", "eta": "14:08:42", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03201, "lr": 0.00001, "mAP": 0.05208, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:05:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08336, "dt_data": 0.02500, "dt_net": 3.05836, "epoch": "16/55", "eta": "12:31:49", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03078, "lr": 0.00001, "mAP": 0.05253, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:06:05][INFO] logging.py:  99: json_stats: {"RAM": "27.49/251.55G", "_type": "train_epoch", "dt": 0.00034, "dt_data": 0.00034, "dt_net": 3.14319, "epoch": "16/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.03272, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:06:05][INFO] train_net.py: 497: Epoch 15 takes 1257.00s. Epochs from 0 to 15 take 1265.49s in average and 1264.39s in median.
[03/08 01:06:05][INFO] train_net.py: 503: For epoch 15, each iteraction takes 3.35s in average. From epoch 0 to 15, each iteraction takes 3.37s in average.
[03/08 01:06:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:02:04", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05451, "time_diff": 1.44375, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:06:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:02:14", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05232, "time_diff": 1.77528, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:06:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:01:41", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.05826, "time_diff": 1.53035, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:07:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:01:30", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.05860, "time_diff": 1.62029, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:07:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:01:09", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.05341, "time_diff": 1.51635, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:07:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:00:55", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05348, "time_diff": 1.54486, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:08:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.05305, "time_diff": 1.73150, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:08:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:00:23", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05692, "time_diff": 1.49218, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:08:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05409, "time_diff": 1.89006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:08:43][INFO] logging.py:  99: json_stats: {"RAM": "27.54/251.55G", "_type": "val_epoch", "epoch": "16/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:09:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74220, "dt_data": 3.19188, "dt_net": 0.55031, "epoch": "17/55", "eta": "15:11:32", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03101, "lr": 0.00001, "mAP": 0.05751, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:09:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33094, "dt_data": 2.77725, "dt_net": 0.55369, "epoch": "17/55", "eta": "13:30:48", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03046, "lr": 0.00001, "mAP": 0.05003, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:10:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69861, "dt_data": 3.14713, "dt_net": 0.55148, "epoch": "17/55", "eta": "14:59:41", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03308, "lr": 0.00001, "mAP": 0.04993, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:11:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13683, "dt_data": 2.57540, "dt_net": 0.56143, "epoch": "17/55", "eta": "12:42:30", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.03075, "lr": 0.00001, "mAP": 0.04999, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:11:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91951, "dt_data": 3.36669, "dt_net": 0.55281, "epoch": "17/55", "eta": "15:52:06", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03033, "lr": 0.00001, "mAP": 0.05729, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:12:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56690, "dt_data": 3.01786, "dt_net": 0.54905, "epoch": "17/55", "eta": "14:25:51", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03001, "lr": 0.00001, "mAP": 0.05342, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:12:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59376, "dt_data": 3.04894, "dt_net": 0.54483, "epoch": "17/55", "eta": "14:31:47", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03153, "lr": 0.00001, "mAP": 0.05179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:13:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00358, "dt_data": 2.45332, "dt_net": 0.55026, "epoch": "17/55", "eta": "12:08:07", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03159, "lr": 0.00001, "mAP": 0.06057, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:13:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45818, "dt_data": 2.90992, "dt_net": 0.54826, "epoch": "17/55", "eta": "13:57:44", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03279, "lr": 0.00001, "mAP": 0.05183, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:14:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21902, "dt_data": 2.66817, "dt_net": 0.55086, "epoch": "17/55", "eta": "12:59:16", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03428, "lr": 0.00001, "mAP": 0.05022, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:14:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97323, "dt_data": 2.42169, "dt_net": 0.55154, "epoch": "17/55", "eta": "11:59:16", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03217, "lr": 0.00001, "mAP": 0.05513, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:15:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17806, "dt_data": 2.62714, "dt_net": 0.55092, "epoch": "17/55", "eta": "12:48:17", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03333, "lr": 0.00001, "mAP": 0.05030, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:16:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18657, "dt_data": 2.63565, "dt_net": 0.55092, "epoch": "17/55", "eta": "12:49:49", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03350, "lr": 0.00001, "mAP": 0.05469, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:16:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87963, "dt_data": 2.32831, "dt_net": 0.55132, "epoch": "17/55", "eta": "11:35:11", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.03269, "lr": 0.00001, "mAP": 0.05847, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:17:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95648, "dt_data": 2.40881, "dt_net": 0.54766, "epoch": "17/55", "eta": "11:53:14", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03187, "lr": 0.00001, "mAP": 0.05201, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:17:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97995, "dt_data": 0.97890, "dt_net": 2.00105, "epoch": "17/55", "eta": "11:58:25", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03110, "lr": 0.00001, "mAP": 0.05506, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:18:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96967, "dt_data": 0.02497, "dt_net": 2.94470, "epoch": "17/55", "eta": "11:55:26", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.03169, "lr": 0.00001, "mAP": 0.04792, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:18:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15849, "dt_data": 0.02508, "dt_net": 3.13340, "epoch": "17/55", "eta": "12:40:24", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03131, "lr": 0.00001, "mAP": 0.05019, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:19:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85234, "dt_data": 0.02504, "dt_net": 2.82730, "epoch": "17/55", "eta": "11:26:13", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03144, "lr": 0.00001, "mAP": 0.05908, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:19:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54739, "dt_data": 0.02502, "dt_net": 3.52236, "epoch": "17/55", "eta": "14:12:51", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03098, "lr": 0.00001, "mAP": 0.05436, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:20:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62441, "dt_data": 0.02514, "dt_net": 3.59927, "epoch": "17/55", "eta": "14:30:45", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03167, "lr": 0.00001, "mAP": 0.05638, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:21:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91308, "dt_data": 0.02509, "dt_net": 3.88799, "epoch": "17/55", "eta": "15:39:27", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03266, "lr": 0.00001, "mAP": 0.06217, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:21:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.70176, "dt_data": 0.02529, "dt_net": 2.67647, "epoch": "17/55", "eta": "10:48:11", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03421, "lr": 0.00001, "mAP": 0.05604, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:22:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.12153, "dt_data": 0.02499, "dt_net": 4.09654, "epoch": "17/55", "eta": "16:28:08", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03214, "lr": 0.00001, "mAP": 0.04807, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:22:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95917, "dt_data": 0.02502, "dt_net": 3.93414, "epoch": "17/55", "eta": "15:48:33", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03004, "lr": 0.00001, "mAP": 0.05101, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:23:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.20751, "dt_data": 0.02496, "dt_net": 4.18255, "epoch": "17/55", "eta": "16:47:20", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.03193, "lr": 0.00001, "mAP": 0.04930, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:23:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27664, "dt_data": 0.02498, "dt_net": 3.25166, "epoch": "17/55", "eta": "13:03:56", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03005, "lr": 0.00001, "mAP": 0.05001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:24:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76070, "dt_data": 0.02511, "dt_net": 3.73559, "epoch": "17/55", "eta": "14:59:07", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03061, "lr": 0.00001, "mAP": 0.05908, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:25:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30307, "dt_data": 0.02502, "dt_net": 3.27805, "epoch": "17/55", "eta": "13:09:09", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03037, "lr": 0.00001, "mAP": 0.05863, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:25:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60637, "dt_data": 0.02500, "dt_net": 3.58137, "epoch": "17/55", "eta": "14:21:01", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03358, "lr": 0.00001, "mAP": 0.05927, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:26:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06309, "dt_data": 0.02498, "dt_net": 3.03811, "epoch": "17/55", "eta": "12:10:48", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03115, "lr": 0.00001, "mAP": 0.04960, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:26:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69330, "dt_data": 0.02502, "dt_net": 3.66828, "epoch": "17/55", "eta": "14:40:32", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03133, "lr": 0.00001, "mAP": 0.05714, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:27:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35489, "dt_data": 0.02504, "dt_net": 3.32985, "epoch": "17/55", "eta": "13:19:18", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03033, "lr": 0.00001, "mAP": 0.05165, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:27:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37970, "dt_data": 0.02499, "dt_net": 3.35470, "epoch": "17/55", "eta": "13:24:39", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03016, "lr": 0.00001, "mAP": 0.05179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:28:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72145, "dt_data": 0.02498, "dt_net": 3.69647, "epoch": "17/55", "eta": "14:45:23", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03118, "lr": 0.00001, "mAP": 0.05439, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:29:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.81787, "dt_data": 0.02497, "dt_net": 3.79290, "epoch": "17/55", "eta": "15:07:41", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03253, "lr": 0.00001, "mAP": 0.05580, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:29:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45039, "dt_data": 0.02505, "dt_net": 3.42534, "epoch": "17/55", "eta": "13:39:45", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03045, "lr": 0.00001, "mAP": 0.06071, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:29:50][INFO] logging.py:  99: json_stats: {"RAM": "26.19/251.55G", "_type": "train_epoch", "dt": 0.00032, "dt_data": 0.00032, "dt_net": 3.49253, "epoch": "17/55", "eta": "0:00:04", "gpu_mem": "17.37G", "loss": 0.03169, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:29:50][INFO] train_net.py: 497: Epoch 16 takes 1261.02s. Epochs from 0 to 16 take 1265.22s in average and 1264.12s in median.
[03/08 01:29:50][INFO] train_net.py: 503: For epoch 16, each iteraction takes 3.36s in average. From epoch 0 to 16, each iteraction takes 3.37s in average.
[03/08 01:30:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:02:07", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05045, "time_diff": 1.48180, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:30:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:02:21", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05070, "time_diff": 1.86501, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:30:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:01:44", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.05412, "time_diff": 1.58353, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:30:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:01:38", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.05327, "time_diff": 1.75892, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:31:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:01:12", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.04938, "time_diff": 1.58440, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:31:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:01:02", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.04969, "time_diff": 1.73774, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:31:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.05454, "time_diff": 1.74987, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:32:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.04943, "time_diff": 1.51785, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:32:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05138, "time_diff": 1.49127, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:32:28][INFO] logging.py:  99: json_stats: {"RAM": "26.40/251.55G", "_type": "val_epoch", "epoch": "17/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:33:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.25271, "dt_data": 3.70545, "dt_net": 0.54726, "epoch": "18/55", "eta": "16:49:18", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.03035, "lr": 0.00001, "mAP": 0.05655, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:33:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88303, "dt_data": 3.33113, "dt_net": 0.55190, "epoch": "18/55", "eta": "15:20:55", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02956, "lr": 0.00001, "mAP": 0.05615, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:34:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64751, "dt_data": 3.09409, "dt_net": 0.55342, "epoch": "18/55", "eta": "14:24:27", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.03148, "lr": 0.00001, "mAP": 0.05220, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:34:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14390, "dt_data": 2.59239, "dt_net": 0.55151, "epoch": "18/55", "eta": "12:24:34", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02949, "lr": 0.00001, "mAP": 0.05914, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:35:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98969, "dt_data": 2.43593, "dt_net": 0.55375, "epoch": "18/55", "eta": "11:47:33", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03096, "lr": 0.00001, "mAP": 0.05908, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:35:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.52257, "dt_data": 1.96686, "dt_net": 0.55571, "epoch": "18/55", "eta": "9:56:35", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03162, "lr": 0.00001, "mAP": 0.06146, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:36:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49103, "dt_data": 0.02513, "dt_net": 3.46590, "epoch": "18/55", "eta": "13:45:02", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03254, "lr": 0.00001, "mAP": 0.05439, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:37:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80830, "dt_data": 0.02511, "dt_net": 2.78319, "epoch": "18/55", "eta": "11:03:13", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.03004, "lr": 0.00001, "mAP": 0.05466, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:37:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.44338, "dt_data": 0.02503, "dt_net": 2.41835, "epoch": "18/55", "eta": "9:36:38", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03093, "lr": 0.00001, "mAP": 0.05186, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:38:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00031, "dt_data": 0.02511, "dt_net": 2.97520, "epoch": "18/55", "eta": "11:47:34", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03100, "lr": 0.00001, "mAP": 0.05249, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:38:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82763, "dt_data": 0.02507, "dt_net": 3.80256, "epoch": "18/55", "eta": "15:02:02", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03216, "lr": 0.00001, "mAP": 0.05826, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:39:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.78434, "dt_data": 0.02500, "dt_net": 2.75935, "epoch": "18/55", "eta": "10:55:42", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.03039, "lr": 0.00001, "mAP": 0.05796, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:39:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27963, "dt_data": 0.02526, "dt_net": 3.25436, "epoch": "18/55", "eta": "12:51:48", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03031, "lr": 0.00001, "mAP": 0.05313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:40:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07999, "dt_data": 0.02502, "dt_net": 3.05497, "epoch": "18/55", "eta": "12:04:18", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02938, "lr": 0.00001, "mAP": 0.05497, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:40:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93679, "dt_data": 0.04894, "dt_net": 3.88785, "epoch": "18/55", "eta": "15:25:08", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.03044, "lr": 0.00001, "mAP": 0.05570, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:41:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08299, "dt_data": 0.02499, "dt_net": 3.05800, "epoch": "18/55", "eta": "12:03:59", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03009, "lr": 0.00001, "mAP": 0.05618, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:41:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50119, "dt_data": 0.02502, "dt_net": 3.47617, "epoch": "18/55", "eta": "13:41:36", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02903, "lr": 0.00001, "mAP": 0.05677, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:42:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58616, "dt_data": 0.02500, "dt_net": 3.56116, "epoch": "18/55", "eta": "14:00:57", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.03164, "lr": 0.00001, "mAP": 0.05260, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:43:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70779, "dt_data": 0.02500, "dt_net": 3.68279, "epoch": "18/55", "eta": "14:28:51", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03037, "lr": 0.00001, "mAP": 0.06492, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:43:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62706, "dt_data": 0.02510, "dt_net": 3.60195, "epoch": "18/55", "eta": "14:09:20", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03340, "lr": 0.00001, "mAP": 0.05692, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:44:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22448, "dt_data": 0.02503, "dt_net": 3.19945, "epoch": "18/55", "eta": "12:34:31", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03176, "lr": 0.00001, "mAP": 0.05275, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:44:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97274, "dt_data": 0.02503, "dt_net": 2.94771, "epoch": "18/55", "eta": "11:35:07", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02996, "lr": 0.00001, "mAP": 0.05729, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:45:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44462, "dt_data": 0.02499, "dt_net": 3.41962, "epoch": "18/55", "eta": "13:24:53", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.03124, "lr": 0.00001, "mAP": 0.05536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:45:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.16052, "dt_data": 0.02508, "dt_net": 4.13543, "epoch": "18/55", "eta": "16:11:28", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.03232, "lr": 0.00001, "mAP": 0.05521, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:46:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83231, "dt_data": 0.02508, "dt_net": 3.80723, "epoch": "18/55", "eta": "14:54:12", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.03103, "lr": 0.00001, "mAP": 0.05536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:47:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59768, "dt_data": 0.02504, "dt_net": 3.57264, "epoch": "18/55", "eta": "13:58:51", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02999, "lr": 0.00001, "mAP": 0.05744, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:47:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20274, "dt_data": 0.02506, "dt_net": 3.17768, "epoch": "18/55", "eta": "12:26:14", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03039, "lr": 0.00001, "mAP": 0.05759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:48:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95245, "dt_data": 0.02504, "dt_net": 2.92741, "epoch": "18/55", "eta": "11:27:25", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.03107, "lr": 0.00001, "mAP": 0.05007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:48:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.30174, "dt_data": 0.79062, "dt_net": 1.51111, "epoch": "18/55", "eta": "8:55:32", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.03114, "lr": 0.00001, "mAP": 0.05336, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:49:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94176, "dt_data": 0.52131, "dt_net": 2.42044, "epoch": "18/55", "eta": "11:23:57", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03176, "lr": 0.00001, "mAP": 0.06345, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:49:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10390, "dt_data": 0.28642, "dt_net": 2.81747, "epoch": "18/55", "eta": "12:01:08", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.03109, "lr": 0.00001, "mAP": 0.05818, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:50:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72771, "dt_data": 1.72807, "dt_net": 0.99964, "epoch": "18/55", "eta": "10:33:16", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03159, "lr": 0.00001, "mAP": 0.04896, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:50:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.39186, "dt_data": 1.84030, "dt_net": 0.55156, "epoch": "18/55", "eta": "9:14:54", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02932, "lr": 0.00001, "mAP": 0.05327, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:51:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31800, "dt_data": 2.76900, "dt_net": 0.54899, "epoch": "18/55", "eta": "12:49:13", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.03078, "lr": 0.00001, "mAP": 0.05327, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:52:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70187, "dt_data": 3.14737, "dt_net": 0.55450, "epoch": "18/55", "eta": "14:17:36", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02955, "lr": 0.00001, "mAP": 0.05774, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:52:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40929, "dt_data": 1.70324, "dt_net": 1.70604, "epoch": "18/55", "eta": "13:09:14", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03057, "lr": 0.00001, "mAP": 0.05644, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:53:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09246, "dt_data": 1.78700, "dt_net": 1.30547, "epoch": "18/55", "eta": "11:55:23", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03110, "lr": 0.00001, "mAP": 0.06429, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:53:25][INFO] logging.py:  99: json_stats: {"RAM": "26.40/251.55G", "_type": "train_epoch", "dt": 0.00025, "dt_data": 0.00025, "dt_net": 0.54763, "epoch": "18/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.03080, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:53:25][INFO] train_net.py: 497: Epoch 17 takes 1250.39s. Epochs from 0 to 17 take 1264.40s in average and 1263.35s in median.
[03/08 01:53:25][INFO] train_net.py: 503: For epoch 17, each iteraction takes 3.33s in average. From epoch 0 to 17, each iteraction takes 3.37s in average.
[03/08 01:53:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05528, "time_diff": 1.51353, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:53:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:02:04", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05244, "time_diff": 1.63613, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:54:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:01:46", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.05618, "time_diff": 1.61477, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:54:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:01:34", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.05312, "time_diff": 1.68026, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:54:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:01:11", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.05540, "time_diff": 1.56308, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:55:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:01:02", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05089, "time_diff": 1.72249, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:55:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.05610, "time_diff": 1.73229, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:55:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:00:23", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05223, "time_diff": 1.47176, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:55:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05246, "time_diff": 1.66666, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:56:04][INFO] logging.py:  99: json_stats: {"RAM": "25.42/251.55G", "_type": "val_epoch", "epoch": "18/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:56:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28807, "dt_data": 2.73268, "dt_net": 0.55539, "epoch": "19/55", "eta": "12:39:49", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02971, "lr": 0.00001, "mAP": 0.04814, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:57:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87581, "dt_data": 2.32622, "dt_net": 0.54960, "epoch": "19/55", "eta": "11:04:04", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03025, "lr": 0.00001, "mAP": 0.05241, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:57:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98956, "dt_data": 1.66083, "dt_net": 1.32872, "epoch": "19/55", "eta": "11:29:50", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02865, "lr": 0.00001, "mAP": 0.05313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:58:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51225, "dt_data": 2.96069, "dt_net": 0.55155, "epoch": "19/55", "eta": "13:29:51", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.03168, "lr": 0.00001, "mAP": 0.05994, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:58:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26859, "dt_data": 2.71517, "dt_net": 0.55341, "epoch": "19/55", "eta": "12:33:08", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.03023, "lr": 0.00001, "mAP": 0.05411, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 01:59:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50491, "dt_data": 0.02509, "dt_net": 3.47981, "epoch": "19/55", "eta": "13:27:00", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03050, "lr": 0.00001, "mAP": 0.05533, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:00:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.39935, "dt_data": 0.02510, "dt_net": 4.37425, "epoch": "19/55", "eta": "16:52:13", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03085, "lr": 0.00001, "mAP": 0.05171, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:00:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34224, "dt_data": 0.02501, "dt_net": 3.31723, "epoch": "19/55", "eta": "12:48:26", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02814, "lr": 0.00001, "mAP": 0.05982, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:01:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14696, "dt_data": 0.02497, "dt_net": 3.12199, "epoch": "19/55", "eta": "12:03:00", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.03115, "lr": 0.00001, "mAP": 0.06254, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:01:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66133, "dt_data": 0.02499, "dt_net": 3.63634, "epoch": "19/55", "eta": "14:00:34", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.03029, "lr": 0.00001, "mAP": 0.05402, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:02:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43373, "dt_data": 2.63101, "dt_net": 0.80272, "epoch": "19/55", "eta": "13:07:45", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.03001, "lr": 0.00001, "mAP": 0.05499, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:02:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73735, "dt_data": 2.80171, "dt_net": 0.93563, "epoch": "19/55", "eta": "14:16:47", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02869, "lr": 0.00001, "mAP": 0.05525, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:03:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20119, "dt_data": 2.64886, "dt_net": 0.55233, "epoch": "19/55", "eta": "12:13:20", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.03116, "lr": 0.00001, "mAP": 0.05195, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:03:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09011, "dt_data": 0.02501, "dt_net": 3.06510, "epoch": "19/55", "eta": "11:47:22", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02948, "lr": 0.00001, "mAP": 0.06266, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:04:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.71474, "dt_data": 0.02512, "dt_net": 2.68962, "epoch": "19/55", "eta": "10:20:59", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02949, "lr": 0.00001, "mAP": 0.05595, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:04:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09844, "dt_data": 1.68376, "dt_net": 2.41468, "epoch": "19/55", "eta": "15:36:50", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.03022, "lr": 0.00001, "mAP": 0.06592, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:05:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74753, "dt_data": 1.27485, "dt_net": 1.47267, "epoch": "19/55", "eta": "10:27:34", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02944, "lr": 0.00001, "mAP": 0.06159, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:06:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60470, "dt_data": 2.40705, "dt_net": 1.19765, "epoch": "19/55", "eta": "13:42:46", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02890, "lr": 0.00001, "mAP": 0.05424, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:06:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24266, "dt_data": 2.69056, "dt_net": 0.55210, "epoch": "19/55", "eta": "12:19:35", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.03210, "lr": 0.00001, "mAP": 0.06113, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:07:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.79222, "dt_data": 2.23847, "dt_net": 0.55375, "epoch": "19/55", "eta": "10:36:23", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.03135, "lr": 0.00001, "mAP": 0.05801, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:07:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16872, "dt_data": 2.61643, "dt_net": 0.55229, "epoch": "19/55", "eta": "12:01:40", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.03070, "lr": 0.00001, "mAP": 0.06256, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:08:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44522, "dt_data": 2.89169, "dt_net": 0.55353, "epoch": "19/55", "eta": "13:04:04", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02896, "lr": 0.00001, "mAP": 0.06347, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:08:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70969, "dt_data": 3.15347, "dt_net": 0.55622, "epoch": "19/55", "eta": "14:03:38", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02911, "lr": 0.00001, "mAP": 0.05774, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:09:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29107, "dt_data": 2.07282, "dt_net": 1.21825, "epoch": "19/55", "eta": "12:27:53", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02959, "lr": 0.00001, "mAP": 0.05804, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:09:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15349, "dt_data": 2.60093, "dt_net": 0.55256, "epoch": "19/55", "eta": "11:56:06", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02939, "lr": 0.00001, "mAP": 0.06250, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:10:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.41944, "dt_data": 0.02514, "dt_net": 2.39430, "epoch": "19/55", "eta": "9:09:00", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02889, "lr": 0.00001, "mAP": 0.06195, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:10:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54730, "dt_data": 0.02515, "dt_net": 3.52215, "epoch": "19/55", "eta": "13:24:21", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.03174, "lr": 0.00001, "mAP": 0.06399, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:11:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48770, "dt_data": 0.02557, "dt_net": 3.46212, "epoch": "19/55", "eta": "13:10:15", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02780, "lr": 0.00001, "mAP": 0.06240, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:12:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83798, "dt_data": 0.02514, "dt_net": 2.81283, "epoch": "19/55", "eta": "10:42:33", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02880, "lr": 0.00001, "mAP": 0.05659, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:12:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82367, "dt_data": 0.02502, "dt_net": 2.79865, "epoch": "19/55", "eta": "10:38:51", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.03037, "lr": 0.00001, "mAP": 0.06220, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:13:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.29390, "dt_data": 0.16336, "dt_net": 4.13054, "epoch": "19/55", "eta": "16:10:46", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02956, "lr": 0.00001, "mAP": 0.05571, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:13:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64551, "dt_data": 0.93694, "dt_net": 2.70856, "epoch": "19/55", "eta": "13:43:34", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.03211, "lr": 0.00001, "mAP": 0.05387, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:14:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89934, "dt_data": 0.02520, "dt_net": 3.87413, "epoch": "19/55", "eta": "14:40:16", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.03047, "lr": 0.00001, "mAP": 0.05772, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:14:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04588, "dt_data": 0.02503, "dt_net": 3.02085, "epoch": "19/55", "eta": "11:27:05", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02968, "lr": 0.00001, "mAP": 0.05766, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:15:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47046, "dt_data": 0.02502, "dt_net": 3.44544, "epoch": "19/55", "eta": "13:02:17", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.03015, "lr": 0.00001, "mAP": 0.06055, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:16:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03672, "dt_data": 0.02519, "dt_net": 3.01153, "epoch": "19/55", "eta": "11:24:01", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.03032, "lr": 0.00001, "mAP": 0.05915, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:16:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41203, "dt_data": 0.02507, "dt_net": 3.38696, "epoch": "19/55", "eta": "12:47:59", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03205, "lr": 0.00001, "mAP": 0.05813, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:16:51][INFO] logging.py:  99: json_stats: {"RAM": "25.17/251.55G", "_type": "train_epoch", "dt": 0.00031, "dt_data": 0.00031, "dt_net": 3.87338, "epoch": "19/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.03003, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:16:51][INFO] train_net.py: 497: Epoch 18 takes 1240.42s. Epochs from 0 to 18 take 1263.14s in average and 1262.58s in median.
[03/08 02:16:51][INFO] train_net.py: 503: For epoch 18, each iteraction takes 3.31s in average. From epoch 0 to 18, each iteraction takes 3.37s in average.
[03/08 02:17:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05720, "time_diff": 1.51832, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:17:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:02:04", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05729, "time_diff": 1.63699, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:17:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:01:38", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06058, "time_diff": 1.48981, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:17:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:01:33", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.05510, "time_diff": 1.66194, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:18:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:01:20", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.05796, "time_diff": 1.75765, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:18:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:00:57", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05553, "time_diff": 1.58411, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:18:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:00:42", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.05972, "time_diff": 1.61588, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:19:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05634, "time_diff": 1.54747, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:19:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05350, "time_diff": 1.51793, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:19:30][INFO] logging.py:  99: json_stats: {"RAM": "25.69/251.55G", "_type": "val_epoch", "epoch": "19/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:20:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25708, "dt_data": 2.70857, "dt_net": 0.54851, "epoch": "20/55", "eta": "12:12:17", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02886, "lr": 0.00001, "mAP": 0.06527, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:20:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20070, "dt_data": 2.64607, "dt_net": 0.55463, "epoch": "20/55", "eta": "11:59:05", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.03001, "lr": 0.00001, "mAP": 0.06548, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:21:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99316, "dt_data": 2.44585, "dt_net": 0.54730, "epoch": "20/55", "eta": "11:11:57", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02892, "lr": 0.00001, "mAP": 0.06408, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:21:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59388, "dt_data": 2.04105, "dt_net": 0.55283, "epoch": "20/55", "eta": "9:41:53", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02843, "lr": 0.00001, "mAP": 0.05277, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:22:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06654, "dt_data": 2.51541, "dt_net": 0.55113, "epoch": "20/55", "eta": "11:27:24", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02921, "lr": 0.00001, "mAP": 0.06067, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:22:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04260, "dt_data": 2.49249, "dt_net": 0.55010, "epoch": "20/55", "eta": "11:21:32", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.03028, "lr": 0.00001, "mAP": 0.05045, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:23:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.05492, "dt_data": 3.50064, "dt_net": 0.55428, "epoch": "20/55", "eta": "15:07:37", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02909, "lr": 0.00001, "mAP": 0.05551, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:24:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41131, "dt_data": 2.85860, "dt_net": 0.55271, "epoch": "20/55", "eta": "12:42:59", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02929, "lr": 0.00001, "mAP": 0.06251, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:24:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.98731, "dt_data": 3.43886, "dt_net": 0.54845, "epoch": "20/55", "eta": "14:51:09", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02828, "lr": 0.00001, "mAP": 0.05479, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:25:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89754, "dt_data": 3.34430, "dt_net": 0.55324, "epoch": "20/55", "eta": "14:30:27", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02934, "lr": 0.00001, "mAP": 0.06079, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:25:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02618, "dt_data": 2.47421, "dt_net": 0.55196, "epoch": "20/55", "eta": "11:15:20", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02967, "lr": 0.00001, "mAP": 0.05972, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:26:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48697, "dt_data": 2.93514, "dt_net": 0.55183, "epoch": "20/55", "eta": "12:57:35", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02901, "lr": 0.00001, "mAP": 0.06653, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:26:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62523, "dt_data": 1.43869, "dt_net": 2.18654, "epoch": "20/55", "eta": "13:27:49", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02980, "lr": 0.00001, "mAP": 0.06555, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:27:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62347, "dt_data": 0.95913, "dt_net": 2.66433, "epoch": "20/55", "eta": "13:26:49", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02888, "lr": 0.00001, "mAP": 0.05729, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:27:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68202, "dt_data": 0.02505, "dt_net": 3.65697, "epoch": "20/55", "eta": "13:39:15", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02978, "lr": 0.00001, "mAP": 0.06272, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:28:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.66172, "dt_data": 0.83414, "dt_net": 1.82758, "epoch": "20/55", "eta": "9:51:47", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02854, "lr": 0.00001, "mAP": 0.05194, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:29:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57998, "dt_data": 3.02764, "dt_net": 0.55234, "epoch": "20/55", "eta": "13:15:21", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02801, "lr": 0.00001, "mAP": 0.05329, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:29:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43269, "dt_data": 2.88240, "dt_net": 0.55029, "epoch": "20/55", "eta": "12:42:03", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02832, "lr": 0.00001, "mAP": 0.05618, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:30:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10870, "dt_data": 3.55868, "dt_net": 0.55001, "epoch": "20/55", "eta": "15:11:26", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02959, "lr": 0.00001, "mAP": 0.05756, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:30:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55126, "dt_data": 1.50243, "dt_net": 2.04882, "epoch": "20/55", "eta": "13:07:11", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02858, "lr": 0.00001, "mAP": 0.06307, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:31:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.73135, "dt_data": 2.18033, "dt_net": 0.55102, "epoch": "20/55", "eta": "10:04:59", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02872, "lr": 0.00001, "mAP": 0.06530, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:31:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76357, "dt_data": 3.21461, "dt_net": 0.54896, "epoch": "20/55", "eta": "13:53:00", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.03040, "lr": 0.00001, "mAP": 0.05476, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:32:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88898, "dt_data": 2.26876, "dt_net": 0.62023, "epoch": "20/55", "eta": "10:38:56", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02843, "lr": 0.00001, "mAP": 0.05506, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:32:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70230, "dt_data": 0.71163, "dt_net": 2.99067, "epoch": "20/55", "eta": "13:38:12", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02866, "lr": 0.00001, "mAP": 0.06027, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:33:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.31564, "dt_data": 0.02500, "dt_net": 4.29064, "epoch": "20/55", "eta": "15:53:02", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02904, "lr": 0.00001, "mAP": 0.06228, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:33:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92210, "dt_data": 0.27618, "dt_net": 2.64592, "epoch": "20/55", "eta": "10:44:48", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02861, "lr": 0.00001, "mAP": 0.05290, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:34:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17434, "dt_data": 1.54553, "dt_net": 1.62881, "epoch": "20/55", "eta": "11:39:56", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02974, "lr": 0.00001, "mAP": 0.05696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:35:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02215, "dt_data": 0.02515, "dt_net": 2.99699, "epoch": "20/55", "eta": "11:05:52", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02958, "lr": 0.00001, "mAP": 0.05874, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:35:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18238, "dt_data": 0.02514, "dt_net": 3.15724, "epoch": "20/55", "eta": "11:40:39", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02917, "lr": 0.00001, "mAP": 0.06061, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:36:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81202, "dt_data": 0.02511, "dt_net": 2.78691, "epoch": "20/55", "eta": "10:18:38", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02977, "lr": 0.00001, "mAP": 0.06391, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:36:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29505, "dt_data": 0.02507, "dt_net": 3.26998, "epoch": "20/55", "eta": "12:04:21", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02880, "lr": 0.00001, "mAP": 0.06600, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:37:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68215, "dt_data": 0.02503, "dt_net": 2.65712, "epoch": "20/55", "eta": "9:49:10", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02987, "lr": 0.00001, "mAP": 0.06503, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:37:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34094, "dt_data": 0.02510, "dt_net": 3.31583, "epoch": "20/55", "eta": "12:13:20", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02830, "lr": 0.00001, "mAP": 0.06882, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:38:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.42505, "dt_data": 0.60407, "dt_net": 1.82097, "epoch": "20/55", "eta": "8:51:53", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02725, "lr": 0.00001, "mAP": 0.05696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:38:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91838, "dt_data": 0.02510, "dt_net": 2.89328, "epoch": "20/55", "eta": "10:39:36", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02941, "lr": 0.00001, "mAP": 0.05969, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:39:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92340, "dt_data": 0.02504, "dt_net": 3.89837, "epoch": "20/55", "eta": "14:19:13", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02908, "lr": 0.00001, "mAP": 0.06153, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:40:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.99696, "dt_data": 0.02508, "dt_net": 3.97187, "epoch": "20/55", "eta": "14:34:40", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.03008, "lr": 0.00001, "mAP": 0.05967, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:40:24][INFO] logging.py:  99: json_stats: {"RAM": "25.70/251.55G", "_type": "train_epoch", "dt": 0.00028, "dt_data": 0.00028, "dt_net": 3.27211, "epoch": "20/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02925, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:40:24][INFO] train_net.py: 497: Epoch 19 takes 1247.87s. Epochs from 0 to 19 take 1262.38s in average and 1262.01s in median.
[03/08 02:40:24][INFO] train_net.py: 503: For epoch 19, each iteraction takes 3.33s in average. From epoch 0 to 19, each iteraction takes 3.37s in average.
[03/08 02:40:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:02:16", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05699, "time_diff": 1.58332, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:40:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:02:11", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05920, "time_diff": 1.73233, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:41:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:01:35", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.05786, "time_diff": 1.45288, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:41:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:01:23", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.05664, "time_diff": 1.49994, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:41:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:01:10", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.05433, "time_diff": 1.52174, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:42:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:00:55", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05534, "time_diff": 1.54176, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:42:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:00:42", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.05685, "time_diff": 1.65346, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:42:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05179, "time_diff": 1.54132, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:42:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05417, "time_diff": 1.55584, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:43:02][INFO] logging.py:  99: json_stats: {"RAM": "26.07/251.55G", "_type": "val_epoch", "epoch": "20/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00008, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:43:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14549, "dt_data": 2.59200, "dt_net": 0.55349, "epoch": "21/55", "eta": "11:27:33", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02830, "lr": 0.00001, "mAP": 0.05402, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:44:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20829, "dt_data": 2.65443, "dt_net": 0.55385, "epoch": "21/55", "eta": "11:40:44", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02778, "lr": 0.00001, "mAP": 0.06741, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:44:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80580, "dt_data": 3.25292, "dt_net": 0.55287, "epoch": "21/55", "eta": "13:50:36", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02579, "lr": 0.00001, "mAP": 0.05719, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:45:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91806, "dt_data": 1.04908, "dt_net": 1.86898, "epoch": "21/55", "eta": "10:36:22", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02746, "lr": 0.00001, "mAP": 0.06496, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:45:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80833, "dt_data": 0.27812, "dt_net": 2.53021, "epoch": "21/55", "eta": "10:11:58", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02857, "lr": 0.00001, "mAP": 0.05939, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:46:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.22445, "dt_data": 1.90296, "dt_net": 2.32149, "epoch": "21/55", "eta": "15:19:52", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02992, "lr": 0.00001, "mAP": 0.05872, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:46:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31999, "dt_data": 0.07749, "dt_net": 3.24250, "epoch": "21/55", "eta": "12:02:22", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.03036, "lr": 0.00001, "mAP": 0.05692, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:47:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93423, "dt_data": 0.02505, "dt_net": 2.90918, "epoch": "21/55", "eta": "10:37:57", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02830, "lr": 0.00001, "mAP": 0.05335, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:48:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34822, "dt_data": 0.02516, "dt_net": 3.32305, "epoch": "21/55", "eta": "12:07:24", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02855, "lr": 0.00001, "mAP": 0.06905, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:48:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79872, "dt_data": 0.02500, "dt_net": 3.77372, "epoch": "21/55", "eta": "13:44:38", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02798, "lr": 0.00001, "mAP": 0.05885, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:49:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91988, "dt_data": 0.02503, "dt_net": 2.89485, "epoch": "21/55", "eta": "10:33:22", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02844, "lr": 0.00001, "mAP": 0.05856, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:49:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18113, "dt_data": 0.02498, "dt_net": 3.15614, "epoch": "21/55", "eta": "11:29:30", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02816, "lr": 0.00001, "mAP": 0.06558, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:50:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96449, "dt_data": 0.02516, "dt_net": 2.93932, "epoch": "21/55", "eta": "10:42:03", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02838, "lr": 0.00001, "mAP": 0.05960, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:50:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59066, "dt_data": 0.02512, "dt_net": 2.56554, "epoch": "21/55", "eta": "9:20:39", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02839, "lr": 0.00001, "mAP": 0.06043, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:51:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37660, "dt_data": 0.12385, "dt_net": 3.25275, "epoch": "21/55", "eta": "12:10:11", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02837, "lr": 0.00001, "mAP": 0.06473, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:51:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01247, "dt_data": 0.02503, "dt_net": 2.98744, "epoch": "21/55", "eta": "10:50:56", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02888, "lr": 0.00001, "mAP": 0.05781, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:52:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.65752, "dt_data": 0.02504, "dt_net": 2.63248, "epoch": "21/55", "eta": "9:33:48", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02951, "lr": 0.00001, "mAP": 0.06152, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:53:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82068, "dt_data": 0.02505, "dt_net": 3.79562, "epoch": "21/55", "eta": "13:44:18", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02810, "lr": 0.00001, "mAP": 0.06487, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:53:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92467, "dt_data": 0.02496, "dt_net": 3.89971, "epoch": "21/55", "eta": "14:06:05", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02808, "lr": 0.00001, "mAP": 0.06436, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:54:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28171, "dt_data": 0.02520, "dt_net": 3.25651, "epoch": "21/55", "eta": "11:46:56", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02851, "lr": 0.00001, "mAP": 0.06546, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:54:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.58977, "dt_data": 0.02496, "dt_net": 2.56481, "epoch": "21/55", "eta": "9:17:26", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02954, "lr": 0.00001, "mAP": 0.05729, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:55:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18221, "dt_data": 0.02505, "dt_net": 3.15716, "epoch": "21/55", "eta": "11:24:26", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02709, "lr": 0.00001, "mAP": 0.05871, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:55:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21132, "dt_data": 0.02499, "dt_net": 3.18633, "epoch": "21/55", "eta": "11:30:09", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02877, "lr": 0.00001, "mAP": 0.06546, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:56:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.35174, "dt_data": 0.02500, "dt_net": 4.32674, "epoch": "21/55", "eta": "15:34:32", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02625, "lr": 0.00001, "mAP": 0.05585, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:57:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22986, "dt_data": 0.02508, "dt_net": 3.20478, "epoch": "21/55", "eta": "11:33:04", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02713, "lr": 0.00001, "mAP": 0.07018, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:57:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89485, "dt_data": 0.02502, "dt_net": 2.86983, "epoch": "21/55", "eta": "10:20:42", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02787, "lr": 0.00001, "mAP": 0.05746, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:58:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.67116, "dt_data": 0.02508, "dt_net": 2.64608, "epoch": "21/55", "eta": "9:32:17", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02786, "lr": 0.00001, "mAP": 0.05350, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:58:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21963, "dt_data": 0.02504, "dt_net": 3.19459, "epoch": "21/55", "eta": "11:29:16", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02936, "lr": 0.00001, "mAP": 0.06225, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:59:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.90113, "dt_data": 0.02503, "dt_net": 2.87610, "epoch": "21/55", "eta": "10:20:36", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02868, "lr": 0.00001, "mAP": 0.05679, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 02:59:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39734, "dt_data": 0.02496, "dt_net": 3.37237, "epoch": "21/55", "eta": "12:06:10", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02880, "lr": 0.00001, "mAP": 0.06302, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:00:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57741, "dt_data": 0.02509, "dt_net": 3.55232, "epoch": "21/55", "eta": "12:44:04", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02690, "lr": 0.00001, "mAP": 0.06251, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:00:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18194, "dt_data": 0.02518, "dt_net": 3.15676, "epoch": "21/55", "eta": "11:19:04", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02837, "lr": 0.00001, "mAP": 0.05506, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:01:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07850, "dt_data": 0.02499, "dt_net": 3.05351, "epoch": "21/55", "eta": "10:56:29", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02845, "lr": 0.00001, "mAP": 0.06228, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:02:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45860, "dt_data": 0.02514, "dt_net": 3.43346, "epoch": "21/55", "eta": "12:16:58", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02729, "lr": 0.00001, "mAP": 0.06600, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:02:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47877, "dt_data": 0.02499, "dt_net": 3.45378, "epoch": "21/55", "eta": "12:20:41", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02869, "lr": 0.00001, "mAP": 0.05938, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:03:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63471, "dt_data": 0.02511, "dt_net": 3.60960, "epoch": "21/55", "eta": "12:53:17", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02859, "lr": 0.00001, "mAP": 0.06131, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:03:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.76304, "dt_data": 0.02510, "dt_net": 2.73794, "epoch": "21/55", "eta": "9:47:22", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02756, "lr": 0.00001, "mAP": 0.06190, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:04:00][INFO] logging.py:  99: json_stats: {"RAM": "25.97/251.55G", "_type": "train_epoch", "dt": 0.00030, "dt_data": 0.00030, "dt_net": 3.88182, "epoch": "21/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02848, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:04:00][INFO] train_net.py: 497: Epoch 20 takes 1252.05s. Epochs from 0 to 20 take 1261.88s in average and 1261.44s in median.
[03/08 03:04:00][INFO] train_net.py: 503: For epoch 20, each iteraction takes 3.34s in average. From epoch 0 to 20, each iteraction takes 3.37s in average.
[03/08 03:04:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:02:12", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06198, "time_diff": 1.53991, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:04:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:02:07", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05803, "time_diff": 1.67564, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:04:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:01:34", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06676, "time_diff": 1.42734, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:05:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:01:35", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06150, "time_diff": 1.71310, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:05:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:01:25", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06224, "time_diff": 1.84827, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:05:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:00:59", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06132, "time_diff": 1.64505, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:05:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:00:42", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.06649, "time_diff": 1.65135, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:06:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06153, "time_diff": 1.55536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:06:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.06086, "time_diff": 1.54122, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:06:39][INFO] logging.py:  99: json_stats: {"RAM": "26.23/251.55G", "_type": "val_epoch", "epoch": "21/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:07:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29325, "dt_data": 2.74381, "dt_net": 0.54944, "epoch": "22/55", "eta": "11:39:16", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02759, "lr": 0.00001, "mAP": 0.07104, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:07:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10117, "dt_data": 2.55022, "dt_net": 0.55095, "epoch": "22/55", "eta": "10:57:57", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02903, "lr": 0.00001, "mAP": 0.06223, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:08:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02985, "dt_data": 2.47852, "dt_net": 0.55133, "epoch": "22/55", "eta": "10:42:19", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02662, "lr": 0.00001, "mAP": 0.06815, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:09:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.13110, "dt_data": 0.34425, "dt_net": 3.78685, "epoch": "22/55", "eta": "14:35:06", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02855, "lr": 0.00001, "mAP": 0.06098, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:09:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72826, "dt_data": 0.10829, "dt_net": 2.61997, "epoch": "22/55", "eta": "9:37:28", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02721, "lr": 0.00001, "mAP": 0.06808, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:10:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85246, "dt_data": 0.02521, "dt_net": 2.82725, "epoch": "22/55", "eta": "10:03:17", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02509, "lr": 0.00001, "mAP": 0.06000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:10:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82577, "dt_data": 0.02519, "dt_net": 2.80058, "epoch": "22/55", "eta": "9:57:10", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02779, "lr": 0.00001, "mAP": 0.06399, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:11:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00820, "dt_data": 0.02502, "dt_net": 2.98318, "epoch": "22/55", "eta": "10:35:13", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02674, "lr": 0.00001, "mAP": 0.06086, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:11:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42011, "dt_data": 0.02534, "dt_net": 3.39476, "epoch": "22/55", "eta": "12:01:38", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02767, "lr": 0.00001, "mAP": 0.06135, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:12:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70924, "dt_data": 0.02504, "dt_net": 3.68420, "epoch": "22/55", "eta": "13:02:01", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02581, "lr": 0.00001, "mAP": 0.05778, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:12:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31827, "dt_data": 0.02513, "dt_net": 3.29313, "epoch": "22/55", "eta": "11:39:02", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02856, "lr": 0.00001, "mAP": 0.06129, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:13:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71907, "dt_data": 0.02513, "dt_net": 3.69394, "epoch": "22/55", "eta": "13:02:51", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02924, "lr": 0.00001, "mAP": 0.06793, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:13:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85497, "dt_data": 0.02518, "dt_net": 2.82978, "epoch": "22/55", "eta": "10:00:29", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02833, "lr": 0.00001, "mAP": 0.06588, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:14:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90356, "dt_data": 0.02530, "dt_net": 3.87826, "epoch": "22/55", "eta": "13:40:23", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02783, "lr": 0.00001, "mAP": 0.05646, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:15:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67016, "dt_data": 0.02506, "dt_net": 3.64510, "epoch": "22/55", "eta": "12:50:44", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02753, "lr": 0.00001, "mAP": 0.05749, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:15:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03010, "dt_data": 0.02511, "dt_net": 3.00499, "epoch": "22/55", "eta": "10:35:48", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02866, "lr": 0.00001, "mAP": 0.05882, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:16:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.43251, "dt_data": 0.02503, "dt_net": 2.40748, "epoch": "22/55", "eta": "8:30:01", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02721, "lr": 0.00001, "mAP": 0.06746, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:16:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.39420, "dt_data": 0.30292, "dt_net": 4.09128, "epoch": "22/55", "eta": "15:20:35", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02708, "lr": 0.00001, "mAP": 0.06534, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:17:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29681, "dt_data": 0.02499, "dt_net": 3.27182, "epoch": "22/55", "eta": "11:30:07", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02737, "lr": 0.00001, "mAP": 0.07061, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:17:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22827, "dt_data": 0.16426, "dt_net": 3.06401, "epoch": "22/55", "eta": "11:15:14", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02666, "lr": 0.00001, "mAP": 0.06116, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:18:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88437, "dt_data": 0.02514, "dt_net": 2.85923, "epoch": "22/55", "eta": "10:02:49", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02797, "lr": 0.00001, "mAP": 0.05686, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:19:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31314, "dt_data": 0.55139, "dt_net": 2.76175, "epoch": "22/55", "eta": "11:31:53", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02793, "lr": 0.00001, "mAP": 0.06094, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:19:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52994, "dt_data": 1.56750, "dt_net": 1.96244, "epoch": "22/55", "eta": "12:16:34", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02610, "lr": 0.00001, "mAP": 0.06314, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:20:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85020, "dt_data": 0.02497, "dt_net": 2.82523, "epoch": "22/55", "eta": "9:54:15", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02933, "lr": 0.00001, "mAP": 0.06106, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:20:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02361, "dt_data": 0.02509, "dt_net": 2.99852, "epoch": "22/55", "eta": "10:29:55", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02915, "lr": 0.00001, "mAP": 0.06466, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:21:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.66912, "dt_data": 0.02513, "dt_net": 2.64399, "epoch": "22/55", "eta": "9:15:37", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02652, "lr": 0.00001, "mAP": 0.06064, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:21:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37218, "dt_data": 0.02513, "dt_net": 3.34705, "epoch": "22/55", "eta": "11:41:24", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02841, "lr": 0.00001, "mAP": 0.05972, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:22:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74883, "dt_data": 0.02499, "dt_net": 3.72384, "epoch": "22/55", "eta": "12:59:07", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02703, "lr": 0.00001, "mAP": 0.06812, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:23:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42659, "dt_data": 2.04307, "dt_net": 1.38352, "epoch": "22/55", "eta": "11:51:35", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02805, "lr": 0.00001, "mAP": 0.05714, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:23:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04919, "dt_data": 2.47539, "dt_net": 0.57379, "epoch": "22/55", "eta": "10:32:42", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02750, "lr": 0.00001, "mAP": 0.06177, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:24:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21116, "dt_data": 2.65908, "dt_net": 0.55207, "epoch": "22/55", "eta": "11:05:46", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02661, "lr": 0.00001, "mAP": 0.07426, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:24:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02178, "dt_data": 3.47173, "dt_net": 0.55005, "epoch": "22/55", "eta": "13:53:10", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02771, "lr": 0.00001, "mAP": 0.05821, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:25:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16490, "dt_data": 2.61400, "dt_net": 0.55090, "epoch": "22/55", "eta": "10:55:08", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02795, "lr": 0.00001, "mAP": 0.05853, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:25:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96082, "dt_data": 0.56412, "dt_net": 3.39670, "epoch": "22/55", "eta": "13:39:13", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02670, "lr": 0.00001, "mAP": 0.06086, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:26:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14292, "dt_data": 1.43938, "dt_net": 1.70355, "epoch": "22/55", "eta": "10:49:32", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02720, "lr": 0.00001, "mAP": 0.05859, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:26:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66169, "dt_data": 0.38294, "dt_net": 3.27875, "epoch": "22/55", "eta": "12:36:08", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02854, "lr": 0.00001, "mAP": 0.06124, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:27:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14273, "dt_data": 0.02504, "dt_net": 3.11769, "epoch": "22/55", "eta": "10:48:26", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02653, "lr": 0.00001, "mAP": 0.06411, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:27:41][INFO] logging.py:  99: json_stats: {"RAM": "26.37/251.55G", "_type": "train_epoch", "dt": 0.00031, "dt_data": 0.00031, "dt_net": 3.19123, "epoch": "22/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02765, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:27:41][INFO] train_net.py: 497: Epoch 21 takes 1255.81s. Epochs from 0 to 21 take 1261.61s in average and 1261.23s in median.
[03/08 03:27:41][INFO] train_net.py: 503: For epoch 21, each iteraction takes 3.35s in average. From epoch 0 to 21, each iteraction takes 3.36s in average.
[03/08 03:27:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06414, "time_diff": 1.51507, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:28:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:02:06", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05833, "time_diff": 1.66087, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:28:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:01:35", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06414, "time_diff": 1.44116, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:28:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:01:35", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06112, "time_diff": 1.70000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:29:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:01:09", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06123, "time_diff": 1.50343, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:29:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:00:56", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05990, "time_diff": 1.57498, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:29:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:00:44", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07076, "time_diff": 1.71717, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:29:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06274, "time_diff": 1.51046, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:30:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.06237, "time_diff": 1.44877, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:30:19][INFO] logging.py:  99: json_stats: {"RAM": "25.64/251.55G", "_type": "val_epoch", "epoch": "22/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00008, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:30:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.90640, "dt_data": 2.35392, "dt_net": 0.55248, "epoch": "23/55", "eta": "9:58:57", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02575, "lr": 0.00001, "mAP": 0.06964, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:31:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29365, "dt_data": 2.74361, "dt_net": 0.55004, "epoch": "23/55", "eta": "11:18:13", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02673, "lr": 0.00001, "mAP": 0.06399, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:32:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49944, "dt_data": 2.39977, "dt_net": 1.09966, "epoch": "23/55", "eta": "12:00:00", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02662, "lr": 0.00001, "mAP": 0.06426, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:32:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.67014, "dt_data": 0.02544, "dt_net": 2.64470, "epoch": "23/55", "eta": "9:08:56", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02785, "lr": 0.00001, "mAP": 0.06452, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:33:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.67875, "dt_data": 0.31807, "dt_net": 2.36068, "epoch": "23/55", "eta": "9:10:15", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02759, "lr": 0.00001, "mAP": 0.05714, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:33:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24564, "dt_data": 0.76924, "dt_net": 2.47640, "epoch": "23/55", "eta": "11:06:10", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02599, "lr": 0.00001, "mAP": 0.06817, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:34:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21652, "dt_data": 0.02531, "dt_net": 3.19121, "epoch": "23/55", "eta": "10:59:39", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02789, "lr": 0.00001, "mAP": 0.05915, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:34:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.81101, "dt_data": 0.02508, "dt_net": 3.78593, "epoch": "23/55", "eta": "13:00:56", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02818, "lr": 0.00001, "mAP": 0.07058, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:35:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14511, "dt_data": 0.02501, "dt_net": 3.12010, "epoch": "23/55", "eta": "10:43:57", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02505, "lr": 0.00001, "mAP": 0.06592, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:35:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15557, "dt_data": 0.02509, "dt_net": 3.13047, "epoch": "23/55", "eta": "10:45:34", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02575, "lr": 0.00001, "mAP": 0.06306, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:36:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47091, "dt_data": 0.02507, "dt_net": 3.44585, "epoch": "23/55", "eta": "11:49:30", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02717, "lr": 0.00001, "mAP": 0.05975, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:37:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61668, "dt_data": 0.02503, "dt_net": 3.59165, "epoch": "23/55", "eta": "12:18:42", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02596, "lr": 0.00001, "mAP": 0.06827, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:37:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94782, "dt_data": 0.02502, "dt_net": 2.92280, "epoch": "23/55", "eta": "10:01:36", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02727, "lr": 0.00001, "mAP": 0.07031, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:38:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28380, "dt_data": 0.02504, "dt_net": 3.25876, "epoch": "23/55", "eta": "11:09:37", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02763, "lr": 0.00001, "mAP": 0.05961, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:38:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34844, "dt_data": 0.02534, "dt_net": 3.32310, "epoch": "23/55", "eta": "11:22:14", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02715, "lr": 0.00001, "mAP": 0.05551, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:39:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09398, "dt_data": 0.02514, "dt_net": 4.06884, "epoch": "23/55", "eta": "13:53:28", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02709, "lr": 0.00001, "mAP": 0.06442, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:39:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62860, "dt_data": 0.02532, "dt_net": 3.60328, "epoch": "23/55", "eta": "12:18:07", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02606, "lr": 0.00001, "mAP": 0.05930, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:40:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14654, "dt_data": 0.02504, "dt_net": 3.12150, "epoch": "23/55", "eta": "10:39:32", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02837, "lr": 0.00001, "mAP": 0.05754, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:41:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23652, "dt_data": 0.02499, "dt_net": 3.21153, "epoch": "23/55", "eta": "10:57:17", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02765, "lr": 0.00001, "mAP": 0.05577, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:41:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.70076, "dt_data": 0.02503, "dt_net": 2.67572, "epoch": "23/55", "eta": "9:08:01", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02723, "lr": 0.00001, "mAP": 0.06518, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:42:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56965, "dt_data": 0.02499, "dt_net": 3.54465, "epoch": "23/55", "eta": "12:03:44", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02781, "lr": 0.00001, "mAP": 0.06400, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:42:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29815, "dt_data": 0.80660, "dt_net": 2.49155, "epoch": "23/55", "eta": "11:08:09", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02763, "lr": 0.00001, "mAP": 0.05298, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:43:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.14615, "dt_data": 3.59388, "dt_net": 0.55227, "epoch": "23/55", "eta": "13:59:14", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02634, "lr": 0.00001, "mAP": 0.06938, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:43:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92564, "dt_data": 1.80155, "dt_net": 1.12408, "epoch": "23/55", "eta": "9:51:42", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02925, "lr": 0.00001, "mAP": 0.06503, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:44:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87669, "dt_data": 2.32730, "dt_net": 0.54938, "epoch": "23/55", "eta": "9:41:19", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02652, "lr": 0.00001, "mAP": 0.07033, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:44:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40493, "dt_data": 2.85346, "dt_net": 0.55147, "epoch": "23/55", "eta": "11:27:30", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02613, "lr": 0.00001, "mAP": 0.06399, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:45:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08195, "dt_data": 2.52544, "dt_net": 0.55651, "epoch": "23/55", "eta": "10:21:47", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02621, "lr": 0.00001, "mAP": 0.06882, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:45:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39402, "dt_data": 2.84469, "dt_net": 0.54933, "epoch": "23/55", "eta": "11:24:10", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02575, "lr": 0.00001, "mAP": 0.06610, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:46:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06433, "dt_data": 2.51087, "dt_net": 0.55345, "epoch": "23/55", "eta": "10:17:12", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02902, "lr": 0.00001, "mAP": 0.06868, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:47:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55899, "dt_data": 3.00499, "dt_net": 0.55400, "epoch": "23/55", "eta": "11:56:14", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02732, "lr": 0.00001, "mAP": 0.05963, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:47:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24254, "dt_data": 2.69794, "dt_net": 0.54460, "epoch": "23/55", "eta": "10:52:01", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02815, "lr": 0.00001, "mAP": 0.07009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:48:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31273, "dt_data": 2.76210, "dt_net": 0.55062, "epoch": "23/55", "eta": "11:05:34", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02833, "lr": 0.00001, "mAP": 0.06277, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:48:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91825, "dt_data": 2.36744, "dt_net": 0.55081, "epoch": "23/55", "eta": "9:45:50", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02740, "lr": 0.00001, "mAP": 0.06213, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:49:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04987, "dt_data": 2.49778, "dt_net": 0.55209, "epoch": "23/55", "eta": "10:11:45", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02652, "lr": 0.00001, "mAP": 0.06805, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:49:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80811, "dt_data": 2.25465, "dt_net": 0.55346, "epoch": "23/55", "eta": "9:22:47", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02722, "lr": 0.00001, "mAP": 0.06118, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:50:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.76302, "dt_data": 2.21394, "dt_net": 0.54907, "epoch": "23/55", "eta": "9:13:17", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02641, "lr": 0.00001, "mAP": 0.07679, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:50:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60138, "dt_data": 3.04994, "dt_net": 0.55143, "epoch": "23/55", "eta": "12:00:34", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02559, "lr": 0.00001, "mAP": 0.05960, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:51:10][INFO] logging.py:  99: json_stats: {"RAM": "25.41/251.55G", "_type": "train_epoch", "dt": 0.00028, "dt_data": 0.00028, "dt_net": 0.55100, "epoch": "23/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02706, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:51:10][INFO] train_net.py: 497: Epoch 22 takes 1244.46s. Epochs from 0 to 22 take 1260.86s in average and 1261.02s in median.
[03/08 03:51:10][INFO] train_net.py: 503: For epoch 22, each iteraction takes 3.32s in average. From epoch 0 to 22, each iteraction takes 3.36s in average.
[03/08 03:51:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:02:18", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05979, "time_diff": 1.60829, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:51:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:02:19", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05902, "time_diff": 1.83242, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:52:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:01:48", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06146, "time_diff": 1.63711, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:52:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:01:29", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06061, "time_diff": 1.60093, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:52:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:01:21", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.05912, "time_diff": 1.77327, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:52:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:00:54", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05860, "time_diff": 1.52755, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:53:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:00:47", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.06381, "time_diff": 1.82363, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:53:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:00:22", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05863, "time_diff": 1.39480, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:53:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05975, "time_diff": 1.48963, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:53:52][INFO] logging.py:  99: json_stats: {"RAM": "26.07/251.55G", "_type": "val_epoch", "epoch": "23/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:54:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16869, "dt_data": 2.62519, "dt_net": 0.54350, "epoch": "24/55", "eta": "10:33:12", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02556, "lr": 0.00001, "mAP": 0.06927, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:55:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.52982, "dt_data": 1.97889, "dt_net": 0.55093, "epoch": "24/55", "eta": "8:25:07", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02516, "lr": 0.00001, "mAP": 0.07173, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:55:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04528, "dt_data": 2.48819, "dt_net": 0.55709, "epoch": "24/55", "eta": "10:07:32", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02566, "lr": 0.00001, "mAP": 0.07266, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:56:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16196, "dt_data": 2.53906, "dt_net": 0.62290, "epoch": "24/55", "eta": "10:30:17", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02786, "lr": 0.00001, "mAP": 0.07098, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:56:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43048, "dt_data": 0.43532, "dt_net": 2.99516, "epoch": "24/55", "eta": "11:23:14", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02719, "lr": 0.00001, "mAP": 0.06365, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:57:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51715, "dt_data": 0.02511, "dt_net": 3.49203, "epoch": "24/55", "eta": "11:39:54", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02591, "lr": 0.00001, "mAP": 0.07298, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:57:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19154, "dt_data": 0.02507, "dt_net": 3.16648, "epoch": "24/55", "eta": "10:34:35", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02612, "lr": 0.00001, "mAP": 0.06890, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:58:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41768, "dt_data": 0.02503, "dt_net": 3.39265, "epoch": "24/55", "eta": "11:18:58", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02509, "lr": 0.00001, "mAP": 0.06644, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:58:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22482, "dt_data": 0.02502, "dt_net": 3.19980, "epoch": "24/55", "eta": "10:40:07", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02513, "lr": 0.00001, "mAP": 0.06774, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 03:59:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38749, "dt_data": 0.02505, "dt_net": 3.36243, "epoch": "24/55", "eta": "11:11:51", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02687, "lr": 0.00001, "mAP": 0.06740, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:00:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14475, "dt_data": 0.02542, "dt_net": 3.11933, "epoch": "24/55", "eta": "10:23:11", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02519, "lr": 0.00001, "mAP": 0.06503, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:00:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48692, "dt_data": 2.93638, "dt_net": 0.55054, "epoch": "24/55", "eta": "11:30:24", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02625, "lr": 0.00001, "mAP": 0.06719, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:01:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18619, "dt_data": 2.63399, "dt_net": 0.55220, "epoch": "24/55", "eta": "10:30:20", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02564, "lr": 0.00001, "mAP": 0.06652, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:01:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63122, "dt_data": 0.09590, "dt_net": 3.53532, "epoch": "24/55", "eta": "11:57:46", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02581, "lr": 0.00001, "mAP": 0.06375, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:02:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.67081, "dt_data": 0.02516, "dt_net": 2.64564, "epoch": "24/55", "eta": "8:47:29", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02753, "lr": 0.00001, "mAP": 0.06830, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:02:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87150, "dt_data": 0.02513, "dt_net": 3.84637, "epoch": "24/55", "eta": "12:43:58", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02645, "lr": 0.00001, "mAP": 0.06135, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:03:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17895, "dt_data": 0.02498, "dt_net": 3.15397, "epoch": "24/55", "eta": "10:26:47", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02782, "lr": 0.00001, "mAP": 0.06744, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:03:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72833, "dt_data": 0.02498, "dt_net": 2.70335, "epoch": "24/55", "eta": "8:57:28", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02631, "lr": 0.00001, "mAP": 0.06339, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:04:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87717, "dt_data": 0.02512, "dt_net": 2.85205, "epoch": "24/55", "eta": "9:26:19", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02557, "lr": 0.00001, "mAP": 0.06265, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:04:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01422, "dt_data": 0.02501, "dt_net": 2.98920, "epoch": "24/55", "eta": "9:52:47", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02618, "lr": 0.00001, "mAP": 0.06644, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:05:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.16622, "dt_data": 0.02502, "dt_net": 4.14120, "epoch": "24/55", "eta": "13:38:39", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02621, "lr": 0.00001, "mAP": 0.06890, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:06:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91151, "dt_data": 0.02501, "dt_net": 3.88649, "epoch": "24/55", "eta": "12:47:57", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02711, "lr": 0.00001, "mAP": 0.06451, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:06:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52718, "dt_data": 0.02506, "dt_net": 3.50212, "epoch": "24/55", "eta": "11:31:54", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02695, "lr": 0.00001, "mAP": 0.06951, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:07:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30331, "dt_data": 0.02510, "dt_net": 3.27821, "epoch": "24/55", "eta": "10:47:26", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02695, "lr": 0.00001, "mAP": 0.06993, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:07:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87507, "dt_data": 0.02512, "dt_net": 3.84994, "epoch": "24/55", "eta": "12:38:52", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02545, "lr": 0.00001, "mAP": 0.06786, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:08:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.73307, "dt_data": 0.02500, "dt_net": 2.70807, "epoch": "24/55", "eta": "8:54:46", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02749, "lr": 0.00001, "mAP": 0.06146, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:08:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69889, "dt_data": 0.02528, "dt_net": 3.67361, "epoch": "24/55", "eta": "12:03:08", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02710, "lr": 0.00001, "mAP": 0.05402, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:09:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74325, "dt_data": 0.02513, "dt_net": 3.71812, "epoch": "24/55", "eta": "12:11:10", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02684, "lr": 0.00001, "mAP": 0.05723, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:10:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02119, "dt_data": 0.02511, "dt_net": 2.99608, "epoch": "24/55", "eta": "9:49:38", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02516, "lr": 0.00001, "mAP": 0.06927, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:10:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70721, "dt_data": 0.02505, "dt_net": 3.68216, "epoch": "24/55", "eta": "12:02:54", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02607, "lr": 0.00001, "mAP": 0.06503, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:11:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93677, "dt_data": 0.02505, "dt_net": 3.91172, "epoch": "24/55", "eta": "12:47:00", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02545, "lr": 0.00001, "mAP": 0.06954, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:11:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15799, "dt_data": 0.02508, "dt_net": 3.13291, "epoch": "24/55", "eta": "10:14:45", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02708, "lr": 0.00001, "mAP": 0.06116, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:12:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44976, "dt_data": 0.02508, "dt_net": 3.42468, "epoch": "24/55", "eta": "11:10:58", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02693, "lr": 0.00001, "mAP": 0.06500, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:12:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.00983, "dt_data": 0.02501, "dt_net": 3.98482, "epoch": "24/55", "eta": "12:59:14", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02720, "lr": 0.00001, "mAP": 0.07477, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:13:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45545, "dt_data": 0.02501, "dt_net": 3.43044, "epoch": "24/55", "eta": "11:10:56", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02788, "lr": 0.00001, "mAP": 0.06307, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:13:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97105, "dt_data": 0.02504, "dt_net": 2.94601, "epoch": "24/55", "eta": "9:36:22", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02770, "lr": 0.00001, "mAP": 0.06414, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:14:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88185, "dt_data": 0.02511, "dt_net": 3.85673, "epoch": "24/55", "eta": "12:32:25", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02585, "lr": 0.00001, "mAP": 0.06112, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:14:43][INFO] logging.py:  99: json_stats: {"RAM": "26.38/251.55G", "_type": "train_epoch", "dt": 0.00035, "dt_data": 0.00035, "dt_net": 2.52194, "epoch": "24/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02646, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:14:43][INFO] train_net.py: 497: Epoch 23 takes 1245.46s. Epochs from 0 to 23 take 1260.22s in average and 1259.45s in median.
[03/08 04:14:43][INFO] train_net.py: 503: For epoch 23, each iteraction takes 3.32s in average. From epoch 0 to 23, each iteraction takes 3.36s in average.
[03/08 04:15:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:02:07", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.05699, "time_diff": 1.48169, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:15:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:01:56", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.05823, "time_diff": 1.53075, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:15:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:01:37", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06277, "time_diff": 1.47602, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:15:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:01:26", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06193, "time_diff": 1.54587, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:16:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:01:24", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06046, "time_diff": 1.84365, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:16:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:01:06", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05982, "time_diff": 1.83524, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:16:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:00:42", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.06786, "time_diff": 1.63610, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:16:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.05565, "time_diff": 1.50504, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:17:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.05723, "time_diff": 1.56945, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:17:22][INFO] logging.py:  99: json_stats: {"RAM": "26.74/251.55G", "_type": "val_epoch", "epoch": "24/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:18:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.61459, "dt_data": 2.06266, "dt_net": 0.55193, "epoch": "25/55", "eta": "8:26:08", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02666, "lr": 0.00001, "mAP": 0.06192, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:18:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92013, "dt_data": 2.36656, "dt_net": 0.55357, "epoch": "25/55", "eta": "9:24:48", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02414, "lr": 0.00001, "mAP": 0.06592, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:19:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68321, "dt_data": 3.13015, "dt_net": 0.55306, "epoch": "25/55", "eta": "11:51:46", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02511, "lr": 0.00001, "mAP": 0.07025, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:19:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22033, "dt_data": 2.47622, "dt_net": 0.74411, "epoch": "25/55", "eta": "10:21:47", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02665, "lr": 0.00001, "mAP": 0.07121, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:20:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.77810, "dt_data": 2.22485, "dt_net": 0.55325, "epoch": "25/55", "eta": "8:55:56", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02537, "lr": 0.00001, "mAP": 0.06786, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:20:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.72134, "dt_data": 2.17068, "dt_net": 0.55066, "epoch": "25/55", "eta": "8:44:32", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02600, "lr": 0.00001, "mAP": 0.07112, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:21:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02835, "dt_data": 2.47912, "dt_net": 0.54922, "epoch": "25/55", "eta": "9:43:12", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02501, "lr": 0.00001, "mAP": 0.07106, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:21:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06837, "dt_data": 2.52054, "dt_net": 0.54783, "epoch": "25/55", "eta": "9:50:24", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02631, "lr": 0.00001, "mAP": 0.07192, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:22:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42626, "dt_data": 2.88060, "dt_net": 0.54566, "epoch": "25/55", "eta": "10:58:41", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02617, "lr": 0.00001, "mAP": 0.06808, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:23:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33985, "dt_data": 2.79084, "dt_net": 0.54901, "epoch": "25/55", "eta": "10:41:31", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02444, "lr": 0.00001, "mAP": 0.06860, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:23:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89684, "dt_data": 2.34481, "dt_net": 0.55203, "epoch": "25/55", "eta": "9:15:57", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02325, "lr": 0.00001, "mAP": 0.06586, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:24:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20174, "dt_data": 2.65252, "dt_net": 0.54922, "epoch": "25/55", "eta": "10:13:56", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02743, "lr": 0.00001, "mAP": 0.06917, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:24:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20344, "dt_data": 2.65127, "dt_net": 0.55217, "epoch": "25/55", "eta": "10:13:43", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02637, "lr": 0.00001, "mAP": 0.05912, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:25:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97741, "dt_data": 1.82343, "dt_net": 2.15398, "epoch": "25/55", "eta": "12:41:20", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02594, "lr": 0.00001, "mAP": 0.06406, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:25:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59228, "dt_data": 3.04143, "dt_net": 0.55085, "epoch": "25/55", "eta": "11:27:01", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02468, "lr": 0.00001, "mAP": 0.06991, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:26:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02110, "dt_data": 0.13562, "dt_net": 3.88547, "epoch": "25/55", "eta": "12:48:21", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02465, "lr": 0.00001, "mAP": 0.06943, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:26:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.61476, "dt_data": 1.82130, "dt_net": 0.79346, "epoch": "25/55", "eta": "8:19:12", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02553, "lr": 0.00001, "mAP": 0.07118, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:27:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39979, "dt_data": 2.84836, "dt_net": 0.55142, "epoch": "25/55", "eta": "10:48:30", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02490, "lr": 0.00001, "mAP": 0.06674, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:27:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37897, "dt_data": 1.57574, "dt_net": 1.80323, "epoch": "25/55", "eta": "10:43:58", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02564, "lr": 0.00001, "mAP": 0.07048, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:28:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55804, "dt_data": 0.02504, "dt_net": 3.53300, "epoch": "25/55", "eta": "11:17:30", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02609, "lr": 0.00001, "mAP": 0.07385, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:29:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03502, "dt_data": 0.02499, "dt_net": 3.01003, "epoch": "25/55", "eta": "9:37:24", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02446, "lr": 0.00001, "mAP": 0.06868, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:29:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18816, "dt_data": 0.02516, "dt_net": 3.16300, "epoch": "25/55", "eta": "10:06:00", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02561, "lr": 0.00001, "mAP": 0.06567, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:30:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57658, "dt_data": 0.02500, "dt_net": 3.55158, "epoch": "25/55", "eta": "11:19:15", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02673, "lr": 0.00001, "mAP": 0.07135, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:30:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26168, "dt_data": 0.02501, "dt_net": 3.23668, "epoch": "25/55", "eta": "10:18:54", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02613, "lr": 0.00001, "mAP": 0.06604, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:31:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42408, "dt_data": 0.02508, "dt_net": 3.39900, "epoch": "25/55", "eta": "10:49:08", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02391, "lr": 0.00001, "mAP": 0.06354, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:31:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19604, "dt_data": 0.02506, "dt_net": 3.17098, "epoch": "25/55", "eta": "10:05:23", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02662, "lr": 0.00001, "mAP": 0.06699, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:32:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07576, "dt_data": 0.02498, "dt_net": 3.05078, "epoch": "25/55", "eta": "9:42:05", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02403, "lr": 0.00001, "mAP": 0.06696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:32:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27644, "dt_data": 0.98554, "dt_net": 2.29090, "epoch": "25/55", "eta": "10:19:31", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02444, "lr": 0.00001, "mAP": 0.06686, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:33:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44143, "dt_data": 0.04314, "dt_net": 3.39829, "epoch": "25/55", "eta": "10:50:08", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02447, "lr": 0.00001, "mAP": 0.06138, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:34:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.73881, "dt_data": 0.02499, "dt_net": 2.71381, "epoch": "25/55", "eta": "8:36:56", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02600, "lr": 0.00001, "mAP": 0.06981, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:34:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01143, "dt_data": 0.02505, "dt_net": 2.98638, "epoch": "25/55", "eta": "9:27:54", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02621, "lr": 0.00001, "mAP": 0.05990, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:35:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.12150, "dt_data": 0.02513, "dt_net": 4.09637, "epoch": "25/55", "eta": "12:56:33", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02544, "lr": 0.00001, "mAP": 0.06857, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:35:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.40482, "dt_data": 0.02502, "dt_net": 4.37980, "epoch": "25/55", "eta": "13:49:12", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02556, "lr": 0.00001, "mAP": 0.06569, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:36:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87479, "dt_data": 0.02501, "dt_net": 2.84978, "epoch": "25/55", "eta": "9:00:41", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02508, "lr": 0.00001, "mAP": 0.06467, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:36:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18694, "dt_data": 0.02503, "dt_net": 3.16190, "epoch": "25/55", "eta": "9:58:52", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02686, "lr": 0.00001, "mAP": 0.06473, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:37:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87202, "dt_data": 0.02503, "dt_net": 2.84699, "epoch": "25/55", "eta": "8:59:13", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02622, "lr": 0.00001, "mAP": 0.07796, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:37:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16976, "dt_data": 1.88140, "dt_net": 1.28837, "epoch": "25/55", "eta": "9:54:35", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02649, "lr": 0.00001, "mAP": 0.06994, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:38:10][INFO] logging.py:  99: json_stats: {"RAM": "26.48/251.55G", "_type": "train_epoch", "dt": 0.00032, "dt_data": 0.00032, "dt_net": 0.54716, "epoch": "25/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02574, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:38:10][INFO] train_net.py: 497: Epoch 24 takes 1241.75s. Epochs from 0 to 24 take 1259.48s in average and 1257.88s in median.
[03/08 04:38:10][INFO] train_net.py: 503: For epoch 24, each iteraction takes 3.31s in average. From epoch 0 to 24, each iteraction takes 3.36s in average.
[03/08 04:38:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06128, "time_diff": 1.51653, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:38:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:02:07", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06124, "time_diff": 1.67951, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:39:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:01:36", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06794, "time_diff": 1.46725, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:39:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:01:36", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06628, "time_diff": 1.71591, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:39:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:01:13", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06631, "time_diff": 1.59208, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:39:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:00:59", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.05871, "time_diff": 1.65760, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:40:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:00:41", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.06760, "time_diff": 1.59273, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:40:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06740, "time_diff": 1.61695, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:40:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.06446, "time_diff": 1.48937, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:40:48][INFO] logging.py:  99: json_stats: {"RAM": "25.79/251.55G", "_type": "val_epoch", "epoch": "25/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:41:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37163, "dt_data": 2.81877, "dt_net": 0.55285, "epoch": "26/55", "eta": "10:31:37", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02707, "lr": 0.00001, "mAP": 0.07232, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:41:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16578, "dt_data": 2.61739, "dt_net": 0.54839, "epoch": "26/55", "eta": "9:52:31", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02411, "lr": 0.00001, "mAP": 0.06760, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:42:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42307, "dt_data": 2.87624, "dt_net": 0.54683, "epoch": "26/55", "eta": "10:40:06", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02483, "lr": 0.00001, "mAP": 0.06493, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:43:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94679, "dt_data": 3.39668, "dt_net": 0.55012, "epoch": "26/55", "eta": "12:17:23", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02592, "lr": 0.00001, "mAP": 0.06381, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:43:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11833, "dt_data": 2.56443, "dt_net": 0.55390, "epoch": "26/55", "eta": "9:42:05", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02568, "lr": 0.00001, "mAP": 0.07058, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:44:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07225, "dt_data": 2.52359, "dt_net": 0.54866, "epoch": "26/55", "eta": "9:32:58", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02519, "lr": 0.00001, "mAP": 0.06488, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:44:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.20023, "dt_data": 3.64787, "dt_net": 0.55236, "epoch": "26/55", "eta": "13:02:38", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02425, "lr": 0.00001, "mAP": 0.06903, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:45:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40761, "dt_data": 1.20774, "dt_net": 2.19987, "epoch": "26/55", "eta": "10:34:23", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02546, "lr": 0.00001, "mAP": 0.06756, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:45:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.28519, "dt_data": 0.53386, "dt_net": 3.75133, "epoch": "26/55", "eta": "13:17:02", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02549, "lr": 0.00001, "mAP": 0.06935, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:46:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16500, "dt_data": 0.02502, "dt_net": 3.13997, "epoch": "26/55", "eta": "9:48:09", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02443, "lr": 0.00001, "mAP": 0.07048, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:46:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74002, "dt_data": 0.02498, "dt_net": 2.71503, "epoch": "26/55", "eta": "8:28:43", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02415, "lr": 0.00001, "mAP": 0.07530, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:47:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80616, "dt_data": 0.02523, "dt_net": 3.78093, "epoch": "26/55", "eta": "11:46:02", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02433, "lr": 0.00001, "mAP": 0.06855, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:48:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89488, "dt_data": 0.02517, "dt_net": 2.86971, "epoch": "26/55", "eta": "8:56:31", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02531, "lr": 0.00001, "mAP": 0.06864, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:48:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59703, "dt_data": 0.02500, "dt_net": 2.57203, "epoch": "26/55", "eta": "8:00:53", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02576, "lr": 0.00001, "mAP": 0.06426, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:49:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06716, "dt_data": 0.02503, "dt_net": 3.04213, "epoch": "26/55", "eta": "9:27:25", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02486, "lr": 0.00001, "mAP": 0.07454, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:49:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05584, "dt_data": 0.02503, "dt_net": 3.03081, "epoch": "26/55", "eta": "9:24:49", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02321, "lr": 0.00001, "mAP": 0.06429, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:50:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98979, "dt_data": 0.02498, "dt_net": 2.96479, "epoch": "26/55", "eta": "9:12:06", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02584, "lr": 0.00001, "mAP": 0.06637, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:50:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33767, "dt_data": 0.02501, "dt_net": 3.31266, "epoch": "26/55", "eta": "10:15:47", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02643, "lr": 0.00001, "mAP": 0.06984, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:51:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.08791, "dt_data": 0.02506, "dt_net": 4.06286, "epoch": "26/55", "eta": "12:33:32", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02488, "lr": 0.00001, "mAP": 0.07229, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:52:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32142, "dt_data": 0.02501, "dt_net": 3.29641, "epoch": "26/55", "eta": "10:11:41", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02524, "lr": 0.00001, "mAP": 0.06198, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:52:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09028, "dt_data": 0.02502, "dt_net": 3.06526, "epoch": "26/55", "eta": "9:28:36", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02558, "lr": 0.00001, "mAP": 0.07277, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:53:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21817, "dt_data": 1.99186, "dt_net": 1.22630, "epoch": "26/55", "eta": "9:51:36", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02485, "lr": 0.00001, "mAP": 0.06808, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:53:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.60405, "dt_data": 0.02504, "dt_net": 2.57900, "epoch": "26/55", "eta": "7:58:16", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02407, "lr": 0.00001, "mAP": 0.06272, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:54:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72952, "dt_data": 0.02513, "dt_net": 3.70440, "epoch": "26/55", "eta": "11:24:22", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02475, "lr": 0.00001, "mAP": 0.06138, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:54:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45807, "dt_data": 0.02501, "dt_net": 3.43305, "epoch": "26/55", "eta": "10:33:58", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02553, "lr": 0.00001, "mAP": 0.07254, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:55:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13403, "dt_data": 0.02498, "dt_net": 3.10904, "epoch": "26/55", "eta": "9:34:02", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02576, "lr": 0.00001, "mAP": 0.07058, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:55:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34331, "dt_data": 0.92025, "dt_net": 2.42305, "epoch": "26/55", "eta": "10:11:49", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02442, "lr": 0.00001, "mAP": 0.07510, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:56:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22945, "dt_data": 0.57595, "dt_net": 2.65349, "epoch": "26/55", "eta": "9:50:27", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02516, "lr": 0.00001, "mAP": 0.06433, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:56:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26752, "dt_data": 2.04123, "dt_net": 1.22628, "epoch": "26/55", "eta": "9:56:51", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02575, "lr": 0.00001, "mAP": 0.05875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:57:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54847, "dt_data": 0.02504, "dt_net": 3.52343, "epoch": "26/55", "eta": "10:47:35", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02613, "lr": 0.00001, "mAP": 0.07135, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:58:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85438, "dt_data": 0.02498, "dt_net": 2.82939, "epoch": "26/55", "eta": "8:40:26", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02710, "lr": 0.00001, "mAP": 0.06701, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:58:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89921, "dt_data": 0.02503, "dt_net": 2.87418, "epoch": "26/55", "eta": "8:48:08", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02456, "lr": 0.00001, "mAP": 0.06749, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:59:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88598, "dt_data": 0.62593, "dt_net": 2.26005, "epoch": "26/55", "eta": "8:45:14", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02515, "lr": 0.00001, "mAP": 0.07068, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 04:59:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55691, "dt_data": 0.88310, "dt_net": 2.67381, "epoch": "26/55", "eta": "10:46:45", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02587, "lr": 0.00001, "mAP": 0.07029, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:00:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72601, "dt_data": 0.02502, "dt_net": 3.70099, "epoch": "26/55", "eta": "11:16:53", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02593, "lr": 0.00001, "mAP": 0.06143, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:00:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02669, "dt_data": 0.59809, "dt_net": 2.42860, "epoch": "26/55", "eta": "9:09:20", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02446, "lr": 0.00001, "mAP": 0.07065, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:01:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44464, "dt_data": 2.48429, "dt_net": 0.96034, "epoch": "26/55", "eta": "10:24:37", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02540, "lr": 0.00001, "mAP": 0.07500, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:01:37][INFO] logging.py:  99: json_stats: {"RAM": "25.81/251.55G", "_type": "train_epoch", "dt": 0.00027, "dt_data": 0.00027, "dt_net": 0.54534, "epoch": "26/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02542, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:01:37][INFO] train_net.py: 497: Epoch 25 takes 1243.56s. Epochs from 0 to 25 take 1258.87s in average and 1257.44s in median.
[03/08 05:01:37][INFO] train_net.py: 503: For epoch 25, each iteraction takes 3.32s in average. From epoch 0 to 25, each iteraction takes 3.36s in average.
[03/08 05:01:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:02:12", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06013, "time_diff": 1.53954, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:02:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:02:06", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06273, "time_diff": 1.66116, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:02:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:01:36", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06990, "time_diff": 1.45771, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:02:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:01:24", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06691, "time_diff": 1.51110, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:03:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:01:12", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06149, "time_diff": 1.57850, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:03:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:00:55", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06286, "time_diff": 1.52996, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:03:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.06816, "time_diff": 1.74350, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:03:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06339, "time_diff": 1.60439, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:04:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.06302, "time_diff": 1.54917, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:04:15][INFO] logging.py:  99: json_stats: {"RAM": "25.98/251.55G", "_type": "val_epoch", "epoch": "26/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:04:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35959, "dt_data": 2.80562, "dt_net": 0.55397, "epoch": "27/55", "eta": "10:08:21", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02503, "lr": 0.00001, "mAP": 0.06560, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:05:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70453, "dt_data": 3.15305, "dt_net": 0.55148, "epoch": "27/55", "eta": "11:10:12", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02392, "lr": 0.00001, "mAP": 0.07229, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:05:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54775, "dt_data": 2.99756, "dt_net": 0.55019, "epoch": "27/55", "eta": "10:41:15", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02382, "lr": 0.00001, "mAP": 0.06369, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:06:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51428, "dt_data": 2.38024, "dt_net": 1.13403, "epoch": "27/55", "eta": "10:34:37", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02461, "lr": 0.00001, "mAP": 0.06661, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:07:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02177, "dt_data": 0.54332, "dt_net": 3.47845, "epoch": "27/55", "eta": "12:05:35", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02292, "lr": 0.00001, "mAP": 0.06631, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:07:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63712, "dt_data": 0.02501, "dt_net": 3.61211, "epoch": "27/55", "eta": "10:55:35", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02402, "lr": 0.00001, "mAP": 0.06909, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:08:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.04986, "dt_data": 0.02504, "dt_net": 4.02482, "epoch": "27/55", "eta": "12:09:18", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02369, "lr": 0.00001, "mAP": 0.07043, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:08:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.50173, "dt_data": 0.02511, "dt_net": 2.47662, "epoch": "27/55", "eta": "7:30:06", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02545, "lr": 0.00001, "mAP": 0.05713, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:09:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12982, "dt_data": 0.02499, "dt_net": 3.10482, "epoch": "27/55", "eta": "9:22:35", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02408, "lr": 0.00001, "mAP": 0.06872, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:09:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89483, "dt_data": 0.02503, "dt_net": 2.86980, "epoch": "27/55", "eta": "8:39:51", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02460, "lr": 0.00001, "mAP": 0.06929, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:10:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93639, "dt_data": 0.02542, "dt_net": 2.91097, "epoch": "27/55", "eta": "8:46:50", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02395, "lr": 0.00001, "mAP": 0.07201, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:11:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63576, "dt_data": 0.02502, "dt_net": 3.61075, "epoch": "27/55", "eta": "10:51:42", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02389, "lr": 0.00001, "mAP": 0.07065, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:11:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68876, "dt_data": 0.02503, "dt_net": 2.66373, "epoch": "27/55", "eta": "8:01:30", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02404, "lr": 0.00001, "mAP": 0.07679, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:12:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16652, "dt_data": 0.02505, "dt_net": 3.14147, "epoch": "27/55", "eta": "9:26:32", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02488, "lr": 0.00001, "mAP": 0.06783, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:12:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12292, "dt_data": 2.49043, "dt_net": 0.63249, "epoch": "27/55", "eta": "9:18:13", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02749, "lr": 0.00001, "mAP": 0.07196, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:13:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.22230, "dt_data": 3.67111, "dt_net": 0.55118, "epoch": "27/55", "eta": "12:34:01", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02527, "lr": 0.00001, "mAP": 0.06875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:13:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18993, "dt_data": 2.63923, "dt_net": 0.55070, "epoch": "27/55", "eta": "9:29:08", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02443, "lr": 0.00001, "mAP": 0.07192, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:14:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83224, "dt_data": 3.28409, "dt_net": 0.54816, "epoch": "27/55", "eta": "11:23:05", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02358, "lr": 0.00001, "mAP": 0.06936, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:14:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73996, "dt_data": 1.38354, "dt_net": 2.35642, "epoch": "27/55", "eta": "11:06:01", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02504, "lr": 0.00001, "mAP": 0.07140, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:15:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.01097, "dt_data": 2.63734, "dt_net": 1.37363, "epoch": "27/55", "eta": "11:53:37", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02352, "lr": 0.00001, "mAP": 0.07408, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:16:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50971, "dt_data": 2.11714, "dt_net": 1.39257, "epoch": "27/55", "eta": "10:23:51", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02405, "lr": 0.00001, "mAP": 0.06765, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:16:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55559, "dt_data": 3.00663, "dt_net": 0.54896, "epoch": "27/55", "eta": "10:31:24", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02418, "lr": 0.00001, "mAP": 0.06896, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:17:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53715, "dt_data": 2.98540, "dt_net": 0.55175, "epoch": "27/55", "eta": "10:27:32", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02611, "lr": 0.00001, "mAP": 0.06579, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:17:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25956, "dt_data": 2.49937, "dt_net": 0.76019, "epoch": "27/55", "eta": "9:37:45", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02439, "lr": 0.00001, "mAP": 0.07377, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:18:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03388, "dt_data": 0.02500, "dt_net": 3.00888, "epoch": "27/55", "eta": "8:57:14", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02483, "lr": 0.00001, "mAP": 0.07039, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:18:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37444, "dt_data": 1.36393, "dt_net": 2.01051, "epoch": "27/55", "eta": "9:56:59", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02591, "lr": 0.00001, "mAP": 0.06972, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:19:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39909, "dt_data": 0.02499, "dt_net": 3.37410, "epoch": "27/55", "eta": "10:00:47", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02616, "lr": 0.00001, "mAP": 0.06746, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:19:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.98856, "dt_data": 0.02501, "dt_net": 3.96355, "epoch": "27/55", "eta": "11:44:18", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02544, "lr": 0.00001, "mAP": 0.06850, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:20:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95014, "dt_data": 0.02503, "dt_net": 3.92510, "epoch": "27/55", "eta": "11:36:52", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02213, "lr": 0.00001, "mAP": 0.06875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:21:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02122, "dt_data": 0.02503, "dt_net": 2.99619, "epoch": "27/55", "eta": "8:52:29", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02435, "lr": 0.00001, "mAP": 0.07241, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:21:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86046, "dt_data": 0.02498, "dt_net": 3.83548, "epoch": "27/55", "eta": "11:19:45", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02570, "lr": 0.00001, "mAP": 0.07422, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:22:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56222, "dt_data": 0.02501, "dt_net": 3.53721, "epoch": "27/55", "eta": "10:26:39", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02524, "lr": 0.00001, "mAP": 0.07552, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:22:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.07104, "dt_data": 0.02509, "dt_net": 4.04595, "epoch": "27/55", "eta": "11:55:29", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02434, "lr": 0.00001, "mAP": 0.07403, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:23:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49085, "dt_data": 0.02501, "dt_net": 3.46584, "epoch": "27/55", "eta": "10:12:56", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02588, "lr": 0.00001, "mAP": 0.06987, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:23:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04718, "dt_data": 0.02506, "dt_net": 3.02212, "epoch": "27/55", "eta": "8:54:31", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02479, "lr": 0.00001, "mAP": 0.07683, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:24:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33323, "dt_data": 0.02509, "dt_net": 3.30814, "epoch": "27/55", "eta": "9:44:08", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02500, "lr": 0.00001, "mAP": 0.06689, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:25:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.18746, "dt_data": 0.35755, "dt_net": 3.82990, "epoch": "27/55", "eta": "12:13:09", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02575, "lr": 0.00001, "mAP": 0.07728, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:25:19][INFO] logging.py:  99: json_stats: {"RAM": "26.04/251.55G", "_type": "train_epoch", "dt": 0.00035, "dt_data": 0.00035, "dt_net": 2.92294, "epoch": "27/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02472, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:25:19][INFO] train_net.py: 497: Epoch 26 takes 1258.31s. Epochs from 0 to 26 take 1258.85s in average and 1257.88s in median.
[03/08 05:25:19][INFO] train_net.py: 503: For epoch 26, each iteraction takes 3.36s in average. From epoch 0 to 26, each iteraction takes 3.36s in average.
[03/08 05:25:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06435, "time_diff": 1.50985, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:25:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:02:08", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06614, "time_diff": 1.69014, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:26:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:01:40", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07144, "time_diff": 1.51521, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:26:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:01:45", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.07283, "time_diff": 1.89079, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:26:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:01:24", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06690, "time_diff": 1.84607, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:27:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:01:12", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06628, "time_diff": 2.00642, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:27:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:00:43", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07402, "time_diff": 1.66278, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:27:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.07028, "time_diff": 1.57206, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:27:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07060, "time_diff": 1.93733, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:27:59][INFO] logging.py:  99: json_stats: {"RAM": "26.14/251.55G", "_type": "val_epoch", "epoch": "27/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:28:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.16611, "dt_data": 1.61922, "dt_net": 0.54689, "epoch": "28/55", "eta": "6:18:42", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02453, "lr": 0.00001, "mAP": 0.07173, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:29:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11732, "dt_data": 0.93325, "dt_net": 2.18407, "epoch": "28/55", "eta": "9:04:29", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02420, "lr": 0.00001, "mAP": 0.06488, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:29:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92432, "dt_data": 0.02504, "dt_net": 2.89928, "epoch": "28/55", "eta": "8:30:17", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02421, "lr": 0.00001, "mAP": 0.07234, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:30:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46669, "dt_data": 0.02507, "dt_net": 3.44161, "epoch": "28/55", "eta": "10:04:21", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02513, "lr": 0.00001, "mAP": 0.06533, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:30:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82075, "dt_data": 0.02520, "dt_net": 2.79555, "epoch": "28/55", "eta": "8:11:16", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02269, "lr": 0.00001, "mAP": 0.07103, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:31:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01462, "dt_data": 0.02527, "dt_net": 2.98935, "epoch": "28/55", "eta": "8:44:32", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02507, "lr": 0.00001, "mAP": 0.07335, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:31:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.87040, "dt_data": 0.02513, "dt_net": 2.84528, "epoch": "28/55", "eta": "8:18:58", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02426, "lr": 0.00001, "mAP": 0.07798, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:32:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25721, "dt_data": 0.88832, "dt_net": 2.36888, "epoch": "28/55", "eta": "9:25:40", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02329, "lr": 0.00001, "mAP": 0.07359, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:32:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26069, "dt_data": 1.35447, "dt_net": 1.90622, "epoch": "28/55", "eta": "9:25:43", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02389, "lr": 0.00001, "mAP": 0.07158, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:33:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56686, "dt_data": 0.43043, "dt_net": 3.13643, "epoch": "28/55", "eta": "10:18:15", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02367, "lr": 0.00001, "mAP": 0.06737, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:34:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47781, "dt_data": 0.78715, "dt_net": 2.69066, "epoch": "28/55", "eta": "10:02:14", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02499, "lr": 0.00001, "mAP": 0.06689, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:34:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44097, "dt_data": 0.02496, "dt_net": 3.41600, "epoch": "28/55", "eta": "9:55:17", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02475, "lr": 0.00001, "mAP": 0.07121, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:35:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66852, "dt_data": 0.04003, "dt_net": 3.62849, "epoch": "28/55", "eta": "10:34:02", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02398, "lr": 0.00001, "mAP": 0.06890, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:35:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67072, "dt_data": 0.02499, "dt_net": 3.64573, "epoch": "28/55", "eta": "10:33:48", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02461, "lr": 0.00001, "mAP": 0.06661, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:36:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.23212, "dt_data": 0.02503, "dt_net": 2.20709, "epoch": "28/55", "eta": "6:25:02", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02488, "lr": 0.00001, "mAP": 0.06988, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:36:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00292, "dt_data": 0.02521, "dt_net": 2.97770, "epoch": "28/55", "eta": "8:37:30", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02492, "lr": 0.00001, "mAP": 0.07696, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:37:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79467, "dt_data": 0.50545, "dt_net": 3.28921, "epoch": "28/55", "eta": "10:53:18", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02399, "lr": 0.00001, "mAP": 0.07291, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:37:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19760, "dt_data": 1.39102, "dt_net": 1.80657, "epoch": "28/55", "eta": "9:09:59", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02463, "lr": 0.00001, "mAP": 0.06664, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:38:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51379, "dt_data": 0.02506, "dt_net": 3.48873, "epoch": "28/55", "eta": "10:03:47", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02364, "lr": 0.00001, "mAP": 0.07705, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:38:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72289, "dt_data": 0.02499, "dt_net": 3.69790, "epoch": "28/55", "eta": "10:39:05", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02425, "lr": 0.00001, "mAP": 0.06376, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:39:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24124, "dt_data": 0.02515, "dt_net": 3.21609, "epoch": "28/55", "eta": "9:15:52", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02306, "lr": 0.00001, "mAP": 0.07269, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:40:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39693, "dt_data": 0.02530, "dt_net": 3.37163, "epoch": "28/55", "eta": "9:42:00", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02415, "lr": 0.00001, "mAP": 0.07225, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:40:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.53952, "dt_data": 0.02529, "dt_net": 2.51422, "epoch": "28/55", "eta": "7:14:40", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02449, "lr": 0.00001, "mAP": 0.07467, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:41:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29539, "dt_data": 0.02502, "dt_net": 3.27037, "epoch": "28/55", "eta": "9:23:30", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02399, "lr": 0.00001, "mAP": 0.07013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:41:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16232, "dt_data": 0.02557, "dt_net": 3.13675, "epoch": "28/55", "eta": "9:00:13", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02330, "lr": 0.00001, "mAP": 0.07086, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:42:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88495, "dt_data": 0.02511, "dt_net": 2.85983, "epoch": "28/55", "eta": "8:12:21", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02529, "lr": 0.00001, "mAP": 0.06656, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:42:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.65912, "dt_data": 0.02538, "dt_net": 3.63374, "epoch": "28/55", "eta": "10:23:52", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02330, "lr": 0.00001, "mAP": 0.07382, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:43:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46891, "dt_data": 0.02502, "dt_net": 3.44389, "epoch": "28/55", "eta": "9:50:52", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02352, "lr": 0.00001, "mAP": 0.07469, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:44:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00482, "dt_data": 0.02500, "dt_net": 2.97982, "epoch": "28/55", "eta": "8:31:19", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02401, "lr": 0.00001, "mAP": 0.06515, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:44:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93294, "dt_data": 0.02508, "dt_net": 2.90786, "epoch": "28/55", "eta": "8:18:36", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02503, "lr": 0.00001, "mAP": 0.06671, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:45:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38673, "dt_data": 0.02504, "dt_net": 3.36169, "epoch": "28/55", "eta": "9:35:10", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02287, "lr": 0.00001, "mAP": 0.07673, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:45:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85023, "dt_data": 0.02506, "dt_net": 2.82517, "epoch": "28/55", "eta": "8:03:35", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02329, "lr": 0.00001, "mAP": 0.06747, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:46:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.78255, "dt_data": 0.80018, "dt_net": 1.98237, "epoch": "28/55", "eta": "7:51:38", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02445, "lr": 0.00001, "mAP": 0.06928, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:46:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.78576, "dt_data": 0.02500, "dt_net": 3.76076, "epoch": "28/55", "eta": "10:41:03", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02409, "lr": 0.00001, "mAP": 0.07178, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:47:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76805, "dt_data": 0.02497, "dt_net": 3.74308, "epoch": "28/55", "eta": "10:37:25", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02346, "lr": 0.00001, "mAP": 0.06757, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:47:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.78647, "dt_data": 0.02512, "dt_net": 3.76135, "epoch": "28/55", "eta": "10:39:54", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02573, "lr": 0.00001, "mAP": 0.06690, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:48:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93090, "dt_data": 0.02500, "dt_net": 3.90590, "epoch": "28/55", "eta": "11:03:40", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02302, "lr": 0.00001, "mAP": 0.07708, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:48:42][INFO] logging.py:  99: json_stats: {"RAM": "26.57/251.55G", "_type": "train_epoch", "dt": 0.00044, "dt_data": 0.00044, "dt_net": 3.10775, "epoch": "28/55", "eta": "0:00:03", "gpu_mem": "17.37G", "loss": 0.02419, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:48:42][INFO] train_net.py: 497: Epoch 27 takes 1237.80s. Epochs from 0 to 27 take 1258.10s in average and 1257.44s in median.
[03/08 05:48:42][INFO] train_net.py: 503: For epoch 27, each iteraction takes 3.30s in average. From epoch 0 to 27, each iteraction takes 3.35s in average.
[03/08 05:49:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06560, "time_diff": 1.50844, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:49:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:02:05", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06915, "time_diff": 1.65779, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:49:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:01:36", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07009, "time_diff": 1.46675, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:49:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:01:42", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06955, "time_diff": 1.82325, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:50:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:01:22", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06705, "time_diff": 1.80334, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:50:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:01:09", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06269, "time_diff": 1.94047, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:50:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:00:43", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07313, "time_diff": 1.65513, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:50:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06778, "time_diff": 1.53066, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:51:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07111, "time_diff": 1.84292, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:51:21][INFO] logging.py:  99: json_stats: {"RAM": "27.00/251.55G", "_type": "val_epoch", "epoch": "28/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00008, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:52:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59538, "dt_data": 3.04597, "dt_net": 0.54941, "epoch": "29/55", "eta": "10:06:07", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02333, "lr": 0.00001, "mAP": 0.07449, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:52:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15011, "dt_data": 2.60239, "dt_net": 0.54771, "epoch": "29/55", "eta": "8:50:31", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02283, "lr": 0.00001, "mAP": 0.07658, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:53:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89933, "dt_data": 2.35031, "dt_net": 0.54902, "epoch": "29/55", "eta": "8:07:48", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02244, "lr": 0.00001, "mAP": 0.07041, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:53:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30372, "dt_data": 2.75529, "dt_net": 0.54843, "epoch": "29/55", "eta": "9:15:18", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02361, "lr": 0.00001, "mAP": 0.06742, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:54:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74085, "dt_data": 3.18692, "dt_net": 0.55393, "epoch": "29/55", "eta": "10:28:09", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02285, "lr": 0.00001, "mAP": 0.07259, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:54:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.66424, "dt_data": 2.11427, "dt_net": 0.54997, "epoch": "29/55", "eta": "7:26:55", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02517, "lr": 0.00001, "mAP": 0.06726, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:55:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49907, "dt_data": 0.02503, "dt_net": 3.47404, "epoch": "29/55", "eta": "9:46:23", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02450, "lr": 0.00001, "mAP": 0.06726, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:55:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10924, "dt_data": 0.02517, "dt_net": 3.08406, "epoch": "29/55", "eta": "8:40:32", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02333, "lr": 0.00001, "mAP": 0.06927, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:56:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.04385, "dt_data": 0.54349, "dt_net": 3.50036, "epoch": "29/55", "eta": "11:16:20", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02315, "lr": 0.00001, "mAP": 0.06901, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:56:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23055, "dt_data": 0.02538, "dt_net": 3.20516, "epoch": "29/55", "eta": "8:59:46", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02346, "lr": 0.00001, "mAP": 0.07658, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:57:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.70916, "dt_data": 0.02532, "dt_net": 2.68384, "epoch": "29/55", "eta": "7:32:12", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02391, "lr": 0.00001, "mAP": 0.07058, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:58:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26701, "dt_data": 0.02502, "dt_net": 3.24199, "epoch": "29/55", "eta": "9:04:46", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02412, "lr": 0.00001, "mAP": 0.07412, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:58:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97009, "dt_data": 0.02531, "dt_net": 2.94478, "epoch": "29/55", "eta": "8:14:46", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02336, "lr": 0.00001, "mAP": 0.07895, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:59:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50251, "dt_data": 0.02511, "dt_net": 3.47740, "epoch": "29/55", "eta": "9:42:52", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02373, "lr": 0.00001, "mAP": 0.07113, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 05:59:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21510, "dt_data": 0.02497, "dt_net": 3.19013, "epoch": "29/55", "eta": "8:54:30", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02423, "lr": 0.00001, "mAP": 0.07131, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:00:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79045, "dt_data": 0.02500, "dt_net": 3.76545, "epoch": "29/55", "eta": "10:29:31", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02484, "lr": 0.00001, "mAP": 0.07225, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:00:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18976, "dt_data": 0.02499, "dt_net": 3.16477, "epoch": "29/55", "eta": "8:49:14", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02345, "lr": 0.00001, "mAP": 0.07344, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:01:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29907, "dt_data": 0.02512, "dt_net": 3.27394, "epoch": "29/55", "eta": "9:06:49", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02398, "lr": 0.00001, "mAP": 0.06939, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:01:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27976, "dt_data": 0.02504, "dt_net": 3.25472, "epoch": "29/55", "eta": "9:03:04", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02431, "lr": 0.00001, "mAP": 0.07180, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:02:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14730, "dt_data": 0.02498, "dt_net": 3.12232, "epoch": "29/55", "eta": "8:40:36", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02480, "lr": 0.00001, "mAP": 0.07509, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:03:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50235, "dt_data": 0.02506, "dt_net": 3.47729, "epoch": "29/55", "eta": "9:38:45", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02445, "lr": 0.00001, "mAP": 0.07065, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:03:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10833, "dt_data": 0.02503, "dt_net": 3.08330, "epoch": "29/55", "eta": "8:33:08", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02360, "lr": 0.00001, "mAP": 0.07269, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:04:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.33148, "dt_data": 0.62728, "dt_net": 3.70419, "epoch": "29/55", "eta": "11:54:19", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02508, "lr": 0.00001, "mAP": 0.06771, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:04:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77092, "dt_data": 0.02508, "dt_net": 3.74583, "epoch": "29/55", "eta": "10:21:15", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02422, "lr": 0.00001, "mAP": 0.07269, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:05:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81638, "dt_data": 0.02527, "dt_net": 2.79111, "epoch": "29/55", "eta": "7:43:31", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02430, "lr": 0.00001, "mAP": 0.06852, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:05:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43160, "dt_data": 0.53625, "dt_net": 2.89536, "epoch": "29/55", "eta": "9:24:12", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02426, "lr": 0.00001, "mAP": 0.07009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:06:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82080, "dt_data": 1.46770, "dt_net": 2.35310, "epoch": "29/55", "eta": "10:27:34", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02354, "lr": 0.00001, "mAP": 0.07482, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:06:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68240, "dt_data": 2.13254, "dt_net": 0.54985, "epoch": "29/55", "eta": "7:20:08", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02466, "lr": 0.00001, "mAP": 0.06994, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:07:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.78179, "dt_data": 2.22330, "dt_net": 0.55849, "epoch": "29/55", "eta": "7:35:58", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02223, "lr": 0.00001, "mAP": 0.07824, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:08:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18433, "dt_data": 2.62780, "dt_net": 0.55653, "epoch": "29/55", "eta": "8:41:26", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02224, "lr": 0.00001, "mAP": 0.06994, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:08:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50465, "dt_data": 2.80375, "dt_net": 0.70090, "epoch": "29/55", "eta": "9:33:18", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02276, "lr": 0.00001, "mAP": 0.07780, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:09:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12657, "dt_data": 2.15111, "dt_net": 0.97545, "epoch": "29/55", "eta": "8:30:56", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02419, "lr": 0.00001, "mAP": 0.06607, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:09:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35077, "dt_data": 2.71583, "dt_net": 0.63494, "epoch": "29/55", "eta": "9:07:00", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02279, "lr": 0.00001, "mAP": 0.06908, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:10:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19465, "dt_data": 2.64635, "dt_net": 0.54830, "epoch": "29/55", "eta": "8:40:59", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02349, "lr": 0.00001, "mAP": 0.06844, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:10:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.86349, "dt_data": 2.31248, "dt_net": 0.55101, "epoch": "29/55", "eta": "7:46:30", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02314, "lr": 0.00001, "mAP": 0.06909, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:11:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.98168, "dt_data": 3.43034, "dt_net": 0.55134, "epoch": "29/55", "eta": "10:48:01", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02348, "lr": 0.00001, "mAP": 0.07507, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:11:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85126, "dt_data": 3.30072, "dt_net": 0.55053, "epoch": "29/55", "eta": "10:26:09", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02351, "lr": 0.00001, "mAP": 0.07219, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:12:13][INFO] logging.py:  99: json_stats: {"RAM": "26.87/251.55G", "_type": "train_epoch", "dt": 0.00029, "dt_data": 0.00029, "dt_net": 0.54155, "epoch": "29/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02386, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:12:13][INFO] train_net.py: 497: Epoch 28 takes 1246.42s. Epochs from 0 to 28 take 1257.69s in average and 1257.00s in median.
[03/08 06:12:13][INFO] train_net.py: 503: For epoch 28, each iteraction takes 3.32s in average. From epoch 0 to 28, each iteraction takes 3.35s in average.
[03/08 06:12:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:02:13", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06374, "time_diff": 1.55259, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:12:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:02:08", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06740, "time_diff": 1.69713, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:13:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:01:35", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07254, "time_diff": 1.45233, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:13:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:01:34", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06943, "time_diff": 1.67873, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:13:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:01:10", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.07091, "time_diff": 1.53380, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:13:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:00:54", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06359, "time_diff": 1.52731, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:14:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:00:49", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07575, "time_diff": 1.88687, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:14:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:00:22", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06864, "time_diff": 1.38718, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:14:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07066, "time_diff": 1.44815, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:14:53][INFO] logging.py:  99: json_stats: {"RAM": "25.90/251.55G", "_type": "val_epoch", "epoch": "29/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:15:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.90946, "dt_data": 2.36152, "dt_net": 0.54794, "epoch": "30/55", "eta": "7:52:18", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02273, "lr": 0.00001, "mAP": 0.06719, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:16:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.67336, "dt_data": 2.12247, "dt_net": 0.55090, "epoch": "30/55", "eta": "7:13:31", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02250, "lr": 0.00001, "mAP": 0.06634, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:16:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97937, "dt_data": 3.42571, "dt_net": 0.55366, "epoch": "30/55", "eta": "10:44:39", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02409, "lr": 0.00001, "mAP": 0.07701, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:17:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08830, "dt_data": 2.53371, "dt_net": 0.55459, "epoch": "30/55", "eta": "8:19:47", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02285, "lr": 0.00001, "mAP": 0.07699, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:17:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19822, "dt_data": 2.64705, "dt_net": 0.55117, "epoch": "30/55", "eta": "8:37:02", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02463, "lr": 0.00001, "mAP": 0.07036, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:18:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24117, "dt_data": 2.69601, "dt_net": 0.54515, "epoch": "30/55", "eta": "8:43:26", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02313, "lr": 0.00001, "mAP": 0.06996, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:18:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79963, "dt_data": 3.24876, "dt_net": 0.55086, "epoch": "30/55", "eta": "10:13:00", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02145, "lr": 0.00001, "mAP": 0.07390, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:19:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38157, "dt_data": 2.83278, "dt_net": 0.54879, "epoch": "30/55", "eta": "9:04:59", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02293, "lr": 0.00001, "mAP": 0.07403, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:19:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82376, "dt_data": 2.27245, "dt_net": 0.55131, "epoch": "30/55", "eta": "7:34:37", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02130, "lr": 0.00001, "mAP": 0.06961, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:20:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28741, "dt_data": 2.11294, "dt_net": 1.17447, "epoch": "30/55", "eta": "8:48:43", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02300, "lr": 0.00001, "mAP": 0.08311, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:21:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30296, "dt_data": 1.09425, "dt_net": 2.20871, "epoch": "30/55", "eta": "8:50:40", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02298, "lr": 0.00001, "mAP": 0.07794, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:21:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71880, "dt_data": 0.02501, "dt_net": 3.69379, "epoch": "30/55", "eta": "9:56:52", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02262, "lr": 0.00001, "mAP": 0.07500, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:22:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10500, "dt_data": 0.02498, "dt_net": 3.08001, "epoch": "30/55", "eta": "8:17:50", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02353, "lr": 0.00001, "mAP": 0.07681, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:22:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.27611, "dt_data": 3.72519, "dt_net": 0.55092, "epoch": "30/55", "eta": "11:24:53", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02276, "lr": 0.00001, "mAP": 0.07533, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:23:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25918, "dt_data": 2.70770, "dt_net": 0.55147, "epoch": "30/55", "eta": "8:41:28", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02246, "lr": 0.00001, "mAP": 0.07121, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:23:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45637, "dt_data": 2.90925, "dt_net": 0.54712, "epoch": "30/55", "eta": "9:12:26", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02151, "lr": 0.00001, "mAP": 0.07515, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:24:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62066, "dt_data": 3.06750, "dt_net": 0.55316, "epoch": "30/55", "eta": "9:38:05", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02272, "lr": 0.00001, "mAP": 0.07693, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:24:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24581, "dt_data": 2.69343, "dt_net": 0.55237, "epoch": "30/55", "eta": "8:37:42", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02418, "lr": 0.00001, "mAP": 0.07946, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:25:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68275, "dt_data": 2.50486, "dt_net": 1.17789, "epoch": "30/55", "eta": "9:46:47", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02309, "lr": 0.00001, "mAP": 0.07249, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:26:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97201, "dt_data": 0.03928, "dt_net": 2.93272, "epoch": "30/55", "eta": "7:53:02", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02381, "lr": 0.00001, "mAP": 0.06836, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:26:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51955, "dt_data": 0.80458, "dt_net": 2.71497, "epoch": "30/55", "eta": "9:19:36", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02314, "lr": 0.00001, "mAP": 0.06760, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:27:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87521, "dt_data": 0.02516, "dt_net": 3.85005, "epoch": "30/55", "eta": "10:15:30", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02186, "lr": 0.00001, "mAP": 0.07360, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:27:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.30877, "dt_data": 0.02500, "dt_net": 4.28377, "epoch": "30/55", "eta": "11:23:39", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02317, "lr": 0.00001, "mAP": 0.06723, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:28:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86271, "dt_data": 0.02501, "dt_net": 3.83769, "epoch": "30/55", "eta": "10:12:14", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02332, "lr": 0.00001, "mAP": 0.07568, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:28:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88677, "dt_data": 0.02503, "dt_net": 2.86174, "epoch": "30/55", "eta": "7:37:04", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02413, "lr": 0.00001, "mAP": 0.07085, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:29:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80417, "dt_data": 0.02515, "dt_net": 3.77901, "epoch": "30/55", "eta": "10:01:41", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02312, "lr": 0.00001, "mAP": 0.07449, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:29:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21585, "dt_data": 0.02521, "dt_net": 3.19064, "epoch": "30/55", "eta": "8:28:06", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02301, "lr": 0.00001, "mAP": 0.07173, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:30:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29461, "dt_data": 0.02506, "dt_net": 3.26955, "epoch": "30/55", "eta": "8:39:59", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02099, "lr": 0.00001, "mAP": 0.07430, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:31:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09051, "dt_data": 0.02505, "dt_net": 4.06546, "epoch": "30/55", "eta": "10:44:56", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02351, "lr": 0.00001, "mAP": 0.07324, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:31:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08535, "dt_data": 0.02539, "dt_net": 3.05996, "epoch": "30/55", "eta": "8:05:56", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02427, "lr": 0.00001, "mAP": 0.07463, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:32:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32747, "dt_data": 0.02515, "dt_net": 3.30232, "epoch": "30/55", "eta": "8:43:31", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02253, "lr": 0.00001, "mAP": 0.07418, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:32:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45181, "dt_data": 0.02505, "dt_net": 3.42676, "epoch": "30/55", "eta": "9:02:30", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02311, "lr": 0.00001, "mAP": 0.07461, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:33:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70526, "dt_data": 0.02506, "dt_net": 3.68020, "epoch": "30/55", "eta": "9:41:43", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02305, "lr": 0.00001, "mAP": 0.07688, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:33:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67803, "dt_data": 0.02504, "dt_net": 3.65300, "epoch": "30/55", "eta": "9:36:50", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02477, "lr": 0.00001, "mAP": 0.06405, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:34:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76179, "dt_data": 0.02500, "dt_net": 3.73679, "epoch": "30/55", "eta": "9:49:20", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02320, "lr": 0.00001, "mAP": 0.06932, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:35:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.30416, "dt_data": 0.02518, "dt_net": 2.27898, "epoch": "30/55", "eta": "6:00:36", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02346, "lr": 0.00001, "mAP": 0.07385, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:35:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75624, "dt_data": 0.02514, "dt_net": 3.73110, "epoch": "30/55", "eta": "9:47:13", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02316, "lr": 0.00001, "mAP": 0.07189, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:35:51][INFO] logging.py:  99: json_stats: {"RAM": "26.02/251.55G", "_type": "train_epoch", "dt": 0.00031, "dt_data": 0.00031, "dt_net": 3.05439, "epoch": "30/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02324, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:35:51][INFO] train_net.py: 497: Epoch 29 takes 1251.91s. Epochs from 0 to 29 take 1257.50s in average and 1256.40s in median.
[03/08 06:35:51][INFO] train_net.py: 503: For epoch 29, each iteraction takes 3.34s in average. From epoch 0 to 29, each iteraction takes 3.35s in average.
[03/08 06:36:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:02:05", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06857, "time_diff": 1.45436, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:36:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:02:05", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06312, "time_diff": 1.64791, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:36:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:01:32", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07226, "time_diff": 1.40764, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:36:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:01:26", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06921, "time_diff": 1.54658, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:37:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:01:08", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06507, "time_diff": 1.48975, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:37:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:00:56", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06618, "time_diff": 1.58007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:37:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:00:44", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07244, "time_diff": 1.70680, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:38:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:00:23", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06746, "time_diff": 1.49389, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:38:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07351, "time_diff": 1.46346, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:38:29][INFO] logging.py:  99: json_stats: {"RAM": "26.33/251.55G", "_type": "val_epoch", "epoch": "30/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:39:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09710, "dt_data": 2.54351, "dt_net": 0.55359, "epoch": "31/55", "eta": "8:03:24", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02304, "lr": 0.00001, "mAP": 0.06932, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:39:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25610, "dt_data": 2.70452, "dt_net": 0.55159, "epoch": "31/55", "eta": "8:27:40", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02386, "lr": 0.00001, "mAP": 0.07561, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:40:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.29094, "dt_data": 3.73753, "dt_net": 0.55340, "epoch": "31/55", "eta": "11:08:18", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02500, "lr": 0.00001, "mAP": 0.06866, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:40:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77703, "dt_data": 3.22390, "dt_net": 0.55313, "epoch": "31/55", "eta": "9:47:38", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02253, "lr": 0.00001, "mAP": 0.07740, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:41:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44407, "dt_data": 2.89462, "dt_net": 0.54945, "epoch": "31/55", "eta": "8:55:15", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02552, "lr": 0.00001, "mAP": 0.07546, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:41:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.26490, "dt_data": 3.71176, "dt_net": 0.55313, "epoch": "31/55", "eta": "11:02:07", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02398, "lr": 0.00001, "mAP": 0.06734, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:42:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27564, "dt_data": 2.72495, "dt_net": 0.55069, "epoch": "31/55", "eta": "8:27:59", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02422, "lr": 0.00001, "mAP": 0.06991, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:43:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58013, "dt_data": 3.02809, "dt_net": 0.55203, "epoch": "31/55", "eta": "9:14:37", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02283, "lr": 0.00001, "mAP": 0.06845, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:43:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38839, "dt_data": 2.83569, "dt_net": 0.55270, "epoch": "31/55", "eta": "8:44:21", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02174, "lr": 0.00001, "mAP": 0.06775, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:44:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56133, "dt_data": 3.00837, "dt_net": 0.55295, "epoch": "31/55", "eta": "9:10:31", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02295, "lr": 0.00001, "mAP": 0.07596, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:44:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22746, "dt_data": 2.67807, "dt_net": 0.54939, "epoch": "31/55", "eta": "8:18:22", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02411, "lr": 0.00001, "mAP": 0.07440, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:45:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.71018, "dt_data": 0.02505, "dt_net": 4.68513, "epoch": "31/55", "eta": "12:06:32", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02255, "lr": 0.00001, "mAP": 0.07506, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:45:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80355, "dt_data": 0.02501, "dt_net": 2.77854, "epoch": "31/55", "eta": "7:11:58", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02269, "lr": 0.00001, "mAP": 0.07450, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:46:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77254, "dt_data": 0.02538, "dt_net": 3.74716, "epoch": "31/55", "eta": "9:40:39", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02267, "lr": 0.00001, "mAP": 0.08222, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:46:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.70512, "dt_data": 0.02510, "dt_net": 2.68002, "epoch": "31/55", "eta": "6:55:54", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02239, "lr": 0.00001, "mAP": 0.06778, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:47:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37454, "dt_data": 2.12406, "dt_net": 1.25048, "epoch": "31/55", "eta": "8:38:16", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02078, "lr": 0.00001, "mAP": 0.07753, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:47:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17166, "dt_data": 1.93616, "dt_net": 1.23549, "epoch": "31/55", "eta": "8:06:35", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02099, "lr": 0.00001, "mAP": 0.07926, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:48:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32382, "dt_data": 2.77142, "dt_net": 0.55240, "epoch": "31/55", "eta": "8:29:22", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02254, "lr": 0.00001, "mAP": 0.07539, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:49:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79452, "dt_data": 3.24274, "dt_net": 0.55178, "epoch": "31/55", "eta": "9:40:52", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02183, "lr": 0.00001, "mAP": 0.06864, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:49:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00647, "dt_data": 2.45756, "dt_net": 0.54891, "epoch": "31/55", "eta": "7:39:44", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02298, "lr": 0.00001, "mAP": 0.07813, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:50:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.57922, "dt_data": 2.02638, "dt_net": 0.55284, "epoch": "31/55", "eta": "6:33:58", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02314, "lr": 0.00001, "mAP": 0.08735, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:50:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42651, "dt_data": 2.88433, "dt_net": 0.54217, "epoch": "31/55", "eta": "8:42:49", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02320, "lr": 0.00001, "mAP": 0.07634, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:51:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27708, "dt_data": 2.72865, "dt_net": 0.54843, "epoch": "31/55", "eta": "8:19:28", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02316, "lr": 0.00001, "mAP": 0.07088, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:51:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05618, "dt_data": 2.50502, "dt_net": 0.55115, "epoch": "31/55", "eta": "7:45:18", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02412, "lr": 0.00001, "mAP": 0.07418, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:52:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01503, "dt_data": 2.46737, "dt_net": 0.54766, "epoch": "31/55", "eta": "7:38:32", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02096, "lr": 0.00001, "mAP": 0.08037, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:53:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.86965, "dt_data": 2.31994, "dt_net": 0.54971, "epoch": "31/55", "eta": "7:15:56", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02157, "lr": 0.00001, "mAP": 0.07454, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:53:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.61512, "dt_data": 2.06018, "dt_net": 0.55494, "epoch": "31/55", "eta": "6:36:50", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02104, "lr": 0.00001, "mAP": 0.07365, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:54:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.47092, "dt_data": 3.91737, "dt_net": 0.55355, "epoch": "31/55", "eta": "11:17:43", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02279, "lr": 0.00001, "mAP": 0.08508, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:54:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01026, "dt_data": 2.45468, "dt_net": 0.55558, "epoch": "31/55", "eta": "7:35:48", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02226, "lr": 0.00001, "mAP": 0.07420, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:55:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74575, "dt_data": 2.19129, "dt_net": 0.55445, "epoch": "31/55", "eta": "6:55:17", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02266, "lr": 0.00001, "mAP": 0.07422, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:55:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50457, "dt_data": 1.67197, "dt_net": 1.83259, "epoch": "31/55", "eta": "8:49:28", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02295, "lr": 0.00001, "mAP": 0.07283, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:56:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28496, "dt_data": 0.02502, "dt_net": 3.25993, "epoch": "31/55", "eta": "8:15:45", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02189, "lr": 0.00001, "mAP": 0.06875, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:56:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32103, "dt_data": 0.02508, "dt_net": 3.29595, "epoch": "31/55", "eta": "8:20:38", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02232, "lr": 0.00001, "mAP": 0.07454, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:57:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83208, "dt_data": 0.02510, "dt_net": 2.80697, "epoch": "31/55", "eta": "7:06:27", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02313, "lr": 0.00001, "mAP": 0.07159, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:58:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69918, "dt_data": 0.02555, "dt_net": 3.67363, "epoch": "31/55", "eta": "9:16:25", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02179, "lr": 0.00001, "mAP": 0.07155, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:58:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81544, "dt_data": 0.02510, "dt_net": 2.79034, "epoch": "31/55", "eta": "7:03:01", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02374, "lr": 0.00001, "mAP": 0.07507, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:59:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.46988, "dt_data": 0.02503, "dt_net": 2.44485, "epoch": "31/55", "eta": "6:10:41", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02297, "lr": 0.00001, "mAP": 0.08441, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:59:21][INFO] logging.py:  99: json_stats: {"RAM": "26.38/251.55G", "_type": "train_epoch", "dt": 0.00031, "dt_data": 0.00031, "dt_net": 3.38318, "epoch": "31/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02276, "lr": 0.00001, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:59:21][INFO] train_net.py: 497: Epoch 30 takes 1246.50s. Epochs from 0 to 30 take 1257.15s in average and 1255.81s in median.
[03/08 06:59:21][INFO] train_net.py: 503: For epoch 30, each iteraction takes 3.32s in average. From epoch 0 to 30, each iteraction takes 3.35s in average.
[03/08 06:59:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06801, "time_diff": 1.51041, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 06:59:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:02:07", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06625, "time_diff": 1.67877, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:00:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:01:34", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07521, "time_diff": 1.43576, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:00:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:01:20", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.07190, "time_diff": 1.44265, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:00:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:01:23", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06668, "time_diff": 1.81547, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:01:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:01:09", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06718, "time_diff": 1.92858, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:01:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:00:46", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07491, "time_diff": 1.78861, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:01:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06912, "time_diff": 1.56210, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:01:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "31/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07110, "time_diff": 1.54827, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:02:01][INFO] logging.py:  99: json_stats: {"RAM": "26.77/251.55G", "_type": "val_epoch", "epoch": "31/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:02:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22104, "dt_data": 2.66895, "dt_net": 0.55209, "epoch": "32/55", "eta": "8:02:37", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02208, "lr": 0.00001, "mAP": 0.07710, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:03:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82410, "dt_data": 2.27347, "dt_net": 0.55063, "epoch": "32/55", "eta": "7:02:40", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02306, "lr": 0.00001, "mAP": 0.07189, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:03:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94026, "dt_data": 2.38672, "dt_net": 0.55354, "epoch": "32/55", "eta": "7:19:34", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02186, "lr": 0.00001, "mAP": 0.07381, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:04:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18512, "dt_data": 1.58655, "dt_net": 1.59857, "epoch": "32/55", "eta": "7:55:38", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02270, "lr": 0.00001, "mAP": 0.08391, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:04:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05432, "dt_data": 2.50364, "dt_net": 0.55068, "epoch": "32/55", "eta": "7:35:36", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02196, "lr": 0.00001, "mAP": 0.07220, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:05:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22622, "dt_data": 1.22678, "dt_net": 1.99944, "epoch": "32/55", "eta": "8:00:42", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02127, "lr": 0.00001, "mAP": 0.07740, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:05:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39442, "dt_data": 0.02507, "dt_net": 3.36935, "epoch": "32/55", "eta": "8:25:12", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02224, "lr": 0.00001, "mAP": 0.07282, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:06:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93772, "dt_data": 0.02497, "dt_net": 3.91275, "epoch": "32/55", "eta": "9:45:24", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02213, "lr": 0.00001, "mAP": 0.07571, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:07:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91870, "dt_data": 0.02499, "dt_net": 2.89371, "epoch": "32/55", "eta": "7:13:25", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02214, "lr": 0.00001, "mAP": 0.07024, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:07:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15582, "dt_data": 0.99347, "dt_net": 2.16235, "epoch": "32/55", "eta": "7:48:06", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02267, "lr": 0.00001, "mAP": 0.08283, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:08:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37636, "dt_data": 0.02501, "dt_net": 3.35135, "epoch": "32/55", "eta": "8:20:15", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02330, "lr": 0.00001, "mAP": 0.08966, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:08:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.71324, "dt_data": 0.02523, "dt_net": 2.68800, "epoch": "32/55", "eta": "6:41:33", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02252, "lr": 0.00001, "mAP": 0.07634, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:09:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43182, "dt_data": 0.02514, "dt_net": 3.40668, "epoch": "32/55", "eta": "8:27:20", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02340, "lr": 0.00001, "mAP": 0.07735, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:09:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57372, "dt_data": 0.02504, "dt_net": 3.54868, "epoch": "32/55", "eta": "8:47:43", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02191, "lr": 0.00001, "mAP": 0.07442, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:10:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89136, "dt_data": 0.02508, "dt_net": 2.86628, "epoch": "32/55", "eta": "7:06:28", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02217, "lr": 0.00001, "mAP": 0.07614, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:10:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.08568, "dt_data": 0.02517, "dt_net": 4.06051, "epoch": "32/55", "eta": "10:01:57", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02076, "lr": 0.00001, "mAP": 0.07842, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:11:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.65909, "dt_data": 0.02510, "dt_net": 3.63399, "epoch": "32/55", "eta": "8:58:29", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02187, "lr": 0.00001, "mAP": 0.07502, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:12:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36553, "dt_data": 0.08470, "dt_net": 3.28082, "epoch": "32/55", "eta": "8:14:43", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02338, "lr": 0.00001, "mAP": 0.07434, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:12:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69313, "dt_data": 0.02515, "dt_net": 3.66798, "epoch": "32/55", "eta": "9:02:16", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02347, "lr": 0.00001, "mAP": 0.07485, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:13:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32435, "dt_data": 0.02509, "dt_net": 3.29926, "epoch": "32/55", "eta": "8:07:34", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02304, "lr": 0.00001, "mAP": 0.08340, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:13:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77439, "dt_data": 0.02499, "dt_net": 3.74940, "epoch": "32/55", "eta": "9:12:56", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02225, "lr": 0.00001, "mAP": 0.07487, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:14:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95125, "dt_data": 0.62179, "dt_net": 2.32946, "epoch": "32/55", "eta": "7:11:52", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02095, "lr": 0.00001, "mAP": 0.07359, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:14:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91135, "dt_data": 0.82484, "dt_net": 2.08651, "epoch": "32/55", "eta": "7:05:32", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02237, "lr": 0.00001, "mAP": 0.07930, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:15:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61090, "dt_data": 0.02527, "dt_net": 3.58563, "epoch": "32/55", "eta": "8:47:11", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02154, "lr": 0.00001, "mAP": 0.06981, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:15:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85031, "dt_data": 1.08381, "dt_net": 1.76650, "epoch": "32/55", "eta": "6:55:40", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02297, "lr": 0.00001, "mAP": 0.06996, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:16:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88426, "dt_data": 2.23781, "dt_net": 0.64645, "epoch": "32/55", "eta": "7:00:08", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02318, "lr": 0.00001, "mAP": 0.06854, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:17:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10703, "dt_data": 2.46343, "dt_net": 0.64360, "epoch": "32/55", "eta": "7:32:04", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02333, "lr": 0.00001, "mAP": 0.07527, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:17:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03941, "dt_data": 2.48595, "dt_net": 0.55346, "epoch": "32/55", "eta": "7:21:43", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02366, "lr": 0.00001, "mAP": 0.06567, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:18:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74957, "dt_data": 2.53642, "dt_net": 1.21315, "epoch": "32/55", "eta": "9:04:18", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02269, "lr": 0.00001, "mAP": 0.06778, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:18:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.05839, "dt_data": 3.33241, "dt_net": 0.72598, "epoch": "32/55", "eta": "9:48:28", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02331, "lr": 0.00000, "mAP": 0.07448, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:19:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18980, "dt_data": 2.63880, "dt_net": 0.55100, "epoch": "32/55", "eta": "7:41:59", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02166, "lr": 0.00000, "mAP": 0.07111, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:19:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.60056, "dt_data": 2.05209, "dt_net": 0.54846, "epoch": "32/55", "eta": "6:16:12", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02391, "lr": 0.00000, "mAP": 0.07618, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:20:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97105, "dt_data": 2.40886, "dt_net": 0.56219, "epoch": "32/55", "eta": "7:09:19", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02163, "lr": 0.00000, "mAP": 0.07284, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:20:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39356, "dt_data": 0.16769, "dt_net": 3.22587, "epoch": "32/55", "eta": "8:09:48", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02079, "lr": 0.00000, "mAP": 0.07753, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:21:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66117, "dt_data": 0.02505, "dt_net": 3.63612, "epoch": "32/55", "eta": "8:47:49", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02138, "lr": 0.00000, "mAP": 0.07735, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:22:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.45627, "dt_data": 0.02518, "dt_net": 2.43109, "epoch": "32/55", "eta": "5:53:42", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02199, "lr": 0.00000, "mAP": 0.06656, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:22:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37547, "dt_data": 0.02503, "dt_net": 3.35044, "epoch": "32/55", "eta": "8:05:30", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02202, "lr": 0.00000, "mAP": 0.07649, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:22:48][INFO] logging.py:  99: json_stats: {"RAM": "26.40/251.55G", "_type": "train_epoch", "dt": 0.00025, "dt_data": 0.00025, "dt_net": 0.54878, "epoch": "32/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02235, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:22:48][INFO] train_net.py: 497: Epoch 31 takes 1240.75s. Epochs from 0 to 31 take 1256.63s in average and 1255.17s in median.
[03/08 07:22:48][INFO] train_net.py: 503: For epoch 31, each iteraction takes 3.31s in average. From epoch 0 to 31, each iteraction takes 3.35s in average.
[03/08 07:23:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06768, "time_diff": 1.51448, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:23:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06830, "time_diff": 1.70337, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:23:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:01:34", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07379, "time_diff": 1.42586, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:23:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:01:36", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.07281, "time_diff": 1.73155, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:24:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:01:18", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06808, "time_diff": 1.71566, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:24:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:01:08", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06548, "time_diff": 1.91070, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:24:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:00:39", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07538, "time_diff": 1.52924, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:25:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:00:22", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.07075, "time_diff": 1.43165, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:25:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "32/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07033, "time_diff": 1.59258, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:25:27][INFO] logging.py:  99: json_stats: {"RAM": "25.67/251.55G", "_type": "val_epoch", "epoch": "32/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:26:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54994, "dt_data": 2.99566, "dt_net": 0.55427, "epoch": "33/55", "eta": "8:29:42", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02207, "lr": 0.00000, "mAP": 0.07440, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:26:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16816, "dt_data": 2.61419, "dt_net": 0.55397, "epoch": "33/55", "eta": "7:34:22", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02255, "lr": 0.00000, "mAP": 0.07722, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:27:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91494, "dt_data": 2.36398, "dt_net": 0.55095, "epoch": "33/55", "eta": "6:57:33", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02189, "lr": 0.00000, "mAP": 0.07457, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:27:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28824, "dt_data": 2.74194, "dt_net": 0.54629, "epoch": "33/55", "eta": "7:50:29", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02243, "lr": 0.00000, "mAP": 0.07887, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:28:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.51033, "dt_data": 1.95063, "dt_net": 0.55970, "epoch": "33/55", "eta": "5:58:46", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02093, "lr": 0.00000, "mAP": 0.07492, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:28:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75203, "dt_data": 3.20243, "dt_net": 0.54960, "epoch": "33/55", "eta": "8:55:36", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02079, "lr": 0.00000, "mAP": 0.07457, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:29:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87339, "dt_data": 0.02498, "dt_net": 3.84841, "epoch": "33/55", "eta": "9:12:16", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02181, "lr": 0.00000, "mAP": 0.07664, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:30:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.30387, "dt_data": 0.02501, "dt_net": 4.27886, "epoch": "33/55", "eta": "10:12:56", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02325, "lr": 0.00000, "mAP": 0.07757, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:30:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07347, "dt_data": 0.02507, "dt_net": 3.04840, "epoch": "33/55", "eta": "7:17:12", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02118, "lr": 0.00000, "mAP": 0.07197, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:31:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01639, "dt_data": 0.02517, "dt_net": 2.99122, "epoch": "33/55", "eta": "7:08:34", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02169, "lr": 0.00000, "mAP": 0.07589, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:31:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61239, "dt_data": 0.02509, "dt_net": 3.58729, "epoch": "33/55", "eta": "8:32:39", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02279, "lr": 0.00000, "mAP": 0.07973, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:32:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11188, "dt_data": 2.27101, "dt_net": 0.84087, "epoch": "33/55", "eta": "7:21:06", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02001, "lr": 0.00000, "mAP": 0.08087, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:32:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.52387, "dt_data": 3.97143, "dt_net": 0.55244, "epoch": "33/55", "eta": "10:40:30", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02171, "lr": 0.00000, "mAP": 0.08772, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:33:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50243, "dt_data": 2.95065, "dt_net": 0.55178, "epoch": "33/55", "eta": "8:15:18", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02121, "lr": 0.00000, "mAP": 0.08892, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:33:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59833, "dt_data": 3.04583, "dt_net": 0.55249, "epoch": "33/55", "eta": "8:28:15", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02139, "lr": 0.00000, "mAP": 0.08007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:34:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57874, "dt_data": 3.02886, "dt_net": 0.54988, "epoch": "33/55", "eta": "8:24:54", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02332, "lr": 0.00000, "mAP": 0.08012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:35:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00599, "dt_data": 2.02594, "dt_net": 0.98006, "epoch": "33/55", "eta": "7:03:35", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02051, "lr": 0.00000, "mAP": 0.08661, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:35:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68599, "dt_data": 0.70133, "dt_net": 2.98466, "epoch": "33/55", "eta": "8:38:48", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02090, "lr": 0.00000, "mAP": 0.07583, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:36:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48814, "dt_data": 0.02500, "dt_net": 3.46314, "epoch": "33/55", "eta": "8:10:22", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02227, "lr": 0.00000, "mAP": 0.08013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:36:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17146, "dt_data": 0.02502, "dt_net": 3.14644, "epoch": "33/55", "eta": "7:25:19", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02121, "lr": 0.00000, "mAP": 0.07835, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:37:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04948, "dt_data": 0.02500, "dt_net": 3.02448, "epoch": "33/55", "eta": "7:07:41", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02139, "lr": 0.00000, "mAP": 0.07033, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:37:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15425, "dt_data": 0.02501, "dt_net": 3.12924, "epoch": "33/55", "eta": "7:21:51", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02164, "lr": 0.00000, "mAP": 0.07516, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:38:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16366, "dt_data": 0.02502, "dt_net": 3.13863, "epoch": "33/55", "eta": "7:22:38", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02171, "lr": 0.00000, "mAP": 0.07216, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:38:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.71162, "dt_data": 0.02504, "dt_net": 2.68658, "epoch": "33/55", "eta": "6:18:56", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02049, "lr": 0.00000, "mAP": 0.08244, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:39:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25364, "dt_data": 0.02500, "dt_net": 3.22864, "epoch": "33/55", "eta": "7:34:09", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02192, "lr": 0.00000, "mAP": 0.07455, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:39:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.47039, "dt_data": 0.51232, "dt_net": 3.95806, "epoch": "33/55", "eta": "10:23:14", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02238, "lr": 0.00000, "mAP": 0.06906, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:40:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95050, "dt_data": 0.46091, "dt_net": 2.48958, "epoch": "33/55", "eta": "6:50:51", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02164, "lr": 0.00000, "mAP": 0.08602, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:41:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40180, "dt_data": 0.02502, "dt_net": 3.37678, "epoch": "33/55", "eta": "7:53:08", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02265, "lr": 0.00000, "mAP": 0.07792, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:41:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39245, "dt_data": 0.02500, "dt_net": 3.36745, "epoch": "33/55", "eta": "7:51:16", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02296, "lr": 0.00000, "mAP": 0.07961, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:42:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54437, "dt_data": 1.52151, "dt_net": 2.02286, "epoch": "33/55", "eta": "8:11:46", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02231, "lr": 0.00000, "mAP": 0.08403, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:42:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87446, "dt_data": 0.79361, "dt_net": 3.08084, "epoch": "33/55", "eta": "8:56:56", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02142, "lr": 0.00000, "mAP": 0.07935, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:43:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85188, "dt_data": 0.45549, "dt_net": 3.39639, "epoch": "33/55", "eta": "8:53:09", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02162, "lr": 0.00000, "mAP": 0.07504, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:43:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59036, "dt_data": 1.41908, "dt_net": 1.17128, "epoch": "33/55", "eta": "5:58:07", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02132, "lr": 0.00000, "mAP": 0.07701, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:44:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.73733, "dt_data": 1.00502, "dt_net": 1.73230, "epoch": "33/55", "eta": "6:17:58", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02104, "lr": 0.00000, "mAP": 0.07257, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:44:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11477, "dt_data": 2.56391, "dt_net": 0.55086, "epoch": "33/55", "eta": "7:09:34", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02164, "lr": 0.00000, "mAP": 0.07732, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:45:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97238, "dt_data": 2.42105, "dt_net": 0.55133, "epoch": "33/55", "eta": "6:49:26", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02161, "lr": 0.00000, "mAP": 0.07609, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:46:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45746, "dt_data": 2.90599, "dt_net": 0.55146, "epoch": "33/55", "eta": "7:55:41", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02088, "lr": 0.00000, "mAP": 0.07318, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:46:16][INFO] logging.py:  99: json_stats: {"RAM": "25.85/251.55G", "_type": "train_epoch", "dt": 0.00033, "dt_data": 0.00032, "dt_net": 0.54563, "epoch": "33/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02183, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:46:16][INFO] train_net.py: 497: Epoch 32 takes 1243.59s. Epochs from 0 to 32 take 1256.24s in average and 1254.52s in median.
[03/08 07:46:16][INFO] train_net.py: 503: For epoch 32, each iteraction takes 3.32s in average. From epoch 0 to 32, each iteraction takes 3.35s in average.
[03/08 07:46:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06644, "time_diff": 1.50713, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:46:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:02:06", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06591, "time_diff": 1.65850, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:47:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:01:35", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07311, "time_diff": 1.44150, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:47:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:01:29", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.07235, "time_diff": 1.59840, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:47:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:01:18", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.07282, "time_diff": 1.69700, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:47:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:00:59", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06759, "time_diff": 1.65914, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:48:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:00:46", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07338, "time_diff": 1.78974, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:48:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:00:23", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06726, "time_diff": 1.46583, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:48:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "33/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07272, "time_diff": 1.48013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:48:56][INFO] logging.py:  99: json_stats: {"RAM": "26.43/251.55G", "_type": "val_epoch", "epoch": "33/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:49:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.91152, "dt_data": 2.36589, "dt_net": 0.54563, "epoch": "34/55", "eta": "6:39:50", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02201, "lr": 0.00000, "mAP": 0.07256, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:50:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.45738, "dt_data": 3.90525, "dt_net": 0.55213, "epoch": "34/55", "eta": "10:11:24", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02046, "lr": 0.00000, "mAP": 0.07695, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:50:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05054, "dt_data": 2.49791, "dt_net": 0.55263, "epoch": "34/55", "eta": "6:57:55", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02152, "lr": 0.00000, "mAP": 0.08548, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:51:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28889, "dt_data": 2.73475, "dt_net": 0.55414, "epoch": "34/55", "eta": "7:30:01", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02097, "lr": 0.00000, "mAP": 0.07807, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:51:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.03809, "dt_data": 3.48782, "dt_net": 0.55027, "epoch": "34/55", "eta": "9:11:52", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02068, "lr": 0.00000, "mAP": 0.07378, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:52:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.53496, "dt_data": 1.97993, "dt_net": 0.55503, "epoch": "34/55", "eta": "5:46:01", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02262, "lr": 0.00000, "mAP": 0.07424, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:53:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80239, "dt_data": 3.25393, "dt_net": 0.54846, "epoch": "34/55", "eta": "8:38:23", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02132, "lr": 0.00000, "mAP": 0.07455, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:53:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60279, "dt_data": 3.05123, "dt_net": 0.55156, "epoch": "34/55", "eta": "8:10:34", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02165, "lr": 0.00000, "mAP": 0.07475, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:54:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39956, "dt_data": 2.84849, "dt_net": 0.55108, "epoch": "34/55", "eta": "7:42:20", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02000, "lr": 0.00000, "mAP": 0.07981, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:54:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97631, "dt_data": 2.42426, "dt_net": 0.55205, "epoch": "34/55", "eta": "6:44:16", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02170, "lr": 0.00000, "mAP": 0.07673, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:55:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94595, "dt_data": 2.39568, "dt_net": 0.55026, "epoch": "34/55", "eta": "6:39:40", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02146, "lr": 0.00000, "mAP": 0.08253, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:55:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97948, "dt_data": 2.42758, "dt_net": 0.55189, "epoch": "34/55", "eta": "6:43:43", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02181, "lr": 0.00000, "mAP": 0.07554, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:56:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57582, "dt_data": 2.40920, "dt_net": 1.16662, "epoch": "34/55", "eta": "8:03:55", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02248, "lr": 0.00000, "mAP": 0.07443, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:56:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52148, "dt_data": 0.02500, "dt_net": 3.49647, "epoch": "34/55", "eta": "7:55:59", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02092, "lr": 0.00000, "mAP": 0.06787, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:57:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27383, "dt_data": 0.02522, "dt_net": 3.24861, "epoch": "34/55", "eta": "7:21:58", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02178, "lr": 0.00000, "mAP": 0.08591, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:57:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82993, "dt_data": 2.21681, "dt_net": 0.61311, "epoch": "34/55", "eta": "6:21:34", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02059, "lr": 0.00000, "mAP": 0.07597, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:58:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26090, "dt_data": 2.40152, "dt_net": 0.85938, "epoch": "34/55", "eta": "7:19:08", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01958, "lr": 0.00000, "mAP": 0.08048, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:59:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62607, "dt_data": 0.57516, "dt_net": 3.05091, "epoch": "34/55", "eta": "8:07:42", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02097, "lr": 0.00000, "mAP": 0.07540, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 07:59:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25589, "dt_data": 0.02501, "dt_net": 3.23087, "epoch": "34/55", "eta": "7:17:22", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02190, "lr": 0.00000, "mAP": 0.08034, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:00:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84856, "dt_data": 0.02508, "dt_net": 2.82348, "epoch": "34/55", "eta": "6:22:10", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02164, "lr": 0.00000, "mAP": 0.08290, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:00:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43613, "dt_data": 0.02501, "dt_net": 3.41112, "epoch": "34/55", "eta": "7:40:26", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02172, "lr": 0.00000, "mAP": 0.07162, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:01:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34304, "dt_data": 2.44815, "dt_net": 0.89488, "epoch": "34/55", "eta": "7:27:24", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02089, "lr": 0.00000, "mAP": 0.08418, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:01:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08117, "dt_data": 0.02502, "dt_net": 3.05615, "epoch": "34/55", "eta": "6:51:50", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02205, "lr": 0.00000, "mAP": 0.08190, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:02:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84370, "dt_data": 0.02500, "dt_net": 2.81870, "epoch": "34/55", "eta": "6:19:38", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02233, "lr": 0.00000, "mAP": 0.07810, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:02:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09804, "dt_data": 0.98540, "dt_net": 2.11264, "epoch": "34/55", "eta": "6:53:04", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02092, "lr": 0.00000, "mAP": 0.08065, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:03:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10898, "dt_data": 0.02497, "dt_net": 4.08400, "epoch": "34/55", "eta": "9:07:10", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02166, "lr": 0.00000, "mAP": 0.07554, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:04:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32023, "dt_data": 1.44288, "dt_net": 1.87735, "epoch": "34/55", "eta": "7:21:35", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02207, "lr": 0.00000, "mAP": 0.07961, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:04:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58468, "dt_data": 0.02508, "dt_net": 3.55960, "epoch": "34/55", "eta": "7:56:09", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02168, "lr": 0.00000, "mAP": 0.07232, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:05:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.59547, "dt_data": 1.00250, "dt_net": 1.59297, "epoch": "34/55", "eta": "5:44:19", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02120, "lr": 0.00000, "mAP": 0.07897, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:05:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74592, "dt_data": 0.58791, "dt_net": 3.15801, "epoch": "34/55", "eta": "8:16:20", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02112, "lr": 0.00000, "mAP": 0.08486, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:06:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25069, "dt_data": 0.02502, "dt_net": 3.22567, "epoch": "34/55", "eta": "7:10:10", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02316, "lr": 0.00000, "mAP": 0.08973, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:06:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89563, "dt_data": 0.02503, "dt_net": 3.87060, "epoch": "34/55", "eta": "8:34:52", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02261, "lr": 0.00000, "mAP": 0.07625, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:07:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82718, "dt_data": 0.02505, "dt_net": 2.80212, "epoch": "34/55", "eta": "6:13:11", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02167, "lr": 0.00000, "mAP": 0.07051, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:07:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45980, "dt_data": 0.02503, "dt_net": 3.43477, "epoch": "34/55", "eta": "7:36:07", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02124, "lr": 0.00000, "mAP": 0.07839, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:08:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82229, "dt_data": 0.02508, "dt_net": 3.79721, "epoch": "34/55", "eta": "8:23:16", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02083, "lr": 0.00000, "mAP": 0.08088, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:09:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30029, "dt_data": 0.02506, "dt_net": 3.27523, "epoch": "34/55", "eta": "7:13:59", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02149, "lr": 0.00000, "mAP": 0.07601, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:09:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33727, "dt_data": 0.02512, "dt_net": 3.31215, "epoch": "34/55", "eta": "7:18:17", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02117, "lr": 0.00000, "mAP": 0.07649, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:09:53][INFO] logging.py:  99: json_stats: {"RAM": "26.00/251.55G", "_type": "train_epoch", "dt": 0.00029, "dt_data": 0.00029, "dt_net": 3.64872, "epoch": "34/55", "eta": "0:00:01", "gpu_mem": "17.37G", "loss": 0.02152, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:09:53][INFO] train_net.py: 497: Epoch 33 takes 1251.35s. Epochs from 0 to 33 take 1256.09s in average and 1253.28s in median.
[03/08 08:09:53][INFO] train_net.py: 503: For epoch 33, each iteraction takes 3.34s in average. From epoch 0 to 33, each iteraction takes 3.35s in average.
[03/08 08:10:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:02:10", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06429, "time_diff": 1.51898, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:10:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:02:06", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06739, "time_diff": 1.66007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:10:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:01:43", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.06972, "time_diff": 1.57188, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:11:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:01:28", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.06869, "time_diff": 1.58755, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:11:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:01:10", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06769, "time_diff": 1.52603, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:11:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:00:57", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06859, "time_diff": 1.59216, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:11:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:00:49", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07209, "time_diff": 1.90370, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:12:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06219, "time_diff": 1.55951, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:12:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "34/55", "eta": "0:00:08", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07147, "time_diff": 1.46057, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:12:34][INFO] logging.py:  99: json_stats: {"RAM": "25.68/251.55G", "_type": "val_epoch", "epoch": "34/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:13:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19519, "dt_data": 2.64363, "dt_net": 0.55156, "epoch": "35/55", "eta": "6:58:50", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02110, "lr": 0.00000, "mAP": 0.08013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:13:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18568, "dt_data": 2.63351, "dt_net": 0.55217, "epoch": "35/55", "eta": "6:57:03", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02090, "lr": 0.00000, "mAP": 0.07996, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:14:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47291, "dt_data": 2.92779, "dt_net": 0.54512, "epoch": "35/55", "eta": "7:34:04", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01915, "lr": 0.00000, "mAP": 0.07430, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:14:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.70577, "dt_data": 2.15887, "dt_net": 0.54689, "epoch": "35/55", "eta": "5:53:19", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02078, "lr": 0.00000, "mAP": 0.07879, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:15:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96211, "dt_data": 3.41655, "dt_net": 0.54555, "epoch": "35/55", "eta": "8:36:43", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02152, "lr": 0.00000, "mAP": 0.07728, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:16:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16367, "dt_data": 1.95709, "dt_net": 1.20658, "epoch": "35/55", "eta": "6:52:04", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02100, "lr": 0.00000, "mAP": 0.08436, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:16:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21889, "dt_data": 1.40852, "dt_net": 1.81035, "epoch": "35/55", "eta": "6:58:43", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02197, "lr": 0.00000, "mAP": 0.07519, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:17:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11396, "dt_data": 0.02513, "dt_net": 3.08883, "epoch": "35/55", "eta": "6:44:33", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02024, "lr": 0.00000, "mAP": 0.07790, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:17:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66706, "dt_data": 0.02512, "dt_net": 3.64194, "epoch": "35/55", "eta": "7:55:48", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02242, "lr": 0.00000, "mAP": 0.07975, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:18:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09861, "dt_data": 0.02521, "dt_net": 3.07339, "epoch": "35/55", "eta": "6:41:31", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02101, "lr": 0.00000, "mAP": 0.08055, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:18:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73413, "dt_data": 0.02513, "dt_net": 3.70900, "epoch": "35/55", "eta": "8:03:15", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02168, "lr": 0.00000, "mAP": 0.06629, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:19:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42829, "dt_data": 0.02504, "dt_net": 3.40324, "epoch": "35/55", "eta": "7:23:06", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02018, "lr": 0.00000, "mAP": 0.08115, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:20:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22959, "dt_data": 0.02501, "dt_net": 3.20458, "epoch": "35/55", "eta": "6:56:53", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02013, "lr": 0.00000, "mAP": 0.07560, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:20:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72881, "dt_data": 0.02502, "dt_net": 3.70379, "epoch": "35/55", "eta": "8:00:42", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02190, "lr": 0.00000, "mAP": 0.07314, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:21:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06800, "dt_data": 0.02502, "dt_net": 3.04298, "epoch": "35/55", "eta": "6:35:00", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02094, "lr": 0.00000, "mAP": 0.07951, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:21:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13117, "dt_data": 0.02504, "dt_net": 3.10613, "epoch": "35/55", "eta": "6:42:36", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02115, "lr": 0.00000, "mAP": 0.07150, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:22:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07904, "dt_data": 0.02518, "dt_net": 3.05386, "epoch": "35/55", "eta": "6:35:24", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02121, "lr": 0.00000, "mAP": 0.07561, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:22:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96077, "dt_data": 0.02500, "dt_net": 3.93577, "epoch": "35/55", "eta": "8:27:58", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01981, "lr": 0.00000, "mAP": 0.06978, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:23:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11529, "dt_data": 0.02502, "dt_net": 3.09027, "epoch": "35/55", "eta": "6:39:01", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02004, "lr": 0.00000, "mAP": 0.08354, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:23:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35149, "dt_data": 0.02511, "dt_net": 3.32637, "epoch": "35/55", "eta": "7:08:42", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02105, "lr": 0.00000, "mAP": 0.07475, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:24:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64356, "dt_data": 0.02510, "dt_net": 3.61846, "epoch": "35/55", "eta": "7:45:27", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02222, "lr": 0.00000, "mAP": 0.07833, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:25:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89707, "dt_data": 0.02511, "dt_net": 3.87196, "epoch": "35/55", "eta": "8:17:12", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02224, "lr": 0.00000, "mAP": 0.07597, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:25:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58712, "dt_data": 0.02513, "dt_net": 3.56199, "epoch": "35/55", "eta": "7:37:03", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02098, "lr": 0.00000, "mAP": 0.07994, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:26:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68399, "dt_data": 0.02501, "dt_net": 2.65898, "epoch": "35/55", "eta": "5:41:32", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02007, "lr": 0.00000, "mAP": 0.08757, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:26:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56445, "dt_data": 0.02513, "dt_net": 3.53932, "epoch": "35/55", "eta": "7:32:58", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02162, "lr": 0.00000, "mAP": 0.07879, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:27:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68183, "dt_data": 0.02502, "dt_net": 2.65681, "epoch": "35/55", "eta": "5:40:22", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01946, "lr": 0.00000, "mAP": 0.07823, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:27:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92449, "dt_data": 0.02516, "dt_net": 2.89933, "epoch": "35/55", "eta": "6:10:40", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02191, "lr": 0.00000, "mAP": 0.08140, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:28:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.12404, "dt_data": 0.02503, "dt_net": 4.09901, "epoch": "35/55", "eta": "8:42:02", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02073, "lr": 0.00000, "mAP": 0.07631, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:29:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23180, "dt_data": 0.02504, "dt_net": 3.20676, "epoch": "35/55", "eta": "6:48:33", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02061, "lr": 0.00000, "mAP": 0.07943, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:29:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.44276, "dt_data": 0.02505, "dt_net": 4.41771, "epoch": "35/55", "eta": "9:20:53", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02015, "lr": 0.00000, "mAP": 0.08089, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:30:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.65757, "dt_data": 0.02504, "dt_net": 3.63253, "epoch": "35/55", "eta": "7:41:09", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02040, "lr": 0.00000, "mAP": 0.08047, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:30:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83125, "dt_data": 0.02514, "dt_net": 2.80611, "epoch": "35/55", "eta": "5:56:30", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02147, "lr": 0.00000, "mAP": 0.07353, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:31:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94871, "dt_data": 0.02498, "dt_net": 2.92373, "epoch": "35/55", "eta": "6:10:47", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02276, "lr": 0.00000, "mAP": 0.08334, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:31:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.77747, "dt_data": 1.21599, "dt_net": 1.56147, "epoch": "35/55", "eta": "5:48:48", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02045, "lr": 0.00000, "mAP": 0.07838, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:32:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86795, "dt_data": 3.31597, "dt_net": 0.55198, "epoch": "35/55", "eta": "8:05:06", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02096, "lr": 0.00000, "mAP": 0.07395, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:32:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09957, "dt_data": 2.55157, "dt_net": 0.54800, "epoch": "35/55", "eta": "6:28:13", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02170, "lr": 0.00000, "mAP": 0.07642, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:33:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00727, "dt_data": 2.45518, "dt_net": 0.55209, "epoch": "35/55", "eta": "6:16:09", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02113, "lr": 0.00000, "mAP": 0.08051, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:33:35][INFO] logging.py:  99: json_stats: {"RAM": "25.90/251.55G", "_type": "train_epoch", "dt": 0.00030, "dt_data": 0.00030, "dt_net": 0.54555, "epoch": "35/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02108, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:33:35][INFO] train_net.py: 497: Epoch 34 takes 1254.55s. Epochs from 0 to 34 take 1256.05s in average and 1254.52s in median.
[03/08 08:33:35][INFO] train_net.py: 503: For epoch 34, each iteraction takes 3.35s in average. From epoch 0 to 34, each iteraction takes 3.35s in average.
[03/08 08:33:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:02:13", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.06999, "time_diff": 1.55388, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:34:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:02:02", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.06609, "time_diff": 1.60612, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:34:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:01:38", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.07125, "time_diff": 1.48549, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:34:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:01:31", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.07054, "time_diff": 1.62638, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:34:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:01:20", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.06834, "time_diff": 1.74372, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:35:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:00:55", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.06519, "time_diff": 1.54612, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:35:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:00:43", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.07437, "time_diff": 1.65443, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:35:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:00:23", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.06949, "time_diff": 1.46631, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:36:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "35/55", "eta": "0:00:09", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.07165, "time_diff": 1.56715, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:36:14][INFO] logging.py:  99: json_stats: {"RAM": "26.64/251.55G", "_type": "val_epoch", "epoch": "35/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:36:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70376, "dt_data": 3.15042, "dt_net": 0.55334, "epoch": "36/55", "eta": "7:42:21", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01856, "lr": 0.00000, "mAP": 0.08148, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:37:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.58975, "dt_data": 2.03510, "dt_net": 0.55465, "epoch": "36/55", "eta": "5:22:51", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02046, "lr": 0.00000, "mAP": 0.07664, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:38:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95147, "dt_data": 3.39902, "dt_net": 0.55245, "epoch": "36/55", "eta": "8:11:57", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01916, "lr": 0.00000, "mAP": 0.09368, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:38:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80767, "dt_data": 2.20472, "dt_net": 0.60295, "epoch": "36/55", "eta": "5:49:05", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02011, "lr": 0.00000, "mAP": 0.07628, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 08:43:17][INFO] test_net.py: 160: Test with config:
[03/08 08:43:17][INFO] test_net.py: 161: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.0
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  EXTRA_PATH_TO_DATA_DIR: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/
  PATH_PREFIX_LIST: ['']
  PATH_TO_DATA_DIR: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/
  PATH_TO_DATA_DIR_LIST: ['']
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 1
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ARCH: uniformerv2
  CHECKPOINT_NUM: [0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  EMA_DECAY: 0.9999
  EMA_EPOCH: -1
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: bce_logit
  MODEL_NAME: Uniformerv2
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 140
  NUM_CLASSES_LIST: [400, 600, 700]
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2']
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_MUL: []
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  SEP_POS_EMBED: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 8
NUM_SHARDS: 1
OUTPUT_DIR: ./exp/animal
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BACKBONE_LR_RATIO: 0.1
  BASE_LR: 1e-05
  BASE_LR_SCALE_NUM_SHARDS: False
  CLIP_GRADIENT: 20
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 55
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  SPECIAL_LIST: []
  SPECIAL_RATIO: 1.0
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  ADD_SOFTMAX: True
  BATCH_SIZE: 128
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: True
  INTERVAL: 2000
  NUM_ENSEMBLE_VIEWS: 4
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 64
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 100
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  INIT_VALUE: 1.0
  KS: 5
  MBCONV: False
  MLP_RATIO: [4.0, 4.0, 4.0, 4.0]
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
UNIFORMERV2:
  BACKBONE: uniformerv2_b16
  BACKBONE_DROP_PATH_RATE: 0.0
  CLS_DROPOUT: 0.5
  DELETE_SPECIAL_HEAD: False
  DOUBLE_LMHRA: True
  DROP_PATH_RATE: 0.0
  DW_REDUCTION: 1.5
  FROZEN: False
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  NO_LMHRA: False
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  PRETRAIN: 
  RETURN_LIST: [8, 9, 10, 11]
  TEMPORAL_DOWNSAMPLE: False
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:43:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:43:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:43:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:43:18][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 08:43:18][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 08:43:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:43:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:43:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:43:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:43:18][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 08:43:18][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 08:43:18][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 08:43:20][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 08:43:20][INFO] misc.py: 185: Params: 133,343,372
[03/08 08:43:20][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 08:43:20][INFO] misc.py: 187: Flops: 0 G
[03/08 08:43:20][INFO] misc.py: 192: Activations: 0 M
[03/08 08:43:20][INFO] misc.py: 197: nvidia-smi
[03/08 08:43:21][INFO] checkpoint.py: 224: Loading network weights from ./exp/animal/best.pyth.
[03/08 08:43:22][INFO] checkpoint.py: 357: Load strict==True
[03/08 08:44:06][INFO] test_net.py: 160: Test with config:
[03/08 08:44:06][INFO] test_net.py: 161: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.0
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  EXTRA_PATH_TO_DATA_DIR: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/
  PATH_PREFIX_LIST: ['']
  PATH_TO_DATA_DIR: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/
  PATH_TO_DATA_DIR_LIST: ['']
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 1
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ARCH: uniformerv2
  CHECKPOINT_NUM: [0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  EMA_DECAY: 0.9999
  EMA_EPOCH: -1
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: bce_logit
  MODEL_NAME: Uniformerv2
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 140
  NUM_CLASSES_LIST: [400, 600, 700]
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2']
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_MUL: []
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  SEP_POS_EMBED: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 8
NUM_SHARDS: 1
OUTPUT_DIR: ./exp/animal
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BACKBONE_LR_RATIO: 0.1
  BASE_LR: 1e-05
  BASE_LR_SCALE_NUM_SHARDS: False
  CLIP_GRADIENT: 20
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 55
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  SPECIAL_LIST: []
  SPECIAL_RATIO: 1.0
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  ADD_SOFTMAX: True
  BATCH_SIZE: 128
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: True
  INTERVAL: 2000
  NUM_ENSEMBLE_VIEWS: 4
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 64
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 100
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  INIT_VALUE: 1.0
  KS: 5
  MBCONV: False
  MLP_RATIO: [4.0, 4.0, 4.0, 4.0]
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
UNIFORMERV2:
  BACKBONE: uniformerv2_b16
  BACKBONE_DROP_PATH_RATE: 0.0
  CLS_DROPOUT: 0.5
  DELETE_SPECIAL_HEAD: False
  DOUBLE_LMHRA: True
  DROP_PATH_RATE: 0.0
  DW_REDUCTION: 1.5
  FROZEN: False
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  NO_LMHRA: False
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  PRETRAIN: 
  RETURN_LIST: [8, 9, 10, 11]
  TEMPORAL_DOWNSAMPLE: False
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[03/08 08:44:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:44:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:44:07][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 08:44:07][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 08:44:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:44:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:44:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:44:08][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 08:44:08][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 08:44:08][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 08:44:09][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 08:44:09][INFO] misc.py: 185: Params: 133,343,372
[03/08 08:44:09][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 08:44:09][INFO] misc.py: 187: Flops: 0 G
[03/08 08:44:09][INFO] misc.py: 192: Activations: 0 M
[03/08 08:44:09][INFO] misc.py: 197: nvidia-smi
[03/08 08:44:10][INFO] checkpoint.py: 224: Loading network weights from ./exp/animal/best.pyth.
[03/08 08:44:11][INFO] checkpoint.py: 357: Load strict==True
[03/08 08:44:11][INFO] kinetics_sparse.py:  79: Constructing Kinetics test...
[03/08 08:44:11][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/test.csv
[03/08 08:44:12][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 73152) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/test.csv
[03/08 08:44:12][INFO] test_net.py: 172: Testing model for 572 iterations
[03/08 08:44:12][INFO] test_net.py: 173: Add softmax after prediction: True
[03/08 08:45:30][INFO] test_net.py: 160: Test with config:
[03/08 08:45:30][INFO] test_net.py: 161: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.0
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  EXTRA_PATH_TO_DATA_DIR: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/
  PATH_PREFIX_LIST: ['']
  PATH_TO_DATA_DIR: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/
  PATH_TO_DATA_DIR_LIST: ['']
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 1
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ARCH: uniformerv2
  CHECKPOINT_NUM: [0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  EMA_DECAY: 0.9999
  EMA_EPOCH: -1
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: bce_logit
  MODEL_NAME: Uniformerv2
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 140
  NUM_CLASSES_LIST: [400, 600, 700]
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2']
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_MUL: []
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  SEP_POS_EMBED: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 8
NUM_SHARDS: 1
OUTPUT_DIR: ./exp/animal
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BACKBONE_LR_RATIO: 0.1
  BASE_LR: 1e-05
  BASE_LR_SCALE_NUM_SHARDS: False
  CLIP_GRADIENT: 20
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 55
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  SPECIAL_LIST: []
  SPECIAL_RATIO: 1.0
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  ADD_SOFTMAX: True
  BATCH_SIZE: 128
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: True
  INTERVAL: 2000
  NUM_ENSEMBLE_VIEWS: 4
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 64
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 100
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  INIT_VALUE: 1.0
  KS: 5
  MBCONV: False
  MLP_RATIO: [4.0, 4.0, 4.0, 4.0]
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
UNIFORMERV2:
  BACKBONE: uniformerv2_b16
  BACKBONE_DROP_PATH_RATE: 0.0
  CLS_DROPOUT: 0.5
  DELETE_SPECIAL_HEAD: False
  DOUBLE_LMHRA: True
  DROP_PATH_RATE: 0.0
  DW_REDUCTION: 1.5
  FROZEN: False
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  NO_LMHRA: False
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  PRETRAIN: 
  RETURN_LIST: [8, 9, 10, 11]
  TEMPORAL_DOWNSAMPLE: False
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[03/08 08:45:30][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:30][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:30][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:30][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:30][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:30][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:45:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:45:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:45:31][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 08:45:31][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 08:45:31][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:45:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:45:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:45:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:45:32][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 08:45:32][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 08:45:32][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 08:45:33][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 08:45:33][INFO] misc.py: 185: Params: 133,343,372
[03/08 08:45:33][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 08:45:33][INFO] misc.py: 187: Flops: 0 G
[03/08 08:45:33][INFO] misc.py: 192: Activations: 0 M
[03/08 08:45:33][INFO] misc.py: 197: nvidia-smi
[03/08 08:45:34][INFO] checkpoint.py: 224: Loading network weights from ./exp/animal/best.pyth.
[03/08 08:45:35][INFO] checkpoint.py: 357: Load strict==True
[03/08 08:45:35][INFO] kinetics_sparse.py:  79: Constructing Kinetics test...
[03/08 08:45:35][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/test.csv
[03/08 08:45:36][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 73152) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/test.csv
[03/08 08:45:36][INFO] test_net.py: 172: Testing model for 572 iterations
[03/08 08:45:36][INFO] test_net.py: 173: Add softmax after prediction: True
[03/08 08:50:13][INFO] test_net.py: 160: Test with config:
[03/08 08:50:13][INFO] test_net.py: 161: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.0
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  EXTRA_PATH_TO_DATA_DIR: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: True
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/
  PATH_PREFIX_LIST: ['']
  PATH_TO_DATA_DIR: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/
  PATH_TO_DATA_DIR_LIST: ['']
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 1
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ARCH: uniformerv2
  CHECKPOINT_NUM: [0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  EMA_DECAY: 0.9999
  EMA_EPOCH: -1
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: bce_logit
  MODEL_NAME: Uniformerv2
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 140
  NUM_CLASSES_LIST: [400, 600, 700]
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2']
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_MUL: []
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  SEP_POS_EMBED: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 8
NUM_SHARDS: 1
OUTPUT_DIR: ./exp/animal
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BACKBONE_LR_RATIO: 0.1
  BASE_LR: 1e-05
  BASE_LR_SCALE_NUM_SHARDS: False
  CLIP_GRADIENT: 20
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 55
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  SPECIAL_LIST: []
  SPECIAL_RATIO: 1.0
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  ADD_SOFTMAX: True
  BATCH_SIZE: 128
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: True
  INTERVAL: 2000
  NUM_ENSEMBLE_VIEWS: 4
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 64
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 100
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  INIT_VALUE: 1.0
  KS: 5
  MBCONV: False
  MLP_RATIO: [4.0, 4.0, 4.0, 4.0]
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
UNIFORMERV2:
  BACKBONE: uniformerv2_b16
  BACKBONE_DROP_PATH_RATE: 0.0
  CLS_DROPOUT: 0.5
  DELETE_SPECIAL_HEAD: False
  DOUBLE_LMHRA: True
  DROP_PATH_RATE: 0.0
  DW_REDUCTION: 1.5
  FROZEN: False
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  NO_LMHRA: False
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  PRETRAIN: 
  RETURN_LIST: [8, 9, 10, 11]
  TEMPORAL_DOWNSAMPLE: False
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 08:50:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 08:50:14][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 08:50:14][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 08:50:14][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 08:50:14][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 08:50:15][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 08:50:15][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 08:50:16][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 08:50:16][INFO] misc.py: 185: Params: 133,343,372
[03/08 08:50:16][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 08:50:16][INFO] misc.py: 187: Flops: 0 G
[03/08 08:50:16][INFO] misc.py: 192: Activations: 0 M
[03/08 08:50:16][INFO] misc.py: 197: nvidia-smi
[03/08 08:50:17][INFO] checkpoint.py: 224: Loading network weights from ./exp/animal/best.pyth.
[03/08 08:50:18][INFO] checkpoint.py: 357: Load strict==True
[03/08 08:50:18][INFO] kinetics_sparse.py:  79: Constructing Kinetics test...
[03/08 08:50:18][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/test.csv
[03/08 08:50:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 73152) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/test.csv
[03/08 08:50:19][INFO] test_net.py: 172: Testing model for 572 iterations
[03/08 08:50:19][INFO] test_net.py: 173: Add softmax after prediction: True
[03/08 08:50:27][INFO] logging.py:  99: json_stats: {"cur_iter": "1", "eta": "1:14:37", "split": "test_iter", "time_diff": 7.82767}
[03/08 08:50:28][INFO] logging.py:  99: json_stats: {"cur_iter": "2", "eta": "0:14:14", "split": "test_iter", "time_diff": 1.49625}
[03/08 08:50:30][INFO] logging.py:  99: json_stats: {"cur_iter": "3", "eta": "0:17:04", "split": "test_iter", "time_diff": 1.79708}
[03/08 08:50:32][INFO] logging.py:  99: json_stats: {"cur_iter": "4", "eta": "0:19:01", "split": "test_iter", "time_diff": 2.00669}
[03/08 08:50:34][INFO] logging.py:  99: json_stats: {"cur_iter": "5", "eta": "0:18:07", "split": "test_iter", "time_diff": 1.91543}
[03/08 08:50:36][INFO] logging.py:  99: json_stats: {"cur_iter": "6", "eta": "0:16:44", "split": "test_iter", "time_diff": 1.77200}
[03/08 08:50:37][INFO] logging.py:  99: json_stats: {"cur_iter": "7", "eta": "0:16:30", "split": "test_iter", "time_diff": 1.74973}
[03/08 08:50:40][INFO] logging.py:  99: json_stats: {"cur_iter": "8", "eta": "0:21:05", "split": "test_iter", "time_diff": 2.24021}
[03/08 08:50:42][INFO] logging.py:  99: json_stats: {"cur_iter": "9", "eta": "0:20:15", "split": "test_iter", "time_diff": 2.15442}
[03/08 08:50:44][INFO] logging.py:  99: json_stats: {"cur_iter": "10", "eta": "0:19:53", "split": "test_iter", "time_diff": 2.12011}
[03/08 08:50:46][INFO] logging.py:  99: json_stats: {"cur_iter": "11", "eta": "0:17:57", "split": "test_iter", "time_diff": 1.91784}
[03/08 08:50:48][INFO] logging.py:  99: json_stats: {"cur_iter": "12", "eta": "0:20:14", "split": "test_iter", "time_diff": 2.16415}
[03/08 08:50:50][INFO] logging.py:  99: json_stats: {"cur_iter": "13", "eta": "0:18:26", "split": "test_iter", "time_diff": 1.97589}
[03/08 08:50:52][INFO] logging.py:  99: json_stats: {"cur_iter": "14", "eta": "0:21:12", "split": "test_iter", "time_diff": 2.27633}
[03/08 08:50:54][INFO] logging.py:  99: json_stats: {"cur_iter": "15", "eta": "0:19:57", "split": "test_iter", "time_diff": 2.14644}
[03/08 08:50:57][INFO] logging.py:  99: json_stats: {"cur_iter": "16", "eta": "0:22:37", "split": "test_iter", "time_diff": 2.43686}
[03/08 08:50:59][INFO] logging.py:  99: json_stats: {"cur_iter": "17", "eta": "0:19:57", "split": "test_iter", "time_diff": 2.15360}
[03/08 08:51:02][INFO] logging.py:  99: json_stats: {"cur_iter": "18", "eta": "0:23:07", "split": "test_iter", "time_diff": 2.49970}
[03/08 08:51:04][INFO] logging.py:  99: json_stats: {"cur_iter": "19", "eta": "0:18:42", "split": "test_iter", "time_diff": 2.02572}
[03/08 08:51:06][INFO] logging.py:  99: json_stats: {"cur_iter": "20", "eta": "0:18:42", "split": "test_iter", "time_diff": 2.03014}
[03/08 08:51:08][INFO] logging.py:  99: json_stats: {"cur_iter": "21", "eta": "0:19:28", "split": "test_iter", "time_diff": 2.11732}
[03/08 08:51:10][INFO] logging.py:  99: json_stats: {"cur_iter": "22", "eta": "0:18:20", "split": "test_iter", "time_diff": 1.99661}
[03/08 08:51:12][INFO] logging.py:  99: json_stats: {"cur_iter": "23", "eta": "0:20:21", "split": "test_iter", "time_diff": 2.22080}
[03/08 08:51:14][INFO] logging.py:  99: json_stats: {"cur_iter": "24", "eta": "0:20:23", "split": "test_iter", "time_diff": 2.22800}
[03/08 08:51:16][INFO] logging.py:  99: json_stats: {"cur_iter": "25", "eta": "0:18:23", "split": "test_iter", "time_diff": 2.01444}
[03/08 08:51:19][INFO] logging.py:  99: json_stats: {"cur_iter": "26", "eta": "0:21:35", "split": "test_iter", "time_diff": 2.36891}
[03/08 08:51:21][INFO] logging.py:  99: json_stats: {"cur_iter": "27", "eta": "0:19:34", "split": "test_iter", "time_diff": 2.15179}
[03/08 08:51:23][INFO] logging.py:  99: json_stats: {"cur_iter": "28", "eta": "0:20:21", "split": "test_iter", "time_diff": 2.24068}
[03/08 08:51:25][INFO] logging.py:  99: json_stats: {"cur_iter": "29", "eta": "0:19:44", "split": "test_iter", "time_diff": 2.17665}
[03/08 08:51:27][INFO] logging.py:  99: json_stats: {"cur_iter": "30", "eta": "0:17:54", "split": "test_iter", "time_diff": 1.97910}
[03/08 08:51:29][INFO] logging.py:  99: json_stats: {"cur_iter": "31", "eta": "0:18:48", "split": "test_iter", "time_diff": 2.08292}
[03/08 08:51:31][INFO] logging.py:  99: json_stats: {"cur_iter": "32", "eta": "0:19:56", "split": "test_iter", "time_diff": 2.21111}
[03/08 08:51:34][INFO] logging.py:  99: json_stats: {"cur_iter": "33", "eta": "0:18:24", "split": "test_iter", "time_diff": 2.04621}
[03/08 08:51:36][INFO] logging.py:  99: json_stats: {"cur_iter": "34", "eta": "0:18:49", "split": "test_iter", "time_diff": 2.09514}
[03/08 08:51:38][INFO] logging.py:  99: json_stats: {"cur_iter": "35", "eta": "0:19:09", "split": "test_iter", "time_diff": 2.13594}
[03/08 08:51:40][INFO] logging.py:  99: json_stats: {"cur_iter": "36", "eta": "0:20:10", "split": "test_iter", "time_diff": 2.25493}
[03/08 08:51:42][INFO] logging.py:  99: json_stats: {"cur_iter": "37", "eta": "0:20:04", "split": "test_iter", "time_diff": 2.24743}
[03/08 08:51:44][INFO] logging.py:  99: json_stats: {"cur_iter": "38", "eta": "0:19:15", "split": "test_iter", "time_diff": 2.16022}
[03/08 08:51:47][INFO] logging.py:  99: json_stats: {"cur_iter": "39", "eta": "0:19:41", "split": "test_iter", "time_diff": 2.21171}
[03/08 08:51:49][INFO] logging.py:  99: json_stats: {"cur_iter": "40", "eta": "0:19:51", "split": "test_iter", "time_diff": 2.23586}
[03/08 08:51:51][INFO] logging.py:  99: json_stats: {"cur_iter": "41", "eta": "0:21:12", "split": "test_iter", "time_diff": 2.39117}
[03/08 08:51:53][INFO] logging.py:  99: json_stats: {"cur_iter": "42", "eta": "0:17:44", "split": "test_iter", "time_diff": 2.00459}
[03/08 08:51:56][INFO] logging.py:  99: json_stats: {"cur_iter": "43", "eta": "0:19:49", "split": "test_iter", "time_diff": 2.24373}
[03/08 08:51:58][INFO] logging.py:  99: json_stats: {"cur_iter": "44", "eta": "0:20:41", "split": "test_iter", "time_diff": 2.34671}
[03/08 08:52:00][INFO] logging.py:  99: json_stats: {"cur_iter": "45", "eta": "0:19:45", "split": "test_iter", "time_diff": 2.24545}
[03/08 08:52:02][INFO] logging.py:  99: json_stats: {"cur_iter": "46", "eta": "0:18:07", "split": "test_iter", "time_diff": 2.06425}
[03/08 08:52:04][INFO] logging.py:  99: json_stats: {"cur_iter": "47", "eta": "0:17:34", "split": "test_iter", "time_diff": 2.00408}
[03/08 08:52:06][INFO] logging.py:  99: json_stats: {"cur_iter": "48", "eta": "0:18:28", "split": "test_iter", "time_diff": 2.11097}
[03/08 08:52:08][INFO] logging.py:  99: json_stats: {"cur_iter": "49", "eta": "0:17:56", "split": "test_iter", "time_diff": 2.05500}
[03/08 08:52:10][INFO] logging.py:  99: json_stats: {"cur_iter": "50", "eta": "0:16:55", "split": "test_iter", "time_diff": 1.94220}
[03/08 08:52:13][INFO] logging.py:  99: json_stats: {"cur_iter": "51", "eta": "0:20:35", "split": "test_iter", "time_diff": 2.36619}
[03/08 08:52:15][INFO] logging.py:  99: json_stats: {"cur_iter": "52", "eta": "0:20:07", "split": "test_iter", "time_diff": 2.31853}
[03/08 08:52:17][INFO] logging.py:  99: json_stats: {"cur_iter": "53", "eta": "0:19:53", "split": "test_iter", "time_diff": 2.29561}
[03/08 08:52:20][INFO] logging.py:  99: json_stats: {"cur_iter": "54", "eta": "0:19:30", "split": "test_iter", "time_diff": 2.25455}
[03/08 08:52:22][INFO] logging.py:  99: json_stats: {"cur_iter": "55", "eta": "0:17:22", "split": "test_iter", "time_diff": 2.01349}
[03/08 08:52:24][INFO] logging.py:  99: json_stats: {"cur_iter": "56", "eta": "0:18:49", "split": "test_iter", "time_diff": 2.18377}
[03/08 08:52:26][INFO] logging.py:  99: json_stats: {"cur_iter": "57", "eta": "0:17:03", "split": "test_iter", "time_diff": 1.98299}
[03/08 08:52:29][INFO] logging.py:  99: json_stats: {"cur_iter": "58", "eta": "0:22:29", "split": "test_iter", "time_diff": 2.62026}
[03/08 08:52:31][INFO] logging.py:  99: json_stats: {"cur_iter": "59", "eta": "0:20:43", "split": "test_iter", "time_diff": 2.41903}
[03/08 08:52:33][INFO] logging.py:  99: json_stats: {"cur_iter": "60", "eta": "0:13:46", "split": "test_iter", "time_diff": 1.61171}
[03/08 08:52:35][INFO] logging.py:  99: json_stats: {"cur_iter": "61", "eta": "0:17:14", "split": "test_iter", "time_diff": 2.01963}
[03/08 08:52:37][INFO] logging.py:  99: json_stats: {"cur_iter": "62", "eta": "0:19:27", "split": "test_iter", "time_diff": 2.28449}
[03/08 08:52:39][INFO] logging.py:  99: json_stats: {"cur_iter": "63", "eta": "0:18:09", "split": "test_iter", "time_diff": 2.13576}
[03/08 08:52:41][INFO] logging.py:  99: json_stats: {"cur_iter": "64", "eta": "0:17:18", "split": "test_iter", "time_diff": 2.03970}
[03/08 08:52:43][INFO] logging.py:  99: json_stats: {"cur_iter": "65", "eta": "0:17:05", "split": "test_iter", "time_diff": 2.01895}
[03/08 08:52:45][INFO] logging.py:  99: json_stats: {"cur_iter": "66", "eta": "0:17:15", "split": "test_iter", "time_diff": 2.04213}
[03/08 08:52:47][INFO] logging.py:  99: json_stats: {"cur_iter": "67", "eta": "0:18:41", "split": "test_iter", "time_diff": 2.21549}
[03/08 08:52:50][INFO] logging.py:  99: json_stats: {"cur_iter": "68", "eta": "0:18:21", "split": "test_iter", "time_diff": 2.18142}
[03/08 08:52:52][INFO] logging.py:  99: json_stats: {"cur_iter": "69", "eta": "0:18:53", "split": "test_iter", "time_diff": 2.24914}
[03/08 08:52:54][INFO] logging.py:  99: json_stats: {"cur_iter": "70", "eta": "0:18:01", "split": "test_iter", "time_diff": 2.14926}
[03/08 08:52:56][INFO] logging.py:  99: json_stats: {"cur_iter": "71", "eta": "0:18:57", "split": "test_iter", "time_diff": 2.26674}
[03/08 08:52:59][INFO] logging.py:  99: json_stats: {"cur_iter": "72", "eta": "0:18:50", "split": "test_iter", "time_diff": 2.25648}
[03/08 08:53:01][INFO] logging.py:  99: json_stats: {"cur_iter": "73", "eta": "0:17:53", "split": "test_iter", "time_diff": 2.14758}
[03/08 08:53:03][INFO] logging.py:  99: json_stats: {"cur_iter": "74", "eta": "0:17:49", "split": "test_iter", "time_diff": 2.14302}
[03/08 08:53:05][INFO] logging.py:  99: json_stats: {"cur_iter": "75", "eta": "0:17:22", "split": "test_iter", "time_diff": 2.09294}
[03/08 08:53:07][INFO] logging.py:  99: json_stats: {"cur_iter": "76", "eta": "0:17:02", "split": "test_iter", "time_diff": 2.05709}
[03/08 08:53:09][INFO] logging.py:  99: json_stats: {"cur_iter": "77", "eta": "0:17:52", "split": "test_iter", "time_diff": 2.16180}
[03/08 08:53:12][INFO] logging.py:  99: json_stats: {"cur_iter": "78", "eta": "0:20:48", "split": "test_iter", "time_diff": 2.52211}
[03/08 08:53:14][INFO] logging.py:  99: json_stats: {"cur_iter": "79", "eta": "0:18:13", "split": "test_iter", "time_diff": 2.21295}
[03/08 08:53:16][INFO] logging.py:  99: json_stats: {"cur_iter": "80", "eta": "0:17:20", "split": "test_iter", "time_diff": 2.11068}
[03/08 08:53:18][INFO] logging.py:  99: json_stats: {"cur_iter": "81", "eta": "0:19:35", "split": "test_iter", "time_diff": 2.38932}
[03/08 08:53:21][INFO] logging.py:  99: json_stats: {"cur_iter": "82", "eta": "0:19:25", "split": "test_iter", "time_diff": 2.37379}
[03/08 08:53:23][INFO] logging.py:  99: json_stats: {"cur_iter": "83", "eta": "0:16:27", "split": "test_iter", "time_diff": 2.01469}
[03/08 08:53:25][INFO] logging.py:  99: json_stats: {"cur_iter": "84", "eta": "0:17:33", "split": "test_iter", "time_diff": 2.15404}
[03/08 08:53:27][INFO] logging.py:  99: json_stats: {"cur_iter": "85", "eta": "0:17:36", "split": "test_iter", "time_diff": 2.16494}
[03/08 08:53:29][INFO] logging.py:  99: json_stats: {"cur_iter": "86", "eta": "0:16:14", "split": "test_iter", "time_diff": 2.00188}
[03/08 08:53:31][INFO] logging.py:  99: json_stats: {"cur_iter": "87", "eta": "0:18:03", "split": "test_iter", "time_diff": 2.23028}
[03/08 08:53:33][INFO] logging.py:  99: json_stats: {"cur_iter": "88", "eta": "0:15:29", "split": "test_iter", "time_diff": 1.91609}
[03/08 08:53:36][INFO] logging.py:  99: json_stats: {"cur_iter": "89", "eta": "0:17:17", "split": "test_iter", "time_diff": 2.14424}
[03/08 08:53:38][INFO] logging.py:  99: json_stats: {"cur_iter": "90", "eta": "0:19:41", "split": "test_iter", "time_diff": 2.44634}
[03/08 08:53:40][INFO] logging.py:  99: json_stats: {"cur_iter": "91", "eta": "0:16:53", "split": "test_iter", "time_diff": 2.10245}
[03/08 08:53:42][INFO] logging.py:  99: json_stats: {"cur_iter": "92", "eta": "0:17:34", "split": "test_iter", "time_diff": 2.19232}
[03/08 08:53:44][INFO] logging.py:  99: json_stats: {"cur_iter": "93", "eta": "0:15:36", "split": "test_iter", "time_diff": 1.95013}
[03/08 08:53:47][INFO] logging.py:  99: json_stats: {"cur_iter": "94", "eta": "0:18:12", "split": "test_iter", "time_diff": 2.28174}
[03/08 08:53:49][INFO] logging.py:  99: json_stats: {"cur_iter": "95", "eta": "0:16:37", "split": "test_iter", "time_diff": 2.08742}
[03/08 08:53:51][INFO] logging.py:  99: json_stats: {"cur_iter": "96", "eta": "0:17:25", "split": "test_iter", "time_diff": 2.19284}
[03/08 08:53:53][INFO] logging.py:  99: json_stats: {"cur_iter": "97", "eta": "0:16:58", "split": "test_iter", "time_diff": 2.13894}
[03/08 08:53:55][INFO] logging.py:  99: json_stats: {"cur_iter": "98", "eta": "0:16:44", "split": "test_iter", "time_diff": 2.11385}
[03/08 08:53:57][INFO] logging.py:  99: json_stats: {"cur_iter": "99", "eta": "0:16:59", "split": "test_iter", "time_diff": 2.15057}
[03/08 08:53:59][INFO] logging.py:  99: json_stats: {"cur_iter": "100", "eta": "0:14:32", "split": "test_iter", "time_diff": 1.84445}
[03/08 08:54:01][INFO] logging.py:  99: json_stats: {"cur_iter": "101", "eta": "0:16:54", "split": "test_iter", "time_diff": 2.14842}
[03/08 08:54:03][INFO] logging.py:  99: json_stats: {"cur_iter": "102", "eta": "0:17:12", "split": "test_iter", "time_diff": 2.19239}
[03/08 08:54:06][INFO] logging.py:  99: json_stats: {"cur_iter": "103", "eta": "0:17:20", "split": "test_iter", "time_diff": 2.21339}
[03/08 08:54:08][INFO] logging.py:  99: json_stats: {"cur_iter": "104", "eta": "0:15:53", "split": "test_iter", "time_diff": 2.03329}
[03/08 08:54:10][INFO] logging.py:  99: json_stats: {"cur_iter": "105", "eta": "0:15:56", "split": "test_iter", "time_diff": 2.04277}
[03/08 08:54:12][INFO] logging.py:  99: json_stats: {"cur_iter": "106", "eta": "0:16:04", "split": "test_iter", "time_diff": 2.06551}
[03/08 08:54:14][INFO] logging.py:  99: json_stats: {"cur_iter": "107", "eta": "0:16:08", "split": "test_iter", "time_diff": 2.07834}
[03/08 08:54:16][INFO] logging.py:  99: json_stats: {"cur_iter": "108", "eta": "0:16:49", "split": "test_iter", "time_diff": 2.17183}
[03/08 08:54:18][INFO] logging.py:  99: json_stats: {"cur_iter": "109", "eta": "0:15:12", "split": "test_iter", "time_diff": 1.96752}
[03/08 08:54:20][INFO] logging.py:  99: json_stats: {"cur_iter": "110", "eta": "0:15:24", "split": "test_iter", "time_diff": 1.99606}
[03/08 08:54:22][INFO] logging.py:  99: json_stats: {"cur_iter": "111", "eta": "0:16:06", "split": "test_iter", "time_diff": 2.09117}
[03/08 08:54:24][INFO] logging.py:  99: json_stats: {"cur_iter": "112", "eta": "0:15:35", "split": "test_iter", "time_diff": 2.02913}
[03/08 08:54:27][INFO] logging.py:  99: json_stats: {"cur_iter": "113", "eta": "0:17:42", "split": "test_iter", "time_diff": 2.30997}
[03/08 08:54:29][INFO] logging.py:  99: json_stats: {"cur_iter": "114", "eta": "0:15:54", "split": "test_iter", "time_diff": 2.08051}
[03/08 08:54:31][INFO] logging.py:  99: json_stats: {"cur_iter": "115", "eta": "0:18:34", "split": "test_iter", "time_diff": 2.43413}
[03/08 08:54:33][INFO] logging.py:  99: json_stats: {"cur_iter": "116", "eta": "0:15:05", "split": "test_iter", "time_diff": 1.98128}
[03/08 08:54:35][INFO] logging.py:  99: json_stats: {"cur_iter": "117", "eta": "0:18:17", "split": "test_iter", "time_diff": 2.40708}
[03/08 08:54:38][INFO] logging.py:  99: json_stats: {"cur_iter": "118", "eta": "0:15:57", "split": "test_iter", "time_diff": 2.10499}
[03/08 08:54:40][INFO] logging.py:  99: json_stats: {"cur_iter": "119", "eta": "0:15:38", "split": "test_iter", "time_diff": 2.06698}
[03/08 08:54:42][INFO] logging.py:  99: json_stats: {"cur_iter": "120", "eta": "0:15:19", "split": "test_iter", "time_diff": 2.02919}
[03/08 08:54:44][INFO] logging.py:  99: json_stats: {"cur_iter": "121", "eta": "0:17:24", "split": "test_iter", "time_diff": 2.31101}
[03/08 08:54:46][INFO] logging.py:  99: json_stats: {"cur_iter": "122", "eta": "0:18:20", "split": "test_iter", "time_diff": 2.44092}
[03/08 08:54:49][INFO] logging.py:  99: json_stats: {"cur_iter": "123", "eta": "0:18:40", "split": "test_iter", "time_diff": 2.48970}
[03/08 08:54:51][INFO] logging.py:  99: json_stats: {"cur_iter": "124", "eta": "0:17:22", "split": "test_iter", "time_diff": 2.32208}
[03/08 08:54:53][INFO] logging.py:  99: json_stats: {"cur_iter": "125", "eta": "0:16:10", "split": "test_iter", "time_diff": 2.16605}
[03/08 09:17:24][INFO] train_net.py: 400: Train with config:
[03/08 09:17:24][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:17:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:17:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:17:24][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:17:24][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:17:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:17:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:17:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:17:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:17:25][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:17:25][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:17:25][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:17:26][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:17:26][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:17:26][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:17:26][INFO] misc.py: 187: Flops: 0 G
[03/08 09:17:26][INFO] misc.py: 192: Activations: 0 M
[03/08 09:17:26][INFO] misc.py: 197: nvidia-smi
[03/08 09:17:27][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:17:27][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:17:27][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:17:28][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:17:28][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:17:29][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:17:29][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:17:29][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:17:29][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:17:29][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:20:07][INFO] train_net.py: 400: Train with config:
[03/08 09:20:07][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:20:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:20:08][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:20:08][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:20:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:20:08][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:20:09][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:20:09][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:20:09][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:20:10][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:20:10][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:20:10][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:20:10][INFO] misc.py: 187: Flops: 0 G
[03/08 09:20:10][INFO] misc.py: 192: Activations: 0 M
[03/08 09:20:10][INFO] misc.py: 197: nvidia-smi
[03/08 09:20:11][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:20:11][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:20:11][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:20:12][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:20:12][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:20:13][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:20:13][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:20:13][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:20:13][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:20:13][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:22:49][INFO] train_net.py: 400: Train with config:
[03/08 09:22:49][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:22:49][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:22:49][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:22:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:22:50][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:22:50][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:22:50][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:22:50][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:22:50][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:22:50][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:22:51][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:22:51][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:22:51][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:22:51][INFO] misc.py: 187: Flops: 0 G
[03/08 09:22:51][INFO] misc.py: 192: Activations: 0 M
[03/08 09:22:51][INFO] misc.py: 197: nvidia-smi
[03/08 09:22:52][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:22:52][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:22:52][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:22:53][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:22:53][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:22:53][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:22:53][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:22:53][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:22:54][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:22:54][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:23:43][INFO] train_net.py: 400: Train with config:
[03/08 09:23:43][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:44][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:23:44][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:23:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:23:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:23:44][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:23:44][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:23:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:23:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:23:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:23:44][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:23:44][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:23:44][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:23:44][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:23:45][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:23:45][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:23:45][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:23:45][INFO] misc.py: 187: Flops: 0 G
[03/08 09:23:45][INFO] misc.py: 192: Activations: 0 M
[03/08 09:23:45][INFO] misc.py: 197: nvidia-smi
[03/08 09:23:46][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:23:46][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:23:46][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:23:48][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:23:48][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:23:48][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:23:48][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:23:48][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:23:48][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:23:48][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:24:32][INFO] train_net.py: 400: Train with config:
[03/08 09:24:32][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:24:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:24:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:24:33][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:24:33][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:24:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:24:33][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:24:33][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:24:33][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:24:34][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:24:34][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:24:34][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:24:34][INFO] misc.py: 187: Flops: 0 G
[03/08 09:24:34][INFO] misc.py: 192: Activations: 0 M
[03/08 09:24:34][INFO] misc.py: 197: nvidia-smi
[03/08 09:24:35][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:24:35][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:24:35][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:24:37][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:24:37][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:24:37][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:24:37][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:24:37][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:24:37][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:24:37][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:25:35][INFO] train_net.py: 400: Train with config:
[03/08 09:25:35][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:25:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:25:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:25:36][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:25:36][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:25:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:25:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:25:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:25:36][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:25:36][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:25:36][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:25:36][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:25:37][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:25:37][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:25:37][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:25:37][INFO] misc.py: 187: Flops: 0 G
[03/08 09:25:37][INFO] misc.py: 192: Activations: 0 M
[03/08 09:25:37][INFO] misc.py: 197: nvidia-smi
[03/08 09:25:38][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:25:38][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:25:38][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:25:40][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:25:40][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:25:40][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:25:40][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:25:40][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:25:40][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:25:40][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:27:48][INFO] train_net.py: 400: Train with config:
[03/08 09:27:48][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:27:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:27:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:27:49][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:27:49][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:27:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:27:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:27:50][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:27:50][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:27:50][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:27:51][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:27:51][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:27:51][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:27:51][INFO] misc.py: 187: Flops: 0 G
[03/08 09:27:51][INFO] misc.py: 192: Activations: 0 M
[03/08 09:27:51][INFO] misc.py: 197: nvidia-smi
[03/08 09:27:52][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:27:52][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:27:52][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:27:54][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:27:54][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:27:54][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:27:54][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:27:54][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:27:54][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:27:54][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:28:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96979, "dt_data": 0.02519, "dt_net": 2.94460, "epoch": "36/55", "eta": "6:10:43", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:29:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32016, "dt_data": 1.32939, "dt_net": 1.99076, "epoch": "36/55", "eta": "6:53:54", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02047, "lr": 0.00000, "mAP": NaN}
[03/08 09:30:58][INFO] train_net.py: 400: Train with config:
[03/08 09:30:58][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:59][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:30:59][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:30:59][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:30:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:30:59][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:30:59][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:30:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:30:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:30:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:30:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:30:59][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:30:59][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:30:59][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:31:00][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:31:00][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:31:00][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:31:00][INFO] misc.py: 187: Flops: 0 G
[03/08 09:31:00][INFO] misc.py: 192: Activations: 0 M
[03/08 09:31:00][INFO] misc.py: 197: nvidia-smi
[03/08 09:31:01][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:31:01][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:31:01][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:31:03][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:31:03][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:31:03][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:31:03][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:31:03][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:31:03][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:31:03][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:31:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83951, "dt_data": 0.02519, "dt_net": 2.81433, "epoch": "36/55", "eta": "5:54:27", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:33:34][INFO] train_net.py: 400: Train with config:
[03/08 09:33:34][INFO] train_net.py: 401: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:33:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:33:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:33:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:33:35][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:33:35][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:33:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:33:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:33:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:33:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:33:35][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:33:35][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:33:35][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:33:36][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:33:36][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:33:36][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:33:36][INFO] misc.py: 187: Flops: 0 G
[03/08 09:33:36][INFO] misc.py: 192: Activations: 0 M
[03/08 09:33:36][INFO] misc.py: 197: nvidia-smi
[03/08 09:33:37][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:33:37][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:33:37][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:33:39][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:33:39][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:33:39][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:33:39][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:33:39][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:33:39][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:33:39][INFO] train_net.py: 443: Start epoch: 36
[03/08 09:34:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.84652, "dt_data": 0.22726, "dt_net": 2.61926, "epoch": "36/55", "eta": "5:55:20", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:34:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52183, "dt_data": 0.02529, "dt_net": 3.49653, "epoch": "36/55", "eta": "7:19:03", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02047, "lr": 0.00000, "mAP": NaN}
[03/08 09:35:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80195, "dt_data": 0.02520, "dt_net": 3.77675, "epoch": "36/55", "eta": "7:53:20", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01921, "lr": 0.00000, "mAP": NaN}
[03/08 09:41:28][INFO] train_net.py: 401: Train with config:
[03/08 09:41:28][INFO] train_net.py: 402: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:41:29][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:41:29][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:41:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:41:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:41:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:41:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:41:29][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:41:29][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:41:29][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:41:30][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:41:30][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:41:30][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:41:30][INFO] misc.py: 187: Flops: 0 G
[03/08 09:41:30][INFO] misc.py: 192: Activations: 0 M
[03/08 09:41:30][INFO] misc.py: 197: nvidia-smi
[03/08 09:41:31][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:41:31][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:41:31][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:41:33][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:41:33][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:41:33][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:41:33][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:41:33][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:41:33][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:41:33][INFO] train_net.py: 444: Start epoch: 36
[03/08 09:42:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04747, "dt_data": 1.58754, "dt_net": 1.45992, "epoch": "36/55", "eta": "6:20:25", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:42:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55303, "dt_data": 1.78458, "dt_net": 1.76845, "epoch": "36/55", "eta": "7:22:56", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02047, "lr": 0.00000, "mAP": NaN}
[03/08 09:45:45][INFO] train_net.py: 403: Train with config:
[03/08 09:45:45][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:45:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:45:46][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:45:46][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:45:46][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:45:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:45:46][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:45:47][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:45:47][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:45:48][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:45:48][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:45:48][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:45:48][INFO] misc.py: 187: Flops: 0 G
[03/08 09:45:48][INFO] misc.py: 192: Activations: 0 M
[03/08 09:45:48][INFO] misc.py: 197: nvidia-smi
[03/08 09:45:48][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:45:48][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:45:48][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:45:50][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:45:50][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:45:50][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:45:50][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:45:50][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:45:50][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:45:50][INFO] train_net.py: 446: Start epoch: 36
[03/08 09:46:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75189, "dt_data": 0.63410, "dt_net": 2.11778, "epoch": "36/55", "eta": "5:43:31", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:47:39][INFO] train_net.py: 403: Train with config:
[03/08 09:47:39][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:47:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:47:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:47:40][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:47:40][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:47:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:47:40][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:47:40][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:47:40][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:47:41][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:47:41][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:47:41][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:47:42][INFO] misc.py: 187: Flops: 0 G
[03/08 09:47:42][INFO] misc.py: 192: Activations: 0 M
[03/08 09:47:42][INFO] misc.py: 197: nvidia-smi
[03/08 09:47:42][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:47:42][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:47:42][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:47:44][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:47:44][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:47:44][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:47:44][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:47:44][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:47:44][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:47:44][INFO] train_net.py: 446: Start epoch: 36
[03/08 09:48:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85818, "dt_data": 0.38979, "dt_net": 2.46838, "epoch": "36/55", "eta": "5:56:47", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:49:16][INFO] train_net.py: 403: Train with config:
[03/08 09:49:16][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:49:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:49:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:49:16][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:49:16][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:49:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:49:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:49:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:49:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:49:17][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:49:17][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:49:17][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:49:18][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:49:18][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:49:18][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:49:18][INFO] misc.py: 187: Flops: 0 G
[03/08 09:49:18][INFO] misc.py: 192: Activations: 0 M
[03/08 09:49:18][INFO] misc.py: 197: nvidia-smi
[03/08 09:49:19][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:49:19][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:49:19][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:49:20][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:49:20][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:49:20][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:49:20][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:49:20][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:49:21][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:49:21][INFO] train_net.py: 446: Start epoch: 36
[03/08 09:50:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19034, "dt_data": 0.85149, "dt_net": 2.33885, "epoch": "36/55", "eta": "6:38:15", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:51:23][INFO] train_net.py: 403: Train with config:
[03/08 09:51:23][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:51:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:51:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:51:24][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:51:24][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:51:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:51:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:51:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:51:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:51:24][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:51:24][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:51:24][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:51:25][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:51:25][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:51:25][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:51:25][INFO] misc.py: 187: Flops: 0 G
[03/08 09:51:25][INFO] misc.py: 192: Activations: 0 M
[03/08 09:51:25][INFO] misc.py: 197: nvidia-smi
[03/08 09:51:26][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:51:26][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:51:26][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:51:27][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:51:27][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:51:28][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:51:28][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:51:28][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:51:28][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:51:28][INFO] train_net.py: 446: Start epoch: 36
[03/08 09:52:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18690, "dt_data": 2.41215, "dt_net": 0.77475, "epoch": "36/55", "eta": "6:37:49", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 09:55:06][INFO] train_net.py: 403: Train with config:
[03/08 09:55:06][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 09:55:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:06][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:06][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:06][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 09:55:07][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 09:55:07][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 09:55:07][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 09:55:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 09:55:07][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 09:55:08][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 09:55:08][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 09:55:09][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 09:55:09][INFO] misc.py: 185: Params: 133,343,372
[03/08 09:55:09][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 09:55:09][INFO] misc.py: 187: Flops: 0 G
[03/08 09:55:09][INFO] misc.py: 192: Activations: 0 M
[03/08 09:55:09][INFO] misc.py: 197: nvidia-smi
[03/08 09:55:09][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 09:55:09][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 09:55:09][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 09:55:11][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 09:55:11][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:55:11][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 09:55:11][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 09:55:11][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:55:11][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 09:55:11][INFO] train_net.py: 446: Start epoch: 36
[03/08 09:55:17][INFO] train_net.py: 244: tensor([-6.2066,  0.5994,  1.2826,  2.2950, -6.4003, -4.6548, -6.0412, -4.9205,
        -4.4688, -5.2875, -4.5683, -6.4471, -5.4115, -4.9042, -5.9912, -4.1541,
        -4.8604, -6.3053, -7.0267, -5.0329, -5.6584, -5.4931, -5.1176, -6.6315,
        -7.5394, -5.3580, -3.9728, -4.6482, -5.3704, -5.9898, -5.9374, -5.7848,
        -5.0984, -5.9038, -6.4883, -5.9130, -6.2216, -5.8109, -4.4316, -4.6784,
        -4.2300, -5.3458, -5.9105, -5.8717, -5.0217, -4.9877, -4.9014, -4.0833,
        -4.4107, -4.2193, -6.3739, -4.3398, -3.4383, -6.7164, -6.7655, -5.3180,
        -6.0023, -5.7180, -4.1864, -4.9504, -6.5739, -6.0157, -4.9371, -5.9497,
        -5.5218, -6.0633, -5.7156, -4.5421,  3.8854, -4.1624, -6.5297, -5.8408,
        -5.9045, -5.4125, -4.8924, -5.7168, -5.4710, -7.4239, -3.4476, -6.2054,
        -5.4214, -5.3557, -5.1140, -5.8867, -4.5770, -5.9029, -6.6620, -5.1622,
        -6.2918, -6.2400, -4.5271, -4.6746, -5.7652, -6.3574, -6.1995, -5.1806,
        -0.0686,  2.6173, -6.6745, -5.0854, -5.1272, -6.0951,  1.9874, -4.3039,
         0.9613, -5.2724, -5.6561, -6.1340, -0.2006, -5.4164, -5.1899, -6.4419,
        -5.7647, -7.4151, -5.2368, -5.7976, -0.9906, -4.9416,  1.9047, -6.2512,
        -4.6896, -6.0572, -5.4680, -5.3536, -6.5399, -5.8883, -5.3359, -6.2101,
        -4.8467, -7.1427, -5.4324, -7.1463, -5.0650,  0.4160, -5.8528, -5.0853,
        -5.7876, -6.6058, -5.8656, -5.1261], device='cuda:0')
[03/08 09:55:17][INFO] train_net.py: 245: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:18][INFO] train_net.py: 244: tensor([-7.5640, -3.1337, -1.0200, -8.1552, -7.8988, -5.3212, -7.2541, -3.4920,
        -1.7470, -5.6830, -8.0612, -8.9043, -6.4643, -4.0813, -7.0410, -6.3693,
        -6.3773, -8.9431, -9.3023, -6.1687, -8.4747, -6.2486, -6.1689, -9.1001,
        -9.3854, -6.9139, -6.4337, -7.5624, -6.3016, -7.0139, -9.2855, -8.8419,
        -6.4204, -7.6885, -9.6261, -7.6665, -8.9630, -8.5943, -6.1693, -7.9165,
        -1.1072, -7.6933, -6.5484, -7.2643, -7.2997, -3.7128, -7.3022, -4.1524,
        -5.4375, -6.8581, -9.1867, -4.4232, -6.4826, -8.3108, -9.1409, -8.3954,
        -8.5086, -8.1478, -4.4546, -8.2844, -8.8953, -8.8835, -7.1870, -7.6688,
        -8.8790, -6.3647, -6.3725, -4.9378, -2.4187, -6.5197, -9.3594, -5.6910,
        -8.7972, -6.0861, -7.6931, -5.9177, -8.9096, -9.5994, -2.6478, -8.4476,
        -8.3007, -6.9869, -8.4696, -8.2501, -7.5403, -7.1020, -8.3084, -7.9178,
        -8.3233, -9.5179, -6.0724, -6.9170, -7.5668, -9.7754, -9.3441, -8.5362,
        -5.5977, -6.7678, -7.4946, -8.3413, -5.8977, -8.8350, -3.3646, -8.9751,
        -4.8824, -7.7505, -8.3837, -8.1711, -7.2172, -8.2720, -8.5615, -9.2966,
        -8.7054, -9.2854, -4.8415, -8.5986, -6.3971, -8.0729, -7.9584, -7.3870,
        -2.9022, -6.9140, -6.1457, -5.2168, -9.1335, -9.4256, -8.2387, -6.4987,
        -6.6907, -8.7979, -9.0476, -8.4982, -8.7853, -3.6373, -8.9541, -8.5659,
        -8.9896, -7.8950, -6.7443, -7.3055], device='cuda:0')
[03/08 09:55:18][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:20][INFO] train_net.py: 244: tensor([-7.4497, -5.5691, -4.3172, -6.6702, -7.1809, -7.9553, -5.1794, -5.4109,
        -3.8074, -5.0547, -7.0884, -6.9200, -5.1830, -5.9107, -5.9714, -4.9504,
        -6.5743, -7.4349, -6.4806, -5.8408, -6.1129, -6.4778, -6.9005, -7.0451,
        -7.4493, -6.0083, -6.0758, -5.5279, -6.1007, -7.3955, -7.3312, -6.7695,
        -4.7172, -6.8457, -7.3196, -7.9703, -7.2320, -5.9027, -4.6127, -7.5030,
        -3.3578, -6.4945, -7.5278, -5.5379, -4.9950, -2.5147, -5.2597, -2.0441,
        -0.4536, -5.0035, -7.6204, -5.0731, -6.1705, -7.9833, -7.8598, -7.9407,
        -7.5594, -7.5890, -3.8072, -8.5439, -7.8434, -8.2199, -8.0137, -8.5850,
        -7.8460, -7.2808, -4.8190, -7.1435, -3.0152, -7.1406, -8.6422, -5.9851,
        -7.8698, -7.8982, -5.9603, -4.7364, -5.6593, -7.3524, -1.8172, -8.1165,
        -6.1405, -5.5122, -6.6710, -6.7893, -4.5879, -7.7921, -6.9702, -5.8437,
        -5.6331, -9.0371, -4.8029, -6.9953, -7.0914, -7.9950, -6.3546, -6.5056,
        -4.4279, -5.6612, -6.2424, -7.1711, -7.3848, -6.3891, -2.9962, -3.2368,
        -6.1011, -4.3333, -7.7557, -6.9438, -6.1674, -7.3024, -6.4108, -7.6826,
        -6.6095, -8.0931, -4.6999, -7.3012, -6.0796, -7.1561, -7.0553, -6.0902,
        -4.4321, -7.5950, -5.3451, -8.1054, -8.0941, -8.4742, -6.7777, -5.4155,
        -7.9537, -7.4980, -7.2482, -7.7685, -5.9950, -5.5312, -8.1218, -5.8003,
        -8.1721, -6.9721, -6.4712, -6.6374], device='cuda:0')
[03/08 09:55:20][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:22][INFO] train_net.py: 244: tensor([-8.4961, -5.7258, -4.0068, -6.7885, -8.5476, -7.2219, -7.8534, -6.5143,
        -6.5340, -6.9169, -7.5068, -9.0235, -7.2231, -5.1111, -6.8047, -4.4584,
        -6.1713, -8.8763, -7.7769, -7.8748, -8.6181, -7.0366, -6.1333, -9.0250,
        -8.4821, -5.1663, -6.5118, -5.1097, -7.4624, -7.4991, -7.4776, -7.9541,
        -6.4251, -6.6797, -8.8466, -7.4115, -8.5055, -7.6270, -5.6826, -8.0418,
         5.4878, -7.7113, -7.4137, -7.3956, -7.2537, -3.3451, -7.2354, -6.5274,
        -4.2425, -6.2636, -8.2836, -5.7754, -4.4979, -7.8808, -8.9706, -7.3025,
        -8.4901, -8.0754, -6.9954, -7.4208, -8.6624, -6.8058, -7.2520, -7.9232,
        -8.0888, -6.7414, -7.6983, -5.9408, -3.8893, -4.5589, -8.9412, -8.6204,
        -8.2290, -7.3343, -7.3282, -7.1511, -6.9608, -8.5803, -5.5636, -8.0970,
        -6.8133, -8.3906, -7.7019, -7.3199, -7.1587, -7.1829, -8.9867, -7.4379,
        -7.8287, -9.1959, -4.3620, -7.4364, -7.8092, -7.9060, -7.4318, -7.1507,
        -6.6577, -5.9755, -7.7666, -6.6122, -6.2039, -8.9068, -0.5026, -4.9996,
        -5.1837, -5.0471, -7.8214, -7.7738, -5.8427, -8.0856, -6.9030, -8.5889,
        -7.5038, -8.6026, -5.1601, -7.9300, -5.3588, -6.6481, -6.5778, -8.3251,
        -5.6888, -7.6673, -7.6205, -5.9703, -9.0355, -9.4535, -7.4354, -7.6087,
        -5.8779, -8.6068, -7.7674, -8.5086, -6.7787,  3.2503, -9.1389, -6.6846,
        -8.3462, -8.4085, -8.1102, -6.6962], device='cuda:0')
[03/08 09:55:22][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:24][INFO] train_net.py: 244: tensor([ -8.4623,  -6.2436,   0.7891,  -6.7011,  -8.6992,  -7.2489,  -7.4558,
         -6.8117,  -5.6538,  -7.7204,  -7.5033,  -8.0081,  -7.6306,  -5.6228,
         -7.5616,   3.4759,  -7.2150,  -9.5189,  -8.2907,  -7.9703,  -7.6390,
         -7.9883,  -5.0763,  -8.2500,  -9.1996,  -7.5192,  -6.9475,  -7.0881,
         -6.5106,  -7.3715,  -5.6453,  -7.8740,  -6.8169,  -7.5025,  -8.4337,
         -7.5036,  -8.0997,  -6.5340,  -6.2885,  -8.5675,  -5.5124,  -6.6966,
         -7.8509,  -7.3365,  -6.7177,  -5.9293,  -7.8235,  -6.4144,  -5.0171,
          1.1107,  -8.4327,  -6.0726,  -4.8503,  -8.1053,  -8.9631,  -8.1926,
         -8.3510,  -7.8925,  -6.3520,  -7.9726,  -9.3840,  -7.7657,  -7.8339,
         -8.7229,  -6.3596,  -7.0005,  -7.3262,  -6.5166,  -3.1443,  -5.5630,
         -9.6495,  -7.8486,  -7.9067,  -7.0338,  -6.6324,  -6.7347,  -7.3902,
         -9.3898,  -5.9000,  -7.8177,  -7.6050,  -7.6949,  -8.1107,  -8.7815,
         -8.2258,  -8.5185,  -8.7773,  -8.1614,  -8.5899, -10.0182,  -6.0255,
         -7.8346,  -8.6129,  -9.0270,  -7.3349,  -6.9228,  -6.6990,  -5.7100,
         -7.2938,  -6.9129,  -7.3894,  -7.3664,  -2.6735,  -6.3370,  -6.8301,
         -6.8934,  -7.5393,  -7.6345,  -6.2146,  -8.0136,  -6.8880,  -9.2507,
         -6.6727, -10.2259,  -6.6729,  -7.5230,  -6.4112,  -8.1187,  -6.2503,
         -8.3182,  -6.8903,  -7.8561,  -7.5597,  -6.0757,  -9.2177,  -9.0245,
         -7.8419,  -8.0744,  -6.7337,  -9.1012,  -8.1551,  -9.1720,  -7.1395,
         -5.1265,  -9.2446,  -7.5726,  -8.3424,  -7.9034,  -8.5693,  -7.2641],
       device='cuda:0')
[03/08 09:55:24][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:26][INFO] train_net.py: 244: tensor([ -9.3398,  -5.5558,   0.3525,  -5.4543,  -9.5936,  -8.0659,  -9.0269,
         -6.5230,  -5.5586,  -7.7334,  -8.0482,  -8.6433,  -7.7379,  -6.0711,
         -8.7632,  -5.9050,  -6.0739,  -8.9623,  -8.4016,  -7.6588,  -9.1142,
         -7.8030,  -7.0096,  -9.3488,  -9.3648,  -7.2276,  -8.1125,  -7.3391,
         -7.1793,  -8.2283,  -8.2582,  -9.5751,  -6.9378,  -6.9988,  -9.7558,
         -8.0526,  -8.7075,  -7.9428,  -6.2591,  -7.6884,  -4.1522,  -8.5540,
         -8.2279,  -7.7510,  -7.8166,  -6.3795,  -7.3550,  -7.1212,  -8.2652,
         -7.0703,  -9.2578,  -6.3060,  -5.4477,  -8.3338,  -9.1873,  -8.9845,
        -10.0231,  -9.1724,  -6.6532,  -8.2326,  -9.1693,  -7.9534,  -5.9648,
         -8.5348,  -8.4465,  -7.1258,  -8.5017,  -6.3211,  -4.1563,  -7.9783,
        -10.3240,  -8.1962,  -7.6030,  -6.9569,  -6.2166,  -7.4254,  -7.9654,
         -9.2837,  -5.3920,  -9.0234,  -7.4885,  -7.9900,  -6.8613,  -7.8752,
         -7.8421,  -7.0473,  -9.8578,  -6.6471,  -8.9955,  -9.3642,  -6.5452,
         -8.1083,  -9.2334,  -8.9440,  -5.4715,  -7.2578,  -6.7843,  -5.9780,
         -7.8663,  -6.9411,  -7.0043,  -8.0350,   1.5435,  -6.7145,  -6.4264,
         -7.5986,  -7.0422,  -8.6516,  -4.8754,  -7.9687,  -8.0428,  -8.4774,
         -7.1081,  -9.7961,  -6.8031,  -6.4578,  -4.9980,  -7.0003,  -7.9251,
         -8.8757,  -6.2073,  -7.6438,  -7.8396,  -7.1799,  -9.2044,  -9.3515,
         -8.9798,  -8.4663,  -8.5522,  -9.3535,  -8.7825,  -9.4178,  -8.6621,
         -3.4483,  -9.4681,  -7.2310,  -9.7406,  -8.7652,  -8.0001,  -5.0452],
       device='cuda:0')
[03/08 09:55:26][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:27][INFO] train_net.py: 244: tensor([ -8.1597,  -5.8811,  -5.0941,  -7.1476,  -7.8451,  -6.4889,  -7.4121,
         -6.0490,  -6.4015,  -6.8574,  -7.6977,  -7.7172,  -7.5208,  -6.8100,
         -7.1465,  -5.0812,  -6.4162,  -8.3837,  -8.0072,  -7.9191,  -7.5949,
         -6.4650,  -7.8369,  -7.7549,  -9.1667,  -6.3088,   0.0989,   0.5319,
         -6.5130,  -7.4252,  -7.7259,  -8.1111,  -6.6493,  -7.3556,  -9.3822,
         -7.7174,  -8.0882,  -7.3339,   3.5941,  -7.4239,  -5.4659,  -7.2489,
         -7.7053,  -7.7922,  -7.0047,  -6.1579,  -6.9838,  -0.2611,  -6.4894,
         -7.4308,  -8.6448,  -6.5932,  -5.9640,  -8.8475,  -9.5691,  -7.4509,
         -9.0069,  -7.6241,  -6.5526,  -7.9294,  -8.5797,  -8.2414,  -6.8874,
         -8.5754,  -8.4691,  -6.4514,  -8.6991,  -5.5228,  -4.3816,  -6.3819,
        -10.1664,  -6.8800,  -8.4978,  -8.0798,  -6.9791,  -6.9256,  -7.5981,
         -8.7425,  -4.3918,  -8.4445,  -7.1179,  -6.8161,  -8.1275,  -7.8243,
         -7.0250,  -7.7031,  -8.2504,  -7.5197,  -7.7703,  -9.6918,  -3.7592,
         -7.5458,  -8.5377,  -8.4950,  -6.9267,  -7.5140,  -2.9612,  -6.4254,
         -7.5517,  -7.3686,  -6.4878,  -7.4785,   0.6713,  -6.5633,  -5.3882,
         -7.8398,  -8.0797,  -7.5144,  -6.7643,  -7.5845,  -7.7483,  -8.9329,
         -7.3807,  -9.1642,  -6.4155,  -7.7355,  -7.1131,  -7.4780,  -7.0414,
         -8.4420,  -6.1576,  -7.5019,  -7.5104,  -6.0540,  -8.6494,  -8.6765,
         -7.7002,  -7.1270,  -6.3967,  -8.7190,  -8.5942,  -9.0871,  -7.4335,
         -3.8997,  -9.6535,  -6.6563,  -8.5752,  -8.3491,  -8.2049,  -7.1925],
       device='cuda:0')
[03/08 09:55:28][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:29][INFO] train_net.py: 244: tensor([-10.0265,  -7.6175,  -1.4518,  -8.6261, -10.3103,  -8.7315, -10.0097,
         -7.9680,  -7.4118,  -8.4989,  -7.9286,  -9.2161,  -9.6126,  -7.2944,
         -8.6866,  -6.4862,  -8.7577, -10.8132, -10.1848,  -9.7266,  -9.7725,
         -6.8387,  -8.0325, -10.6879, -10.5829,  -8.3718,  -7.8471,  -8.2664,
         -7.8887,  -9.2348,  -9.0483,  -9.5218,  -7.6624,  -8.5908, -10.6575,
         -9.5461, -10.1626,  -8.2728,  -7.1000, -10.0036,  -6.7893,  -8.9159,
         -9.6432,  -9.4295,  -8.2875,  -7.7023,  -9.1943,  -8.3221,  -5.9745,
         -8.2268, -10.2898,  -8.1227,  -7.4055, -10.2519, -10.4602,  -9.8428,
        -10.1279,  -9.7818,  -7.6044,  -9.7611, -10.6744,  -9.7873,  -8.2763,
        -10.5995,  -9.0161,  -8.1773,  -8.6367,  -8.2617,   1.2534,  -6.2135,
        -12.0418,  -9.3606,  -9.9233,  -9.0105,  -7.8761,  -8.0301,  -8.7045,
        -10.8262,  -4.7943, -10.0863,  -8.9134,  -9.1448,  -9.7293,  -9.5062,
         -9.0624,  -9.1854, -10.9707,  -9.1046,  -9.7672, -11.2141,  -6.3854,
         -9.4726,  -9.5419, -10.7549,  -8.0877,  -8.7267,  -7.9052,  -7.2903,
         -9.0242,  -8.3216,  -8.3458,  -9.1395,  -4.2779,  -7.7781,  -6.0878,
         -8.7961,  -9.4960,  -9.5212,  -7.8819,  -9.0737,  -8.5761, -10.0894,
         -8.2557, -11.0429,  -7.4566,  -9.3843,  -6.9165,  -8.6208,  -7.5160,
        -10.0970,  -8.6461,  -9.0359,  -9.0833,  -6.4541, -10.7334, -10.9483,
         -9.6759,  -8.8908,  -7.2579, -10.7683, -10.2183, -10.6125,  -8.2005,
         -5.8738, -10.7747,  -7.6864, -10.0675, -10.3277,  -9.4947,  -7.7297],
       device='cuda:0')
[03/08 09:55:30][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:31][INFO] train_net.py: 244: tensor([-9.1921, -4.8582, -3.1215, -7.1714, -8.3079, -7.1791, -8.5961, -6.1681,
        -5.4137, -7.5126, -6.7026, -8.8548, -7.3697, -6.0177, -5.8833, -8.0103,
        -6.4317, -9.4646, -8.3737, -8.1238, -9.7654, -7.1181, -7.7011, -9.4133,
        -9.2545, -6.5614, -5.4925, -6.0838, -7.3737, -7.1719, -8.1130, -8.6619,
        -6.7412, -6.4957, -9.7554, -7.4228, -7.9700, -8.3317, -7.5844, -8.0929,
         1.4188, -7.2616, -7.8688, -7.9683, -7.6529, -2.3987, -6.7401, -4.7888,
        -6.3325, -7.4671, -8.6715, -4.3079, -6.8811, -8.6371, -8.8716, -7.2996,
        -9.7322, -8.3057, -6.0382, -7.9959, -8.6066, -6.9482, -7.3606, -6.9216,
        -8.3510, -6.1793, -7.6387, -5.4477, -4.2001, -4.5193, -9.7354, -7.5361,
        -8.5581, -7.2356, -6.5006, -7.8466, -6.1375, -9.4518, -5.2991, -8.9093,
        -9.2486, -8.3072, -7.3425, -7.0878, -7.1252, -8.1779, -8.9018, -5.2912,
        -8.3709, -9.1830, -6.0783, -5.8155, -8.1135, -9.2001, -8.3167, -7.1077,
        -5.6582, -5.0231, -8.6681, -7.9546, -5.3999, -9.7700,  0.9631, -6.1675,
        -4.8279, -7.0660, -6.0879, -7.7110, -3.4564, -7.7645, -8.0907, -8.8888,
        -7.7020, -9.3667, -4.3858, -8.2386, -6.2835, -5.1780, -5.9598, -8.4284,
        -5.4532, -8.1813, -7.7726, -5.8130, -9.8739, -8.8544, -8.1322, -8.1247,
        -3.5697, -9.3020, -8.1298, -9.1294, -8.1259, -2.0064, -9.6398, -7.2472,
        -8.7663, -8.4395, -8.4315, -6.3556], device='cuda:0')
[03/08 09:55:32][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:33][INFO] train_net.py: 244: tensor([-7.6236, -1.0676, -3.7057, -6.6054, -7.0305, -6.4164, -7.9434, -5.7851,
        -5.7601, -7.1927, -6.1373, -6.8889, -5.3031, -6.7492, -5.2924, -4.2826,
        -5.8835, -8.0696, -8.3204, -6.3319, -6.8526, -5.9732, -6.7232, -7.8835,
        -8.0722, -6.1001, -4.6973, -7.1487, -6.3215, -6.1868, -7.9903, -7.5235,
        -5.6357, -6.1412, -9.0341, -7.3135, -6.0825, -7.1252, -6.0851, -6.7882,
        -3.8125, -6.6621, -6.3077, -7.8521, -6.3156, -6.8916, -5.8826, -4.0332,
         1.9339, -7.7345, -8.3195, -3.7556, -5.8849, -8.6309, -7.8065, -7.7367,
        -7.1261, -7.0166, -6.5560, -7.3765, -8.2879, -7.8766, -6.4474, -6.8438,
        -6.5960, -5.9579, -6.6684,  1.7000,  0.8420, -2.5940, -8.3487, -6.1888,
        -8.0922, -7.7706, -5.7750, -6.3412, -3.4092, -8.6230, -4.7897, -7.6315,
        -6.4509, -6.4815, -7.1230, -7.2187, -5.7363, -6.8578, -7.6349, -6.1329,
        -6.6400, -8.0588, -4.4596, -6.2610, -6.2245, -7.3722, -6.1285, -6.8907,
        -5.2262, -5.2951, -6.8986, -7.3538, -0.5738, -7.0977,  0.0617, -6.1933,
        -4.9664, -6.0420, -7.0635, -7.1434, -6.3197, -7.1029, -6.2906, -8.1618,
        -7.0508, -8.3311, -3.8855, -6.5738, -6.7224, -6.4459, -6.1043, -7.7977,
        -5.6832, -7.0570, -5.8725, -6.0453, -8.2306, -7.6867, -7.2507, -6.8304,
        -5.6432, -8.4035, -7.5020, -7.9592, -7.6343, -2.8391, -7.6927, -5.5945,
        -7.3531, -7.8455, -7.9220, -6.7393], device='cuda:0')
[03/08 09:55:33][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:40", "gpu_mem": "3.53G", "iter": "10/96", "time_diff": 1.86729}
[03/08 09:55:35][INFO] train_net.py: 244: tensor([ -9.6196,  -7.7703,  -3.2400,  -7.7574,  -9.8355,  -9.3406,  -9.3258,
         -6.2907,  -7.9674,  -7.8029,  -6.8248,  -9.0237,  -8.3137,  -6.3409,
         -7.9095,  -6.0620,  -7.3696, -10.1676,  -8.8205,  -8.3927,  -9.6525,
         -6.7206,  -8.4696,  -9.4182,  -9.9455,  -6.1190,  -7.6531,  -6.3058,
         -7.9201,  -9.0183,  -8.4725,  -8.9631,  -5.5348,  -9.1070, -10.2773,
         -8.4105,  -9.2592,  -7.7759,  -4.0188, -10.1444,  -1.9432,  -8.4454,
         -9.6668,  -7.4528,  -7.5509,  -3.3073,  -7.7932,  -6.5906,  -5.7286,
         -8.1260,  -9.4701,  -7.3537,  -5.4497,  -8.7928,  -9.9849,  -8.8846,
         -9.7966,  -8.6150,  -3.4438,  -9.0267,  -9.4910,  -7.7644,  -8.1117,
         -9.3973,  -9.7213,  -6.3268,  -7.8584,  -6.0491,  -3.1714,  -5.8603,
        -10.2192,  -8.8489,  -9.4203,  -9.0358,  -8.2572,  -6.9391,  -7.2375,
         -9.7091,  -2.7982,  -9.3135,  -9.9821,  -8.9399,  -8.0000,  -8.4385,
         -7.6945,  -6.4877,  -9.8280,  -8.6667,  -9.2485, -10.2863,  -7.3174,
         -8.9276,  -8.6182,  -9.9036,  -5.8602,  -7.2902,  -8.2863,  -7.5155,
         -8.3398,  -8.5190,  -8.6204,  -8.4382,  -3.2069,  -8.5393,  -5.5127,
         -5.6498,  -8.1755,  -9.1351,  -5.7801,  -8.1810,  -8.6838,  -9.2570,
         -8.3599,  -9.4268,  -6.4751,  -9.2091,  -6.9048,  -7.6606,  -7.1138,
         -9.5838,  -8.1551,  -8.4762,  -8.0428,  -6.8728, -10.3860, -10.1906,
         -8.2696,  -8.2465,  -4.9507,  -9.9935,  -8.5598,  -9.9735,  -9.0086,
          0.4490,  -9.9478,  -6.8576,  -9.1125,  -8.6841,  -9.6093,  -6.0626],
       device='cuda:0')
[03/08 09:55:35][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:37][INFO] train_net.py: 244: tensor([-7.9622, -3.8937, -7.6486, -6.0249, -7.8527, -6.6397, -7.5918, -5.5011,
        -5.3307, -5.7885, -6.5601, -6.5328, -6.1952, -6.5384, -5.6820, -5.1225,
        -6.0168, -7.7714, -7.2888, -6.5288, -0.9936, -7.0368, -7.0092, -7.1091,
        -8.1070, -6.3163, -6.2743, -6.1233, -3.7410, -6.7495, -3.3254, -4.8059,
        -5.1349, -5.5673, -6.6684, -6.6319, -7.3414, -4.8117, -4.8411, -6.7491,
        -5.2374, -6.3186, -6.1728, -7.3814, -6.4322, -6.5621, -6.2977, -5.6005,
        -2.1117, -2.9841, -7.2110, -5.1905, -2.9789, -6.8572, -7.1772, -7.1757,
        -7.0479, -7.6659, -6.1935, -7.3288, -7.9313, -7.1505, -6.1747, -7.8365,
        -7.4400, -6.8839, -6.9187, -7.3041, -3.9107, -3.1943, -8.3476, -6.4513,
        -7.9213, -6.5002, -6.0840, -6.3608, -6.1044, -6.9842, -5.3329, -7.9415,
        -7.4244, -6.2842, -6.2046, -7.1838, -6.9524, -6.6582, -7.5996, -6.5486,
        -6.6839, -8.4513, -5.1367, -7.9481, -6.6934, -6.8352, -6.3916, -6.7763,
        -5.9222, -6.0942, -4.9862, -7.2365, -6.9047, -1.6260, -1.3903, -6.2272,
        -3.9881, -6.5903, -6.2114, -6.7673, -5.7904, -7.7765, -7.1095, -7.3239,
        -5.7615, -7.7427, -5.8264, -6.3978, -6.1871, -6.6858, -6.1323, -7.2985,
        -5.1546, -3.8188, -6.6106, -2.7828, -7.2990, -8.5177, -8.0954, -7.0647,
        -6.6196, -7.4775, -6.4900, -7.8554, -6.0811, -3.8290, -8.3072, -5.0906,
        -7.5580, -7.5196, -7.1846, -5.1020], device='cuda:0')
[03/08 09:55:37][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:39][INFO] train_net.py: 244: tensor([-8.2844, -6.2642,  2.4546, -7.0601, -8.2955, -6.7590, -7.8200, -6.3787,
        -5.4616, -8.1800, -6.5423, -7.6358, -6.5676, -6.6161, -6.8182, -3.9819,
        -6.0120, -8.7181, -8.0736, -7.7771, -8.7103, -6.3592, -6.4590, -9.4384,
        -8.6727, -6.0486, -6.0116, -5.7956, -6.2846, -7.0022, -8.0994, -8.1279,
        -6.1531, -6.0208, -8.8167, -7.1453, -8.3500, -7.7586, -4.0950, -8.6173,
         1.0141, -7.7390, -7.6793, -7.5860, -7.0082, -5.8673, -6.2677, -6.0005,
        -4.1825, -6.1538, -7.9795, -5.8885, -4.7405, -8.3831, -8.5382, -8.3426,
        -8.2891, -7.5871, -6.4995, -7.3312, -8.4218, -7.1250, -7.7862, -7.6882,
        -7.0593, -6.9397, -8.1942, -4.5500,  3.4151, -3.7616, -9.4469, -8.1327,
        -8.5190, -7.3703, -6.8640, -6.5977, -6.6887, -8.7941, -5.4562, -7.9371,
        -7.0869, -8.0368, -6.9274, -7.6295, -6.7551, -7.6515, -8.8726, -6.8599,
        -7.7635, -8.1555, -3.4356, -7.0653, -7.3556, -7.8546, -6.9597, -7.7045,
        -6.5544, -7.0356, -7.4251, -6.8955, -0.9535, -7.9350, -0.2249, -5.6361,
        -5.1253, -5.9057, -7.4414, -8.4901, -6.6500, -7.6742, -6.8769, -8.6275,
        -7.0209, -8.4258, -5.1811, -7.6186, -5.6635, -7.5361, -7.1089, -8.4399,
        -6.0311, -7.3632, -7.0107, -6.5644, -8.9900, -9.3563, -6.9391, -7.4298,
        -5.2298, -9.2770, -8.4874, -8.8281, -7.8279,  4.4657, -9.0013, -6.2476,
        -8.5355, -8.3484, -8.4148, -7.2505], device='cuda:0')
[03/08 09:55:39][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:41][INFO] train_net.py: 244: tensor([ -9.4649,  -6.6041,  -6.3707,  -9.0949,  -8.7223,  -6.7547,  -8.4954,
         -5.7500,  -4.8447,  -6.7385,  -7.9811,  -9.0751,  -7.1052,  -4.8009,
         -8.1805,  -6.3104,  -7.0008,  -9.7888,  -8.2739,  -8.2539,  -9.1998,
         -6.3809,  -8.5436,  -9.2989,  -9.5870,  -6.4549,  -8.5310,  -7.0218,
         -8.0337,  -8.1540,  -8.9933,  -9.0373,  -6.9892,  -8.2051, -10.0658,
         -8.1364,  -9.6640,  -8.1021,  -7.0462,  -9.1511,  -4.8033,  -7.4162,
         -8.2290,  -8.0880,  -6.8612,  -3.5193,  -7.7462,  -6.9936,  -6.5400,
         -7.8550, -10.0221,  -7.3021,  -6.8117,  -7.7373,  -9.5660,  -8.4673,
         -9.3072,  -8.8712,  -6.8066,  -9.1003,  -9.5708,  -9.7655,  -7.2720,
        -10.2621,  -8.9224,  -7.0485,  -8.0891,  -6.8105,  -3.4207,  -7.9217,
        -10.0431,  -7.6214,  -9.2201,  -8.6820,  -8.3522,  -7.0681,  -8.5665,
         -9.2034,   2.4027,  -9.3932,  -7.8546,  -7.9584,  -8.6671,  -8.8636,
         -7.3553,  -7.5004,  -8.8601,  -8.1849,  -8.6288, -10.0279,  -7.2927,
         -9.0434,  -8.5951,  -9.7317,  -6.7936,  -8.6405,  -6.8760,  -7.2800,
         -7.5871,  -8.6436,  -7.3884,  -8.4631,  -3.5085,  -7.3444,  -6.9664,
         -6.4573,  -9.2161,  -8.6419,  -7.8871,  -8.6746,  -8.1500,  -9.5297,
         -8.7326,  -9.4123,  -7.3104,  -8.3085,  -7.0744,  -7.7335,  -8.2895,
         -8.9085,  -5.4551,  -7.9375,  -7.2638,  -6.3153,  -9.8533, -10.3105,
         -8.6333,  -7.8339,  -6.7064,  -9.1542,  -8.3030,  -9.3249,  -7.7975,
         -4.6463, -10.0517,  -7.8301,  -9.3458,  -8.3466,  -8.8220,  -6.8767],
       device='cuda:0')
[03/08 09:55:41][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:42][INFO] train_net.py: 244: tensor([ -9.8695,  -6.8544,  -0.5802,  -8.8442,  -9.4808,  -8.4633,  -8.9791,
         -7.3183,  -5.8127,  -8.0041,  -7.4794,  -9.5016,  -6.9929,  -7.8474,
         -8.4546,  -5.8511,  -7.5794, -10.1129,  -9.0492,  -9.3845,  -9.9944,
         -7.6885,  -7.4097,  -9.8889,  -9.7717,  -7.4557,  -7.4042,  -6.4074,
         -7.9403,  -6.8163,  -9.2220,  -9.7399,  -7.6352,  -7.4229, -11.1020,
         -8.4750,  -9.9924,  -8.8505,  -6.4773,  -8.8334,  -0.8357,  -8.9301,
         -9.2200,  -8.9219,  -8.5082,  -5.4805,  -6.9781,  -7.5173,  -7.6720,
         -7.7153,  -9.8492,  -6.6820,  -6.8992,  -9.5606, -10.0816,  -8.3050,
        -10.0638,  -9.1178,  -7.2090,  -8.3125, -10.0955,  -6.8334,  -8.5992,
         -7.2155,  -8.9071,  -7.8364,  -8.8762,  -4.6786,  -2.9911,  -5.7986,
        -10.6859,  -9.0642,  -8.8585,  -8.3060,  -7.7668,  -7.8635,  -7.5498,
        -10.0650,  -3.1606,  -8.8516,  -8.5263,  -9.7824,  -8.0878,  -9.0617,
         -6.8551,  -9.2082, -10.0006,  -8.2197,  -9.0708,  -9.7636,  -6.5664,
         -8.1480,  -9.5449,  -9.9999,  -9.3039,  -8.6916,  -8.3165,  -6.3867,
         -8.9923,  -8.2235,  -5.5081,  -9.3322,  -0.9022,  -6.1713,  -6.8251,
         -6.7978,  -8.5204,  -9.4307,  -6.1281,  -8.8295,  -7.9219,  -9.5582,
         -9.2142,  -9.7131,  -7.2122,  -8.8136,  -5.8001,  -7.2327,  -6.4755,
         -9.0998,  -7.1861,  -8.3808,  -8.5855,  -7.6805,  -9.9624, -10.2701,
         -7.8761,  -8.6404,  -7.7692, -10.0842,  -8.6178, -10.4841,  -6.6196,
         -1.1792, -10.2311,  -8.3425,  -9.5596,  -9.1464,  -9.0992,  -7.5653],
       device='cuda:0')
[03/08 09:55:43][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:44][INFO] train_net.py: 244: tensor([-7.2495, -4.4648, -4.5194, -8.3307, -7.7544, -7.2731, -8.2717, -6.8414,
        -6.7035, -7.2179, -7.5616, -8.4036, -6.5474, -7.6658, -6.5756, -5.3984,
        -5.5811, -8.1623, -8.1458, -6.8964, -8.1114, -7.4282, -6.6034, -7.6986,
        -8.8626, -6.7804, -6.7926, -6.5032, -6.8153, -5.7532, -8.0059, -8.8093,
        -6.8697, -8.3419, -8.9141, -6.9600, -7.6307, -8.2374, -6.3910, -7.3159,
        -2.2706, -6.7062, -7.5689, -6.3055, -7.1517, -3.5383, -4.9126, -5.2661,
        -4.5707, -5.5836, -9.0558, -4.5628,  0.4671, -8.5325, -8.7701, -8.1924,
        -7.3702, -7.4336, -4.7971, -6.4120, -7.7519, -8.5736, -6.6195, -8.6624,
        -6.9061, -6.8393, -7.7854, -5.1492, -3.6574, -2.1198, -9.5052, -5.8615,
        -7.9574, -7.2174, -7.5313, -6.6728, -8.1219, -9.2305, -2.2302, -8.1895,
        -6.9114, -6.7799, -7.5587, -6.9056, -7.3805, -6.3390, -7.6832, -8.4430,
        -7.2705, -8.9934, -5.5063, -7.0018, -7.7258, -9.1353, -7.4533, -7.1142,
        -5.7949, -6.6629, -8.3848, -7.8089, -5.6374, -7.8994, -4.3781, -5.5806,
        -5.7330, -7.4800, -7.7446, -7.1740, -5.7927, -6.9651, -8.2287, -9.0730,
        -7.4516, -9.1220, -3.8985, -7.8706, -5.8757, -7.2908, -6.3396, -7.8431,
        -4.5963, -5.7965, -7.2690, -5.4931, -9.2583, -8.6830, -7.8370, -6.6867,
        -6.1858, -7.8891, -8.5722, -8.1389, -7.9933, -7.1072, -8.6831, -8.6976,
        -8.2621, -7.8801, -7.2929, -7.0721], device='cuda:0')
[03/08 09:55:44][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:46][INFO] train_net.py: 244: tensor([-7.9663, -2.3126,  0.3793, -7.1968, -8.1357, -6.7143, -7.3294, -7.0018,
        -4.4052, -7.3377, -5.8202, -7.6657, -5.5517, -6.2749, -6.5953, -4.8558,
        -6.2386, -8.7231, -7.7997, -7.0122, -8.5856, -6.3497, -7.3430, -8.0086,
        -8.9927, -6.5667, -4.1009, -6.0490, -7.7339, -7.4406, -7.9676, -8.8540,
        -5.8582, -7.7860, -8.9477, -7.5521, -8.4443, -7.9058, -6.1385, -5.3294,
        -4.7903, -6.6009, -7.6475, -7.3922, -6.8753, -4.1309, -6.2058, -6.1348,
        -5.8629, -6.0176, -8.6589, -2.5132, -4.7940, -7.8373, -8.5041, -7.8602,
        -8.1301, -8.0961, -5.1673, -7.5744, -8.2465, -7.7408, -5.6735, -7.7767,
        -6.8436, -6.2447, -7.1902, -4.2095, -4.0589, -3.9746, -8.3269, -7.2898,
        -8.1037, -7.7747, -7.3640, -5.9929, -6.5343, -9.1621,  2.8956, -7.9595,
        -6.9905, -7.8872, -7.5441, -7.9183, -6.7247, -7.1384, -8.0341, -6.5489,
        -7.8483, -8.2167, -5.7041, -7.1612, -8.0461, -8.5272, -7.8324, -7.8374,
        -5.2199,  0.8071, -7.3491, -7.1895, -5.4698, -8.0484,  1.1447, -5.2919,
        -5.9321, -6.8598, -7.5708, -8.4229, -6.1135, -7.3240, -6.7753, -8.5420,
        -8.0124, -8.7969, -6.5260, -7.0460, -4.8783, -5.9444, -2.7162, -8.3342,
        -4.1046, -7.5814, -7.1525, -5.8924, -8.9965, -8.5998, -7.5518, -8.0779,
        -6.2346, -8.9520, -7.7460, -8.2693, -7.4750,  1.6274, -8.6687, -6.6632,
        -8.2344, -7.7835, -7.6604, -7.1482], device='cuda:0')
[03/08 09:55:46][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:48][INFO] train_net.py: 244: tensor([-8.3083, -5.9259, -0.8630, -7.6043, -8.8723, -7.2871, -8.2874, -5.8039,
        -5.8360, -7.2228, -7.2363, -8.0048, -7.5279, -6.8852, -7.4560, -3.6462,
        -6.6230, -9.2589, -9.1295, -8.2336, -7.7883, -7.0017, -6.9044, -8.5563,
        -9.0548, -7.6727, -7.7882, -8.2728, -6.5598, -7.2994, -7.8773, -8.8241,
        -7.4921, -7.5416, -9.1738, -7.7390, -8.1488, -7.8021, -5.7674, -8.8998,
        -5.0815, -6.8432, -7.9591, -7.7207, -6.9921, -7.3696, -6.6878, -6.7911,
        -2.0754, -4.9237, -8.7304, -5.9566, -5.1432, -8.7045, -8.7358, -8.5186,
        -8.1708, -8.3940, -6.3025, -8.3655, -9.0723, -8.5606, -7.2308, -7.9768,
        -7.4335, -7.5488, -7.1109, -3.6431,  0.4684, -4.9928, -8.3719, -7.7849,
        -8.8735, -7.4777, -2.6269, -6.2464, -7.9901, -9.2265, -5.8566, -7.9244,
        -6.6044, -8.1212, -7.9295, -8.5630, -7.3072, -8.0177, -8.6473, -8.4833,
        -7.9290, -9.4161, -4.2987, -6.8663, -8.1161, -9.0407, -7.8302, -8.2356,
        -6.1051, -7.0022, -8.2332,  0.1778, -5.6800, -7.2134, -2.6324, -6.0247,
        -1.9487, -7.6376, -7.1912, -7.6753, -7.1363, -8.0166, -7.2986, -8.8432,
        -6.7910, -9.4243, -1.8349, -8.2700, -3.2856, -7.9260, -6.7772, -8.0320,
        -6.3912, -6.7689, -6.9377, -5.8957, -9.1118, -9.3414, -7.8014, -7.4512,
        -6.7979, -9.1093, -8.3999, -9.3251, -7.4338, -4.3392, -8.8490, -7.5481,
        -8.7605, -8.2182, -7.1903, -7.1876], device='cuda:0')
[03/08 09:55:48][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:50][INFO] train_net.py: 244: tensor([ -9.4953,  -6.1702,  -5.0059,  -8.3535,  -9.2048,  -6.7258,  -9.8080,
         -6.8462,  -6.6384,  -8.5655,  -7.5219,  -9.0404,  -8.5387,  -6.2173,
         -8.4706,  -4.3205,  -8.6012, -10.5824,  -9.8998,  -8.9207,  -9.0480,
         -8.1921,  -8.6552,  -9.5002, -10.3308,  -9.1748,  -6.9094,  -7.7313,
         -8.9820,  -8.3733,  -8.6259,  -9.1082,  -6.9554,  -7.2077, -10.2339,
         -8.9524,  -9.0920,  -8.8416,  -6.8166,  -8.9192,  -5.6657,  -8.5725,
         -8.5543,  -9.4456,  -8.4068,  -6.2257,  -7.7423,  -6.1268,  -2.7681,
         -7.1998, -10.2074,  -7.2221,  -6.4375,  -9.1752,  -9.9071,  -9.1408,
         -9.0989,  -8.5255,  -6.5609,  -9.8033, -10.8816, -10.0884,  -7.4172,
         -9.3187, -10.0121,  -8.1857,  -8.5080,  -5.9172,  -4.3106,  -6.8990,
        -10.6041,  -8.2953,  -9.5452,  -7.7115,  -8.0192,  -8.6986,  -8.7587,
        -10.9734,  -4.1634,  -9.2999,  -8.3907,  -8.0465,  -8.3883,  -8.8493,
         -8.0267,  -9.0133,  -9.6542,  -8.8602,  -9.4462, -10.8770,  -2.1817,
         -8.5611,  -9.3994, -10.2296,  -9.3265,  -8.7876,  -7.6848,  -6.7607,
         -9.5293,  -8.8172,  -7.5221,  -9.4200,  -0.8057,  -4.9229,   0.1897,
         -9.7948,  -8.9818,  -8.7644,  -7.7372,  -9.1254,  -8.7902, -10.1763,
         -8.0077, -11.1501,  -4.6630,  -8.1868,  -6.3713,  -7.0163,  -6.6598,
         -9.1486,  -7.4792,  -8.7602,  -9.1511,  -7.5675, -10.6315, -10.3557,
         -9.6616,  -8.8432,  -4.5577,  -9.7117,  -9.2994,  -9.9043,  -8.0664,
         -6.3498,  -9.9746,  -5.8662,  -9.9479,  -9.8149,  -8.9194,  -8.0268],
       device='cuda:0')
[03/08 09:55:50][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:51][INFO] train_net.py: 244: tensor([-7.1108, -4.1103, -4.7095, -8.0243, -7.2763, -4.2634, -7.8660, -3.5495,
        -3.8300, -5.7115, -7.5305, -7.9136, -6.1504, -4.3343, -7.8216, -5.4481,
        -5.8695, -8.0782, -7.9295, -6.8003, -8.6041, -5.9746, -6.2264, -8.6960,
        -8.4407, -6.4061, -7.0827, -6.4725, -7.3394, -5.9280, -8.0922, -8.7445,
        -7.3483, -6.8830, -9.2393, -6.3764, -9.3822, -8.0502, -7.7925, -8.0954,
        -2.5542, -6.3626, -7.4125, -7.3507, -5.7282, -3.0173, -5.7273, -6.5352,
        -8.3546, -5.2495, -8.9976, -5.3317, -4.9459, -7.8734, -8.7451, -6.9165,
        -7.5756, -8.1083, -5.3798, -7.3662, -8.8634, -8.5366, -6.6683, -8.9092,
        -7.3854, -5.7368, -5.0599, -6.1375,  0.4170, -7.0640, -8.9041, -4.8444,
        -8.2648, -7.4138, -7.6873, -5.3131, -7.7339, -8.1615,  0.5753, -8.3328,
        -7.0834, -6.2995, -7.5779, -7.7417, -6.8050, -6.1442, -7.7810, -7.5915,
        -7.5761, -8.6712, -6.9304, -7.4381, -6.2496, -9.1653, -7.6717, -8.1489,
        -5.4876, -6.4130, -7.7842, -8.9811, -6.9303, -7.9406, -2.2119, -6.7550,
        -6.5836, -6.7421, -8.4377, -7.7591, -7.1220, -7.7422, -8.7073, -8.9239,
        -8.1705, -9.2811, -5.1715, -7.5345, -7.2912, -6.5349, -6.7768, -7.3384,
        -3.6658, -6.7729, -5.4769, -7.2342, -8.5655, -8.7584, -8.0306, -5.7130,
        -6.2767, -7.7695, -7.7965, -8.2433, -6.4573, -6.2134, -8.9740, -8.0156,
        -7.6430, -7.0932, -7.3639, -6.7336], device='cuda:0')
[03/08 09:55:52][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:11", "gpu_mem": "3.53G", "iter": "20/96", "time_diff": 1.73470}
[03/08 09:55:53][INFO] train_net.py: 244: tensor([-8.2415, -5.7647, -4.4317, -7.1133, -7.7816, -6.2016, -7.0210, -4.6658,
        -5.8237, -6.2845, -5.6852, -3.6884, -6.6677, -6.1513, -7.0556, -4.8524,
        -6.4376, -7.5391, -7.3641, -6.1456, -7.3633, -6.0917, -6.0814, -8.7279,
        -7.3295, -0.4294, -6.6063, -6.2818, -6.3001, -8.0707, -6.9539, -7.6956,
        -7.5630, -6.0117, -8.4397, -7.6270, -7.6807, -5.1637, -5.9142, -7.6018,
        -2.8049, -4.7882, -7.3049, -7.1024, -3.8638, -5.1359, -6.7630, -5.8086,
        -6.3888, -4.7362, -7.4926, -5.2124, -5.5500, -7.7335, -7.9544, -7.1430,
        -8.2633, -8.2000, -4.5855, -8.0416, -8.5803, -7.2759, -7.4858, -9.0147,
        -6.8584, -6.7027, -5.1984, -6.9105, -0.4359, -6.5574, -9.4376, -6.3957,
        -8.2120, -7.8427, -6.5237, -5.1931, -3.4428, -6.8431, -4.0002, -8.1528,
        -6.1821, -7.0021, -7.8627, -7.7152, -7.0529, -7.0919, -7.7091, -6.8887,
        -5.7300, -9.2863, -5.3622, -7.7357, -6.6260, -8.1489, -5.7819, -6.9224,
        -7.4778, -5.2897, -7.1669, -8.0560, -6.4366, -6.6326, -2.5729, -2.9628,
        -7.4874, -7.5976, -8.0594, -6.6198, -6.5261, -7.2137, -7.7920, -8.0324,
        -5.5343, -9.1350, -6.9237, -6.9771, -7.5469, -5.9769, -6.9065, -7.2842,
        -5.8719, -7.4882, -7.0001, -5.4906, -8.1123, -8.8971, -7.7883, -6.5303,
        -7.7223, -8.4659, -8.0884, -7.5168, -6.3696, -6.6101, -8.9052, -6.8692,
        -6.0741, -7.1592, -7.5042, -6.9807], device='cuda:0')
[03/08 09:55:53][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:55][INFO] train_net.py: 244: tensor([-8.2002, -2.0896, -2.9827, -7.0930, -8.3603, -8.8433, -7.5106, -6.9506,
        -7.0914, -5.9662, -5.7783, -8.0964, -6.8586, -7.7469, -5.4459, -5.2196,
        -4.4139, -8.1273, -8.5768, -7.4058, -7.2144, -7.8733, -8.1089, -8.4903,
        -8.4616, -7.0486, -7.4622, -8.4897, -2.9534, -5.9494, -7.8330, -8.5090,
        -6.3021, -9.0387, -9.7225, -8.2352, -8.6679, -6.9059, -6.9914, -7.7131,
        -6.1720, -6.0394, -6.7367, -7.9310, -6.6106, -6.6523, -5.4535, -6.9205,
        -6.9573, -6.9818, -9.0051, -3.3383, -4.0633, -8.8313, -8.3375, -8.7828,
        -7.7859, -6.9083, -5.0425, -7.3552, -8.0605, -8.8682, -7.2778, -8.8260,
        -7.7219, -6.9285, -8.0282, -6.8876, -2.1961, -3.1202, -9.7027, -7.5714,
        -8.4307, -8.3220, -6.2110, -6.6635, -8.1602, -8.9745,  0.0325, -7.9960,
        -6.4560, -6.6254, -7.9924, -8.4039, -8.0619, -7.5289, -8.2905, -7.8812,
        -8.0871, -9.0570, -6.6287, -6.6904, -8.2802, -8.7486, -7.8736, -8.4755,
        -4.8796, -5.3079, -6.9636, -6.7323, -4.4393, -6.4223, -3.9762, -5.5326,
        -4.8926, -7.5177, -7.1779, -5.6151, -7.1213, -8.3084, -7.8402, -9.0220,
        -7.8770, -8.4143, -7.1438, -6.9987, -6.1117, -7.6825, -5.3340, -8.3470,
        -5.5575, -4.6307, -6.9971, -4.8525, -9.3242, -8.9445, -7.7908, -7.0720,
        -8.2763, -8.7265, -8.5918, -8.0873, -7.5518, -3.7358, -9.4900, -7.5645,
        -8.3514, -7.7914, -7.2795, -6.5794], device='cuda:0')
[03/08 09:55:55][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:56][INFO] train_net.py: 244: tensor([-8.3960, -7.0248, -3.3493, -7.8086, -8.3686, -7.1299, -7.2598, -5.2676,
        -5.7307, -6.0521, -6.7673, -3.9572, -6.6826, -5.7052, -8.0727, -5.8523,
        -7.5969, -8.1745, -8.0853, -4.9299, -8.0279, -5.8947, -7.0295, -8.7687,
        -8.2835, -1.2670, -7.1090, -7.2868, -7.3105, -8.6511, -7.9329, -8.2889,
        -6.6487, -6.2015, -8.9244, -7.9350, -8.8530, -6.5501, -5.9698, -8.5501,
        -3.2043, -4.7472, -8.2441, -6.2010, -4.5855, -4.7669, -6.4385, -5.7345,
        -5.8147, -6.0984, -8.3364, -6.1089, -6.5328, -7.2253, -8.6509, -7.5424,
        -9.0348, -8.9320, -4.5438, -8.7261, -8.3274, -7.9654, -7.5602, -8.6841,
        -8.0626, -7.8065, -6.2319, -5.8872, -3.3054, -5.7401, -9.6542, -6.1930,
        -8.4435, -8.5725, -7.6632, -5.7800, -4.2957, -7.4660, -2.2034, -8.5325,
        -8.0129, -6.1150, -8.0590, -8.3436, -6.3113, -6.9892, -8.1875, -6.9260,
        -7.1669, -9.1789, -7.4266, -8.8103, -7.5863, -8.4636, -5.7616, -7.7632,
        -7.8581, -5.7993, -7.4730, -8.5163, -7.4035, -6.7375, -1.4059, -3.9950,
        -7.4821, -5.5141, -8.0890, -7.4891, -5.8641, -7.5603, -7.7853, -8.1735,
        -7.0432, -9.2578, -6.6312, -7.3802, -7.3645, -6.8992, -7.9077, -7.6065,
        -4.4110, -7.3828, -6.8088, -6.3070, -8.8565, -9.5500, -8.1743, -6.6765,
        -7.4032, -8.3075, -8.2562, -7.7992, -7.6948, -5.7903, -9.2710, -7.6978,
        -7.4412, -5.7811, -8.2075, -6.6097], device='cuda:0')
[03/08 09:55:56][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:55:58][INFO] train_net.py: 244: tensor([-8.7799, -4.0128, -2.5864, -8.3807, -8.1788, -5.7433, -7.0535, -0.8563,
        -2.4400, -7.6197, -6.8271, -6.8780, -6.8491, -4.8000, -6.9972, -7.2624,
        -7.1558, -8.7529, -8.1288, -6.3696, -8.7374, -5.8811, -7.2452, -9.7300,
        -8.7885, -4.8119, -8.0080, -7.0755, -7.4970, -8.5371, -8.2287, -8.1403,
        -7.0190, -7.0547, -8.8000, -8.4664, -9.0251, -7.6277, -6.5913, -8.5923,
         1.2549, -6.9134, -7.1391, -7.3716, -5.4782, -2.5900, -7.5629, -5.7453,
        -5.0925, -6.9522, -8.6658, -5.3065, -5.5724, -7.6734, -9.0116, -7.7926,
        -8.8039, -9.1834, -3.5326, -9.2128, -8.8875, -8.0443, -8.0069, -8.8368,
        -8.0716, -7.7344, -5.1817, -7.2643, -1.1626, -6.5909, -9.8138, -6.5172,
        -8.6242, -7.6837, -8.1162, -6.5785, -6.0852, -8.0138, -2.2823, -9.0094,
        -7.9156, -7.4104, -7.9732, -7.9513, -7.2611, -6.8063, -7.9917, -6.4924,
        -6.8864, -9.8666, -5.6657, -7.6995, -7.1333, -9.2384, -7.8051, -8.1396,
        -7.0973, -6.0623, -7.2092, -8.7636, -5.8507, -8.1527, -2.5528, -6.2865,
        -4.7955, -6.1493, -8.6220, -8.2414, -7.8091, -7.6533, -8.5776, -8.0552,
        -7.3181, -9.3826, -6.8830, -7.6649, -7.6624, -6.6897, -7.1195, -7.2929,
        -5.2418, -7.6397, -6.5773, -6.2161, -9.1579, -9.4025, -7.4171, -6.9672,
        -6.1136, -9.1223, -8.4130, -8.6334, -7.1034, -4.1260, -8.9417, -7.8286,
        -8.2561, -7.8851, -8.2784, -6.9562], device='cuda:0')
[03/08 09:55:58][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:00][INFO] train_net.py: 244: tensor([ -9.2174,  -7.3932,  -2.1079,  -6.5572,  -9.8047,  -8.8665,  -9.2852,
         -7.1089,  -8.1924,  -7.3843,  -6.0765,  -8.5366,  -7.0806,  -7.0288,
         -7.8124,  -4.7954,  -4.7425,  -9.9425,  -8.8909,  -7.9898,  -9.4591,
         -7.2164,  -8.2025,  -9.5324,  -8.9952,  -8.0449,  -8.1812,  -7.5400,
         -7.6468,  -8.2248,  -8.5796,  -8.5957,  -7.1604,  -8.5482, -10.0173,
         -7.4941,  -8.8174,  -8.3600,  -5.9050,  -9.8079,  -2.9971,  -7.6930,
         -9.1697,  -8.6661,  -8.2725,  -4.2992,  -4.4247,  -7.1761,  -6.0500,
         -7.6654,  -9.0066,  -6.4143,  -4.3274,  -9.0977,  -9.5603,  -8.5652,
         -9.2487,  -8.0939,  -4.4835,  -6.2909,  -9.0114,  -8.4808,  -8.6966,
         -8.5763,  -8.3609,  -5.0678,  -8.6641,  -5.0774,   0.9503,  -3.3847,
        -10.4852,  -8.3014,  -8.2737,  -7.9998,  -6.6801,  -7.1592,  -7.1061,
         -9.7227,  -3.6669,  -9.2463,  -7.8146,  -7.8136,  -5.8302,  -8.1668,
         -6.6056,  -7.3879,  -9.0374,  -6.2660,  -9.5553,  -8.6141,  -7.1119,
         -8.4367,  -7.3255,  -9.2269,  -8.0679,  -7.4662,  -7.8003,  -8.2462,
         -7.9032,  -8.2273,  -7.5773,  -8.6231,  -0.1523,  -5.7907,  -4.6587,
         -7.0289,  -5.6894,  -9.0860,  -4.0466,  -6.6807,  -7.8992,  -9.1478,
         -7.8447,  -9.6161,  -6.5390,  -6.5371,  -6.6874,  -5.7662,  -6.9824,
         -9.6843,  -7.6051,  -7.6331,  -8.1898,  -6.2469, -10.3241,  -9.6205,
         -7.7657,  -8.0147,  -6.5287,  -9.4836,  -8.2199,  -9.9270,  -8.3575,
          0.6592, -10.0044,  -7.4571,  -9.4373,  -9.1644,  -8.6587,  -6.2400],
       device='cuda:0')
[03/08 09:56:00][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:02][INFO] train_net.py: 244: tensor([-8.1266, -6.0585, -4.5795, -6.6236, -7.3870, -6.4384, -7.4496, -6.2660,
        -6.0361, -6.2155, -7.3014, -8.0567, -6.0178, -3.4749, -5.9980, -6.5761,
        -5.1646, -7.9408, -7.1133, -6.6196, -8.2484, -5.7947, -5.8273, -7.8199,
        -7.8071, -4.5702, -6.4540, -4.2319, -7.2715, -6.6246, -6.8421, -7.8171,
        -5.8334, -6.7237, -7.9109, -6.6207, -7.6732, -7.4762, -4.3920, -8.0850,
         3.1861, -6.7541, -6.8411, -6.7699, -6.1720,  1.4578, -6.3141, -5.8236,
        -5.7225, -4.8137, -7.2898, -4.9565, -4.6673, -6.4484, -8.1298, -6.9881,
        -8.3754, -6.6441, -6.4218, -6.9789, -7.6962, -6.6691, -6.6667, -6.8288,
        -7.7678, -5.1086, -7.5410, -4.4665, -5.2716, -6.1886, -7.7174, -7.3391,
        -7.4519, -7.1831, -7.3367, -6.5455, -5.3731, -7.4574, -5.4854, -7.9255,
        -7.1521, -7.3554, -6.5018, -6.4712, -6.7679, -7.0850, -7.9174, -6.5861,
        -7.5130, -8.2304, -2.3856, -7.0362, -7.4350, -8.1034, -6.5123, -6.1552,
        -5.8740, -6.0737, -6.7096, -7.0368, -5.1756, -7.7136, -3.8154, -5.4157,
        -5.0883, -5.4897, -6.4487, -7.4811, -5.4426, -6.9702, -6.9867, -8.0813,
        -7.3541, -7.7090, -6.0783, -7.6700, -5.6918, -5.8373, -6.6166, -7.8428,
        -5.2889, -6.7555, -7.0180, -4.9532, -8.3221, -8.4083, -6.5685, -7.0118,
        -6.0326, -8.2513, -7.3468, -7.5778, -6.7273,  2.9965, -8.2947, -6.3611,
        -7.5434, -7.3330, -7.3688, -6.3529], device='cuda:0')
[03/08 09:56:02][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:04][INFO] train_net.py: 244: tensor([-8.4537, -3.8400, -5.9772, -8.4963, -8.7218, -5.7654, -7.9570, -5.2918,
        -4.6146, -6.9198, -7.9095, -7.4295, -7.7371, -5.6042, -7.1958, -5.9890,
        -5.9551, -8.9475, -8.3842, -7.4482, -8.0063, -6.1846, -6.7935, -8.6567,
        -8.6100, -5.6119, -6.7929, -7.4053, -4.5921, -7.3342, -7.3675, -8.3474,
        -6.2700, -7.5402, -8.8415, -7.8394, -7.6328, -6.1392, -6.6537, -7.8801,
        -2.7492, -6.4425, -5.6447, -7.6714, -6.8483, -4.9896, -6.8763, -5.9075,
        -5.8415, -6.0619, -8.5750, -2.9136, -6.7215, -8.6456, -7.3874, -7.8062,
        -8.3484, -8.0706, -7.1433, -8.3641, -8.3785, -7.7985, -7.8305, -8.0816,
        -7.4514, -6.3296, -7.3839, -5.7688, -4.3807, -6.7210, -9.7837, -7.0601,
        -8.5887, -8.0466, -7.3695, -7.3172, -7.5266, -8.3595, -5.4067, -8.8219,
        -7.5439, -7.9303, -8.2044, -7.3417, -7.6949, -7.1264, -9.0876, -6.6514,
        -7.6656, -9.4229, -6.3441, -7.4158, -7.5920, -8.2760, -7.7641, -7.7529,
        -6.7980, -6.0059, -7.2323, -7.9355, -6.2417, -7.9488, -5.0698, -6.6368,
        -5.8952, -7.6898, -7.7826, -6.9071, -7.3854, -8.1518, -7.8757, -9.2045,
        -7.0823, -8.9762, -6.5545, -8.3680, -6.6746, -7.0663, -7.7278, -8.4468,
        -5.8608, -5.1621, -7.2962,  3.4556, -8.9133, -9.3806, -8.2956, -8.1889,
        -6.0572, -9.3428, -7.7662, -8.7280, -7.5632, -6.0869, -9.8096, -7.5657,
        -8.4201, -8.3936, -7.7045, -6.9568], device='cuda:0')
[03/08 09:56:04][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:05][INFO] train_net.py: 244: tensor([-6.2076, -5.3272, -0.7960, -6.7560, -5.9322, -5.3735, -6.6089, -5.0332,
        -4.9192, -6.5096, -5.4185, -6.4463, -6.3775, -5.0036, -5.5266, -4.0753,
        -5.7892, -6.5714, -6.1683, -6.7337, -6.2296, -5.7845, -5.9300, -6.9003,
        -6.1519, -4.9835, -5.5004, -5.1366, -5.8421, -5.8135, -4.9805, -5.9476,
         0.6358, -1.8112, -5.6858, -5.9082, -5.7764, -5.7387, -4.7830, -5.9629,
         3.8857, -6.5078, -5.9169, -5.6593, -6.1146, -5.1934, -5.6179, -5.9357,
        -0.3659,  0.3979, -6.1180, -4.3249, -3.7317, -5.6262, -6.1102, -6.4239,
        -5.9309, -5.9531, -6.0782, -6.3785, -6.9825, -5.6796, -6.1209, -6.0614,
        -5.2945, -6.5074, -7.0076, -4.2489, -3.1490, -4.5805, -7.2685, -6.5686,
        -5.8636, -5.1319, -5.5308, -5.7733, -5.2978, -6.9072, -5.1350, -6.7353,
        -4.6472, -5.9520, -5.9048, -5.3794, -5.0800, -6.0898, -7.2377, -5.8855,
        -5.0858, -7.9251,  5.6293, -5.5705, -6.0537, -5.8685, -6.0306, -5.7782,
        -5.8838, -5.0681, -7.2047, -5.3136, -1.2334, -6.0817,  1.3561,  0.6409,
        -1.8967, -4.8498, -6.4113, -5.2640, -6.1094, -6.5447, -4.8741, -6.4291,
        -5.2751, -7.2903, -1.1734, -5.4469, -5.3156, -5.0263, -6.0162, -6.5302,
        -4.4974, -5.4375, -6.1591, -4.5266, -6.7086, -6.9227, -6.2698, -6.5389,
        -5.1636, -7.3947, -6.5447, -6.9251, -5.3918, -0.1480, -6.9631, -4.3191,
        -7.5500, -6.6861, -5.9644, -5.4674], device='cuda:0')
[03/08 09:56:06][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:07][INFO] train_net.py: 244: tensor([-10.5317,  -7.4902,  -2.4386,  -6.9678, -10.1525,  -8.3291, -10.3806,
         -8.2771,  -8.4140,  -9.2132,  -7.3785,  -9.1388,  -8.0449,  -7.1050,
         -8.9870,  -7.3958,  -6.9858, -10.9291,  -9.8918,  -9.0593, -10.7848,
         -7.3562,  -8.8413, -10.4455, -10.1006,  -6.7895,  -7.5003,  -7.9046,
         -8.6857,  -8.8146,  -9.4798,  -9.4255,  -7.7795,  -8.6212, -11.0283,
         -7.9657, -10.0418,  -8.6417,  -5.0279,  -9.4524,  -5.5390,  -9.0217,
         -9.9463,  -9.6583,  -7.9582,  -4.5804,  -8.2028,  -7.4265,  -7.0310,
         -8.1973,  -9.8594,  -7.9048,  -7.3834,  -9.7126, -10.2759,  -9.2893,
        -10.7277,  -8.3954,  -6.3380,  -9.2867, -10.0070,  -8.7103,  -8.8241,
         -9.9190,  -9.4099,  -7.6776,  -9.5163,  -4.4824,  -0.1365,  -7.4249,
        -10.8696,  -9.0418,  -9.2014,  -8.7087,  -7.3410,  -7.8299,  -7.7086,
        -10.0398,  -6.0664, -10.2087,  -9.0289,  -8.9185,  -7.8463,  -9.0739,
         -7.6722,  -8.8525, -10.2368,  -8.3926,  -9.8791, -10.3670,  -6.8809,
         -8.9735,  -9.5994, -10.2200,  -8.2878,  -8.4139,  -7.6530,  -7.8529,
         -8.9365,  -9.0185,  -4.4540,  -9.1068,  -1.8612,  -6.5056,  -5.7422,
         -8.9612,  -8.4423, -10.2061,  -5.9212,  -7.2049,  -9.4002, -10.0637,
         -7.7235, -10.5893,  -8.8365,  -8.5783,  -6.8352,  -8.0091,  -8.3638,
        -10.1295,  -8.2119,  -9.5493,  -8.6148,  -8.0338, -11.0752, -10.4972,
         -8.7352,  -9.2693,  -5.3769, -10.7241,  -9.6186, -10.4649,  -9.2132,
         -0.7852, -10.9547,  -8.4096,  -9.3614,  -9.6824,  -9.9227,  -7.2976],
       device='cuda:0')
[03/08 09:56:07][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:09][INFO] train_net.py: 244: tensor([ -8.8579,  -6.2408,   1.9299,  -7.3467,  -8.7546,  -7.1040,  -8.0727,
         -6.9157,  -6.2482,  -7.4318,  -6.6185,  -7.9986,  -7.3626,  -5.8585,
         -7.9656,   4.3437,  -6.8688,  -9.3810,  -8.7817,  -7.9129,  -8.6038,
         -7.2773,   0.0110,  -9.2239,  -9.5972,  -7.2040,  -6.9691,  -6.9613,
         -6.9553,  -7.5470,  -8.2620,  -8.2086,  -7.2302,  -6.7319,  -9.4765,
         -7.6237,  -8.9092,  -7.4761,  -6.3234,  -8.5833,  -4.8421,  -7.7083,
         -7.6948,  -7.8168,  -7.0279,  -6.4257,  -7.0122,  -6.0920,  -5.5933,
         -6.0586,  -9.2871,  -6.6127,  -5.8902,  -9.0134,  -8.8644,  -8.5232,
         -8.3738,  -8.6548,  -6.6338,  -7.2832,  -8.9823,  -8.2252,  -6.7945,
         -8.2381,  -7.1145,  -6.8818,  -7.2408,  -5.5768,   1.6630,  -5.3412,
        -10.1470,  -7.6891,  -8.2933,  -8.0188,  -7.1976,  -6.5156,  -7.5496,
         -9.8157,  -5.2890,  -7.5805,  -6.9622,  -7.3773,  -7.9548,  -8.1264,
         -7.0538,  -8.6527,  -9.1955,  -7.7245,  -8.7095,  -9.5592,  -6.2789,
         -7.9818,  -7.6586,  -8.9872,  -7.8545,  -7.2176,  -7.2168,  -6.3334,
         -7.8673,  -7.4288,  -6.4317,  -7.8717,   0.6294,  -6.5486,  -6.2222,
         -6.9155,  -7.9868,  -8.1425,  -6.6801,  -8.0251,  -7.3919,  -9.2841,
         -7.0485,  -9.8093,  -7.1791,  -7.3149,  -6.8301,  -7.8874,  -6.7704,
         -8.0772,  -6.5476,  -8.3653,  -7.1492,  -6.4395,  -9.4984,  -9.4340,
         -7.7557,  -7.3028,  -6.5089,  -9.6264,  -8.5455,  -9.0181,  -7.0699,
         -4.9872,  -9.9189,  -7.0169,  -8.8604,  -8.8024,  -8.3104,  -7.4207],
       device='cuda:0')
[03/08 09:56:09][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:50", "gpu_mem": "3.53G", "iter": "30/96", "time_diff": 1.67000}
[03/08 09:56:11][INFO] train_net.py: 244: tensor([ -8.8114,  -7.2900,  -1.2497,  -7.2141,  -8.9064,  -7.7720,  -8.3535,
         -6.9687,  -6.5296,  -7.2046,  -6.7086,  -7.4008,  -7.8559,  -6.6844,
         -8.0950,  -0.2864,  -7.5095,  -9.1845,  -8.3565,  -8.5957,  -8.5786,
         -7.5489,  -5.4520,  -8.3481,  -8.4929,  -6.4438,  -7.1781,  -7.4022,
         -6.5685,  -6.9942,  -5.9443,  -8.3216,  -7.9031,  -7.2186,  -9.1563,
         -7.4779,  -8.4597,  -7.3081,  -6.9277,  -8.5135,  -7.3626,  -7.4556,
         -8.1057,  -8.0933,  -6.9084,  -7.0654,  -7.4268,  -7.4009,  -8.1965,
         -3.5099,  -8.5308,  -7.1675,  -5.1874,  -8.5074,  -8.7954,  -8.1865,
         -9.0289,  -8.2940,  -7.0566,  -7.9419,  -9.0288,  -7.2171,  -7.3723,
         -9.0374,  -3.8915,  -6.9190,  -6.9896,  -5.0420,  -2.1496,  -3.9536,
        -10.2614,  -7.7306,  -8.1990,  -8.3334,  -6.9988,  -6.9273,  -6.3506,
         -9.2389,  -5.8982,  -8.1068,  -7.1179,  -7.9232,  -8.2106,  -8.2930,
         -8.1417,  -8.5177,  -9.4139,  -7.1843,  -8.4932,  -9.3171,  -6.7368,
         -8.0756,  -8.7923,  -9.0488,  -6.2202,  -6.1022,  -7.0227,  -6.9921,
         -7.1124,  -7.3626,  -7.8884,  -8.3829,   0.5650,  -5.8371,  -8.9765,
         -7.8182,  -7.3353,  -7.8730,  -6.3158,  -7.0200,  -6.8495,  -9.0428,
         -6.4136, -10.2336,  -7.0253,  -6.6126,  -7.7744,  -7.4381,  -6.2931,
         -8.1151,  -7.4907,  -8.0138,  -7.8601,  -5.6395,  -9.0673,  -8.9400,
         -8.1412,  -7.7395,  -5.3179,  -9.4185,  -8.4033,  -9.1975,  -5.7201,
         -6.4937,  -9.8271,  -7.9818,  -8.3334,  -8.0326,  -8.0142,  -6.9180],
       device='cuda:0')
[03/08 09:56:11][INFO] train_net.py: 245: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:12][INFO] train_net.py: 244: tensor([-7.0002, -4.8709, -3.0346, -5.9354, -6.7629, -5.2443, -7.1304, -5.8898,
        -4.9408, -6.8952, -5.5416, -6.1318, -5.9171, -5.0049, -5.5075, -3.9255,
        -5.4456, -6.5535, -6.4539, -6.5156, -6.9578, -6.5223, -6.8065, -7.4984,
        -6.9083, -4.7277, -5.6905, -4.1011, -5.7174, -5.4081, -5.6171, -5.9214,
         2.0721, -3.8808, -6.2227, -5.6755, -6.1232, -5.6648, -3.9332, -5.9748,
        -2.5976, -6.1784, -6.0547, -5.9840, -6.0479, -4.6183, -4.9485, -5.8004,
        -3.6078,  0.2772, -6.1688, -4.6851,  1.2616, -6.0027, -5.9578, -6.5187,
        -6.8812, -4.7912, -5.8660, -6.1107, -6.8980, -6.0643, -6.5439, -7.0935,
        -4.9227, -6.6340, -7.2706, -3.4152,  0.3944, -3.3083, -7.0900, -6.7812,
        -6.7883, -5.9346, -5.6124, -5.8132, -5.9905, -7.1123, -5.1833, -6.9749,
        -5.7409, -5.9689, -5.8016, -5.6626, -4.8845, -5.9614, -6.9500, -6.4467,
        -5.7720, -7.2275,  3.2098, -5.6751, -6.3247, -6.3533, -5.7757, -6.0309,
        -5.5139, -4.6726, -7.5664, -4.9740,  0.3398, -5.4110,  1.4857, -2.5492,
        -3.4736, -5.4892, -5.8492, -5.9809, -6.3450, -6.1536, -5.8329, -6.9767,
        -5.5258, -6.7864, -3.3719, -5.7604, -5.0019, -6.0233, -6.1784, -7.1319,
        -4.9472, -5.6149, -6.5172, -3.4508, -7.2723, -7.1606, -6.6865, -6.5284,
        -4.7286, -8.2468, -6.5300, -7.1606, -5.4289,  3.5772, -7.8512, -4.5072,
        -6.7886, -6.7905, -6.8531, -5.2064], device='cuda:0')
[03/08 09:56:13][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 09:56:14][INFO] train_net.py: 244: tensor([ -9.0115,  -6.6622,   0.4329,  -7.1126,  -9.2939,  -8.3345,  -8.8335,
         -5.6533,  -6.2506,  -8.3296,  -5.2685,  -8.3111,  -8.4693,  -8.0882,
         -7.2677,  -6.4363,  -7.3713,  -9.9024,  -9.2711,  -7.7587,  -9.1604,
         -4.8843,  -7.9939,  -9.8969,  -9.8683,  -7.2471,  -8.9871,  -8.2829,
         -8.7925,  -8.8667,  -8.1276,  -9.0962,  -8.0516,  -7.7409,  -9.8891,
         -8.6809,  -8.8479,  -7.7146,  -7.7813,  -9.1097,  -0.8888,  -8.4684,
         -8.3850,  -8.1160,  -6.3766,  -6.6615,  -8.8978,  -7.5766,  -4.6152,
         -7.1163,  -9.2261,  -6.4019,  -5.4071,  -8.6564,  -9.9736,  -8.8997,
         -9.4445,  -9.3925,  -3.4493,  -8.8818,  -9.4695,  -8.2467,  -6.4000,
         -9.0107,  -8.7312,  -8.5456,  -7.5172,  -6.6000,  -0.6236,  -5.7755,
        -10.6820,  -8.4702,  -7.4496,  -6.0018,  -7.1694,  -7.3432,  -7.5044,
         -9.4111,  -3.5510,  -8.9120,  -7.9993,  -7.6849,  -7.6668,  -8.5079,
         -8.3513,  -7.4498,  -9.1431,  -8.5961,  -8.0848, -10.6107,  -6.5870,
         -7.5650,  -8.4298,  -9.3363,  -7.8635,  -8.0991,  -7.7292,  -7.2257,
         -8.3438,  -7.6199,  -6.4524,  -8.0168,  -3.0565,  -6.4662,  -4.6940,
         -7.6351,  -8.8672,  -8.4443,  -7.1349,  -7.1705,  -8.8956,  -8.7818,
         -6.3587, -10.1001,  -7.3379,  -7.8056,  -8.1382,  -7.6004,  -6.4626,
         -8.7626,  -7.2642,  -8.7730,  -8.0589,  -7.7326,  -9.7916,  -9.7109,
         -8.1245,  -8.2759,  -7.6773,  -9.7279,  -9.4986,  -9.6342,  -7.6100,
         -5.6660,  -9.1144,  -8.2522,  -8.8824,  -8.6889,  -8.8554,  -4.6303],
       device='cuda:0')
[03/08 09:56:14][INFO] train_net.py: 245: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', dtype=torch.float64)
[03/08 10:03:34][INFO] train_net.py: 403: Train with config:
[03/08 10:03:34][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:34][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:34][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:34][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:34][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:03:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:03:35][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:03:35][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:03:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:03:35][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:03:35][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:03:35][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:03:36][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:03:36][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:03:36][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:03:36][INFO] misc.py: 187: Flops: 0 G
[03/08 10:03:36][INFO] misc.py: 192: Activations: 0 M
[03/08 10:03:36][INFO] misc.py: 197: nvidia-smi
[03/08 10:03:37][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:03:37][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:03:37][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:03:39][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:03:39][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:03:39][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:03:39][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:03:39][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:03:39][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:03:39][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:04:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96911, "dt_data": 1.37157, "dt_net": 1.59753, "epoch": "36/55", "eta": "6:10:38", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 10:07:10][INFO] train_net.py: 403: Train with config:
[03/08 10:07:10][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:07:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:07:11][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:07:11][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:07:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:07:11][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:07:11][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:07:11][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:07:12][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:07:12][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:07:12][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:07:12][INFO] misc.py: 187: Flops: 0 G
[03/08 10:07:12][INFO] misc.py: 192: Activations: 0 M
[03/08 10:07:12][INFO] misc.py: 197: nvidia-smi
[03/08 10:07:13][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:07:13][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:07:13][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:07:15][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:07:15][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:07:15][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:07:15][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:07:15][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:07:15][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:07:15][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:07:54][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f00382cb850>
[03/08 10:07:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25707, "dt_data": 1.33458, "dt_net": 1.92248, "epoch": "36/55", "eta": "6:46:35", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": NaN}
[03/08 10:08:28][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f00382cb850>
[03/08 10:08:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71041, "dt_data": 1.18820, "dt_net": 2.52220, "epoch": "36/55", "eta": "7:42:33", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02047, "lr": 0.00000, "mAP": NaN}
[03/08 10:09:05][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f00382cb850>
[03/08 10:09:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95717, "dt_data": 0.02516, "dt_net": 3.93201, "epoch": "36/55", "eta": "8:12:40", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01921, "lr": 0.00000, "mAP": NaN}
[03/08 10:09:40][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f00382cb850>
[03/08 10:09:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72650, "dt_data": 0.02509, "dt_net": 3.70141, "epoch": "36/55", "eta": "7:43:19", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02050, "lr": 0.00000, "mAP": NaN}
[03/08 10:10:14][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f00382cb850>
[03/08 10:10:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09839, "dt_data": 0.02506, "dt_net": 4.07333, "epoch": "36/55", "eta": "8:28:52", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02056, "lr": 0.00000, "mAP": NaN}
[03/08 10:10:50][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f00382cb850>
[03/08 10:10:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.62387, "dt_data": 0.02518, "dt_net": 2.59868, "epoch": "36/55", "eta": "5:25:21", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02096, "lr": 0.00000, "mAP": NaN}
[03/08 10:11:22][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f00382cb850>
[03/08 10:11:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04276, "dt_data": 0.02505, "dt_net": 3.01771, "epoch": "36/55", "eta": "6:16:47", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01945, "lr": 0.00000, "mAP": NaN}
[03/08 10:14:51][INFO] train_net.py: 403: Train with config:
[03/08 10:14:51][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:14:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:14:52][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:14:52][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:14:52][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:14:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:14:52][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:14:52][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:14:52][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:14:54][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:14:54][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:14:54][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:14:54][INFO] misc.py: 187: Flops: 0 G
[03/08 10:14:54][INFO] misc.py: 192: Activations: 0 M
[03/08 10:14:54][INFO] misc.py: 197: nvidia-smi
[03/08 10:14:54][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:14:54][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:14:54][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:14:56][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:14:56][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:14:56][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:14:56][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:14:56][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:14:56][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:14:56][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:15:05][INFO] meters.py: 539: 0
[03/08 10:15:07][INFO] meters.py: 539: 0
[03/08 10:15:11][INFO] meters.py: 539: 0
[03/08 10:15:14][INFO] meters.py: 539: 0
[03/08 10:15:18][INFO] meters.py: 539: 0
[03/08 10:15:22][INFO] meters.py: 539: 0
[03/08 10:15:25][INFO] meters.py: 539: 0
[03/08 10:15:29][INFO] meters.py: 539: 0
[03/08 10:15:32][INFO] meters.py: 539: 0
[03/08 10:15:36][INFO] meters.py: 539: 0
[03/08 10:15:36][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f420818b8b0>
[03/08 10:15:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24629, "dt_data": 0.77861, "dt_net": 2.46768, "epoch": "36/55", "eta": "6:45:14", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:15:39][INFO] meters.py: 539: 0
[03/08 10:15:42][INFO] meters.py: 539: 0
[03/08 10:16:32][INFO] train_net.py: 403: Train with config:
[03/08 10:16:32][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:16:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:16:33][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:16:33][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:16:33][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:16:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:16:33][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:16:34][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:16:34][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:16:34][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:16:34][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:16:34][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:16:35][INFO] misc.py: 187: Flops: 0 G
[03/08 10:16:35][INFO] misc.py: 192: Activations: 0 M
[03/08 10:16:35][INFO] misc.py: 197: nvidia-smi
[03/08 10:16:35][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:16:35][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:16:35][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:16:37][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:16:37][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:16:37][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:16:37][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:16:37][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:16:37][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:16:37][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:16:46][INFO] meters.py: 539: 0.9743464052287583
[03/08 10:16:48][INFO] meters.py: 539: 0.9554673721340389
[03/08 10:16:52][INFO] meters.py: 539: 0.9790816326530613
[03/08 10:16:56][INFO] meters.py: 539: 0.9731060606060605
[03/08 10:16:59][INFO] meters.py: 539: 0.9203787878787878
[03/08 10:17:03][INFO] meters.py: 539: 0.8258571428571428
[03/08 10:17:06][INFO] meters.py: 539: 0.9447089947089948
[03/08 10:17:10][INFO] meters.py: 539: 0.920098316035816
[03/08 10:17:14][INFO] meters.py: 539: 0.9147546897546897
[03/08 10:17:17][INFO] meters.py: 539: 0.9873015873015873
[03/08 10:17:17][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f547818f880>
[03/08 10:17:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01133, "dt_data": 0.83754, "dt_net": 2.17378, "epoch": "36/55", "eta": "6:15:54", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": 0.95009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:17:21][INFO] meters.py: 539: 0.7988624338624338
[03/08 10:17:24][INFO] meters.py: 539: 0.9083382936507935
[03/08 10:17:28][INFO] meters.py: 539: 0.909126984126984
[03/08 10:17:30][INFO] meters.py: 539: 0.922420634920635
[03/08 10:17:33][INFO] meters.py: 539: 0.9644862836438924
[03/08 10:17:36][INFO] meters.py: 539: 0.9922619047619047
[03/08 10:17:40][INFO] meters.py: 539: 0.9328231292517006
[03/08 10:17:44][INFO] meters.py: 539: 0.9314659197012138
[03/08 10:17:47][INFO] meters.py: 539: 0.967099567099567
[03/08 10:17:50][INFO] meters.py: 539: 0.9214814814814815
[03/08 10:17:50][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f547818f880>
[03/08 10:17:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61822, "dt_data": 1.92172, "dt_net": 1.69650, "epoch": "36/55", "eta": "7:31:04", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02047, "lr": 0.00000, "mAP": 0.92694, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:17:55][INFO] meters.py: 539: 0.9601851851851853
[03/08 10:17:58][INFO] meters.py: 539: 0.986115520282187
[03/08 10:18:01][INFO] meters.py: 539: 0.9752834467120183
[03/08 10:18:58][INFO] train_net.py: 403: Train with config:
[03/08 10:18:58][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:18:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:59][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:59][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:59][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:59][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:59][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:18:59][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:18:59][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:18:59][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:18:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:18:59][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:18:59][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:18:59][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:19:01][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:19:01][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:19:01][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:19:01][INFO] misc.py: 187: Flops: 0 G
[03/08 10:19:01][INFO] misc.py: 192: Activations: 0 M
[03/08 10:19:01][INFO] misc.py: 197: nvidia-smi
[03/08 10:19:01][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:19:01][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:19:01][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:19:03][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:19:03][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:19:03][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:19:03][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:19:03][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:19:03][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:19:03][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:19:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:35", "gpu_mem": "3.53G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.80654, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:20:47][INFO] train_net.py: 403: Train with config:
[03/08 10:20:47][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:20:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:20:47][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:20:47][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:20:47][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:20:47][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:20:48][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:20:48][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:20:48][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:20:48][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:20:49][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:20:49][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:20:49][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:20:49][INFO] misc.py: 187: Flops: 0 G
[03/08 10:20:49][INFO] misc.py: 192: Activations: 0 M
[03/08 10:20:49][INFO] misc.py: 197: nvidia-smi
[03/08 10:20:50][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:20:50][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:20:50][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:20:52][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:20:52][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:20:52][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:20:52][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:20:52][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:20:52][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:20:52][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:21:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:36", "gpu_mem": "3.53G", "iter": "10/96", "mAP": 0.00000, "time_diff": 1.81639, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:21:58][INFO] train_net.py: 403: Train with config:
[03/08 10:21:58][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:21:58][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:21:58][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:21:58][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:21:58][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:21:58][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:21:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:21:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:21:59][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:21:59][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:21:59][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:21:59][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:22:00][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:22:00][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:22:00][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:22:00][INFO] misc.py: 187: Flops: 0 G
[03/08 10:22:00][INFO] misc.py: 192: Activations: 0 M
[03/08 10:22:00][INFO] misc.py: 197: nvidia-smi
[03/08 10:22:01][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:22:01][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:22:01][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:22:02][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:22:02][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:22:02][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:22:02][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:22:02][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:22:03][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:22:03][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:24:16][INFO] train_net.py: 403: Train with config:
[03/08 10:24:16][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:24:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:24:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:24:17][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:24:17][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:24:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:24:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:24:18][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:24:18][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:24:18][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:24:19][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:24:19][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:24:19][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:24:19][INFO] misc.py: 187: Flops: 0 G
[03/08 10:24:19][INFO] misc.py: 192: Activations: 0 M
[03/08 10:24:19][INFO] misc.py: 197: nvidia-smi
[03/08 10:24:20][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:24:20][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 10:24:20][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/best.pyth.
[03/08 10:24:21][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:24:21][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:24:21][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:24:21][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:24:21][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:24:22][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:24:22][INFO] train_net.py: 446: Start epoch: 36
[03/08 10:24:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:34", "gpu_mem": "3.53G", "iter": "10/96", "mAP": 0.88623, "time_diff": 1.79182, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:25:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:02", "gpu_mem": "3.53G", "iter": "20/96", "mAP": 0.79304, "time_diff": 1.61327, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:25:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:57", "gpu_mem": "3.53G", "iter": "30/96", "mAP": 0.86664, "time_diff": 1.77558, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:25:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:53", "gpu_mem": "3.53G", "iter": "40/96", "mAP": 0.91429, "time_diff": 2.02473, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:25:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:29", "gpu_mem": "3.53G", "iter": "50/96", "mAP": 0.88266, "time_diff": 1.94261, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:26:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:11", "gpu_mem": "3.53G", "iter": "60/96", "mAP": 0.85736, "time_diff": 1.99611, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:26:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:00:41", "gpu_mem": "3.53G", "iter": "70/96", "mAP": 0.89343, "time_diff": 1.61534, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:26:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:00:26", "gpu_mem": "3.53G", "iter": "80/96", "mAP": 0.84879, "time_diff": 1.63924, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:27:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:00:12", "gpu_mem": "3.53G", "iter": "90/96", "mAP": 0.87487, "time_diff": 2.01465, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:27:14][INFO] logging.py:  99: json_stats: {"RAM": "21.90/251.55G", "_type": "val_epoch", "epoch": "36/55", "gpu_mem": "3.53G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:27:23][INFO] meters.py: 539: 0.9044817927170868
[03/08 10:27:25][INFO] meters.py: 539: 0.9809303350970018
[03/08 10:27:29][INFO] meters.py: 539: 0.9962747003563329
[03/08 10:27:33][INFO] meters.py: 539: 0.9004419191919191
[03/08 10:27:36][INFO] meters.py: 539: 0.9222222222222222
[03/08 10:27:40][INFO] meters.py: 539: 0.9145833333333334
[03/08 10:27:43][INFO] meters.py: 539: 0.9378858024691357
[03/08 10:27:47][INFO] meters.py: 539: 0.9091149376417232
[03/08 10:27:50][INFO] meters.py: 539: 0.8361562049062049
[03/08 10:27:53][INFO] meters.py: 539: 0.9813888888888889
[03/08 10:27:53][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f93b437b8b0>
[03/08 10:27:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43105, "dt_data": 2.44129, "dt_net": 0.98977, "epoch": "36/55", "eta": "7:08:18", "gpu_mem": "17.36G", "iter": "10/375", "loss": 0.01976, "lr": 0.00000, "mAP": 0.91840, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:27:56][INFO] meters.py: 539: 0.8774074074074075
[03/08 10:27:59][INFO] meters.py: 539: 0.986388888888889
[03/08 10:28:03][INFO] meters.py: 539: 0.8825396825396824
[03/08 10:28:06][INFO] meters.py: 539: 0.8251704545454543
[03/08 10:28:09][INFO] meters.py: 539: 0.9543478260869565
[03/08 10:28:12][INFO] meters.py: 539: 0.9821428571428571
[03/08 10:28:15][INFO] meters.py: 539: 0.7129818594104308
[03/08 10:28:18][INFO] meters.py: 539: 0.8559254471019176
[03/08 10:28:21][INFO] meters.py: 539: 0.9774621212121212
[03/08 10:28:26][INFO] meters.py: 539: 0.9332828282828284
[03/08 10:28:26][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f93b437b8b0>
[03/08 10:28:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.15533, "dt_data": 2.70355, "dt_net": 1.45178, "epoch": "36/55", "eta": "8:38:01", "gpu_mem": "17.36G", "iter": "20/375", "loss": 0.02123, "lr": 0.00000, "mAP": 0.90791, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:28:28][INFO] meters.py: 539: 0.9320216049382716
[03/08 10:28:32][INFO] meters.py: 539: 0.9635185185185186
[03/08 10:28:36][INFO] meters.py: 539: 0.9075850340136055
[03/08 10:28:39][INFO] meters.py: 539: 0.9877604166666667
[03/08 10:28:42][INFO] meters.py: 539: 0.8556818181818181
[03/08 10:28:46][INFO] meters.py: 539: 0.8525843253968254
[03/08 10:28:50][INFO] meters.py: 539: 0.9345203373015872
[03/08 10:28:54][INFO] meters.py: 539: 0.9788624338624339
[03/08 10:28:58][INFO] meters.py: 539: 0.9935087719298245
[03/08 10:29:02][INFO] meters.py: 539: 0.9880840773809524
[03/08 10:29:02][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f93b437b8b0>
[03/08 10:29:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90126, "dt_data": 0.02518, "dt_net": 3.87608, "epoch": "36/55", "eta": "8:05:42", "gpu_mem": "17.36G", "iter": "30/375", "loss": 0.01948, "lr": 0.00000, "mAP": 0.94902, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:29:05][INFO] meters.py: 539: 0.9545989974937342
[03/08 10:29:08][INFO] meters.py: 539: 0.9084763649049362
[03/08 10:29:12][INFO] meters.py: 539: 0.937938596491228
[03/08 10:29:16][INFO] meters.py: 539: 0.8848148148148148
[03/08 10:29:19][INFO] meters.py: 539: 0.9444444444444445
[03/08 10:29:23][INFO] meters.py: 539: 0.8823721340388008
[03/08 10:29:26][INFO] meters.py: 539: 0.7853395061728395
[03/08 10:29:30][INFO] meters.py: 539: 0.9898726851851853
[03/08 10:29:33][INFO] meters.py: 539: 0.9028061224489796
[03/08 10:29:37][INFO] meters.py: 539: 0.942085137085137
[03/08 10:29:37][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f93b437b8b0>
[03/08 10:29:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53137, "dt_data": 0.02505, "dt_net": 3.50631, "epoch": "36/55", "eta": "7:19:04", "gpu_mem": "17.36G", "iter": "40/375", "loss": 0.02119, "lr": 0.00000, "mAP": 0.92321, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:29:40][INFO] meters.py: 539: 0.9199999999999999
[03/08 10:29:44][INFO] meters.py: 539: 0.9281084656084657
[03/08 10:29:47][INFO] meters.py: 539: 0.8140598663707906
[03/08 10:29:51][INFO] meters.py: 539: 0.9896739130434781
[03/08 10:29:54][INFO] meters.py: 539: 0.9207589285714286
[03/08 10:29:57][INFO] meters.py: 539: 0.9588095238095237
[03/08 10:30:01][INFO] meters.py: 539: 0.9294101731601732
[03/08 10:30:04][INFO] meters.py: 539: 0.9195190356844493
[03/08 10:30:07][INFO] meters.py: 539: 0.891156462585034
[03/08 10:30:10][INFO] meters.py: 539: 0.9438721827114684
[03/08 10:30:10][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f93b437b8b0>
[03/08 10:30:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34909, "dt_data": 0.02517, "dt_net": 3.32392, "epoch": "36/55", "eta": "6:55:50", "gpu_mem": "17.36G", "iter": "50/375", "loss": 0.02071, "lr": 0.00000, "mAP": 0.92443, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:30:14][INFO] meters.py: 539: 0.9446666666666667
[03/08 10:30:17][INFO] meters.py: 539: 0.9686403508771931
[03/08 10:30:21][INFO] meters.py: 539: 0.9383386243386241
[03/08 10:30:24][INFO] meters.py: 539: 0.9286398467432949
[03/08 10:30:28][INFO] meters.py: 539: 0.8754677113010446
[03/08 10:30:31][INFO] meters.py: 539: 0.9666666666666666
[03/08 10:30:33][INFO] meters.py: 539: 0.9904411764705882
[03/08 10:30:37][INFO] meters.py: 539: 0.9573412698412698
[03/08 10:31:24][INFO] train_net.py: 403: Train with config:
[03/08 10:31:24][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:31:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:31:25][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:31:25][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:31:25][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:31:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:31:25][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:31:26][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:31:26][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:31:27][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:31:27][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:31:27][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:31:27][INFO] misc.py: 187: Flops: 0 G
[03/08 10:31:27][INFO] misc.py: 192: Activations: 0 M
[03/08 10:31:27][INFO] misc.py: 197: nvidia-smi
[03/08 10:31:27][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:31:27][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:31:27][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:31:28][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:31:28][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:31:28][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:31:28][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:31:28][INFO] train_net.py: 446: Start epoch: 1
[03/08 10:31:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:02:54", "gpu_mem": "2.52G", "iter": "10/96", "mAP": 0.21971, "time_diff": 2.02906, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:32:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/55", "eta": "0:01:59", "gpu_mem": "2.52G", "iter": "20/96", "mAP": 0.22363, "time_diff": 1.56914, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:32:47][INFO] train_net.py: 403: Train with config:
[03/08 10:32:47][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 10:32:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:47][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:47][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:47][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 10:32:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 10:32:48][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 10:32:48][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 10:32:48][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 10:32:48][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 10:32:48][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 10:32:48][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 10:32:49][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 10:32:49][INFO] misc.py: 185: Params: 133,343,372
[03/08 10:32:49][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 10:32:49][INFO] misc.py: 187: Flops: 0 G
[03/08 10:32:49][INFO] misc.py: 192: Activations: 0 M
[03/08 10:32:49][INFO] misc.py: 197: nvidia-smi
[03/08 10:32:50][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 10:32:50][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 10:32:50][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:32:50][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 10:32:50][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 10:32:50][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:32:50][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 10:32:50][INFO] train_net.py: 446: Start epoch: 1
[03/08 10:32:59][INFO] meters.py: 539: 0.258292958930714
[03/08 10:33:02][INFO] meters.py: 539: 0.2090074112395541
[03/08 10:33:05][INFO] meters.py: 539: 0.27041540470111897
[03/08 10:33:09][INFO] meters.py: 539: 0.26059694273979983
[03/08 10:33:12][INFO] meters.py: 539: 0.25399510982844314
[03/08 10:33:16][INFO] meters.py: 539: 0.24182380119880115
[03/08 10:33:20][INFO] meters.py: 539: 0.241820516085222
[03/08 10:33:24][INFO] meters.py: 539: 0.23999574499574503
[03/08 10:33:28][INFO] meters.py: 539: 0.2569310126601793
[03/08 10:33:32][INFO] meters.py: 539: 0.3376893939393939
[03/08 10:33:32][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:33:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72366, "dt_data": 0.05687, "dt_net": 3.66680, "epoch": "1/55", "eta": "21:19:23", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.68755, "lr": 0.00000, "mAP": 0.25546, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:33:35][INFO] meters.py: 539: 0.1996779735416099
[03/08 10:33:39][INFO] meters.py: 539: 0.21837090378757046
[03/08 10:33:42][INFO] meters.py: 539: 0.28770724425486327
[03/08 10:33:45][INFO] meters.py: 539: 0.3029264230944903
[03/08 10:33:48][INFO] meters.py: 539: 0.2978924721112221
[03/08 10:33:51][INFO] meters.py: 539: 0.2464093877137355
[03/08 10:33:55][INFO] meters.py: 539: 0.26161536611536607
[03/08 10:33:59][INFO] meters.py: 539: 0.2246635182998819
[03/08 10:34:01][INFO] meters.py: 539: 0.23445795459684352
[03/08 10:34:05][INFO] meters.py: 539: 0.21935989935989936
[03/08 10:34:05][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:34:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28771, "dt_data": 1.86469, "dt_net": 1.42301, "epoch": "1/55", "eta": "18:49:03", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.54518, "lr": 0.00000, "mAP": 0.24043, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:34:08][INFO] meters.py: 539: 0.3424686794686795
[03/08 10:34:12][INFO] meters.py: 539: 0.22513503361717646
[03/08 10:34:15][INFO] meters.py: 539: 0.20666715229215227
[03/08 10:34:19][INFO] meters.py: 539: 0.19130305968541264
[03/08 10:34:23][INFO] meters.py: 539: 0.3115339396053682
[03/08 10:34:27][INFO] meters.py: 539: 0.28069277828652833
[03/08 10:34:30][INFO] meters.py: 539: 0.25012475949975954
[03/08 10:34:33][INFO] meters.py: 539: 0.2192661703375989
[03/08 10:34:37][INFO] meters.py: 539: 0.22238799306107
[03/08 10:34:41][INFO] meters.py: 539: 0.2581826969326969
[03/08 10:34:41][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:34:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50722, "dt_data": 0.02531, "dt_net": 3.48191, "epoch": "1/55", "eta": "20:03:51", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.44107, "lr": 0.00000, "mAP": 0.23763, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:34:44][INFO] meters.py: 539: 0.20096604784104785
[03/08 10:34:47][INFO] meters.py: 539: 0.20891636141636144
[03/08 10:34:50][INFO] meters.py: 539: 0.1952871335014192
[03/08 10:34:53][INFO] meters.py: 539: 0.3372171395855606
[03/08 10:34:57][INFO] meters.py: 539: 0.3403288297853515
[03/08 10:35:01][INFO] meters.py: 539: 0.3165371780996781
[03/08 10:35:04][INFO] meters.py: 539: 0.29818186715245537
[03/08 10:35:07][INFO] meters.py: 539: 0.2114191948402475
[03/08 10:35:10][INFO] meters.py: 539: 0.2908351569065855
[03/08 10:35:14][INFO] meters.py: 539: 0.282904163996601
[03/08 10:35:14][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:35:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58104, "dt_data": 1.18367, "dt_net": 2.39737, "epoch": "1/55", "eta": "20:28:35", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.36865, "lr": 0.00000, "mAP": 0.28687, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:35:17][INFO] meters.py: 539: 0.21145412920412923
[03/08 10:35:20][INFO] meters.py: 539: 0.3668917502250835
[03/08 10:35:24][INFO] meters.py: 539: 0.2943463282748997
[03/08 10:35:28][INFO] meters.py: 539: 0.26642950752950756
[03/08 10:35:32][INFO] meters.py: 539: 0.31245501574448936
[03/08 10:35:35][INFO] meters.py: 539: 0.23100133526604116
[03/08 10:35:38][INFO] meters.py: 539: 0.27313987863987865
[03/08 10:35:42][INFO] meters.py: 539: 0.28442035547298705
[03/08 10:35:46][INFO] meters.py: 539: 0.2699094655344655
[03/08 10:35:49][INFO] meters.py: 539: 0.21193391485058155
[03/08 10:35:49][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:35:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98371, "dt_data": 1.07244, "dt_net": 1.91126, "epoch": "1/55", "eta": "17:03:09", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.32475, "lr": 0.00000, "mAP": 0.27152, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:35:53][INFO] meters.py: 539: 0.1785409851586322
[03/08 10:35:56][INFO] meters.py: 539: 0.23154496067539543
[03/08 10:36:00][INFO] meters.py: 539: 0.2915000690447119
[03/08 10:36:03][INFO] meters.py: 539: 0.2817137677137677
[03/08 10:36:06][INFO] meters.py: 539: 0.21232995032598204
[03/08 10:36:10][INFO] meters.py: 539: 0.27083739673025387
[03/08 10:36:13][INFO] meters.py: 539: 0.2297787952787953
[03/08 10:36:17][INFO] meters.py: 539: 0.2544848256901828
[03/08 10:36:20][INFO] meters.py: 539: 0.3412280121838945
[03/08 10:36:24][INFO] meters.py: 539: 0.18511181279038422
[03/08 10:36:24][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:36:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53534, "dt_data": 1.82459, "dt_net": 1.71075, "epoch": "1/55", "eta": "20:11:44", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.30959, "lr": 0.00000, "mAP": 0.24301, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:36:27][INFO] meters.py: 539: 0.2576781749996036
[03/08 10:36:30][INFO] meters.py: 539: 0.2505176767676767
[03/08 10:36:34][INFO] meters.py: 539: 0.23886777904635048
[03/08 10:36:37][INFO] meters.py: 539: 0.2317583560230619
[03/08 10:36:41][INFO] meters.py: 539: 0.2795091945091944
[03/08 10:36:44][INFO] meters.py: 539: 0.1799995143745144
[03/08 10:36:47][INFO] meters.py: 539: 0.21246632418507416
[03/08 10:36:50][INFO] meters.py: 539: 0.2916614470185898
[03/08 10:36:53][INFO] meters.py: 539: 0.23781705412140192
[03/08 10:36:57][INFO] meters.py: 539: 0.33370529470529475
[03/08 10:36:57][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:36:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37362, "dt_data": 2.83799, "dt_net": 0.53563, "epoch": "1/55", "eta": "19:15:44", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.29698, "lr": 0.00000, "mAP": 0.24469, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:37:01][INFO] meters.py: 539: 0.2933279220779221
[03/08 10:37:04][INFO] meters.py: 539: 0.22783897319611607
[03/08 10:37:07][INFO] meters.py: 539: 0.22691259357926022
[03/08 10:37:11][INFO] meters.py: 539: 0.3209961219336219
[03/08 10:37:15][INFO] meters.py: 539: 0.3519885484885485
[03/08 10:37:18][INFO] meters.py: 539: 0.19625313575313577
[03/08 10:37:22][INFO] meters.py: 539: 0.17770062829586641
[03/08 10:37:25][INFO] meters.py: 539: 0.2440760123714669
[03/08 10:37:28][INFO] meters.py: 539: 0.21955451955451957
[03/08 10:37:31][INFO] meters.py: 539: 0.38168345543345544
[03/08 10:37:31][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:37:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13493, "dt_data": 2.59149, "dt_net": 0.54344, "epoch": "1/55", "eta": "17:53:27", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.28923, "lr": 0.00000, "mAP": 0.23596, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:37:35][INFO] meters.py: 539: 0.19253407600629818
[03/08 10:37:38][INFO] meters.py: 539: 0.35157809223743286
[03/08 10:37:42][INFO] meters.py: 539: 0.24274691358024686
[03/08 10:37:46][INFO] meters.py: 539: 0.19640692640692642
[03/08 10:37:49][INFO] meters.py: 539: 0.30782652918069586
[03/08 10:37:52][INFO] meters.py: 539: 0.2604793354793355
[03/08 10:37:56][INFO] meters.py: 539: 0.24245237086146176
[03/08 10:38:00][INFO] meters.py: 539: 0.20098134889801555
[03/08 10:38:02][INFO] meters.py: 539: 0.28422958620327043
[03/08 10:38:05][INFO] meters.py: 539: 0.26685754721469007
[03/08 10:38:05][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:38:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.49571, "dt_data": 2.95095, "dt_net": 0.54475, "epoch": "1/55", "eta": "19:56:24", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.28762, "lr": 0.00000, "mAP": 0.25161, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:38:09][INFO] meters.py: 539: 0.1940867103910582
[03/08 10:38:12][INFO] meters.py: 539: 0.23205124415733658
[03/08 10:38:15][INFO] meters.py: 539: 0.25497695206028537
[03/08 10:38:19][INFO] meters.py: 539: 0.29043648150791007
[03/08 10:38:22][INFO] meters.py: 539: 0.3099058638121138
[03/08 10:38:26][INFO] meters.py: 539: 0.24070832676095835
[03/08 10:38:29][INFO] meters.py: 539: 0.21233856421356423
[03/08 10:38:32][INFO] meters.py: 539: 0.19172660672660674
[03/08 10:38:35][INFO] meters.py: 539: 0.2412237544590486
[03/08 10:38:38][INFO] meters.py: 539: 0.2729723707664884
[03/08 10:38:38][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:38:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.86268, "dt_data": 2.31779, "dt_net": 0.54489, "epoch": "1/55", "eta": "16:19:16", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.28242, "lr": 0.00000, "mAP": 0.24097, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:38:41][INFO] meters.py: 539: 0.3072849372849373
[03/08 10:38:45][INFO] meters.py: 539: 0.2011658027962375
[03/08 10:38:49][INFO] meters.py: 539: 0.3181337335504002
[03/08 10:38:52][INFO] meters.py: 539: 0.26955964405964405
[03/08 10:38:55][INFO] meters.py: 539: 0.27353349428349427
[03/08 10:38:59][INFO] meters.py: 539: 0.3216114540221683
[03/08 10:39:01][INFO] meters.py: 539: 0.2166758946520851
[03/08 10:39:05][INFO] meters.py: 539: 0.21413839137053428
[03/08 10:39:08][INFO] meters.py: 539: 0.18605243675119454
[03/08 10:39:11][INFO] meters.py: 539: 0.24270338457838453
[03/08 10:39:11][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7fcbbc0d7700>
[03/08 10:39:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46033, "dt_data": 2.91781, "dt_net": 0.54251, "epoch": "1/55", "eta": "19:43:08", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.28262, "lr": 0.00000, "mAP": 0.25613, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 10:39:15][INFO] meters.py: 539: 0.23090468559218558
[03/08 11:16:08][INFO] train_net.py: 403: Train with config:
[03/08 11:16:08][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:16:08][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:16:08][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:08][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:16:09][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 11:16:09][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 11:16:09][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:16:09][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:16:09][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:16:09][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:16:09][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 11:16:09][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 11:16:09][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 11:16:10][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 11:16:10][INFO] misc.py: 185: Params: 133,343,372
[03/08 11:16:10][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 11:16:10][INFO] misc.py: 187: Flops: 0 G
[03/08 11:16:10][INFO] misc.py: 192: Activations: 0 M
[03/08 11:16:10][INFO] misc.py: 197: nvidia-smi
[03/08 11:16:11][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 11:16:11][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 11:16:11][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 11:16:12][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 11:16:12][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 11:16:12][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 11:16:12][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 11:16:12][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 11:16:12][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 11:16:12][INFO] train_net.py: 446: Start epoch: 36
[03/08 11:16:21][INFO] meters.py: 539: 0.9743464052287583
[03/08 11:16:23][INFO] meters.py: 539: 0.9554673721340389
[03/08 11:16:28][INFO] meters.py: 539: 0.9790816326530613
[03/08 11:16:31][INFO] meters.py: 539: 0.9731060606060605
[03/08 11:16:34][INFO] meters.py: 539: 0.9203787878787878
[03/08 11:18:02][INFO] train_net.py: 403: Train with config:
[03/08 11:18:02][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})
[03/08 11:18:02][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:02][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:02][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:02][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:02][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 11:18:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 11:18:03][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 11:18:03][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 11:18:03][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:18:03][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 11:18:04][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 11:18:04][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 11:18:04][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 11:18:05][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 11:18:05][INFO] misc.py: 185: Params: 133,343,372
[03/08 11:18:05][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 11:18:05][INFO] misc.py: 187: Flops: 0 G
[03/08 11:18:05][INFO] misc.py: 192: Activations: 0 M
[03/08 11:18:05][INFO] misc.py: 197: nvidia-smi
[03/08 11:18:06][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 11:18:06][INFO] checkpoint_amp.py: 566: Load from best checkpoint file.
[03/08 11:18:06][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 11:18:07][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 11:18:07][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 11:18:07][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 11:18:07][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 11:18:07][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 11:18:08][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 11:18:08][INFO] train_net.py: 446: Start epoch: 36
[03/08 11:18:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81827, "dt_data": 0.31750, "dt_net": 2.50077, "epoch": "36/55", "eta": "5:51:48", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01966, "lr": 0.00000, "mAP": 0.95009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:19:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55786, "dt_data": 1.88675, "dt_net": 1.67111, "epoch": "36/55", "eta": "7:23:32", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02047, "lr": 0.00000, "mAP": 0.92694, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:19:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.99305, "dt_data": 0.02531, "dt_net": 3.96775, "epoch": "36/55", "eta": "8:17:08", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01921, "lr": 0.00000, "mAP": 0.95357, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:20:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12072, "dt_data": 0.02516, "dt_net": 3.09556, "epoch": "36/55", "eta": "6:28:00", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02049, "lr": 0.00000, "mAP": 0.90850, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:21:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.15166, "dt_data": 0.02511, "dt_net": 4.12655, "epoch": "36/55", "eta": "8:35:29", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02056, "lr": 0.00000, "mAP": 0.91723, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:21:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.69458, "dt_data": 0.02519, "dt_net": 2.66939, "epoch": "36/55", "eta": "5:34:07", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02096, "lr": 0.00000, "mAP": 0.93450, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:22:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61580, "dt_data": 0.02501, "dt_net": 3.59079, "epoch": "36/55", "eta": "7:27:45", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01945, "lr": 0.00000, "mAP": 0.93501, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:22:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28818, "dt_data": 0.02509, "dt_net": 3.26309, "epoch": "36/55", "eta": "6:46:38", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02002, "lr": 0.00000, "mAP": 0.92685, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:23:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.78286, "dt_data": 3.24392, "dt_net": 0.53893, "epoch": "36/55", "eta": "7:47:10", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02116, "lr": 0.00000, "mAP": 0.91087, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:23:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72905, "dt_data": 3.19878, "dt_net": 0.53027, "epoch": "36/55", "eta": "7:39:54", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01914, "lr": 0.00000, "mAP": 0.89331, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:24:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.66274, "dt_data": 0.02522, "dt_net": 2.63752, "epoch": "36/55", "eta": "5:27:57", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02061, "lr": 0.00000, "mAP": 0.90726, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:25:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30534, "dt_data": 0.02514, "dt_net": 3.28020, "epoch": "36/55", "eta": "6:46:33", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02102, "lr": 0.00000, "mAP": 0.90662, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:25:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61445, "dt_data": 0.02524, "dt_net": 3.58921, "epoch": "36/55", "eta": "7:23:58", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02147, "lr": 0.00000, "mAP": 0.91157, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:26:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.01324, "dt_data": 0.02505, "dt_net": 3.98819, "epoch": "36/55", "eta": "8:12:17", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.02205, "lr": 0.00000, "mAP": 0.91425, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:26:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.43344, "dt_data": 0.02501, "dt_net": 2.40843, "epoch": "36/55", "eta": "4:58:05", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02134, "lr": 0.00000, "mAP": 0.91723, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:27:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52505, "dt_data": 0.02518, "dt_net": 3.49987, "epoch": "36/55", "eta": "7:11:13", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02109, "lr": 0.00000, "mAP": 0.92366, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:27:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28739, "dt_data": 0.02518, "dt_net": 3.26220, "epoch": "36/55", "eta": "6:41:36", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02127, "lr": 0.00000, "mAP": 0.91957, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:28:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10151, "dt_data": 0.02502, "dt_net": 3.07649, "epoch": "36/55", "eta": "6:18:23", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02030, "lr": 0.00000, "mAP": 0.90009, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:29:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63464, "dt_data": 1.95058, "dt_net": 1.68406, "epoch": "36/55", "eta": "7:22:49", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02084, "lr": 0.00000, "mAP": 0.94688, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:29:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.14945, "dt_data": 1.75361, "dt_net": 2.39583, "epoch": "36/55", "eta": "8:24:50", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02149, "lr": 0.00000, "mAP": 0.93058, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:30:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14979, "dt_data": 0.02842, "dt_net": 3.12137, "epoch": "36/55", "eta": "6:22:41", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02189, "lr": 0.00000, "mAP": 0.87556, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:30:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47252, "dt_data": 0.74669, "dt_net": 2.72583, "epoch": "36/55", "eta": "7:01:19", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02130, "lr": 0.00000, "mAP": 0.91134, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:31:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.15452, "dt_data": 0.16490, "dt_net": 2.98962, "epoch": "36/55", "eta": "6:22:13", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02030, "lr": 0.00000, "mAP": 0.94023, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:31:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.11603, "dt_data": 2.44995, "dt_net": 1.66608, "epoch": "36/55", "eta": "8:18:02", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.02121, "lr": 0.00000, "mAP": 0.87929, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:32:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23722, "dt_data": 2.69596, "dt_net": 0.54126, "epoch": "36/55", "eta": "6:31:09", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.02143, "lr": 0.00000, "mAP": 0.93891, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:33:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70836, "dt_data": 3.16581, "dt_net": 0.54255, "epoch": "36/55", "eta": "7:27:28", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02125, "lr": 0.00000, "mAP": 0.95371, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:33:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.40112, "dt_data": 3.86272, "dt_net": 0.53840, "epoch": "36/55", "eta": "8:50:20", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02022, "lr": 0.00000, "mAP": 0.94054, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:34:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68220, "dt_data": 3.13844, "dt_net": 0.54376, "epoch": "36/55", "eta": "7:23:05", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02071, "lr": 0.00000, "mAP": 0.94683, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:34:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02482, "dt_data": 2.48477, "dt_net": 0.54005, "epoch": "36/55", "eta": "6:03:28", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01936, "lr": 0.00000, "mAP": 0.87284, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:35:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02221, "dt_data": 3.48480, "dt_net": 0.53740, "epoch": "36/55", "eta": "8:02:39", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02087, "lr": 0.00000, "mAP": 0.91879, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:36:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.63296, "dt_data": 2.09159, "dt_net": 0.54137, "epoch": "36/55", "eta": "5:15:30", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02086, "lr": 0.00000, "mAP": 0.90447, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:36:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28784, "dt_data": 2.74644, "dt_net": 0.54140, "epoch": "36/55", "eta": "6:33:26", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02072, "lr": 0.00000, "mAP": 0.88982, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:37:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11550, "dt_data": 2.57428, "dt_net": 0.54122, "epoch": "36/55", "eta": "6:12:18", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01945, "lr": 0.00000, "mAP": 0.93332, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:37:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94622, "dt_data": 3.40723, "dt_net": 0.53899, "epoch": "36/55", "eta": "7:50:54", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02064, "lr": 0.00000, "mAP": 0.92336, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:38:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09191, "dt_data": 3.54714, "dt_net": 0.54477, "epoch": "36/55", "eta": "8:07:37", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.02070, "lr": 0.00000, "mAP": 0.93646, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:38:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19942, "dt_data": 2.65380, "dt_net": 0.54562, "epoch": "36/55", "eta": "6:20:43", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02061, "lr": 0.00000, "mAP": 0.92124, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:39:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36218, "dt_data": 2.33499, "dt_net": 1.02719, "epoch": "36/55", "eta": "6:39:32", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02068, "lr": 0.00000, "mAP": 0.92903, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:39:42][INFO] logging.py:  99: json_stats: {"RAM": "22.69/251.55G", "_type": "train_epoch", "dt": 0.00029, "dt_data": 0.00029, "dt_net": 2.26742, "epoch": "36/55", "eta": "0:00:01", "gpu_mem": "17.37G", "loss": 0.02079, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:39:42][INFO] train_net.py: 485: Epoch 35 takes 1294.79s. Epochs from 35 to 35 take 1294.79s in average and 1294.79s in median.
[03/08 11:39:42][INFO] train_net.py: 491: For epoch 35, each iteraction takes 3.45s in average. From epoch 35 to 35, each iteraction takes 3.45s in average.
[03/08 11:40:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:48", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.87733, "time_diff": 1.95947, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:40:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.80959, "time_diff": 1.70509, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:40:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:51", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.85718, "time_diff": 1.68819, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:41:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:49", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.91585, "time_diff": 1.95625, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:41:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:26", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.89403, "time_diff": 1.88291, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:41:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:01:13", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.88722, "time_diff": 2.04701, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:41:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:00:41", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.88651, "time_diff": 1.61313, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:42:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.85928, "time_diff": 1.59772, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:42:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "36/55", "eta": "0:00:12", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.87339, "time_diff": 2.08101, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:42:36][INFO] logging.py:  99: json_stats: {"RAM": "35.82/251.55G", "_type": "val_epoch", "epoch": "36/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:43:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88770, "dt_data": 3.34133, "dt_net": 0.54638, "epoch": "37/55", "eta": "7:41:01", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02030, "lr": 0.00000, "mAP": 0.89166, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:43:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41011, "dt_data": 2.87095, "dt_net": 0.53916, "epoch": "37/55", "eta": "6:43:48", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02086, "lr": 0.00000, "mAP": 0.93907, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:44:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.78540, "dt_data": 2.23665, "dt_net": 0.54875, "epoch": "37/55", "eta": "5:29:22", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.02026, "lr": 0.00000, "mAP": 0.91872, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:45:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.03672, "dt_data": 3.49227, "dt_net": 0.54445, "epoch": "37/55", "eta": "7:56:40", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01969, "lr": 0.00000, "mAP": 0.93179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:45:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.03892, "dt_data": 3.49498, "dt_net": 0.54394, "epoch": "37/55", "eta": "7:56:15", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02021, "lr": 0.00000, "mAP": 0.92077, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:46:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96898, "dt_data": 3.42646, "dt_net": 0.54251, "epoch": "37/55", "eta": "7:47:20", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01965, "lr": 0.00000, "mAP": 0.91639, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:46:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.80385, "dt_data": 4.25614, "dt_net": 0.54771, "epoch": "37/55", "eta": "9:24:51", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02006, "lr": 0.00000, "mAP": 0.92834, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:47:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85343, "dt_data": 3.30936, "dt_net": 0.54406, "epoch": "37/55", "eta": "7:32:27", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02077, "lr": 0.00000, "mAP": 0.93712, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:48:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79670, "dt_data": 3.25138, "dt_net": 0.54531, "epoch": "37/55", "eta": "7:25:09", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.02042, "lr": 0.00000, "mAP": 0.90972, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:48:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.13396, "dt_data": 3.58837, "dt_net": 0.54559, "epoch": "37/55", "eta": "8:04:01", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01865, "lr": 0.00000, "mAP": 0.91291, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:49:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26011, "dt_data": 2.70626, "dt_net": 0.55384, "epoch": "37/55", "eta": "6:21:09", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02043, "lr": 0.00000, "mAP": 0.91541, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:50:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87694, "dt_data": 3.31749, "dt_net": 0.55923, "epoch": "37/55", "eta": "7:32:37", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02032, "lr": 0.00000, "mAP": 0.89007, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:50:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08754, "dt_data": 2.53222, "dt_net": 0.55531, "epoch": "37/55", "eta": "5:59:57", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02087, "lr": 0.00000, "mAP": 0.90524, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:51:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67872, "dt_data": 3.13336, "dt_net": 0.54537, "epoch": "37/55", "eta": "7:08:15", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01991, "lr": 0.00000, "mAP": 0.92264, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:51:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.34997, "dt_data": 3.79766, "dt_net": 0.55230, "epoch": "37/55", "eta": "8:25:41", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01961, "lr": 0.00000, "mAP": 0.91317, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:52:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41344, "dt_data": 2.86977, "dt_net": 0.54367, "epoch": "37/55", "eta": "6:36:14", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02026, "lr": 0.00000, "mAP": 0.90103, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:52:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54246, "dt_data": 2.98707, "dt_net": 0.55539, "epoch": "37/55", "eta": "6:50:37", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01979, "lr": 0.00000, "mAP": 0.94153, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:53:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20282, "dt_data": 2.61408, "dt_net": 0.58873, "epoch": "37/55", "eta": "6:10:43", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02108, "lr": 0.00000, "mAP": 0.93406, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:54:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.47376, "dt_data": 3.93209, "dt_net": 0.54167, "epoch": "37/55", "eta": "8:37:05", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01964, "lr": 0.00000, "mAP": 0.90744, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:54:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50689, "dt_data": 2.96526, "dt_net": 0.54163, "epoch": "37/55", "eta": "6:44:45", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01926, "lr": 0.00000, "mAP": 0.91898, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:55:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96541, "dt_data": 3.40963, "dt_net": 0.55578, "epoch": "37/55", "eta": "7:37:00", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02035, "lr": 0.00000, "mAP": 0.90266, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:56:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.18710, "dt_data": 3.64158, "dt_net": 0.54552, "epoch": "37/55", "eta": "8:01:51", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02049, "lr": 0.00000, "mAP": 0.91536, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:56:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21435, "dt_data": 2.66597, "dt_net": 0.54838, "epoch": "37/55", "eta": "6:09:22", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02067, "lr": 0.00000, "mAP": 0.89120, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:57:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27771, "dt_data": 2.72396, "dt_net": 0.55374, "epoch": "37/55", "eta": "6:16:07", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01979, "lr": 0.00000, "mAP": 0.89505, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:57:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42650, "dt_data": 2.87368, "dt_net": 0.55282, "epoch": "37/55", "eta": "6:32:37", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01970, "lr": 0.00000, "mAP": 0.92628, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:58:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.13938, "dt_data": 2.83501, "dt_net": 1.30437, "epoch": "37/55", "eta": "7:53:36", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02010, "lr": 0.00000, "mAP": 0.91962, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:59:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47064, "dt_data": 1.26870, "dt_net": 2.20194, "epoch": "37/55", "eta": "6:36:31", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02050, "lr": 0.00000, "mAP": 0.91761, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 11:59:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.98321, "dt_data": 0.02520, "dt_net": 3.95802, "epoch": "37/55", "eta": "7:34:25", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02088, "lr": 0.00000, "mAP": 0.92388, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:00:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10357, "dt_data": 0.02524, "dt_net": 4.07833, "epoch": "37/55", "eta": "7:47:27", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.02166, "lr": 0.00000, "mAP": 0.90759, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:01:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59287, "dt_data": 0.02534, "dt_net": 3.56753, "epoch": "37/55", "eta": "6:48:41", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02087, "lr": 0.00000, "mAP": 0.90141, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:01:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72416, "dt_data": 0.02531, "dt_net": 3.69885, "epoch": "37/55", "eta": "7:03:00", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02005, "lr": 0.00000, "mAP": 0.91755, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:02:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08340, "dt_data": 0.28937, "dt_net": 2.79403, "epoch": "37/55", "eta": "5:49:42", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02095, "lr": 0.00000, "mAP": 0.94253, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:02:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.26656, "dt_data": 0.02526, "dt_net": 4.24129, "epoch": "37/55", "eta": "8:03:11", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.02217, "lr": 0.00000, "mAP": 0.93494, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:03:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13213, "dt_data": 0.02549, "dt_net": 3.10664, "epoch": "37/55", "eta": "5:54:11", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01993, "lr": 0.00000, "mAP": 0.94328, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:04:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.98871, "dt_data": 0.02523, "dt_net": 3.96348, "epoch": "37/55", "eta": "7:30:23", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01969, "lr": 0.00000, "mAP": 0.90774, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:04:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.11503, "dt_data": 0.02519, "dt_net": 3.08983, "epoch": "37/55", "eta": "5:51:13", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02100, "lr": 0.00000, "mAP": 0.93639, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:05:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94942, "dt_data": 0.02530, "dt_net": 3.92412, "epoch": "37/55", "eta": "7:24:38", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02167, "lr": 0.00000, "mAP": 0.90719, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:05:40][INFO] logging.py:  99: json_stats: {"RAM": "38.38/251.55G", "_type": "train_epoch", "dt": 0.00030, "dt_data": 0.00030, "dt_net": 2.49314, "epoch": "37/55", "eta": "0:00:01", "gpu_mem": "17.37G", "loss": 0.02030, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:05:40][INFO] train_net.py: 485: Epoch 36 takes 1376.51s. Epochs from 35 to 36 take 1335.65s in average and 1335.65s in median.
[03/08 12:05:40][INFO] train_net.py: 491: For epoch 36, each iteraction takes 3.67s in average. From epoch 35 to 36, each iteraction takes 3.56s in average.
[03/08 12:05:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:02:36", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.89210, "time_diff": 1.81795, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:06:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:02:17", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.82244, "time_diff": 1.80734, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:06:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:01:43", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.86823, "time_diff": 1.56927, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:06:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:01:52", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.91088, "time_diff": 2.00092, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:07:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:01:20", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.88781, "time_diff": 1.75943, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:07:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:01:08", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.87037, "time_diff": 1.89805, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:07:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:00:41", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.89335, "time_diff": 1.59393, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:07:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:00:24", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.84450, "time_diff": 1.55111, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:08:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "37/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.86381, "time_diff": 1.92526, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:08:25][INFO] logging.py:  99: json_stats: {"RAM": "43.60/251.55G", "_type": "val_epoch", "epoch": "37/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:09:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61489, "dt_data": 1.69232, "dt_net": 1.92257, "epoch": "38/55", "eta": "6:46:04", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01999, "lr": 0.00000, "mAP": 0.91937, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:09:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26000, "dt_data": 0.02508, "dt_net": 3.23492, "epoch": "38/55", "eta": "6:05:39", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01985, "lr": 0.00000, "mAP": 0.89897, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:10:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22289, "dt_data": 0.18042, "dt_net": 3.04247, "epoch": "38/55", "eta": "6:00:57", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01944, "lr": 0.00000, "mAP": 0.94630, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:11:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.45995, "dt_data": 3.21920, "dt_net": 1.24075, "epoch": "38/55", "eta": "8:18:46", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01887, "lr": 0.00000, "mAP": 0.90500, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:11:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59178, "dt_data": 0.97643, "dt_net": 2.61535, "epoch": "38/55", "eta": "6:41:04", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01975, "lr": 0.00000, "mAP": 0.94457, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:12:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53138, "dt_data": 1.02273, "dt_net": 2.50865, "epoch": "38/55", "eta": "6:33:44", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.02071, "lr": 0.00000, "mAP": 0.90497, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:12:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62558, "dt_data": 3.06657, "dt_net": 0.55901, "epoch": "38/55", "eta": "6:43:38", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.02047, "lr": 0.00000, "mAP": 0.92899, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:13:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.97839, "dt_data": 2.42961, "dt_net": 0.54878, "epoch": "38/55", "eta": "5:31:05", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01878, "lr": 0.00000, "mAP": 0.91453, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:14:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68410, "dt_data": 3.13156, "dt_net": 0.55254, "epoch": "38/55", "eta": "6:48:56", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01942, "lr": 0.00000, "mAP": 0.94091, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:14:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.14717, "dt_data": 3.58921, "dt_net": 0.55795, "epoch": "38/55", "eta": "7:39:38", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.02061, "lr": 0.00000, "mAP": 0.96020, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:15:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.10794, "dt_data": 2.56833, "dt_net": 0.53961, "epoch": "38/55", "eta": "5:43:56", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01864, "lr": 0.00000, "mAP": 0.90000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:16:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39643, "dt_data": 2.84790, "dt_net": 0.54853, "epoch": "38/55", "eta": "6:15:18", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.02079, "lr": 0.00000, "mAP": 0.89595, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:16:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71138, "dt_data": 3.16689, "dt_net": 0.54449, "epoch": "38/55", "eta": "6:49:29", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.02068, "lr": 0.00000, "mAP": 0.93418, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:17:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50000, "dt_data": 2.51002, "dt_net": 0.98998, "epoch": "38/55", "eta": "6:25:35", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01913, "lr": 0.00000, "mAP": 0.93503, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:17:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29372, "dt_data": 1.54000, "dt_net": 1.75372, "epoch": "38/55", "eta": "6:02:18", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02056, "lr": 0.00000, "mAP": 0.93244, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:18:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.66250, "dt_data": 0.02530, "dt_net": 3.63719, "epoch": "38/55", "eta": "6:42:15", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01923, "lr": 0.00000, "mAP": 0.92246, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:19:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62452, "dt_data": 0.02531, "dt_net": 3.59921, "epoch": "38/55", "eta": "6:37:29", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02038, "lr": 0.00000, "mAP": 0.91444, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:19:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94127, "dt_data": 1.07569, "dt_net": 2.86558, "epoch": "38/55", "eta": "7:11:34", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.02085, "lr": 0.00000, "mAP": 0.91730, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:20:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46034, "dt_data": 0.02548, "dt_net": 3.43486, "epoch": "38/55", "eta": "6:18:19", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.02059, "lr": 0.00000, "mAP": 0.90866, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:20:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50901, "dt_data": 0.02510, "dt_net": 3.48391, "epoch": "38/55", "eta": "6:23:04", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01965, "lr": 0.00000, "mAP": 0.89735, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:21:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44909, "dt_data": 1.98692, "dt_net": 1.46217, "epoch": "38/55", "eta": "6:15:57", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01881, "lr": 0.00000, "mAP": 0.93665, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:22:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.05943, "dt_data": 3.51376, "dt_net": 0.54567, "epoch": "38/55", "eta": "7:21:48", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01966, "lr": 0.00000, "mAP": 0.91280, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:22:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.75358, "dt_data": 0.42078, "dt_net": 4.33280, "epoch": "38/55", "eta": "8:36:33", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.02061, "lr": 0.00000, "mAP": 0.91468, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:23:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.05862, "dt_data": 0.02506, "dt_net": 4.03355, "epoch": "38/55", "eta": "7:20:21", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01960, "lr": 0.00000, "mAP": 0.92069, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:23:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95940, "dt_data": 0.02523, "dt_net": 3.93417, "epoch": "38/55", "eta": "7:08:56", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01945, "lr": 0.00000, "mAP": 0.93364, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:24:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.21283, "dt_data": 0.02523, "dt_net": 4.18760, "epoch": "38/55", "eta": "7:35:41", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01799, "lr": 0.00000, "mAP": 0.93500, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:25:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47262, "dt_data": 0.02518, "dt_net": 3.44744, "epoch": "38/55", "eta": "6:15:02", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02050, "lr": 0.00000, "mAP": 0.91026, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:25:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09987, "dt_data": 0.02506, "dt_net": 4.07481, "epoch": "38/55", "eta": "7:22:06", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02073, "lr": 0.00000, "mAP": 0.91002, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:26:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79703, "dt_data": 0.02510, "dt_net": 3.77193, "epoch": "38/55", "eta": "6:48:48", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01959, "lr": 0.00000, "mAP": 0.93514, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:27:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63945, "dt_data": 0.02510, "dt_net": 3.61435, "epoch": "38/55", "eta": "6:31:14", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02069, "lr": 0.00000, "mAP": 0.89285, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:27:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.17744, "dt_data": 0.02545, "dt_net": 4.15199, "epoch": "38/55", "eta": "7:28:22", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.02062, "lr": 0.00000, "mAP": 0.90207, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:28:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.60719, "dt_data": 0.02522, "dt_net": 4.58197, "epoch": "38/55", "eta": "8:13:44", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.02213, "lr": 0.00000, "mAP": 0.93824, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:28:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31691, "dt_data": 0.02512, "dt_net": 3.29179, "epoch": "38/55", "eta": "5:54:54", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01891, "lr": 0.00000, "mAP": 0.95121, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:29:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.06661, "dt_data": 0.02509, "dt_net": 4.04152, "epoch": "38/55", "eta": "7:14:27", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01979, "lr": 0.00000, "mAP": 0.88924, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:30:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.22575, "dt_data": 0.02526, "dt_net": 4.20048, "epoch": "38/55", "eta": "7:30:44", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01983, "lr": 0.00000, "mAP": 0.92739, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:30:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.12917, "dt_data": 0.02518, "dt_net": 3.10399, "epoch": "38/55", "eta": "5:33:15", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02026, "lr": 0.00000, "mAP": 0.94437, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:31:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.68294, "dt_data": 0.02531, "dt_net": 3.65763, "epoch": "38/55", "eta": "6:31:37", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02035, "lr": 0.00000, "mAP": 0.94506, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:31:44][INFO] logging.py:  99: json_stats: {"RAM": "43.86/251.55G", "_type": "train_epoch", "dt": 0.00038, "dt_data": 0.00038, "dt_net": 3.10365, "epoch": "38/55", "eta": "0:00:02", "gpu_mem": "17.37G", "loss": 0.02003, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:31:44][INFO] train_net.py: 485: Epoch 37 takes 1391.50s. Epochs from 35 to 37 take 1354.27s in average and 1376.51s in median.
[03/08 12:31:44][INFO] train_net.py: 491: For epoch 37, each iteraction takes 3.71s in average. From epoch 35 to 37, each iteraction takes 3.61s in average.
[03/08 12:32:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:02:32", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.87717, "time_diff": 1.77042, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:32:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:02:07", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.80657, "time_diff": 1.68122, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:32:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:01:47", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.86909, "time_diff": 1.62538, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:32:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:01:50", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.89896, "time_diff": 1.96582, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:33:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:01:24", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.89001, "time_diff": 1.83429, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:33:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:01:07", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.86801, "time_diff": 1.88852, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:33:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:00:41", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.86549, "time_diff": 1.58159, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:34:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:00:29", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.86128, "time_diff": 1.82205, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:34:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "38/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.86297, "time_diff": 1.94700, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:34:29][INFO] logging.py:  99: json_stats: {"RAM": "44.97/251.55G", "_type": "val_epoch", "epoch": "38/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:35:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72909, "dt_data": 2.14974, "dt_net": 1.57935, "epoch": "39/55", "eta": "6:35:35", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01924, "lr": 0.00000, "mAP": 0.93437, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:35:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52925, "dt_data": 1.89223, "dt_net": 1.63701, "epoch": "39/55", "eta": "6:13:48", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01924, "lr": 0.00000, "mAP": 0.95025, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:36:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76674, "dt_data": 3.20905, "dt_net": 0.55769, "epoch": "39/55", "eta": "6:38:19", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01893, "lr": 0.00000, "mAP": 0.89971, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:37:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.99778, "dt_data": 3.45109, "dt_net": 0.54669, "epoch": "39/55", "eta": "7:02:05", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02058, "lr": 0.00000, "mAP": 0.93933, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:37:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85165, "dt_data": 3.30510, "dt_net": 0.54655, "epoch": "39/55", "eta": "6:46:01", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01990, "lr": 0.00000, "mAP": 0.89412, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:38:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61354, "dt_data": 3.06454, "dt_net": 0.54900, "epoch": "39/55", "eta": "6:20:19", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01803, "lr": 0.00000, "mAP": 0.91097, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:38:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09890, "dt_data": 3.54627, "dt_net": 0.55263, "epoch": "39/55", "eta": "7:10:43", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01904, "lr": 0.00000, "mAP": 0.90293, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:39:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21249, "dt_data": 2.66952, "dt_net": 0.54297, "epoch": "39/55", "eta": "5:37:02", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01898, "lr": 0.00000, "mAP": 0.92192, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:40:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54618, "dt_data": 2.99357, "dt_net": 0.55261, "epoch": "39/55", "eta": "6:11:27", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01972, "lr": 0.00000, "mAP": 0.93100, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:40:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.15675, "dt_data": 3.61319, "dt_net": 0.54356, "epoch": "39/55", "eta": "7:14:43", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01946, "lr": 0.00000, "mAP": 0.91312, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:41:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.99610, "dt_data": 3.45361, "dt_net": 0.54249, "epoch": "39/55", "eta": "6:57:15", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.02068, "lr": 0.00000, "mAP": 0.89199, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:41:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90123, "dt_data": 0.51186, "dt_net": 3.38937, "epoch": "39/55", "eta": "6:46:42", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01978, "lr": 0.00000, "mAP": 0.95298, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:42:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.19782, "dt_data": 2.35333, "dt_net": 1.84449, "epoch": "39/55", "eta": "7:16:55", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01884, "lr": 0.00000, "mAP": 0.89457, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:43:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86203, "dt_data": 3.31573, "dt_net": 0.54630, "epoch": "39/55", "eta": "6:41:19", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01974, "lr": 0.00000, "mAP": 0.92235, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:43:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34774, "dt_data": 1.78624, "dt_net": 1.56149, "epoch": "39/55", "eta": "5:47:19", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01981, "lr": 0.00000, "mAP": 0.92494, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:44:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70670, "dt_data": 3.15243, "dt_net": 0.55427, "epoch": "39/55", "eta": "6:23:57", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02026, "lr": 0.00000, "mAP": 0.93355, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:45:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85636, "dt_data": 3.30604, "dt_net": 0.55031, "epoch": "39/55", "eta": "6:38:48", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.02088, "lr": 0.00000, "mAP": 0.92667, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:45:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45473, "dt_data": 2.89542, "dt_net": 0.55931, "epoch": "39/55", "eta": "5:56:42", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01955, "lr": 0.00000, "mAP": 0.91026, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:46:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.25279, "dt_data": 2.69359, "dt_net": 0.55919, "epoch": "39/55", "eta": "5:35:18", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01994, "lr": 0.00000, "mAP": 0.93060, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:46:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95684, "dt_data": 3.41248, "dt_net": 0.54435, "epoch": "39/55", "eta": "6:47:13", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.02033, "lr": 0.00000, "mAP": 0.96263, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:47:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84660, "dt_data": 3.29664, "dt_net": 0.54996, "epoch": "39/55", "eta": "6:35:14", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.02039, "lr": 0.00000, "mAP": 0.91107, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:48:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08891, "dt_data": 2.54723, "dt_net": 0.54168, "epoch": "39/55", "eta": "5:16:52", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01999, "lr": 0.00000, "mAP": 0.92574, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:48:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88318, "dt_data": 3.34315, "dt_net": 0.54003, "epoch": "39/55", "eta": "6:37:42", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01910, "lr": 0.00000, "mAP": 0.91488, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:49:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.81095, "dt_data": 0.50406, "dt_net": 2.30689, "epoch": "39/55", "eta": "4:47:25", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01952, "lr": 0.00000, "mAP": 0.90180, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:49:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.17178, "dt_data": 3.61713, "dt_net": 0.55464, "epoch": "39/55", "eta": "7:05:52", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01779, "lr": 0.00000, "mAP": 0.94873, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:50:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76417, "dt_data": 3.21446, "dt_net": 0.54971, "epoch": "39/55", "eta": "6:23:37", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01835, "lr": 0.00000, "mAP": 0.92288, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:51:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.17337, "dt_data": 3.62852, "dt_net": 0.54485, "epoch": "39/55", "eta": "7:04:38", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02138, "lr": 0.00000, "mAP": 0.92919, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:51:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95653, "dt_data": 2.41449, "dt_net": 0.54203, "epoch": "39/55", "eta": "5:00:20", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.02020, "lr": 0.00000, "mAP": 0.92222, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:52:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88756, "dt_data": 2.32594, "dt_net": 0.56161, "epoch": "39/55", "eta": "4:52:50", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01916, "lr": 0.00000, "mAP": 0.93026, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:52:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42538, "dt_data": 2.62968, "dt_net": 0.79570, "epoch": "39/55", "eta": "5:46:49", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.02012, "lr": 0.00000, "mAP": 0.91210, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:53:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.06197, "dt_data": 1.97628, "dt_net": 2.08568, "epoch": "39/55", "eta": "6:50:35", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01921, "lr": 0.00000, "mAP": 0.91758, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:54:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56714, "dt_data": 1.19011, "dt_net": 2.37703, "epoch": "39/55", "eta": "5:59:59", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01854, "lr": 0.00000, "mAP": 0.93042, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:54:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45023, "dt_data": 0.25594, "dt_net": 3.19428, "epoch": "39/55", "eta": "5:47:36", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01842, "lr": 0.00000, "mAP": 0.95859, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:55:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14740, "dt_data": 1.11549, "dt_net": 2.03191, "epoch": "39/55", "eta": "5:16:34", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.02051, "lr": 0.00000, "mAP": 0.93138, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:55:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67662, "dt_data": 2.89297, "dt_net": 0.78365, "epoch": "39/55", "eta": "6:09:11", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01936, "lr": 0.00000, "mAP": 0.93572, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:56:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.59354, "dt_data": 4.05177, "dt_net": 0.54177, "epoch": "39/55", "eta": "7:40:30", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.02019, "lr": 0.00000, "mAP": 0.90364, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:57:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.12274, "dt_data": 3.57823, "dt_net": 0.54450, "epoch": "39/55", "eta": "6:52:37", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01956, "lr": 0.00000, "mAP": 0.94848, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:57:22][INFO] logging.py:  99: json_stats: {"RAM": "45.20/251.55G", "_type": "train_epoch", "dt": 0.00030, "dt_data": 0.00030, "dt_net": 0.54158, "epoch": "39/55", "eta": "0:00:01", "gpu_mem": "17.37G", "loss": 0.01977, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:57:22][INFO] train_net.py: 485: Epoch 38 takes 1367.67s. Epochs from 35 to 38 take 1357.62s in average and 1372.09s in median.
[03/08 12:57:22][INFO] train_net.py: 491: For epoch 38, each iteraction takes 3.65s in average. From epoch 35 to 38, each iteraction takes 3.62s in average.
[03/08 12:57:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:02:37", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.86858, "time_diff": 1.83033, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:57:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:02:11", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.80459, "time_diff": 1.72824, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:58:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:01:46", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.87278, "time_diff": 1.61056, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:58:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:01:47", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.91562, "time_diff": 1.92632, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:58:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:01:27", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.87713, "time_diff": 1.90212, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:59:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:01:08", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.88601, "time_diff": 1.90740, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:59:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:00:42", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.89784, "time_diff": 1.62639, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 12:59:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.87053, "time_diff": 1.58292, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:00:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "39/55", "eta": "0:00:12", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.85843, "time_diff": 2.10666, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:00:09][INFO] logging.py:  99: json_stats: {"RAM": "45.88/251.55G", "_type": "val_epoch", "epoch": "39/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:00:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69923, "dt_data": 3.14944, "dt_net": 0.54979, "epoch": "40/55", "eta": "6:09:18", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.02050, "lr": 0.00000, "mAP": 0.92135, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:01:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93229, "dt_data": 1.73540, "dt_net": 2.19689, "epoch": "40/55", "eta": "6:31:55", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01877, "lr": 0.00000, "mAP": 0.92599, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:02:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61955, "dt_data": 1.98777, "dt_net": 1.63177, "epoch": "40/55", "eta": "6:00:08", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01738, "lr": 0.00000, "mAP": 0.93537, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:02:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.83737, "dt_data": 4.29301, "dt_net": 0.54437, "epoch": "40/55", "eta": "8:00:30", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01732, "lr": 0.00000, "mAP": 0.96721, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:03:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89298, "dt_data": 1.84926, "dt_net": 2.04372, "epoch": "40/55", "eta": "6:26:03", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01761, "lr": 0.00000, "mAP": 0.95690, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:03:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.14614, "dt_data": 1.37865, "dt_net": 2.76748, "epoch": "40/55", "eta": "6:50:28", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01894, "lr": 0.00000, "mAP": 0.94907, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:04:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58740, "dt_data": 0.93291, "dt_net": 2.65448, "epoch": "40/55", "eta": "5:54:33", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01915, "lr": 0.00000, "mAP": 0.90405, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:05:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40143, "dt_data": 2.85232, "dt_net": 0.54910, "epoch": "40/55", "eta": "5:35:36", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02051, "lr": 0.00000, "mAP": 0.91385, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:05:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36790, "dt_data": 2.82173, "dt_net": 0.54617, "epoch": "40/55", "eta": "5:31:44", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01687, "lr": 0.00000, "mAP": 0.95674, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:06:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86735, "dt_data": 3.32696, "dt_net": 0.54039, "epoch": "40/55", "eta": "6:20:17", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01895, "lr": 0.00000, "mAP": 0.92628, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:06:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59561, "dt_data": 2.34595, "dt_net": 1.24966, "epoch": "40/55", "eta": "5:52:58", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01948, "lr": 0.00000, "mAP": 0.92164, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:07:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58252, "dt_data": 3.03230, "dt_net": 0.55022, "epoch": "40/55", "eta": "5:51:05", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01981, "lr": 0.00000, "mAP": 0.93772, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:08:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50342, "dt_data": 2.95728, "dt_net": 0.54613, "epoch": "40/55", "eta": "5:42:45", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01882, "lr": 0.00000, "mAP": 0.95327, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:08:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.01342, "dt_data": 3.45807, "dt_net": 0.55535, "epoch": "40/55", "eta": "6:31:58", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01961, "lr": 0.00000, "mAP": 0.91734, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:09:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80298, "dt_data": 1.42043, "dt_net": 1.38255, "epoch": "40/55", "eta": "4:33:17", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.02037, "lr": 0.00000, "mAP": 0.94791, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:10:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67109, "dt_data": 2.12376, "dt_net": 1.54733, "epoch": "40/55", "eta": "5:57:19", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.02053, "lr": 0.00000, "mAP": 0.89590, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:10:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.24534, "dt_data": 2.88668, "dt_net": 1.35865, "epoch": "40/55", "eta": "6:52:30", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01878, "lr": 0.00000, "mAP": 0.92358, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:11:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01952, "dt_data": 0.02505, "dt_net": 2.99447, "epoch": "40/55", "eta": "4:52:53", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01979, "lr": 0.00000, "mAP": 0.93310, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:11:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56089, "dt_data": 0.88101, "dt_net": 2.67988, "epoch": "40/55", "eta": "5:44:48", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01928, "lr": 0.00000, "mAP": 0.92646, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:12:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.75221, "dt_data": 0.02534, "dt_net": 4.72686, "epoch": "40/55", "eta": "7:39:22", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01952, "lr": 0.00000, "mAP": 0.92982, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:13:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.85109, "dt_data": 0.90328, "dt_net": 3.94781, "epoch": "40/55", "eta": "7:48:07", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01866, "lr": 0.00000, "mAP": 0.93314, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:13:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61183, "dt_data": 1.47760, "dt_net": 2.13423, "epoch": "40/55", "eta": "5:47:56", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01862, "lr": 0.00000, "mAP": 0.91291, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:14:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67664, "dt_data": 0.02535, "dt_net": 3.65129, "epoch": "40/55", "eta": "5:53:34", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01890, "lr": 0.00000, "mAP": 0.91297, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:14:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90377, "dt_data": 0.02518, "dt_net": 3.87860, "epoch": "40/55", "eta": "6:14:45", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01932, "lr": 0.00000, "mAP": 0.89937, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:15:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29639, "dt_data": 0.02510, "dt_net": 3.27129, "epoch": "40/55", "eta": "5:15:54", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01883, "lr": 0.00000, "mAP": 0.92612, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:16:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01189, "dt_data": 0.02516, "dt_net": 2.98673, "epoch": "40/55", "eta": "4:48:08", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.02136, "lr": 0.00000, "mAP": 0.94571, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:16:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95606, "dt_data": 1.23309, "dt_net": 1.72297, "epoch": "40/55", "eta": "4:42:18", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01801, "lr": 0.00000, "mAP": 0.94227, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:17:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50510, "dt_data": 1.61536, "dt_net": 1.88973, "epoch": "40/55", "eta": "5:34:09", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01924, "lr": 0.00000, "mAP": 0.93776, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:17:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29358, "dt_data": 0.02534, "dt_net": 3.26824, "epoch": "40/55", "eta": "5:13:26", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01945, "lr": 0.00000, "mAP": 0.92733, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:18:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94510, "dt_data": 0.02582, "dt_net": 2.91927, "epoch": "40/55", "eta": "4:39:47", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01984, "lr": 0.00000, "mAP": 0.93617, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:19:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73958, "dt_data": 0.02507, "dt_net": 3.71451, "epoch": "40/55", "eta": "5:54:38", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01974, "lr": 0.00000, "mAP": 0.91623, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:19:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89218, "dt_data": 0.02519, "dt_net": 3.86699, "epoch": "40/55", "eta": "6:08:27", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01763, "lr": 0.00000, "mAP": 0.94848, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:20:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45309, "dt_data": 0.02525, "dt_net": 3.42783, "epoch": "40/55", "eta": "5:26:18", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01826, "lr": 0.00000, "mAP": 0.92371, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:20:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82918, "dt_data": 0.02542, "dt_net": 3.80375, "epoch": "40/55", "eta": "6:01:13", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01953, "lr": 0.00000, "mAP": 0.92842, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:21:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19457, "dt_data": 0.02549, "dt_net": 3.16907, "epoch": "40/55", "eta": "5:00:49", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01889, "lr": 0.00000, "mAP": 0.96336, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:22:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02205, "dt_data": 0.02511, "dt_net": 3.99694, "epoch": "40/55", "eta": "6:18:04", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01878, "lr": 0.00000, "mAP": 0.93569, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:22:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29540, "dt_data": 0.02524, "dt_net": 3.27016, "epoch": "40/55", "eta": "5:09:13", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01816, "lr": 0.00000, "mAP": 0.95215, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:23:04][INFO] logging.py:  99: json_stats: {"RAM": "45.01/251.55G", "_type": "train_epoch", "dt": 0.00036, "dt_data": 0.00036, "dt_net": 3.37823, "epoch": "40/55", "eta": "0:00:01", "gpu_mem": "17.37G", "loss": 0.01930, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:23:04][INFO] train_net.py: 485: Epoch 39 takes 1368.05s. Epochs from 35 to 39 take 1359.71s in average and 1368.05s in median.
[03/08 13:23:04][INFO] train_net.py: 491: For epoch 39, each iteraction takes 3.65s in average. From epoch 35 to 39, each iteraction takes 3.63s in average.
[03/08 13:23:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:02:41", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.89297, "time_diff": 1.87791, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:23:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:01:59", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.80385, "time_diff": 1.57701, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:23:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:01:48", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.85975, "time_diff": 1.64814, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:24:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:01:43", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.91404, "time_diff": 1.84608, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:24:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:01:23", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.88406, "time_diff": 1.81743, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:24:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:01:13", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.86953, "time_diff": 2.04459, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:25:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:00:43", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.90015, "time_diff": 1.66213, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:25:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:00:28", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.85125, "time_diff": 1.79710, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:25:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "40/55", "eta": "0:00:12", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.88924, "time_diff": 2.04796, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:25:50][INFO] logging.py:  99: json_stats: {"RAM": "44.86/251.55G", "_type": "val_epoch", "epoch": "40/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:26:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60769, "dt_data": 2.13079, "dt_net": 1.47689, "epoch": "41/55", "eta": "5:37:37", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01862, "lr": 0.00000, "mAP": 0.95248, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:27:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57388, "dt_data": 3.02624, "dt_net": 0.54763, "epoch": "41/55", "eta": "5:33:51", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01823, "lr": 0.00000, "mAP": 0.92913, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:27:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87642, "dt_data": 3.32478, "dt_net": 0.55164, "epoch": "41/55", "eta": "6:01:28", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01787, "lr": 0.00000, "mAP": 0.94885, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:28:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.88578, "dt_data": 3.33309, "dt_net": 0.55268, "epoch": "41/55", "eta": "6:01:42", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.02147, "lr": 0.00000, "mAP": 0.86366, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:29:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90438, "dt_data": 3.35353, "dt_net": 0.55085, "epoch": "41/55", "eta": "6:02:46", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.02028, "lr": 0.00000, "mAP": 0.93071, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:29:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96969, "dt_data": 2.42396, "dt_net": 0.54573, "epoch": "41/55", "eta": "4:35:26", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01937, "lr": 0.00000, "mAP": 0.92644, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:30:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94701, "dt_data": 3.38844, "dt_net": 0.55856, "epoch": "41/55", "eta": "6:05:25", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01753, "lr": 0.00000, "mAP": 0.89872, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:30:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95327, "dt_data": 3.40130, "dt_net": 0.55196, "epoch": "41/55", "eta": "6:05:20", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01859, "lr": 0.00000, "mAP": 0.96208, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:31:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58466, "dt_data": 3.03694, "dt_net": 0.54772, "epoch": "41/55", "eta": "5:30:41", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01927, "lr": 0.00000, "mAP": 0.91462, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:32:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05250, "dt_data": 2.48441, "dt_net": 0.56809, "epoch": "41/55", "eta": "4:41:05", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01874, "lr": 0.00000, "mAP": 0.90532, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:32:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70750, "dt_data": 3.16081, "dt_net": 0.54668, "epoch": "41/55", "eta": "5:40:46", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01910, "lr": 0.00000, "mAP": 0.95208, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:33:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.16633, "dt_data": 1.53896, "dt_net": 1.62737, "epoch": "41/55", "eta": "4:50:30", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01841, "lr": 0.00000, "mAP": 0.93317, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:33:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.09082, "dt_data": 0.02536, "dt_net": 4.06546, "epoch": "41/55", "eta": "6:14:39", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01819, "lr": 0.00000, "mAP": 0.90832, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:34:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98036, "dt_data": 0.02545, "dt_net": 2.95491, "epoch": "41/55", "eta": "4:32:27", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01799, "lr": 0.00000, "mAP": 0.95903, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:35:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37459, "dt_data": 2.83251, "dt_net": 0.54208, "epoch": "41/55", "eta": "5:07:55", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01886, "lr": 0.00000, "mAP": 0.93252, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:35:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.25001, "dt_data": 3.16263, "dt_net": 1.08738, "epoch": "41/55", "eta": "6:27:06", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01796, "lr": 0.00000, "mAP": 0.92573, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:36:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37326, "dt_data": 2.26016, "dt_net": 1.11310, "epoch": "41/55", "eta": "5:06:41", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01919, "lr": 0.00000, "mAP": 0.90321, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:36:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84328, "dt_data": 0.16679, "dt_net": 3.67649, "epoch": "41/55", "eta": "5:48:46", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01812, "lr": 0.00000, "mAP": 0.95557, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:37:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.57045, "dt_data": 0.02520, "dt_net": 3.54525, "epoch": "41/55", "eta": "5:23:25", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01949, "lr": 0.00000, "mAP": 0.90286, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:38:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.94355, "dt_data": 0.05370, "dt_net": 2.88985, "epoch": "41/55", "eta": "4:26:08", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01987, "lr": 0.00000, "mAP": 0.94591, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:38:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52889, "dt_data": 1.36160, "dt_net": 2.16729, "epoch": "41/55", "eta": "5:18:28", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01817, "lr": 0.00000, "mAP": 0.96727, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:39:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46055, "dt_data": 1.90797, "dt_net": 1.55258, "epoch": "41/55", "eta": "5:11:44", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.02006, "lr": 0.00000, "mAP": 0.92508, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:39:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.81177, "dt_data": 0.68523, "dt_net": 3.12654, "epoch": "41/55", "eta": "5:42:44", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01902, "lr": 0.00000, "mAP": 0.94685, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:40:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43666, "dt_data": 2.34191, "dt_net": 1.09475, "epoch": "41/55", "eta": "5:08:26", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01985, "lr": 0.00000, "mAP": 0.90801, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:41:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.31812, "dt_data": 2.32018, "dt_net": 1.99794, "epoch": "41/55", "eta": "6:26:49", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01925, "lr": 0.00000, "mAP": 0.92798, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:41:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62917, "dt_data": 1.28773, "dt_net": 2.34144, "epoch": "41/55", "eta": "5:24:30", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01905, "lr": 0.00000, "mAP": 0.94755, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:42:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.72780, "dt_data": 4.17738, "dt_net": 0.55041, "epoch": "41/55", "eta": "7:01:57", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.02030, "lr": 0.00000, "mAP": 0.93069, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:43:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58946, "dt_data": 2.41536, "dt_net": 1.17409, "epoch": "41/55", "eta": "5:19:45", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01834, "lr": 0.00000, "mAP": 0.91154, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:43:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32662, "dt_data": 2.77381, "dt_net": 0.55281, "epoch": "41/55", "eta": "4:55:47", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01917, "lr": 0.00000, "mAP": 0.92151, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:44:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.42120, "dt_data": 1.22850, "dt_net": 1.19270, "epoch": "41/55", "eta": "3:34:52", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01758, "lr": 0.00000, "mAP": 0.96693, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:44:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35974, "dt_data": 2.80831, "dt_net": 0.55142, "epoch": "41/55", "eta": "4:57:37", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01989, "lr": 0.00000, "mAP": 0.91780, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:45:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21099, "dt_data": 1.74219, "dt_net": 1.46880, "epoch": "41/55", "eta": "4:43:54", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01819, "lr": 0.00000, "mAP": 0.92199, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:46:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73433, "dt_data": 2.20945, "dt_net": 1.52488, "epoch": "41/55", "eta": "5:29:33", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01793, "lr": 0.00000, "mAP": 0.92822, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:46:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.46798, "dt_data": 1.71129, "dt_net": 2.75669, "epoch": "41/55", "eta": "6:33:33", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01922, "lr": 0.00000, "mAP": 0.92358, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:47:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38559, "dt_data": 0.60422, "dt_net": 2.78137, "epoch": "41/55", "eta": "4:57:39", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01990, "lr": 0.00000, "mAP": 0.91764, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:47:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30393, "dt_data": 1.13096, "dt_net": 2.17297, "epoch": "41/55", "eta": "4:49:55", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01748, "lr": 0.00000, "mAP": 0.94890, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:48:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56042, "dt_data": 1.27051, "dt_net": 2.28991, "epoch": "41/55", "eta": "5:11:50", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01978, "lr": 0.00000, "mAP": 0.90857, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:48:44][INFO] logging.py:  99: json_stats: {"RAM": "44.79/251.55G", "_type": "train_epoch", "dt": 0.00036, "dt_data": 0.00036, "dt_net": 2.45134, "epoch": "41/55", "eta": "0:00:01", "gpu_mem": "17.37G", "loss": 0.01906, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:48:44][INFO] train_net.py: 485: Epoch 40 takes 1367.44s. Epochs from 35 to 40 take 1360.99s in average and 1367.86s in median.
[03/08 13:48:44][INFO] train_net.py: 491: For epoch 40, each iteraction takes 3.65s in average. From epoch 35 to 40, each iteraction takes 3.63s in average.
[03/08 13:49:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:02:43", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.88620, "time_diff": 1.89693, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:49:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.80137, "time_diff": 1.70145, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:49:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:01:52", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.87417, "time_diff": 1.70499, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:49:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:01:41", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.91620, "time_diff": 1.81593, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:50:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:01:24", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.90305, "time_diff": 1.83737, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:50:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:01:10", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.87310, "time_diff": 1.96824, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:50:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:00:46", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.88678, "time_diff": 1.80572, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:51:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.85088, "time_diff": 1.60008, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:51:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "41/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.87865, "time_diff": 1.86248, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:51:28][INFO] logging.py:  99: json_stats: {"RAM": "44.80/251.55G", "_type": "val_epoch", "epoch": "41/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:52:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85593, "dt_data": 0.02540, "dt_net": 3.83053, "epoch": "42/55", "eta": "5:36:45", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01792, "lr": 0.00000, "mAP": 0.92334, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:52:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36918, "dt_data": 0.02537, "dt_net": 3.34381, "epoch": "42/55", "eta": "4:53:40", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01870, "lr": 0.00000, "mAP": 0.92556, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:53:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.26273, "dt_data": 0.02531, "dt_net": 4.23742, "epoch": "42/55", "eta": "6:10:51", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01836, "lr": 0.00000, "mAP": 0.92932, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:54:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73819, "dt_data": 0.11685, "dt_net": 3.62134, "epoch": "42/55", "eta": "5:24:35", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01883, "lr": 0.00000, "mAP": 0.91447, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:54:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.27888, "dt_data": 1.77550, "dt_net": 2.50339, "epoch": "42/55", "eta": "6:10:50", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01979, "lr": 0.00000, "mAP": 0.92755, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:55:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.30437, "dt_data": 3.76137, "dt_net": 0.54300, "epoch": "42/55", "eta": "6:12:19", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01730, "lr": 0.00000, "mAP": 0.90383, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:56:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28252, "dt_data": 2.73033, "dt_net": 0.55219, "epoch": "42/55", "eta": "4:43:23", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01979, "lr": 0.00000, "mAP": 0.92647, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:56:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83480, "dt_data": 3.28699, "dt_net": 0.54781, "epoch": "42/55", "eta": "5:30:25", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.02044, "lr": 0.00000, "mAP": 0.90190, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:57:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.50702, "dt_data": 3.95666, "dt_net": 0.55035, "epoch": "42/55", "eta": "6:27:36", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01922, "lr": 0.00000, "mAP": 0.91370, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:57:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67522, "dt_data": 3.12937, "dt_net": 0.54585, "epoch": "42/55", "eta": "5:15:27", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01984, "lr": 0.00000, "mAP": 0.93474, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:58:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21729, "dt_data": 2.66305, "dt_net": 0.55424, "epoch": "42/55", "eta": "4:35:36", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01892, "lr": 0.00000, "mAP": 0.92529, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:59:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39546, "dt_data": 2.84092, "dt_net": 0.55454, "epoch": "42/55", "eta": "4:50:18", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01901, "lr": 0.00000, "mAP": 0.93712, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 13:59:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75766, "dt_data": 0.63724, "dt_net": 3.12042, "epoch": "42/55", "eta": "5:20:39", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01928, "lr": 0.00000, "mAP": 0.91906, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:00:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.65560, "dt_data": 0.02533, "dt_net": 3.63026, "epoch": "42/55", "eta": "5:11:20", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01925, "lr": 0.00000, "mAP": 0.93831, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:00:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33010, "dt_data": 0.02513, "dt_net": 3.30497, "epoch": "42/55", "eta": "4:43:03", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01838, "lr": 0.00000, "mAP": 0.92230, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:01:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82773, "dt_data": 0.02530, "dt_net": 3.80243, "epoch": "42/55", "eta": "5:24:43", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01795, "lr": 0.00000, "mAP": 0.95233, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:02:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96937, "dt_data": 0.02537, "dt_net": 3.94400, "epoch": "42/55", "eta": "5:36:04", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01943, "lr": 0.00000, "mAP": 0.94897, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:02:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.07503, "dt_data": 0.02521, "dt_net": 4.04981, "epoch": "42/55", "eta": "5:44:20", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01867, "lr": 0.00000, "mAP": 0.95328, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:03:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.45479, "dt_data": 0.02532, "dt_net": 4.42946, "epoch": "42/55", "eta": "6:15:41", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01896, "lr": 0.00000, "mAP": 0.94084, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:03:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38044, "dt_data": 0.02527, "dt_net": 3.35517, "epoch": "42/55", "eta": "4:44:31", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01766, "lr": 0.00000, "mAP": 0.93006, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:04:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.04309, "dt_data": 3.49507, "dt_net": 0.54802, "epoch": "42/55", "eta": "5:39:37", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01922, "lr": 0.00000, "mAP": 0.95198, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:05:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.35196, "dt_data": 2.80055, "dt_net": 0.55140, "epoch": "42/55", "eta": "4:41:00", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01971, "lr": 0.00000, "mAP": 0.93486, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:05:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.89422, "dt_data": 2.35479, "dt_net": 0.53942, "epoch": "42/55", "eta": "4:02:08", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01939, "lr": 0.00000, "mAP": 0.93281, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:06:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.45281, "dt_data": 3.90584, "dt_net": 0.54696, "epoch": "42/55", "eta": "6:11:48", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01887, "lr": 0.00000, "mAP": 0.91827, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:06:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58685, "dt_data": 3.04147, "dt_net": 0.54538, "epoch": "42/55", "eta": "4:58:54", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01702, "lr": 0.00000, "mAP": 0.91747, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:07:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.51241, "dt_data": 3.96460, "dt_net": 0.54781, "epoch": "42/55", "eta": "6:15:16", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01910, "lr": 0.00000, "mAP": 0.93761, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:08:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.05047, "dt_data": 3.49232, "dt_net": 0.55814, "epoch": "42/55", "eta": "5:36:11", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01867, "lr": 0.00000, "mAP": 0.94992, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:08:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22268, "dt_data": 2.67729, "dt_net": 0.54539, "epoch": "42/55", "eta": "4:26:56", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01907, "lr": 0.00000, "mAP": 0.93637, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:09:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45719, "dt_data": 2.90681, "dt_net": 0.55038, "epoch": "42/55", "eta": "4:45:47", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01895, "lr": 0.00000, "mAP": 0.91168, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:10:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96821, "dt_data": 3.41835, "dt_net": 0.54985, "epoch": "42/55", "eta": "5:27:22", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01803, "lr": 0.00000, "mAP": 0.92936, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:10:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97101, "dt_data": 3.42724, "dt_net": 0.54376, "epoch": "42/55", "eta": "5:26:56", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01741, "lr": 0.00000, "mAP": 0.93733, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:11:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31185, "dt_data": 2.77214, "dt_net": 0.53971, "epoch": "42/55", "eta": "4:32:07", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01889, "lr": 0.00000, "mAP": 0.92212, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:11:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64479, "dt_data": 3.09665, "dt_net": 0.54814, "epoch": "42/55", "eta": "4:58:52", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01906, "lr": 0.00000, "mAP": 0.92340, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:12:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.08178, "dt_data": 3.53052, "dt_net": 0.55126, "epoch": "42/55", "eta": "5:34:01", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01825, "lr": 0.00000, "mAP": 0.97188, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:13:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.93233, "dt_data": 3.38999, "dt_net": 0.54233, "epoch": "42/55", "eta": "5:21:08", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01990, "lr": 0.00000, "mAP": 0.91362, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:13:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.41994, "dt_data": 3.86478, "dt_net": 0.55515, "epoch": "42/55", "eta": "6:00:13", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01872, "lr": 0.00000, "mAP": 0.92894, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:14:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19240, "dt_data": 2.64475, "dt_net": 0.54765, "epoch": "42/55", "eta": "4:19:38", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01886, "lr": 0.00000, "mAP": 0.93912, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:14:39][INFO] logging.py:  99: json_stats: {"RAM": "44.83/251.55G", "_type": "train_epoch", "dt": 0.00037, "dt_data": 0.00037, "dt_net": 0.54536, "epoch": "42/55", "eta": "0:00:01", "gpu_mem": "17.37G", "loss": 0.01881, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:14:39][INFO] train_net.py: 485: Epoch 41 takes 1385.16s. Epochs from 35 to 41 take 1364.45s in average and 1368.05s in median.
[03/08 14:14:39][INFO] train_net.py: 491: For epoch 41, each iteraction takes 3.69s in average. From epoch 35 to 41, each iteraction takes 3.64s in average.
[03/08 14:14:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:02:36", "gpu_mem": "17.37G", "iter": "10/96", "mAP": 0.86787, "time_diff": 1.82542, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:15:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:02:04", "gpu_mem": "17.37G", "iter": "20/96", "mAP": 0.79578, "time_diff": 1.63556, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:15:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:01:56", "gpu_mem": "17.37G", "iter": "30/96", "mAP": 0.86847, "time_diff": 1.76494, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:15:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:01:44", "gpu_mem": "17.37G", "iter": "40/96", "mAP": 0.90828, "time_diff": 1.86927, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:16:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:01:37", "gpu_mem": "17.37G", "iter": "50/96", "mAP": 0.90186, "time_diff": 2.12172, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:16:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:01:17", "gpu_mem": "17.37G", "iter": "60/96", "mAP": 0.87025, "time_diff": 2.16591, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:16:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:00:41", "gpu_mem": "17.37G", "iter": "70/96", "mAP": 0.88565, "time_diff": 1.61447, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:17:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:00:25", "gpu_mem": "17.37G", "iter": "80/96", "mAP": 0.86568, "time_diff": 1.58828, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:17:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "42/55", "eta": "0:00:11", "gpu_mem": "17.37G", "iter": "90/96", "mAP": 0.89903, "time_diff": 1.99343, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:17:26][INFO] logging.py:  99: json_stats: {"RAM": "44.65/251.55G", "_type": "val_epoch", "epoch": "42/55", "gpu_mem": "17.37G", "mAP": 0, "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00013, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:18:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63175, "dt_data": 1.24098, "dt_net": 2.39076, "epoch": "43/55", "eta": "4:54:28", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01836, "lr": 0.00000, "mAP": 0.93068, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:18:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.79777, "dt_data": 1.33568, "dt_net": 1.46208, "epoch": "43/55", "eta": "3:46:23", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.02057, "lr": 0.00000, "mAP": 0.92779, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:19:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.19624, "dt_data": 2.30484, "dt_net": 0.89140, "epoch": "43/55", "eta": "4:18:05", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01783, "lr": 0.00000, "mAP": 0.93109, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:19:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.52520, "dt_data": 3.97126, "dt_net": 0.55393, "epoch": "43/55", "eta": "6:04:39", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01781, "lr": 0.00000, "mAP": 0.95600, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:20:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.30317, "dt_data": 2.75562, "dt_net": 0.54755, "epoch": "43/55", "eta": "4:25:37", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01718, "lr": 0.00000, "mAP": 0.93801, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:21:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61962, "dt_data": 3.07402, "dt_net": 0.54560, "epoch": "43/55", "eta": "4:50:28", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01873, "lr": 0.00000, "mAP": 0.91950, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:21:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31545, "dt_data": 2.76581, "dt_net": 0.54964, "epoch": "43/55", "eta": "4:25:30", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01809, "lr": 0.00000, "mAP": 0.92110, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:22:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93875, "dt_data": 2.39334, "dt_net": 0.54540, "epoch": "43/55", "eta": "3:54:51", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01865, "lr": 0.00000, "mAP": 0.95467, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:22:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21760, "dt_data": 2.67359, "dt_net": 0.54400, "epoch": "43/55", "eta": "4:16:36", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01850, "lr": 0.00000, "mAP": 0.92101, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:23:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.81787, "dt_data": 3.27517, "dt_net": 0.54270, "epoch": "43/55", "eta": "5:03:50", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01885, "lr": 0.00000, "mAP": 0.92943, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:24:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.65926, "dt_data": 3.10965, "dt_net": 0.54960, "epoch": "43/55", "eta": "4:50:36", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01875, "lr": 0.00000, "mAP": 0.93351, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:24:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45461, "dt_data": 2.91717, "dt_net": 0.53743, "epoch": "43/55", "eta": "4:33:46", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01838, "lr": 0.00000, "mAP": 0.95787, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:25:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.55252, "dt_data": 2.01210, "dt_net": 0.54042, "epoch": "43/55", "eta": "3:21:51", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01786, "lr": 0.00000, "mAP": 0.94025, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:25:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08233, "dt_data": 2.53853, "dt_net": 0.54380, "epoch": "43/55", "eta": "4:03:14", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01835, "lr": 0.00000, "mAP": 0.92989, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:26:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22217, "dt_data": 2.68192, "dt_net": 0.54025, "epoch": "43/55", "eta": "4:13:44", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01923, "lr": 0.00000, "mAP": 0.93689, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:26:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.76124, "dt_data": 1.81133, "dt_net": 1.94990, "epoch": "43/55", "eta": "4:55:34", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01738, "lr": 0.00000, "mAP": 0.93556, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:27:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17281, "dt_data": 0.02616, "dt_net": 3.14665, "epoch": "43/55", "eta": "4:08:48", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01939, "lr": 0.00000, "mAP": 0.93604, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:28:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44523, "dt_data": 0.51349, "dt_net": 2.93173, "epoch": "43/55", "eta": "4:29:35", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01890, "lr": 0.00000, "mAP": 0.93193, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:28:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63844, "dt_data": 2.48002, "dt_net": 1.15842, "epoch": "43/55", "eta": "4:44:06", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01774, "lr": 0.00000, "mAP": 0.92891, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:29:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86889, "dt_data": 2.09732, "dt_net": 1.77157, "epoch": "43/55", "eta": "5:01:27", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01790, "lr": 0.00000, "mAP": 0.92582, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:29:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64063, "dt_data": 1.87341, "dt_net": 1.76721, "epoch": "43/55", "eta": "4:43:03", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01939, "lr": 0.00000, "mAP": 0.88555, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:30:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86222, "dt_data": 1.24508, "dt_net": 2.61714, "epoch": "43/55", "eta": "4:59:38", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01776, "lr": 0.00000, "mAP": 0.94179, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:30:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90323, "dt_data": 0.02519, "dt_net": 3.87804, "epoch": "43/55", "eta": "5:02:10", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01776, "lr": 0.00000, "mAP": 0.91550, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:31:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.40805, "dt_data": 0.02514, "dt_net": 4.38290, "epoch": "43/55", "eta": "5:40:31", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01749, "lr": 0.00000, "mAP": 0.92626, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 14:32:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.81855, "dt_data": 0.02607, "dt_net": 4.79247, "epoch": "43/55", "eta": "6:11:25", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01793, "lr": 0.00000, "mAP": 0.95391, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 15:28:13][INFO] train_net.py: 403: Train with config:
[03/08 15:28:13][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 15:28:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:28:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:28:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:28:14][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 15:28:14][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 15:28:14][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:28:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:28:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:28:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:28:15][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 15:28:15][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 15:28:15][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 15:28:16][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 15:28:16][INFO] misc.py: 185: Params: 133,343,372
[03/08 15:28:16][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 15:28:16][INFO] misc.py: 187: Flops: 0 G
[03/08 15:28:16][INFO] misc.py: 192: Activations: 0 M
[03/08 15:28:16][INFO] misc.py: 197: nvidia-smi
[03/08 15:28:17][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 15:28:17][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 15:28:17][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 15:28:17][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 15:28:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 15:28:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:28:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:28:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 15:28:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:28:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:28:19][INFO] train_net.py: 446: Start epoch: 43
[03/08 15:35:15][INFO] train_net.py: 403: Train with config:
[03/08 15:35:15][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 15:35:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:15][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:15][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:15][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:15][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:15][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:15][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:15][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:35:16][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:35:16][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:35:16][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 15:35:16][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 15:35:16][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:35:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:35:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:35:17][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:35:17][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 15:35:17][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 15:35:17][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 15:35:18][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 15:35:18][INFO] misc.py: 185: Params: 133,343,372
[03/08 15:35:18][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 15:35:18][INFO] misc.py: 187: Flops: 0 G
[03/08 15:35:18][INFO] misc.py: 192: Activations: 0 M
[03/08 15:35:18][INFO] misc.py: 197: nvidia-smi
[03/08 15:35:19][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 15:35:19][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 15:35:19][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 15:35:19][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 15:35:21][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 15:35:21][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:35:21][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:35:21][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 15:35:21][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:35:21][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:35:21][INFO] train_net.py: 446: Start epoch: 43
[03/08 15:44:04][INFO] train_net.py: 403: Train with config:
[03/08 15:44:04][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 15:44:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:44:05][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:44:05][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 15:44:05][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 15:44:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:44:05][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:44:06][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 15:44:06][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 15:44:06][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 15:44:10][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 15:44:10][INFO] misc.py: 185: Params: 133,343,372
[03/08 15:44:10][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 15:44:10][INFO] misc.py: 187: Flops: 0 G
[03/08 15:44:10][INFO] misc.py: 192: Activations: 0 M
[03/08 15:44:10][INFO] misc.py: 197: nvidia-smi
[03/08 15:44:11][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 15:44:11][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 15:44:11][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 15:44:11][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 15:44:13][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 15:44:13][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:44:13][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:44:13][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 15:44:13][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:44:13][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:44:13][INFO] train_net.py: 446: Start epoch: 43
[03/08 15:45:17][INFO] train_net.py: 403: Train with config:
[03/08 15:45:17][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 15:45:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:17][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:17][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:17][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:17][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:45:18][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:45:18][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:45:18][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 15:45:18][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 15:45:18][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:45:19][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:45:19][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:45:19][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:45:19][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 15:45:19][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 15:45:19][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 15:45:20][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 15:45:20][INFO] misc.py: 185: Params: 133,343,372
[03/08 15:45:20][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 15:45:20][INFO] misc.py: 187: Flops: 0 G
[03/08 15:45:20][INFO] misc.py: 192: Activations: 0 M
[03/08 15:45:20][INFO] misc.py: 197: nvidia-smi
[03/08 15:45:21][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 15:45:21][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 15:45:21][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 15:45:21][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 15:45:23][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 15:45:23][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:45:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:45:23][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 15:45:23][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:45:23][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:45:23][INFO] train_net.py: 446: Start epoch: 43
[03/08 15:48:11][INFO] train_net.py: 403: Train with config:
[03/08 15:48:11][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:12][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:48:12][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:48:12][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:48:12][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:12][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:48:12][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 15:48:12][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 15:48:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:48:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:48:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:48:12][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:48:12][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 15:48:12][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 15:48:12][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 15:48:13][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 15:48:13][INFO] misc.py: 185: Params: 133,343,372
[03/08 15:48:13][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 15:48:13][INFO] misc.py: 187: Flops: 0 G
[03/08 15:48:13][INFO] misc.py: 192: Activations: 0 M
[03/08 15:48:13][INFO] misc.py: 197: nvidia-smi
[03/08 15:48:14][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 15:48:14][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 15:48:14][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 15:48:14][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 15:48:16][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 15:48:16][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:48:16][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:48:16][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 15:48:16][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:48:16][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:48:16][INFO] train_net.py: 446: Start epoch: 43
[03/08 15:50:50][INFO] train_net.py: 403: Train with config:
[03/08 15:50:50][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:50][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:50][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:50][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 15:50:51][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 15:50:51][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 15:50:51][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 15:50:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 15:50:51][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 15:50:52][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 15:50:52][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 15:50:53][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 15:50:53][INFO] misc.py: 185: Params: 133,343,372
[03/08 15:50:53][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 15:50:53][INFO] misc.py: 187: Flops: 0 G
[03/08 15:50:53][INFO] misc.py: 192: Activations: 0 M
[03/08 15:50:53][INFO] misc.py: 197: nvidia-smi
[03/08 15:50:54][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 15:50:54][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 15:50:54][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 15:50:54][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 15:50:56][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 15:50:56][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:50:56][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 15:50:56][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 15:50:56][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:50:56][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 15:50:56][INFO] train_net.py: 446: Start epoch: 43
[03/08 15:51:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87699, "dt_data": 3.33452, "dt_net": 0.54247, "epoch": "43/55", "eta": "5:14:21", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01905, "lr": 0.00000, "mAP": 0.90836, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:09:13][INFO] train_net.py: 403: Train with config:
[03/08 16:09:13][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 16:09:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:13][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:13][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:13][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:13][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:09:14][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:09:14][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:09:14][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 16:09:14][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 16:09:14][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:09:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:09:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:09:15][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:09:15][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 16:09:15][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 16:09:15][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 16:09:17][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 16:09:17][INFO] misc.py: 185: Params: 133,343,372
[03/08 16:09:17][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 16:09:17][INFO] misc.py: 187: Flops: 0 G
[03/08 16:09:17][INFO] misc.py: 192: Activations: 0 M
[03/08 16:09:17][INFO] misc.py: 197: nvidia-smi
[03/08 16:09:17][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 16:09:17][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 16:09:17][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 16:09:17][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 16:09:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 16:09:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:09:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:09:19][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 16:09:19][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:09:19][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:09:19][INFO] train_net.py: 446: Start epoch: 43
[03/08 16:22:48][INFO] train_net.py: 403: Train with config:
[03/08 16:22:48][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:48][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:48][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:48][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:22:49][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:22:49][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 16:22:49][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 16:22:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:22:49][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 16:22:50][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 16:22:50][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 16:22:51][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 16:22:51][INFO] misc.py: 185: Params: 133,343,372
[03/08 16:22:51][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 16:22:51][INFO] misc.py: 187: Flops: 0 G
[03/08 16:22:51][INFO] misc.py: 192: Activations: 0 M
[03/08 16:22:51][INFO] misc.py: 197: nvidia-smi
[03/08 16:22:52][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 16:22:52][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 16:22:52][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 16:22:52][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 16:22:54][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 16:22:54][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:22:54][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:22:54][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 16:22:54][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:22:54][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:22:54][INFO] train_net.py: 446: Start epoch: 43
[03/08 16:23:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10359, "dt_data": 3.54206, "dt_net": 0.56152, "epoch": "43/55", "eta": "5:32:43", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01905, "lr": 0.00000, "mAP": 0.90836, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:26:23][INFO] train_net.py: 403: Train with config:
[03/08 16:26:23][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:23][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:23][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:23][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:24][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:26:24][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:26:24][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:26:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:24][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:26:24][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 16:26:24][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 16:26:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:26:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:26:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:26:24][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:26:24][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 16:26:24][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 16:26:24][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 16:26:25][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 16:26:25][INFO] misc.py: 185: Params: 133,343,372
[03/08 16:26:25][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 16:26:25][INFO] misc.py: 187: Flops: 0 G
[03/08 16:26:25][INFO] misc.py: 192: Activations: 0 M
[03/08 16:26:25][INFO] misc.py: 197: nvidia-smi
[03/08 16:26:26][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 16:26:26][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 16:26:26][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 16:26:26][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 16:26:28][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 16:26:28][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:26:29][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:26:29][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 16:26:29][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:26:29][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:26:29][INFO] train_net.py: 446: Start epoch: 43
[03/08 16:31:36][INFO] train_net.py: 403: Train with config:
[03/08 16:31:36][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 16:31:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:31:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:31:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:31:38][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 16:31:38][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 16:31:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:31:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:31:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:31:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:31:38][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 16:31:38][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 16:31:38][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 16:31:39][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 16:31:39][INFO] misc.py: 185: Params: 133,343,372
[03/08 16:31:39][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 16:31:39][INFO] misc.py: 187: Flops: 0 G
[03/08 16:31:39][INFO] misc.py: 192: Activations: 0 M
[03/08 16:31:39][INFO] misc.py: 197: nvidia-smi
[03/08 16:31:40][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 16:31:40][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 16:31:40][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 16:31:40][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 16:31:42][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 16:31:42][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:31:42][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:31:42][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 16:31:42][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:31:42][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:31:42][INFO] train_net.py: 446: Start epoch: 43
[03/08 16:32:27][INFO] train_net.py: 403: Train with config:
[03/08 16:32:27][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:32:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:32:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:32:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:32:28][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 16:32:28][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 16:32:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:32:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:32:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:32:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:32:28][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 16:32:28][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 16:32:28][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 16:32:29][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 16:32:29][INFO] misc.py: 185: Params: 133,343,372
[03/08 16:32:29][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 16:32:30][INFO] misc.py: 187: Flops: 0 G
[03/08 16:32:30][INFO] misc.py: 192: Activations: 0 M
[03/08 16:32:30][INFO] misc.py: 197: nvidia-smi
[03/08 16:32:30][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 16:32:30][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 16:32:30][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 16:32:30][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 16:32:32][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 16:32:32][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:32:32][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:32:32][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 16:32:32][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:32:32][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:32:32][INFO] train_net.py: 446: Start epoch: 43
[03/08 16:33:39][INFO] train_net.py: 403: Train with config:
[03/08 16:33:39][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 16:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:39][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:39][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:39][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 16:33:40][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 16:33:40][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 16:33:40][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 16:33:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 16:33:40][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 16:33:41][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 16:33:41][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 16:33:42][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 16:33:42][INFO] misc.py: 185: Params: 133,343,372
[03/08 16:33:42][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 16:33:42][INFO] misc.py: 187: Flops: 0 G
[03/08 16:33:42][INFO] misc.py: 192: Activations: 0 M
[03/08 16:33:42][INFO] misc.py: 197: nvidia-smi
[03/08 16:33:42][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 16:33:42][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 16:33:42][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 16:33:42][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 16:33:44][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 16:33:44][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:33:45][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 16:33:45][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 16:33:45][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:33:45][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 16:33:45][INFO] train_net.py: 446: Start epoch: 43
[03/08 16:34:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.19430, "dt_data": 3.56825, "dt_net": 0.62605, "epoch": "43/55", "eta": "5:40:05", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01905, "lr": 0.00000, "mAP": 0.90836, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:35:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.11488, "dt_data": 3.54950, "dt_net": 0.56538, "epoch": "43/55", "eta": "5:32:57", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01765, "lr": 0.00000, "mAP": 0.92936, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:35:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52301, "dt_data": 2.96133, "dt_net": 0.56168, "epoch": "43/55", "eta": "4:44:28", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01776, "lr": 0.00000, "mAP": 0.93672, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:36:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63902, "dt_data": 3.07183, "dt_net": 0.56719, "epoch": "43/55", "eta": "4:53:14", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01815, "lr": 0.00000, "mAP": 0.94457, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:36:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.87844, "dt_data": 4.32030, "dt_net": 0.55815, "epoch": "43/55", "eta": "6:32:18", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01735, "lr": 0.00000, "mAP": 0.95408, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:37:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31868, "dt_data": 2.75818, "dt_net": 0.56050, "epoch": "43/55", "eta": "4:26:19", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01890, "lr": 0.00000, "mAP": 0.90241, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:38:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.65213, "dt_data": 3.08536, "dt_net": 0.56677, "epoch": "43/55", "eta": "4:52:28", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01745, "lr": 0.00000, "mAP": 0.92848, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 16:38:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.17816, "dt_data": 1.70104, "dt_net": 2.47711, "epoch": "43/55", "eta": "5:33:54", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01860, "lr": 0.00000, "mAP": 0.94901, "top1_err": 0.00000, "top5_err": 0.00000}
[03/08 17:36:42][INFO] train_net.py: 403: Train with config:
[03/08 17:36:42][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 17:36:42][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:42][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:42][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:42][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:42][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:42][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:42][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:42][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:42][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:42][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:42][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:42][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:42][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:42][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:42][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:42][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:36:43][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:36:43][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 17:36:43][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 17:36:43][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:36:43][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 17:36:44][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 17:36:44][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 17:36:47][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 17:36:47][INFO] misc.py: 185: Params: 133,343,372
[03/08 17:36:47][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 17:36:47][INFO] misc.py: 187: Flops: 0 G
[03/08 17:36:47][INFO] misc.py: 192: Activations: 0 M
[03/08 17:36:47][INFO] misc.py: 197: nvidia-smi
[03/08 17:36:49][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 17:36:49][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 17:36:49][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 17:36:49][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 17:36:50][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 17:36:50][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 17:36:51][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 17:36:51][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 17:36:51][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 17:36:51][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 17:36:51][INFO] train_net.py: 446: Start epoch: 43
[03/08 17:37:35][INFO] train_net.py: 403: Train with config:
[03/08 17:37:35][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 17:37:35][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:35][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:35][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:36][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:36][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:36][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:37:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:37:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:37:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:37:37][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 17:37:37][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 17:37:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:37:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:37:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:37:37][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:37:37][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 17:37:37][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 17:37:37][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 17:37:38][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 17:37:38][INFO] misc.py: 185: Params: 133,343,372
[03/08 17:37:38][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 17:37:39][INFO] misc.py: 187: Flops: 0 G
[03/08 17:37:39][INFO] misc.py: 192: Activations: 0 M
[03/08 17:37:39][INFO] misc.py: 197: nvidia-smi
[03/08 17:37:39][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 17:37:39][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 17:37:39][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 17:37:39][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 17:37:41][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 17:37:41][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 17:37:41][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 17:37:41][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 17:37:41][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 17:37:41][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 17:37:41][INFO] train_net.py: 446: Start epoch: 43
[03/08 17:38:25][INFO] meters.py: 561: <slowfast.utils.meters.ScalarMeter object at 0x7f3308303880>
[03/08 17:38:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.27941, "dt_data": 3.73552, "dt_net": 0.54389, "epoch": "43/55", "eta": "5:46:59", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01905, "lr": 0.00000, "mAP": NaN}
[03/08 17:41:26][INFO] train_net.py: 403: Train with config:
[03/08 17:41:26][INFO] train_net.py: 404: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:27][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:27][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:27][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 17:41:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 17:41:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 17:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 17:41:28][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 17:41:28][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 17:41:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:41:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:41:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:41:28][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 17:41:28][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 17:41:28][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 17:41:28][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 17:41:29][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 17:41:29][INFO] misc.py: 185: Params: 133,343,372
[03/08 17:41:29][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 17:41:29][INFO] misc.py: 187: Flops: 0 G
[03/08 17:41:29][INFO] misc.py: 192: Activations: 0 M
[03/08 17:41:29][INFO] misc.py: 197: nvidia-smi
[03/08 17:41:30][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 17:41:30][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 17:41:30][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 17:41:30][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 17:41:32][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 17:41:32][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 17:41:32][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 17:41:32][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 17:41:32][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 17:41:32][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 17:41:32][INFO] train_net.py: 446: Start epoch: 43
[03/08 17:41:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:02:50", "gpu_mem": "3.53G", "iter": "10/96", "time_diff": 1.98747}
[03/08 17:42:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:02:08", "gpu_mem": "3.53G", "iter": "20/96", "time_diff": 1.69374}
[03/08 17:42:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:58", "gpu_mem": "3.53G", "iter": "30/96", "time_diff": 1.79475}
[03/08 17:42:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:50", "gpu_mem": "3.53G", "iter": "40/96", "time_diff": 1.97453}
[03/08 17:43:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:29", "gpu_mem": "3.53G", "iter": "50/96", "time_diff": 1.93832}
[03/08 17:43:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:15", "gpu_mem": "3.53G", "iter": "60/96", "time_diff": 2.09048}
[03/08 17:43:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:43", "gpu_mem": "3.53G", "iter": "70/96", "time_diff": 1.66440}
[03/08 17:44:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:27", "gpu_mem": "3.53G", "iter": "80/96", "time_diff": 1.70804}
[03/08 17:44:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:11", "gpu_mem": "3.53G", "iter": "90/96", "time_diff": 1.95246}
[03/08 17:44:31][INFO] meters.py: 778: Getting mAP for 1524 examples
[03/08 17:44:32][INFO] logging.py:  99: json_stats: {"RAM": "40.21/251.55G", "_type": "val_epoch", "epoch": "43/55", "gpu_mem": "3.53G", "map": 0.58699, "time_diff": 0.00012}
[03/08 19:21:37][INFO] train_net.py: 396: Train with config:
[03/08 19:21:37][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 19:21:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:37][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:37][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:37][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:21:38][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:21:38][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 19:21:38][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 19:21:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:21:38][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:21:39][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:21:39][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 19:21:39][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 19:21:39][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 19:21:41][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 19:21:41][INFO] misc.py: 185: Params: 133,343,372
[03/08 19:21:41][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 19:21:41][INFO] misc.py: 187: Flops: 0 G
[03/08 19:21:41][INFO] misc.py: 192: Activations: 0 M
[03/08 19:21:41][INFO] misc.py: 197: nvidia-smi
[03/08 19:21:41][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 19:21:41][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 19:21:41][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 19:21:41][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 19:21:43][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 19:21:43][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 19:21:44][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 19:21:44][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 19:21:44][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 19:21:44][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 19:21:44][INFO] train_net.py: 439: Start epoch: 43
[03/08 19:22:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:03:13", "gpu_mem": "3.53G", "iter": "10/96", "time_diff": 2.24759}
[03/08 19:22:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:02:16", "gpu_mem": "3.53G", "iter": "20/96", "time_diff": 1.80144}
[03/08 19:22:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:54", "gpu_mem": "3.53G", "iter": "30/96", "time_diff": 1.74117}
[03/08 19:23:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:58", "gpu_mem": "3.53G", "iter": "40/96", "time_diff": 2.11983}
[03/08 19:23:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:40", "gpu_mem": "3.53G", "iter": "50/96", "time_diff": 2.18117}
[03/08 19:23:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:15", "gpu_mem": "3.53G", "iter": "60/96", "time_diff": 2.10752}
[03/08 19:24:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:42", "gpu_mem": "3.53G", "iter": "70/96", "time_diff": 1.63500}
[03/08 19:24:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:33", "gpu_mem": "3.53G", "iter": "80/96", "time_diff": 2.10068}
[03/08 19:24:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:13", "gpu_mem": "3.53G", "iter": "90/96", "time_diff": 2.29708}
[03/08 19:24:46][INFO] meters.py: 774: Getting mAP for 1524 examples
[03/08 19:24:46][INFO] logging.py:  99: json_stats: {"RAM": "40.56/251.55G", "_type": "val_epoch", "epoch": "43/55", "gpu_mem": "3.53G", "map": 0.58699, "time_diff": 0.00010}
[03/08 19:25:28][INFO] meters.py: 559: <slowfast.utils.meters.ScalarMeter object at 0x7fa764253880>
[03/08 19:25:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64743, "dt_data": 3.09474, "dt_net": 0.55269, "epoch": "43/55", "eta": "4:55:44", "gpu_mem": "17.36G", "iter": "10/375", "loss": 0.01963, "lr": 0.00000}
[03/08 19:26:05][INFO] meters.py: 559: <slowfast.utils.meters.ScalarMeter object at 0x7fa764253880>
[03/08 19:26:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.04193, "dt_data": 2.98467, "dt_net": 1.05725, "epoch": "43/55", "eta": "5:27:03", "gpu_mem": "17.36G", "iter": "20/375", "loss": 0.01871, "lr": 0.00000}
[03/08 19:34:09][INFO] train_net.py: 396: Train with config:
[03/08 19:34:09][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/video/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/08 19:34:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:09][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:09][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:09][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:09][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:09][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:09][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:09][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:09][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:09][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:09][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:09][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/08 19:34:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/08 19:34:10][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/08 19:34:10][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/08 19:34:10][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:34:10][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:34:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:34:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/08 19:34:11][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/08 19:34:11][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/08 19:34:11][INFO] uniformerv2_model.py: 334: Init center: True
[03/08 19:34:12][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/08 19:34:12][INFO] misc.py: 185: Params: 133,343,372
[03/08 19:34:12][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/08 19:34:12][INFO] misc.py: 187: Flops: 0 G
[03/08 19:34:12][INFO] misc.py: 192: Activations: 0 M
[03/08 19:34:12][INFO] misc.py: 197: nvidia-smi
[03/08 19:34:13][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/08 19:34:13][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/08 19:34:13][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/08 19:34:13][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/08 19:34:15][INFO] kinetics_sparse.py:  79: Constructing Kinetics train...
[03/08 19:34:15][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 19:34:15][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/train.csv
[03/08 19:34:15][INFO] kinetics_sparse.py:  79: Constructing Kinetics val...
[03/08 19:34:15][INFO] kinetics_sparse.py: 105: /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 19:34:15][INFO] kinetics_sparse.py: 130: Constructing kinetics dataloader (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/align_annotation/val.csv
[03/08 19:34:15][INFO] train_net.py: 439: Start epoch: 43
[03/08 19:34:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.34046, "dt_data": 3.78647, "dt_net": 0.55398, "epoch": "43/55", "eta": "5:51:56", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01905, "lr": 0.00000}
[03/08 19:35:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52048, "dt_data": 2.08316, "dt_net": 1.43732, "epoch": "43/55", "eta": "4:44:51", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01765, "lr": 0.00000}
[03/08 19:36:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69405, "dt_data": 0.02534, "dt_net": 3.66871, "epoch": "43/55", "eta": "4:58:17", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01776, "lr": 0.00000}
[03/08 19:36:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.64111, "dt_data": 0.02518, "dt_net": 3.61593, "epoch": "43/55", "eta": "4:53:24", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01814, "lr": 0.00000}
[03/08 19:37:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14623, "dt_data": 1.43198, "dt_net": 1.71425, "epoch": "43/55", "eta": "4:13:00", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01735, "lr": 0.00000}
[03/08 19:38:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.28862, "dt_data": 0.02542, "dt_net": 3.26319, "epoch": "43/55", "eta": "4:23:54", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01891, "lr": 0.00000}
[03/08 19:38:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69264, "dt_data": 0.02515, "dt_net": 3.66749, "epoch": "43/55", "eta": "4:55:43", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01746, "lr": 0.00000}
[03/08 19:39:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70797, "dt_data": 0.02537, "dt_net": 3.68260, "epoch": "43/55", "eta": "4:56:19", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01859, "lr": 0.00000}
[03/08 19:39:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98510, "dt_data": 0.02528, "dt_net": 2.95982, "epoch": "43/55", "eta": "3:58:03", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01786, "lr": 0.00000}
[03/08 19:40:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83523, "dt_data": 0.02547, "dt_net": 3.80976, "epoch": "43/55", "eta": "5:05:13", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01982, "lr": 0.00000}
[03/08 19:41:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17537, "dt_data": 0.02537, "dt_net": 3.15000, "epoch": "43/55", "eta": "4:12:10", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01901, "lr": 0.00000}
[03/08 19:41:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.80856, "dt_data": 0.02526, "dt_net": 2.78330, "epoch": "43/55", "eta": "3:42:34", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01936, "lr": 0.00000}
[03/08 19:42:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.39562, "dt_data": 0.86168, "dt_net": 3.53394, "epoch": "43/55", "eta": "5:47:37", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01842, "lr": 0.00000}
[03/08 19:42:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.28365, "dt_data": 0.02535, "dt_net": 4.25830, "epoch": "43/55", "eta": "5:38:03", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01846, "lr": 0.00000}
[03/08 19:43:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.08463, "dt_data": 0.02544, "dt_net": 3.05919, "epoch": "43/55", "eta": "4:02:54", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01977, "lr": 0.00000}
[03/08 19:44:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.53472, "dt_data": 0.02530, "dt_net": 3.50941, "epoch": "43/55", "eta": "4:37:46", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01729, "lr": 0.00000}
[03/08 19:44:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99882, "dt_data": 0.02521, "dt_net": 2.97361, "epoch": "43/55", "eta": "3:55:09", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01778, "lr": 0.00000}
[03/08 19:45:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63116, "dt_data": 0.02530, "dt_net": 3.60586, "epoch": "43/55", "eta": "4:44:08", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01814, "lr": 0.00000}
[03/08 19:45:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.23206, "dt_data": 0.02522, "dt_net": 4.20684, "epoch": "43/55", "eta": "5:30:27", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01835, "lr": 0.00000}
[03/08 19:46:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.29334, "dt_data": 0.02539, "dt_net": 4.26795, "epoch": "43/55", "eta": "5:34:31", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01937, "lr": 0.00000}
[03/08 19:47:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96283, "dt_data": 0.02536, "dt_net": 3.93747, "epoch": "43/55", "eta": "5:08:06", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01792, "lr": 0.00000}
[03/08 19:47:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.99593, "dt_data": 0.02520, "dt_net": 3.97073, "epoch": "43/55", "eta": "5:10:01", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01892, "lr": 0.00000}
[03/08 19:48:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17015, "dt_data": 0.02535, "dt_net": 3.14480, "epoch": "43/55", "eta": "4:05:25", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01900, "lr": 0.00000}
[03/08 19:49:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.23911, "dt_data": 0.02524, "dt_net": 4.21387, "epoch": "43/55", "eta": "5:27:28", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01790, "lr": 0.00000}
[03/08 19:49:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67107, "dt_data": 0.02527, "dt_net": 3.64580, "epoch": "43/55", "eta": "4:42:58", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01831, "lr": 0.00000}
[03/08 19:50:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23535, "dt_data": 0.02544, "dt_net": 3.20991, "epoch": "43/55", "eta": "4:08:51", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01854, "lr": 0.00000}
[03/08 19:50:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58590, "dt_data": 0.42292, "dt_net": 3.16298, "epoch": "43/55", "eta": "4:35:13", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01929, "lr": 0.00000}
[03/08 19:51:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70008, "dt_data": 1.97586, "dt_net": 1.72421, "epoch": "43/55", "eta": "4:43:21", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01933, "lr": 0.00000}
[03/08 19:52:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.26490, "dt_data": 0.29016, "dt_net": 3.97473, "epoch": "43/55", "eta": "5:25:54", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01867, "lr": 0.00000}
[03/08 19:52:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83424, "dt_data": 0.23438, "dt_net": 3.59986, "epoch": "43/55", "eta": "4:52:21", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01836, "lr": 0.00000}
[03/08 19:53:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92465, "dt_data": 0.02521, "dt_net": 3.89944, "epoch": "43/55", "eta": "4:58:36", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01885, "lr": 0.00000}
[03/08 19:53:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54129, "dt_data": 0.15467, "dt_net": 3.38662, "epoch": "43/55", "eta": "4:28:50", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01818, "lr": 0.00000}
[03/08 19:54:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.72752, "dt_data": 0.73270, "dt_net": 2.99481, "epoch": "43/55", "eta": "4:42:21", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01901, "lr": 0.00000}
[03/08 19:55:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93572, "dt_data": 1.54296, "dt_net": 1.39276, "epoch": "43/55", "eta": "3:41:53", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01849, "lr": 0.00000}
[03/08 19:55:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.00260, "dt_data": 0.02519, "dt_net": 3.97741, "epoch": "43/55", "eta": "5:01:51", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01788, "lr": 0.00000}
[03/08 19:56:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75505, "dt_data": 0.02527, "dt_net": 3.72978, "epoch": "43/55", "eta": "4:42:34", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01907, "lr": 0.00000}
[03/08 19:56:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74827, "dt_data": 0.02517, "dt_net": 3.72311, "epoch": "43/55", "eta": "4:41:25", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.02031, "lr": 0.00000}
[03/08 19:57:17][INFO] logging.py:  99: json_stats: {"RAM": "34.68/251.55G", "_type": "train_epoch", "dt": 0.00044, "dt_data": 0.00044, "dt_net": 4.58591, "epoch": "43/55", "eta": "0:00:01", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 19:57:17][INFO] train_net.py: 478: Epoch 42 takes 1381.84s. Epochs from 42 to 42 take 1381.84s in average and 1381.84s in median.
[03/08 19:57:17][INFO] train_net.py: 484: For epoch 42, each iteraction takes 3.68s in average. From epoch 42 to 42, each iteraction takes 3.68s in average.
[03/08 19:57:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:02:45", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 1.93009}
[03/08 19:57:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:02:20", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.85383}
[03/08 19:58:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:53", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.71318}
[03/08 19:58:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:50", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 1.97696}
[03/08 19:58:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:34", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 2.05720}
[03/08 19:59:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:45", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 2.92091}
[03/08 19:59:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:49", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.89644}
[03/08 19:59:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:38", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 2.43624}
[03/08 20:00:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:12", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.05136}
[03/08 20:00:27][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 20:00:27][INFO] logging.py:  99: json_stats: {"RAM": "45.11/251.55G", "_type": "val_epoch", "epoch": "43/55", "gpu_mem": "17.37G", "map": 0.59988, "time_diff": 0.00015}
[03/08 20:01:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77934, "dt_data": 2.68126, "dt_net": 1.09808, "epoch": "44/55", "eta": "4:42:49", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01826, "lr": 0.00000}
[03/08 20:01:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41245, "dt_data": 1.20201, "dt_net": 2.21043, "epoch": "44/55", "eta": "4:14:47", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01846, "lr": 0.00000}
[03/08 20:02:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58218, "dt_data": 2.29986, "dt_net": 1.28232, "epoch": "44/55", "eta": "4:26:52", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01742, "lr": 0.00000}
[03/08 20:02:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.37266, "dt_data": 1.83341, "dt_net": 2.53925, "epoch": "44/55", "eta": "5:25:02", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01862, "lr": 0.00000}
[03/08 20:03:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95536, "dt_data": 0.02521, "dt_net": 3.93015, "epoch": "44/55", "eta": "4:53:21", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01814, "lr": 0.00000}
[03/08 20:04:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33040, "dt_data": 0.02527, "dt_net": 3.30512, "epoch": "44/55", "eta": "4:06:26", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01967, "lr": 0.00000}
[03/08 20:04:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.31675, "dt_data": 0.02555, "dt_net": 3.29121, "epoch": "44/55", "eta": "4:04:53", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01803, "lr": 0.00000}
[03/08 20:05:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61734, "dt_data": 0.02534, "dt_net": 3.59200, "epoch": "44/55", "eta": "4:26:28", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01755, "lr": 0.00000}
[03/08 20:05:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07355, "dt_data": 0.02517, "dt_net": 3.04838, "epoch": "44/55", "eta": "3:45:54", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01873, "lr": 0.00000}
[03/08 20:06:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74346, "dt_data": 0.02545, "dt_net": 2.71801, "epoch": "44/55", "eta": "3:21:11", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01662, "lr": 0.00000}
[03/08 20:07:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.00481, "dt_data": 0.02533, "dt_net": 3.97948, "epoch": "44/55", "eta": "4:53:01", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01686, "lr": 0.00000}
[03/08 20:07:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.52052, "dt_data": 0.02570, "dt_net": 3.49482, "epoch": "44/55", "eta": "4:16:59", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01843, "lr": 0.00000}
[03/08 20:08:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39735, "dt_data": 0.02530, "dt_net": 3.37205, "epoch": "44/55", "eta": "4:07:26", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01849, "lr": 0.00000}
[03/08 20:08:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.43729, "dt_data": 0.02523, "dt_net": 4.41205, "epoch": "44/55", "eta": "5:22:26", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01817, "lr": 0.00000}
[03/08 20:09:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.00186, "dt_data": 0.02533, "dt_net": 2.97653, "epoch": "44/55", "eta": "3:37:38", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01790, "lr": 0.00000}
[03/08 20:10:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46774, "dt_data": 0.02539, "dt_net": 3.44234, "epoch": "44/55", "eta": "4:10:49", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01798, "lr": 0.00000}
[03/08 20:10:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83103, "dt_data": 0.02521, "dt_net": 3.80581, "epoch": "44/55", "eta": "4:36:28", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01782, "lr": 0.00000}
[03/08 20:11:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.41421, "dt_data": 0.02528, "dt_net": 4.38893, "epoch": "44/55", "eta": "5:17:49", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01903, "lr": 0.00000}
[03/08 20:11:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.19311, "dt_data": 0.02542, "dt_net": 4.16769, "epoch": "44/55", "eta": "5:01:12", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01769, "lr": 0.00000}
[03/08 20:12:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70272, "dt_data": 0.44816, "dt_net": 3.25456, "epoch": "44/55", "eta": "4:25:21", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01650, "lr": 0.00000}
[03/08 20:13:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59634, "dt_data": 2.35499, "dt_net": 1.24135, "epoch": "44/55", "eta": "4:17:08", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01854, "lr": 0.00000}
[03/08 20:13:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.21300, "dt_data": 3.66208, "dt_net": 0.55092, "epoch": "44/55", "eta": "5:00:31", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01937, "lr": 0.00000}
[03/08 20:14:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05606, "dt_data": 2.50495, "dt_net": 0.55111, "epoch": "44/55", "eta": "3:37:29", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01701, "lr": 0.00000}
[03/08 20:14:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.18305, "dt_data": 3.62969, "dt_net": 0.55335, "epoch": "44/55", "eta": "4:56:59", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01824, "lr": 0.00000}
[03/08 20:15:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.58373, "dt_data": 2.55755, "dt_net": 2.02618, "epoch": "44/55", "eta": "5:24:40", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01812, "lr": 0.00000}
[03/08 20:16:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24280, "dt_data": 0.02543, "dt_net": 3.21736, "epoch": "44/55", "eta": "3:49:09", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01814, "lr": 0.00000}
[03/08 20:16:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98479, "dt_data": 1.42852, "dt_net": 1.55627, "epoch": "44/55", "eta": "3:30:25", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01700, "lr": 0.00000}
[03/08 20:17:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70532, "dt_data": 3.10342, "dt_net": 0.60190, "epoch": "44/55", "eta": "4:20:36", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01824, "lr": 0.00000}
[03/08 20:17:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86709, "dt_data": 3.32030, "dt_net": 0.54678, "epoch": "44/55", "eta": "4:31:20", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01825, "lr": 0.00000}
[03/08 20:18:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10935, "dt_data": 2.83377, "dt_net": 1.27557, "epoch": "44/55", "eta": "4:47:39", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01875, "lr": 0.00000}
[03/08 20:19:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55812, "dt_data": 0.20412, "dt_net": 3.35400, "epoch": "44/55", "eta": "4:08:28", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01898, "lr": 0.00000}
[03/08 20:19:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90949, "dt_data": 0.02532, "dt_net": 3.88417, "epoch": "44/55", "eta": "4:32:21", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01858, "lr": 0.00000}
[03/08 20:20:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.28902, "dt_data": 0.02522, "dt_net": 4.26380, "epoch": "44/55", "eta": "4:58:05", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01941, "lr": 0.00000}
[03/08 20:21:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21362, "dt_data": 0.02545, "dt_net": 3.18817, "epoch": "44/55", "eta": "3:42:48", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01960, "lr": 0.00000}
[03/08 20:21:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.01849, "dt_data": 0.02527, "dt_net": 3.99321, "epoch": "44/55", "eta": "4:37:56", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01900, "lr": 0.00000}
[03/08 20:22:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42207, "dt_data": 0.02524, "dt_net": 3.39683, "epoch": "44/55", "eta": "3:56:07", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01900, "lr": 0.00000}
[03/08 20:22:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.35279, "dt_data": 0.02509, "dt_net": 4.32770, "epoch": "44/55", "eta": "4:59:37", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01830, "lr": 0.00000}
[03/08 20:23:07][INFO] logging.py:  99: json_stats: {"RAM": "44.42/251.55G", "_type": "train_epoch", "dt": 0.00062, "dt_data": 0.00062, "dt_net": 3.39288, "epoch": "44/55", "eta": "0:00:02", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 20:23:07][INFO] train_net.py: 478: Epoch 43 takes 1360.26s. Epochs from 42 to 43 take 1371.05s in average and 1371.05s in median.
[03/08 20:23:07][INFO] train_net.py: 484: For epoch 43, each iteraction takes 3.63s in average. From epoch 42 to 43, each iteraction takes 3.66s in average.
[03/08 20:23:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:02:47", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 1.95292}
[03/08 20:23:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:02:24", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.89581}
[03/08 20:24:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:02:00", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.83245}
[03/08 20:24:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:01:53", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 2.02589}
[03/08 20:24:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:01:32", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 2.00387}
[03/08 20:25:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:01:19", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 2.20709}
[03/08 20:25:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:00:50", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.93172}
[03/08 20:25:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:00:29", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 1.84942}
[03/08 20:25:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "44/55", "eta": "0:00:12", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.14695}
[03/08 20:26:09][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 20:26:09][INFO] logging.py:  99: json_stats: {"RAM": "46.20/251.55G", "_type": "val_epoch", "epoch": "44/55", "gpu_mem": "17.37G", "map": 0.60362, "time_diff": 0.00010}
[03/08 20:26:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 5.36240, "dt_data": 4.80414, "dt_net": 0.55826, "epoch": "45/55", "eta": "6:07:46", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01749, "lr": 0.00000}
[03/08 20:27:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17555, "dt_data": 2.62228, "dt_net": 0.55327, "epoch": "45/55", "eta": "3:37:15", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01813, "lr": 0.00000}
[03/08 20:28:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.15964, "dt_data": 3.60527, "dt_net": 0.55436, "epoch": "45/55", "eta": "4:43:53", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01867, "lr": 0.00000}
[03/08 20:28:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96983, "dt_data": 3.41438, "dt_net": 0.55544, "epoch": "45/55", "eta": "4:30:16", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01871, "lr": 0.00000}
[03/08 20:29:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10445, "dt_data": 3.55472, "dt_net": 0.54973, "epoch": "45/55", "eta": "4:38:45", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01750, "lr": 0.00000}
[03/08 20:29:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83598, "dt_data": 3.28828, "dt_net": 0.54770, "epoch": "45/55", "eta": "4:19:53", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01709, "lr": 0.00000}
[03/08 20:30:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.95017, "dt_data": 3.39808, "dt_net": 0.55209, "epoch": "45/55", "eta": "4:26:57", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01772, "lr": 0.00000}
[03/08 20:31:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33570, "dt_data": 2.78346, "dt_net": 0.55224, "epoch": "45/55", "eta": "3:44:52", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01667, "lr": 0.00000}
[03/08 20:31:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97218, "dt_data": 3.41934, "dt_net": 0.55284, "epoch": "45/55", "eta": "4:27:07", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01772, "lr": 0.00000}
[03/08 20:32:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.96440, "dt_data": 2.41251, "dt_net": 0.55189, "epoch": "45/55", "eta": "3:18:51", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01899, "lr": 0.00000}
[03/08 20:32:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33660, "dt_data": 2.78417, "dt_net": 0.55243, "epoch": "45/55", "eta": "3:43:16", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01688, "lr": 0.00000}
[03/08 20:33:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46672, "dt_data": 2.91634, "dt_net": 0.55038, "epoch": "45/55", "eta": "3:51:24", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01841, "lr": 0.00000}
[03/08 20:34:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.28563, "dt_data": 3.73232, "dt_net": 0.55331, "epoch": "45/55", "eta": "4:45:21", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01833, "lr": 0.00000}
[03/08 20:34:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89009, "dt_data": 3.33689, "dt_net": 0.55319, "epoch": "45/55", "eta": "4:18:21", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01780, "lr": 0.00000}
[03/08 20:35:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.73740, "dt_data": 3.18792, "dt_net": 0.54948, "epoch": "45/55", "eta": "4:07:36", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01850, "lr": 0.00000}
[03/08 20:35:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47380, "dt_data": 2.92589, "dt_net": 0.54791, "epoch": "45/55", "eta": "3:49:33", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01666, "lr": 0.00000}
[03/08 20:36:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.14945, "dt_data": 0.02524, "dt_net": 3.12421, "epoch": "45/55", "eta": "3:27:36", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01633, "lr": 0.00000}
[03/08 20:37:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40998, "dt_data": 0.02533, "dt_net": 3.38465, "epoch": "45/55", "eta": "3:44:12", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01849, "lr": 0.00000}
[03/08 20:37:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63523, "dt_data": 0.02521, "dt_net": 3.61002, "epoch": "45/55", "eta": "3:58:24", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01759, "lr": 0.00000}
[03/08 20:38:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.42388, "dt_data": 0.02532, "dt_net": 4.39856, "epoch": "45/55", "eta": "4:49:23", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01907, "lr": 0.00000}
[03/08 20:39:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82387, "dt_data": 0.16904, "dt_net": 3.65482, "epoch": "45/55", "eta": "4:09:30", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01781, "lr": 0.00000}
[03/08 20:39:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29367, "dt_data": 0.02544, "dt_net": 3.26823, "epoch": "45/55", "eta": "3:34:21", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01744, "lr": 0.00000}
[03/08 20:40:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85134, "dt_data": 0.02564, "dt_net": 2.82570, "epoch": "45/55", "eta": "3:05:05", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01871, "lr": 0.00000}
[03/08 20:40:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23228, "dt_data": 0.02535, "dt_net": 3.20693, "epoch": "45/55", "eta": "3:29:17", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01843, "lr": 0.00000}
[03/08 20:41:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62817, "dt_data": 0.02523, "dt_net": 3.60294, "epoch": "45/55", "eta": "3:54:19", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01733, "lr": 0.00000}
[03/08 20:42:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89283, "dt_data": 0.02535, "dt_net": 3.86748, "epoch": "45/55", "eta": "4:10:45", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01995, "lr": 0.00000}
[03/08 20:42:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.74038, "dt_data": 0.02542, "dt_net": 2.71495, "epoch": "45/55", "eta": "2:56:04", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01800, "lr": 0.00000}
[03/08 20:43:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.98208, "dt_data": 0.02528, "dt_net": 2.95679, "epoch": "45/55", "eta": "3:11:06", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01733, "lr": 0.00000}
[03/08 20:43:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29269, "dt_data": 0.02540, "dt_net": 3.26728, "epoch": "45/55", "eta": "3:30:27", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01793, "lr": 0.00000}
[03/08 20:44:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.67918, "dt_data": 0.97168, "dt_net": 3.70750, "epoch": "45/55", "eta": "4:58:17", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01836, "lr": 0.00000}
[03/08 20:45:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.20143, "dt_data": 0.02537, "dt_net": 4.17605, "epoch": "45/55", "eta": "4:27:08", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01911, "lr": 0.00000}
[03/08 20:45:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.33284, "dt_data": 0.02586, "dt_net": 3.30698, "epoch": "45/55", "eta": "3:31:21", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01787, "lr": 0.00000}
[03/08 20:46:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.07310, "dt_data": 1.48640, "dt_net": 2.58670, "epoch": "45/55", "eta": "4:17:37", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01803, "lr": 0.00000}
[03/08 20:46:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.24198, "dt_data": 0.06174, "dt_net": 3.18024, "epoch": "45/55", "eta": "3:24:30", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01846, "lr": 0.00000}
[03/08 20:47:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.92356, "dt_data": 0.61468, "dt_net": 2.30888, "epoch": "45/55", "eta": "3:03:56", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01994, "lr": 0.00000}
[03/08 20:48:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60013, "dt_data": 0.29190, "dt_net": 3.30822, "epoch": "45/55", "eta": "3:45:54", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01835, "lr": 0.00000}
[03/08 20:48:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23466, "dt_data": 2.57239, "dt_net": 0.66226, "epoch": "45/55", "eta": "3:22:26", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01772, "lr": 0.00000}
[03/08 20:48:56][INFO] logging.py:  99: json_stats: {"RAM": "46.33/251.55G", "_type": "train_epoch", "dt": 0.00050, "dt_data": 0.00049, "dt_net": 0.99506, "epoch": "45/55", "eta": "0:00:01", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 20:48:56][INFO] train_net.py: 478: Epoch 44 takes 1367.09s. Epochs from 42 to 44 take 1369.73s in average and 1367.09s in median.
[03/08 20:48:56][INFO] train_net.py: 484: For epoch 44, each iteraction takes 3.65s in average. From epoch 42 to 44, each iteraction takes 3.65s in average.
[03/08 20:49:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:02:53", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 2.01565}
[03/08 20:49:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:02:17", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.81295}
[03/08 20:49:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:02:01", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.84061}
[03/08 20:50:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:01:49", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 1.96274}
[03/08 20:50:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:01:39", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 2.16296}
[03/08 20:50:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:01:16", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 2.11360}
[03/08 20:51:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:00:48", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.88252}
[03/08 20:51:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:00:32", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 2.05529}
[03/08 20:51:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "45/55", "eta": "0:00:13", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.30174}
[03/08 20:51:59][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 20:51:59][INFO] logging.py:  99: json_stats: {"RAM": "47.42/251.55G", "_type": "val_epoch", "epoch": "45/55", "gpu_mem": "17.37G", "map": 0.59937, "time_diff": 0.00010}
[03/08 20:52:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.37159, "dt_data": 2.81771, "dt_net": 0.55388, "epoch": "46/55", "eta": "3:30:09", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01752, "lr": 0.00000}
[03/08 20:53:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.13964, "dt_data": 0.02518, "dt_net": 3.11446, "epoch": "46/55", "eta": "3:15:10", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01827, "lr": 0.00000}
[03/08 20:53:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.68264, "dt_data": 0.02519, "dt_net": 4.65745, "epoch": "46/55", "eta": "4:50:19", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01772, "lr": 0.00000}
[03/08 20:54:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.18757, "dt_data": 0.02574, "dt_net": 4.16183, "epoch": "46/55", "eta": "4:18:55", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01825, "lr": 0.00000}
[03/08 20:55:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44821, "dt_data": 0.02526, "dt_net": 3.42295, "epoch": "46/55", "eta": "3:32:38", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01652, "lr": 0.00000}
[03/08 20:55:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.67759, "dt_data": 0.02531, "dt_net": 2.65228, "epoch": "46/55", "eta": "2:44:40", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01770, "lr": 0.00000}
[03/08 20:56:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.07636, "dt_data": 0.02519, "dt_net": 4.05116, "epoch": "46/55", "eta": "4:10:00", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01767, "lr": 0.00000}
[03/08 20:56:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.16353, "dt_data": 0.02519, "dt_net": 4.13834, "epoch": "46/55", "eta": "4:14:40", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01799, "lr": 0.00000}
[03/08 20:57:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.21340, "dt_data": 0.02540, "dt_net": 4.18800, "epoch": "46/55", "eta": "4:17:01", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01657, "lr": 0.00000}
[03/08 20:58:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.52644, "dt_data": 0.02524, "dt_net": 2.50119, "epoch": "46/55", "eta": "2:33:41", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01780, "lr": 0.00000}
[03/08 20:58:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.21903, "dt_data": 0.02548, "dt_net": 3.19355, "epoch": "46/55", "eta": "3:15:17", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01819, "lr": 0.00000}
[03/08 20:59:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.31156, "dt_data": 0.02524, "dt_net": 4.28632, "epoch": "46/55", "eta": "4:20:50", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01714, "lr": 0.00000}
[03/08 20:59:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.16491, "dt_data": 2.67421, "dt_net": 1.49070, "epoch": "46/55", "eta": "4:11:16", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01720, "lr": 0.00000}
[03/08 21:00:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.81195, "dt_data": 3.26134, "dt_net": 0.55061, "epoch": "46/55", "eta": "3:49:21", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01732, "lr": 0.00000}
[03/08 21:01:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29348, "dt_data": 2.74337, "dt_net": 0.55011, "epoch": "46/55", "eta": "3:17:36", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01722, "lr": 0.00000}
[03/08 21:01:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92778, "dt_data": 3.08958, "dt_net": 0.83819, "epoch": "46/55", "eta": "3:55:00", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01843, "lr": 0.00000}
[03/08 21:02:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.22607, "dt_data": 3.67292, "dt_net": 0.55315, "epoch": "46/55", "eta": "4:12:09", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01812, "lr": 0.00000}
[03/08 21:02:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86163, "dt_data": 3.31313, "dt_net": 0.54849, "epoch": "46/55", "eta": "3:49:46", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01771, "lr": 0.00000}
[03/08 21:03:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.82049, "dt_data": 2.27101, "dt_net": 0.54948, "epoch": "46/55", "eta": "2:47:20", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01928, "lr": 0.00000}
[03/08 21:04:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80378, "dt_data": 3.25401, "dt_net": 0.54977, "epoch": "46/55", "eta": "3:45:03", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01748, "lr": 0.00000}
[03/08 21:04:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03005, "dt_data": 2.48145, "dt_net": 0.54860, "epoch": "46/55", "eta": "2:58:46", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01797, "lr": 0.00000}
[03/08 21:05:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.71872, "dt_data": 3.16894, "dt_net": 0.54978, "epoch": "46/55", "eta": "3:38:47", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01722, "lr": 0.00000}
[03/08 21:06:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05369, "dt_data": 2.50097, "dt_net": 0.55271, "epoch": "46/55", "eta": "2:59:08", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01698, "lr": 0.00000}
[03/08 21:06:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.00599, "dt_data": 3.45209, "dt_net": 0.55390, "epoch": "46/55", "eta": "3:54:21", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01693, "lr": 0.00000}
[03/08 21:07:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.87304, "dt_data": 0.13966, "dt_net": 3.73338, "epoch": "46/55", "eta": "3:45:55", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01740, "lr": 0.00000}
[03/08 21:07:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62745, "dt_data": 3.07597, "dt_net": 0.55148, "epoch": "46/55", "eta": "3:30:59", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01835, "lr": 0.00000}
[03/08 21:08:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.94248, "dt_data": 0.02531, "dt_net": 3.91717, "epoch": "46/55", "eta": "3:48:39", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01809, "lr": 0.00000}
[03/08 21:09:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34478, "dt_data": 0.02510, "dt_net": 3.31968, "epoch": "46/55", "eta": "3:13:26", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01739, "lr": 0.00000}
[03/08 21:09:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91600, "dt_data": 0.02522, "dt_net": 3.89078, "epoch": "46/55", "eta": "3:45:49", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01711, "lr": 0.00000}
[03/08 21:10:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.64879, "dt_data": 0.02534, "dt_net": 4.62345, "epoch": "46/55", "eta": "4:27:18", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01590, "lr": 0.00000}
[03/08 21:10:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23667, "dt_data": 0.02550, "dt_net": 3.21117, "epoch": "46/55", "eta": "3:05:34", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01709, "lr": 0.00000}
[03/08 21:11:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74998, "dt_data": 0.02518, "dt_net": 3.72479, "epoch": "46/55", "eta": "3:34:22", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01770, "lr": 0.00000}
[03/08 21:12:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.29914, "dt_data": 0.02516, "dt_net": 3.27398, "epoch": "46/55", "eta": "3:08:03", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01831, "lr": 0.00000}
[03/08 21:12:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.02102, "dt_data": 0.02524, "dt_net": 2.99578, "epoch": "46/55", "eta": "2:51:41", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01858, "lr": 0.00000}
[03/08 21:13:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05914, "dt_data": 0.02525, "dt_net": 3.03388, "epoch": "46/55", "eta": "2:53:21", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01662, "lr": 0.00000}
[03/08 21:13:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.24986, "dt_data": 0.83083, "dt_net": 3.41903, "epoch": "46/55", "eta": "4:00:07", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01699, "lr": 0.00000}
[03/08 21:14:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48995, "dt_data": 0.02531, "dt_net": 3.46464, "epoch": "46/55", "eta": "3:16:36", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01804, "lr": 0.00000}
[03/08 21:14:39][INFO] logging.py:  99: json_stats: {"RAM": "47.02/251.55G", "_type": "train_epoch", "dt": 0.00042, "dt_data": 0.00042, "dt_net": 3.16767, "epoch": "46/55", "eta": "0:00:01", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 21:14:39][INFO] train_net.py: 478: Epoch 45 takes 1360.19s. Epochs from 42 to 45 take 1367.34s in average and 1363.67s in median.
[03/08 21:14:39][INFO] train_net.py: 484: For epoch 45, each iteraction takes 3.63s in average. From epoch 42 to 45, each iteraction takes 3.65s in average.
[03/08 21:14:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:02:44", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 1.91404}
[03/08 21:15:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:02:11", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.72486}
[03/08 21:15:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:02:03", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.86786}
[03/08 21:15:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:01:50", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 1.96598}
[03/08 21:16:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:01:30", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 1.97809}
[03/08 21:16:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:01:13", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 2.05424}
[03/08 21:16:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:00:48", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.84687}
[03/08 21:17:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:00:32", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 2.01822}
[03/08 21:17:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "46/55", "eta": "0:00:13", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.20778}
[03/08 21:17:39][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 21:17:39][INFO] logging.py:  99: json_stats: {"RAM": "46.35/251.55G", "_type": "val_epoch", "epoch": "46/55", "gpu_mem": "17.37G", "map": 0.59904, "time_diff": 0.00013}
[03/08 21:18:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74084, "dt_data": 3.19012, "dt_net": 0.55071, "epoch": "47/55", "eta": "3:29:47", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01664, "lr": 0.00000}
[03/08 21:18:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61632, "dt_data": 3.06059, "dt_net": 0.55572, "epoch": "47/55", "eta": "3:22:12", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01788, "lr": 0.00000}
[03/08 21:19:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.67064, "dt_data": 3.11731, "dt_net": 0.55332, "epoch": "47/55", "eta": "3:24:38", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01771, "lr": 0.00000}
[03/08 21:20:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.64186, "dt_data": 2.09131, "dt_net": 0.55055, "epoch": "47/55", "eta": "2:26:50", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01779, "lr": 0.00000}
[03/08 21:20:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.93789, "dt_data": 2.38439, "dt_net": 0.55350, "epoch": "47/55", "eta": "2:42:48", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01735, "lr": 0.00000}
[03/08 21:21:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.34386, "dt_data": 2.79230, "dt_net": 0.55156, "epoch": "47/55", "eta": "3:04:44", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01719, "lr": 0.00000}
[03/08 21:21:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.07852, "dt_data": 2.52800, "dt_net": 0.55052, "epoch": "47/55", "eta": "2:49:34", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01636, "lr": 0.00000}
[03/08 21:22:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91513, "dt_data": 3.36395, "dt_net": 0.55118, "epoch": "47/55", "eta": "3:35:00", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01668, "lr": 0.00000}
[03/08 21:23:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.34966, "dt_data": 1.79784, "dt_net": 0.55183, "epoch": "47/55", "eta": "2:08:38", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01818, "lr": 0.00000}
[03/08 21:23:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84682, "dt_data": 3.29386, "dt_net": 0.55296, "epoch": "47/55", "eta": "3:29:58", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01690, "lr": 0.00000}
[03/08 21:24:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.47541, "dt_data": 2.92312, "dt_net": 0.55229, "epoch": "47/55", "eta": "3:09:07", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01776, "lr": 0.00000}
[03/08 21:24:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.00546, "dt_data": 3.45266, "dt_net": 0.55280, "epoch": "47/55", "eta": "3:37:17", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01936, "lr": 0.00000}
[03/08 21:25:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.08950, "dt_data": 3.54248, "dt_net": 0.54702, "epoch": "47/55", "eta": "3:41:10", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01694, "lr": 0.00000}
[03/08 21:26:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85048, "dt_data": 2.16539, "dt_net": 1.68509, "epoch": "47/55", "eta": "3:27:36", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01723, "lr": 0.00000}
[03/08 21:26:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63160, "dt_data": 2.93444, "dt_net": 0.69716, "epoch": "47/55", "eta": "3:15:11", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01798, "lr": 0.00000}
[03/08 21:27:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.32095, "dt_data": 2.76595, "dt_net": 0.55499, "epoch": "47/55", "eta": "2:57:56", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01854, "lr": 0.00000}
[03/08 21:27:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82991, "dt_data": 3.28233, "dt_net": 0.54757, "epoch": "47/55", "eta": "3:24:34", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01853, "lr": 0.00000}
[03/08 21:28:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.88027, "dt_data": 2.32777, "dt_net": 0.55250, "epoch": "47/55", "eta": "2:33:22", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01808, "lr": 0.00000}
[03/08 21:29:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84216, "dt_data": 3.29029, "dt_net": 0.55186, "epoch": "47/55", "eta": "3:23:57", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01790, "lr": 0.00000}
[03/08 21:29:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.83270, "dt_data": 2.28220, "dt_net": 0.55050, "epoch": "47/55", "eta": "2:29:53", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01759, "lr": 0.00000}
[03/08 21:30:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04707, "dt_data": 2.48984, "dt_net": 0.55723, "epoch": "47/55", "eta": "2:40:43", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01757, "lr": 0.00000}
[03/08 21:30:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.44145, "dt_data": 2.54908, "dt_net": 0.89236, "epoch": "47/55", "eta": "3:00:57", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01822, "lr": 0.00000}
[03/08 21:31:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.39576, "dt_data": 2.84590, "dt_net": 0.54986, "epoch": "47/55", "eta": "2:57:59", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01808, "lr": 0.00000}
[03/08 21:31:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.85633, "dt_data": 3.30441, "dt_net": 0.55191, "epoch": "47/55", "eta": "3:21:29", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01876, "lr": 0.00000}
[03/08 21:32:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61172, "dt_data": 3.06286, "dt_net": 0.54886, "epoch": "47/55", "eta": "3:08:06", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01668, "lr": 0.00000}
[03/08 21:33:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.99324, "dt_data": 2.44347, "dt_net": 0.54977, "epoch": "47/55", "eta": "2:35:23", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01612, "lr": 0.00000}
[03/08 21:33:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54821, "dt_data": 3.00192, "dt_net": 0.54629, "epoch": "47/55", "eta": "3:03:37", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01771, "lr": 0.00000}
[03/08 21:34:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.18791, "dt_data": 3.63667, "dt_net": 0.55124, "epoch": "47/55", "eta": "3:36:01", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01841, "lr": 0.00000}
[03/08 21:34:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.36915, "dt_data": 2.82015, "dt_net": 0.54900, "epoch": "47/55", "eta": "2:53:13", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01827, "lr": 0.00000}
[03/08 21:35:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.84104, "dt_data": 3.28843, "dt_net": 0.55261, "epoch": "47/55", "eta": "3:16:51", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01844, "lr": 0.00000}
[03/08 21:35:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.78817, "dt_data": 2.35633, "dt_net": 1.43184, "epoch": "47/55", "eta": "3:13:30", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01827, "lr": 0.00000}
[03/08 21:36:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18061, "dt_data": 0.02564, "dt_net": 3.15497, "epoch": "47/55", "eta": "2:41:56", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01587, "lr": 0.00000}
[03/08 21:37:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50819, "dt_data": 0.02518, "dt_net": 3.48301, "epoch": "47/55", "eta": "2:58:02", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01864, "lr": 0.00000}
[03/08 21:37:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.40366, "dt_data": 0.02512, "dt_net": 4.37854, "epoch": "47/55", "eta": "3:42:45", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01835, "lr": 0.00000}
[03/08 21:38:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.95347, "dt_data": 0.02544, "dt_net": 2.92802, "epoch": "47/55", "eta": "2:28:54", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01778, "lr": 0.00000}
[03/08 21:38:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.20990, "dt_data": 0.43791, "dt_net": 3.77198, "epoch": "47/55", "eta": "3:31:32", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01761, "lr": 0.00000}
[03/08 21:39:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.59051, "dt_data": 0.02520, "dt_net": 3.56531, "epoch": "47/55", "eta": "2:59:49", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01721, "lr": 0.00000}
[03/08 21:39:49][INFO] logging.py:  99: json_stats: {"RAM": "45.32/251.55G", "_type": "train_epoch", "dt": 0.00037, "dt_data": 0.00037, "dt_net": 3.43376, "epoch": "47/55", "eta": "0:00:01", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 21:39:49][INFO] train_net.py: 478: Epoch 46 takes 1329.65s. Epochs from 42 to 46 take 1359.81s in average and 1360.26s in median.
[03/08 21:39:49][INFO] train_net.py: 484: For epoch 46, each iteraction takes 3.55s in average. From epoch 42 to 46, each iteraction takes 3.63s in average.
[03/08 21:40:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:03:02", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 2.12241}
[03/08 21:40:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:02:08", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.69498}
[03/08 21:40:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:01:51", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.68606}
[03/08 21:41:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:01:48", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 1.93603}
[03/08 21:41:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:01:30", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 1.96188}
[03/08 21:41:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:01:16", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 2.13054}
[03/08 21:41:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:00:44", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.72278}
[03/08 21:42:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:00:30", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 1.92254}
[03/08 21:42:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "47/55", "eta": "0:00:13", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.20271}
[03/08 21:42:46][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 21:42:46][INFO] logging.py:  99: json_stats: {"RAM": "46.64/251.55G", "_type": "val_epoch", "epoch": "47/55", "gpu_mem": "17.37G", "map": 0.60112, "time_diff": 0.00010}
[03/08 21:43:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.62723, "dt_data": 3.06794, "dt_net": 0.55929, "epoch": "48/55", "eta": "3:00:45", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01839, "lr": 0.00000}
[03/08 21:44:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.82120, "dt_data": 3.27082, "dt_net": 0.55037, "epoch": "48/55", "eta": "3:09:47", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01593, "lr": 0.00000}
[03/08 21:44:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.61484, "dt_data": 3.05993, "dt_net": 0.55491, "epoch": "48/55", "eta": "2:58:56", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01758, "lr": 0.00000}
[03/08 21:45:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27868, "dt_data": 2.72445, "dt_net": 0.55423, "epoch": "48/55", "eta": "2:41:44", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01661, "lr": 0.00000}
[03/08 21:45:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48690, "dt_data": 0.91900, "dt_net": 2.56789, "epoch": "48/55", "eta": "2:51:26", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01724, "lr": 0.00000}
[03/08 21:46:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.41555, "dt_data": 0.02526, "dt_net": 3.39028, "epoch": "48/55", "eta": "2:47:21", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01689, "lr": 0.00000}
[03/08 21:47:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83215, "dt_data": 0.02509, "dt_net": 3.80705, "epoch": "48/55", "eta": "3:07:08", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01681, "lr": 0.00000}
[03/08 21:47:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27706, "dt_data": 0.02535, "dt_net": 3.25171, "epoch": "48/55", "eta": "2:39:29", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01646, "lr": 0.00000}
[03/08 21:48:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.43418, "dt_data": 0.02537, "dt_net": 3.40881, "epoch": "48/55", "eta": "2:46:33", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01838, "lr": 0.00000}
[03/08 21:48:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80124, "dt_data": 0.02533, "dt_net": 3.77590, "epoch": "48/55", "eta": "3:03:43", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01800, "lr": 0.00000}
[03/08 21:49:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77952, "dt_data": 0.02519, "dt_net": 3.75434, "epoch": "48/55", "eta": "3:02:02", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01528, "lr": 0.00000}
[03/08 21:50:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.27892, "dt_data": 0.02527, "dt_net": 3.25365, "epoch": "48/55", "eta": "2:37:23", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01779, "lr": 0.00000}
[03/08 21:50:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.48999, "dt_data": 0.02546, "dt_net": 4.46454, "epoch": "48/55", "eta": "3:34:46", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01890, "lr": 0.00000}
[03/08 21:51:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.83302, "dt_data": 0.02523, "dt_net": 3.80779, "epoch": "48/55", "eta": "3:02:42", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01723, "lr": 0.00000}
[03/08 21:52:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.70475, "dt_data": 0.02518, "dt_net": 3.67957, "epoch": "48/55", "eta": "2:55:58", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01681, "lr": 0.00000}
[03/08 21:52:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.37895, "dt_data": 0.02523, "dt_net": 4.35372, "epoch": "48/55", "eta": "3:27:16", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01755, "lr": 0.00000}
[03/08 21:53:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96067, "dt_data": 0.02526, "dt_net": 3.93541, "epoch": "48/55", "eta": "3:06:48", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01695, "lr": 0.00000}
[03/08 21:53:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74219, "dt_data": 0.02517, "dt_net": 3.71701, "epoch": "48/55", "eta": "2:55:52", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01705, "lr": 0.00000}
[03/08 21:54:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.81764, "dt_data": 0.02538, "dt_net": 3.79226, "epoch": "48/55", "eta": "2:58:47", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01723, "lr": 0.00000}
[03/08 21:55:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92857, "dt_data": 0.02521, "dt_net": 3.90337, "epoch": "48/55", "eta": "3:03:20", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01661, "lr": 0.00000}
[03/08 21:55:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48188, "dt_data": 0.02513, "dt_net": 3.45675, "epoch": "48/55", "eta": "2:41:54", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01755, "lr": 0.00000}
[03/08 21:56:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75182, "dt_data": 0.02511, "dt_net": 3.72671, "epoch": "48/55", "eta": "2:53:50", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01550, "lr": 0.00000}
[03/08 21:57:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.98133, "dt_data": 0.02518, "dt_net": 3.95615, "epoch": "48/55", "eta": "3:03:48", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01683, "lr": 0.00000}
[03/08 21:57:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.34233, "dt_data": 0.02534, "dt_net": 4.31699, "epoch": "48/55", "eta": "3:19:44", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01684, "lr": 0.00000}
[03/08 21:58:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.74670, "dt_data": 0.02518, "dt_net": 3.72152, "epoch": "48/55", "eta": "2:51:43", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01748, "lr": 0.00000}
[03/08 21:58:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40263, "dt_data": 0.02541, "dt_net": 3.37722, "epoch": "48/55", "eta": "2:35:23", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01902, "lr": 0.00000}
[03/08 21:59:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.59299, "dt_data": 0.02543, "dt_net": 4.56755, "epoch": "48/55", "eta": "3:28:58", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01742, "lr": 0.00000}
[03/08 22:00:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77729, "dt_data": 0.02556, "dt_net": 3.75173, "epoch": "48/55", "eta": "2:51:14", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01792, "lr": 0.00000}
[03/08 22:00:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.35537, "dt_data": 0.02531, "dt_net": 4.33007, "epoch": "48/55", "eta": "3:16:43", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01735, "lr": 0.00000}
[03/08 22:01:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.69556, "dt_data": 0.02510, "dt_net": 3.67046, "epoch": "48/55", "eta": "2:46:18", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01692, "lr": 0.00000}
[03/08 22:01:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.23512, "dt_data": 0.02519, "dt_net": 3.20993, "epoch": "48/55", "eta": "2:25:02", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01771, "lr": 0.00000}
[03/08 22:02:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10309, "dt_data": 0.02521, "dt_net": 4.07788, "epoch": "48/55", "eta": "3:03:16", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01835, "lr": 0.00000}
[03/08 22:03:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.18178, "dt_data": 0.02566, "dt_net": 4.15611, "epoch": "48/55", "eta": "3:06:05", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01667, "lr": 0.00000}
[03/08 22:03:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91565, "dt_data": 0.02537, "dt_net": 3.89028, "epoch": "48/55", "eta": "2:53:35", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01692, "lr": 0.00000}
[03/08 22:04:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.38364, "dt_data": 0.02529, "dt_net": 3.35835, "epoch": "48/55", "eta": "2:29:26", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01671, "lr": 0.00000}
[03/08 22:04:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.92600, "dt_data": 0.02521, "dt_net": 3.90079, "epoch": "48/55", "eta": "2:52:44", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01642, "lr": 0.00000}
[03/08 22:05:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.49634, "dt_data": 0.02528, "dt_net": 4.47106, "epoch": "48/55", "eta": "3:17:05", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01878, "lr": 0.00000}
[03/08 22:05:52][INFO] logging.py:  99: json_stats: {"RAM": "46.52/251.55G", "_type": "train_epoch", "dt": 0.00056, "dt_data": 0.00056, "dt_net": 2.44182, "epoch": "48/55", "eta": "0:00:01", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 22:05:52][INFO] train_net.py: 478: Epoch 47 takes 1385.19s. Epochs from 42 to 47 take 1364.04s in average and 1363.67s in median.
[03/08 22:05:52][INFO] train_net.py: 484: For epoch 47, each iteraction takes 3.69s in average. From epoch 42 to 47, each iteraction takes 3.64s in average.
[03/08 22:06:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:03:00", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 2.10394}
[03/08 22:06:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:02:09", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.70140}
[03/08 22:06:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:01:53", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.71504}
[03/08 22:07:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:01:49", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 1.95543}
[03/08 22:07:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:01:31", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 1.98071}
[03/08 22:07:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:01:12", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 2.01493}
[03/08 22:07:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:00:44", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.70368}
[03/08 22:08:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:00:28", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 1.76298}
[03/08 22:08:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "48/55", "eta": "0:00:13", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.17897}
[03/08 22:08:47][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 22:08:47][INFO] logging.py:  99: json_stats: {"RAM": "46.82/251.55G", "_type": "val_epoch", "epoch": "48/55", "gpu_mem": "17.37G", "map": 0.60354, "time_diff": 0.00008}
[03/08 22:09:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.96179, "dt_data": 0.02534, "dt_net": 3.93645, "epoch": "49/55", "eta": "2:52:40", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01736, "lr": 0.00000}
[03/08 22:10:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58547, "dt_data": 0.02534, "dt_net": 3.56013, "epoch": "49/55", "eta": "2:35:40", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01829, "lr": 0.00000}
[03/08 22:10:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.58395, "dt_data": 2.05621, "dt_net": 1.52774, "epoch": "49/55", "eta": "2:35:00", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01694, "lr": 0.00000}
[03/08 22:11:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.27317, "dt_data": 1.20920, "dt_net": 3.06397, "epoch": "49/55", "eta": "3:04:06", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01660, "lr": 0.00000}
[03/08 22:11:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.06393, "dt_data": 0.02530, "dt_net": 4.03863, "epoch": "49/55", "eta": "2:54:24", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01626, "lr": 0.00000}
[03/08 22:12:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.37353, "dt_data": 0.02532, "dt_net": 4.34821, "epoch": "49/55", "eta": "3:06:58", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01730, "lr": 0.00000}
[03/08 22:13:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56112, "dt_data": 0.02522, "dt_net": 3.53589, "epoch": "49/55", "eta": "2:31:38", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01642, "lr": 0.00000}
[03/08 22:13:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.75592, "dt_data": 1.30387, "dt_net": 1.45205, "epoch": "49/55", "eta": "1:56:53", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01815, "lr": 0.00000}
[03/08 22:14:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.58331, "dt_data": 0.02523, "dt_net": 2.55808, "epoch": "49/55", "eta": "1:49:08", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01780, "lr": 0.00000}
[03/08 22:14:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.40639, "dt_data": 0.02528, "dt_net": 4.38111, "epoch": "49/55", "eta": "3:05:26", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01786, "lr": 0.00000}
[03/08 22:15:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.41321, "dt_data": 0.02541, "dt_net": 2.38780, "epoch": "49/55", "eta": "1:41:09", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01706, "lr": 0.00000}
[03/08 22:16:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.05962, "dt_data": 0.02543, "dt_net": 3.03419, "epoch": "49/55", "eta": "2:07:44", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01662, "lr": 0.00000}
[03/08 22:16:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01513, "dt_data": 0.98751, "dt_net": 2.02761, "epoch": "49/55", "eta": "2:05:22", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01711, "lr": 0.00000}
[03/08 22:17:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45015, "dt_data": 1.16449, "dt_net": 2.28566, "epoch": "49/55", "eta": "2:22:53", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01704, "lr": 0.00000}
[03/08 22:17:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.46863, "dt_data": 0.02571, "dt_net": 3.44293, "epoch": "49/55", "eta": "2:23:04", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01703, "lr": 0.00000}
[03/08 22:18:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20755, "dt_data": 0.02537, "dt_net": 3.18218, "epoch": "49/55", "eta": "2:11:46", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01813, "lr": 0.00000}
[03/08 22:19:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.95405, "dt_data": 0.02541, "dt_net": 4.92864, "epoch": "49/55", "eta": "3:22:42", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01698, "lr": 0.00000}
[03/08 22:19:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.42059, "dt_data": 0.88664, "dt_net": 2.53395, "epoch": "49/55", "eta": "2:19:23", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01748, "lr": 0.00000}
[03/08 22:20:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.27456, "dt_data": 0.02522, "dt_net": 4.24933, "epoch": "49/55", "eta": "2:53:28", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01716, "lr": 0.00000}
[03/08 22:20:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.16961, "dt_data": 0.02560, "dt_net": 4.14401, "epoch": "49/55", "eta": "2:48:31", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01728, "lr": 0.00000}
[03/08 22:21:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.07695, "dt_data": 0.02511, "dt_net": 4.05184, "epoch": "49/55", "eta": "2:44:05", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01642, "lr": 0.00000}
[03/08 22:22:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.65550, "dt_data": 0.02534, "dt_net": 3.63017, "epoch": "49/55", "eta": "2:26:31", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01697, "lr": 0.00000}
[03/08 22:22:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.72165, "dt_data": 0.02532, "dt_net": 4.69634, "epoch": "49/55", "eta": "3:08:28", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01607, "lr": 0.00000}
[03/08 22:23:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04705, "dt_data": 0.02539, "dt_net": 3.02165, "epoch": "49/55", "eta": "2:01:07", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01708, "lr": 0.00000}
[03/08 22:23:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.75652, "dt_data": 0.02534, "dt_net": 3.73118, "epoch": "49/55", "eta": "2:28:41", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01741, "lr": 0.00000}
[03/08 22:24:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56909, "dt_data": 3.01815, "dt_net": 0.55094, "epoch": "49/55", "eta": "2:20:40", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01816, "lr": 0.00000}
[03/08 22:25:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.86898, "dt_data": 3.31739, "dt_net": 0.55159, "epoch": "49/55", "eta": "2:31:51", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01719, "lr": 0.00000}
[03/08 22:25:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.89187, "dt_data": 3.33620, "dt_net": 0.55567, "epoch": "49/55", "eta": "2:32:06", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01758, "lr": 0.00000}
[03/08 22:26:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03693, "dt_data": 2.48650, "dt_net": 0.55042, "epoch": "49/55", "eta": "1:58:11", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01769, "lr": 0.00000}
[03/08 22:27:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.18383, "dt_data": 2.63198, "dt_net": 0.55186, "epoch": "49/55", "eta": "2:03:22", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01669, "lr": 0.00000}
[03/08 22:27:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.10105, "dt_data": 3.54860, "dt_net": 0.55244, "epoch": "49/55", "eta": "2:38:13", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01671, "lr": 0.00000}
[03/08 22:28:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.24501, "dt_data": 3.68749, "dt_net": 0.55751, "epoch": "49/55", "eta": "2:43:04", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01619, "lr": 0.00000}
[03/08 22:28:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.85670, "dt_data": 0.02558, "dt_net": 2.83112, "epoch": "49/55", "eta": "1:49:16", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01645, "lr": 0.00000}
[03/08 22:29:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.03243, "dt_data": 0.32983, "dt_net": 2.70260, "epoch": "49/55", "eta": "1:55:29", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01622, "lr": 0.00000}
[03/08 22:30:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.46090, "dt_data": 3.90899, "dt_net": 0.55191, "epoch": "49/55", "eta": "2:49:08", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01741, "lr": 0.00000}
[03/08 22:30:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.26648, "dt_data": 1.17745, "dt_net": 2.08903, "epoch": "49/55", "eta": "2:03:18", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01725, "lr": 0.00000}
[03/08 22:31:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.02346, "dt_data": 0.02558, "dt_net": 3.99787, "epoch": "49/55", "eta": "2:31:12", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01752, "lr": 0.00000}
[03/08 22:31:35][INFO] logging.py:  99: json_stats: {"RAM": "46.38/251.55G", "_type": "train_epoch", "dt": 0.00077, "dt_data": 0.00077, "dt_net": 2.74840, "epoch": "49/55", "eta": "0:00:01", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 22:31:35][INFO] train_net.py: 478: Epoch 48 takes 1368.04s. Epochs from 42 to 48 take 1364.61s in average and 1367.09s in median.
[03/08 22:31:35][INFO] train_net.py: 484: For epoch 48, each iteraction takes 3.65s in average. From epoch 42 to 48, each iteraction takes 3.64s in average.
[03/08 22:31:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:02:51", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 1.99494}
[03/08 22:32:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:02:04", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.63383}
[03/08 22:32:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:01:59", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.80451}
[03/08 22:32:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:02:03", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 2.21008}
[03/08 22:33:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:01:49", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 2.37926}
[03/08 22:33:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:01:19", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 2.21146}
[03/08 22:33:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.73372}
[03/08 22:34:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:00:27", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 1.70123}
[03/08 22:34:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "49/55", "eta": "0:00:13", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.27824}
[03/08 22:34:33][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 22:34:33][INFO] logging.py:  99: json_stats: {"RAM": "46.54/251.55G", "_type": "val_epoch", "epoch": "49/55", "gpu_mem": "17.37G", "map": 0.59779, "time_diff": 0.00010}
[03/08 22:35:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.01381, "dt_data": 0.02566, "dt_net": 3.98815, "epoch": "50/55", "eta": "2:29:50", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01653, "lr": 0.00000}
[03/08 22:35:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.97580, "dt_data": 0.02526, "dt_net": 3.95054, "epoch": "50/55", "eta": "2:27:46", "gpu_mem": "17.37G", "iter": "20/375", "loss": 0.01643, "lr": 0.00000}
[03/08 22:36:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.28776, "dt_data": 0.02578, "dt_net": 4.26198, "epoch": "50/55", "eta": "2:38:38", "gpu_mem": "17.37G", "iter": "30/375", "loss": 0.01534, "lr": 0.00000}
[03/08 22:37:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 5.93171, "dt_data": 0.02561, "dt_net": 5.90610, "epoch": "50/55", "eta": "3:38:29", "gpu_mem": "17.37G", "iter": "40/375", "loss": 0.01658, "lr": 0.00000}
[03/08 22:37:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.68089, "dt_data": 0.02522, "dt_net": 2.65566, "epoch": "50/55", "eta": "1:38:17", "gpu_mem": "17.37G", "iter": "50/375", "loss": 0.01822, "lr": 0.00000}
[03/08 22:38:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.20149, "dt_data": 0.02520, "dt_net": 3.17629, "epoch": "50/55", "eta": "1:56:51", "gpu_mem": "17.37G", "iter": "60/375", "loss": 0.01713, "lr": 0.00000}
[03/08 22:38:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.40992, "dt_data": 0.02523, "dt_net": 3.38470, "epoch": "50/55", "eta": "2:03:53", "gpu_mem": "17.37G", "iter": "70/375", "loss": 0.01679, "lr": 0.00000}
[03/08 22:39:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.52236, "dt_data": 0.02607, "dt_net": 2.49629, "epoch": "50/55", "eta": "1:31:13", "gpu_mem": "17.37G", "iter": "80/375", "loss": 0.01529, "lr": 0.00000}
[03/08 22:40:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.65244, "dt_data": 2.45230, "dt_net": 2.20014, "epoch": "50/55", "eta": "2:47:29", "gpu_mem": "17.37G", "iter": "90/375", "loss": 0.01713, "lr": 0.00000}
[03/08 22:40:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.80179, "dt_data": 3.24907, "dt_net": 0.55272, "epoch": "50/55", "eta": "2:16:13", "gpu_mem": "17.37G", "iter": "100/375", "loss": 0.01671, "lr": 0.00000}
[03/08 22:41:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.06025, "dt_data": 2.50901, "dt_net": 0.55124, "epoch": "50/55", "eta": "1:49:08", "gpu_mem": "17.37G", "iter": "110/375", "loss": 0.01670, "lr": 0.00000}
[03/08 22:42:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.60535, "dt_data": 0.02517, "dt_net": 4.58018, "epoch": "50/55", "eta": "2:43:29", "gpu_mem": "17.37G", "iter": "120/375", "loss": 0.01659, "lr": 0.00000}
[03/08 22:42:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.77646, "dt_data": 3.22551, "dt_net": 0.55094, "epoch": "50/55", "eta": "2:13:26", "gpu_mem": "17.37G", "iter": "130/375", "loss": 0.01851, "lr": 0.00000}
[03/08 22:43:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.01476, "dt_data": 3.22135, "dt_net": 0.79341, "epoch": "50/55", "eta": "2:21:11", "gpu_mem": "17.37G", "iter": "140/375", "loss": 0.01834, "lr": 0.00000}
[03/08 22:43:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.01672, "dt_data": 2.46601, "dt_net": 0.55071, "epoch": "50/55", "eta": "1:45:35", "gpu_mem": "17.37G", "iter": "150/375", "loss": 0.01718, "lr": 0.00000}
[03/08 22:44:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.11377, "dt_data": 3.55867, "dt_net": 0.55509, "epoch": "50/55", "eta": "2:23:17", "gpu_mem": "17.37G", "iter": "160/375", "loss": 0.01732, "lr": 0.00000}
[03/08 22:45:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.40113, "dt_data": 3.84749, "dt_net": 0.55364, "epoch": "50/55", "eta": "2:32:34", "gpu_mem": "17.37G", "iter": "170/375", "loss": 0.01788, "lr": 0.00000}
[03/08 22:45:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.04823, "dt_data": 2.49615, "dt_net": 0.55208, "epoch": "50/55", "eta": "1:45:09", "gpu_mem": "17.37G", "iter": "180/375", "loss": 0.01719, "lr": 0.00000}
[03/08 22:46:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.48814, "dt_data": 2.94446, "dt_net": 0.54368, "epoch": "50/55", "eta": "1:59:45", "gpu_mem": "17.37G", "iter": "190/375", "loss": 0.01682, "lr": 0.00000}
[03/08 22:46:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.69446, "dt_data": 2.14381, "dt_net": 0.55065, "epoch": "50/55", "eta": "1:32:03", "gpu_mem": "17.37G", "iter": "200/375", "loss": 0.01777, "lr": 0.00000}
[03/08 22:47:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.45081, "dt_data": 1.78949, "dt_net": 1.66132, "epoch": "50/55", "eta": "1:57:19", "gpu_mem": "17.37G", "iter": "210/375", "loss": 0.01813, "lr": 0.00000}
[03/08 22:48:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.91038, "dt_data": 0.07954, "dt_net": 3.83084, "epoch": "50/55", "eta": "2:12:18", "gpu_mem": "17.37G", "iter": "220/375", "loss": 0.01693, "lr": 0.00000}
[03/08 22:48:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.55207, "dt_data": 0.02526, "dt_net": 3.52681, "epoch": "50/55", "eta": "1:59:35", "gpu_mem": "17.37G", "iter": "230/375", "loss": 0.01625, "lr": 0.00000}
[03/08 22:49:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.79667, "dt_data": 0.18855, "dt_net": 3.60811, "epoch": "50/55", "eta": "2:07:11", "gpu_mem": "17.37G", "iter": "240/375", "loss": 0.01680, "lr": 0.00000}
[03/08 22:49:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.17549, "dt_data": 0.67381, "dt_net": 2.50168, "epoch": "50/55", "eta": "1:45:50", "gpu_mem": "17.37G", "iter": "250/375", "loss": 0.01584, "lr": 0.00000}
[03/08 22:50:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.63538, "dt_data": 0.02582, "dt_net": 3.60955, "epoch": "50/55", "eta": "2:00:34", "gpu_mem": "17.37G", "iter": "260/375", "loss": 0.01610, "lr": 0.00000}
[03/08 22:51:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.09407, "dt_data": 0.02582, "dt_net": 3.06824, "epoch": "50/55", "eta": "1:42:06", "gpu_mem": "17.37G", "iter": "270/375", "loss": 0.01700, "lr": 0.00000}
[03/08 22:51:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.90649, "dt_data": 0.09139, "dt_net": 2.81510, "epoch": "50/55", "eta": "1:35:25", "gpu_mem": "17.37G", "iter": "280/375", "loss": 0.01685, "lr": 0.00000}
[03/08 22:52:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.56801, "dt_data": 0.97070, "dt_net": 2.59730, "epoch": "50/55", "eta": "1:56:33", "gpu_mem": "17.37G", "iter": "290/375", "loss": 0.01820, "lr": 0.00000}
[03/08 22:52:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.50872, "dt_data": 0.02532, "dt_net": 3.48340, "epoch": "50/55", "eta": "1:54:02", "gpu_mem": "17.37G", "iter": "300/375", "loss": 0.01789, "lr": 0.00000}
[03/08 22:53:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.22222, "dt_data": 0.02516, "dt_net": 3.19706, "epoch": "50/55", "eta": "1:44:11", "gpu_mem": "17.37G", "iter": "310/375", "loss": 0.01824, "lr": 0.00000}
[03/08 22:54:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.51958, "dt_data": 0.02538, "dt_net": 3.49420, "epoch": "50/55", "eta": "1:53:12", "gpu_mem": "17.37G", "iter": "320/375", "loss": 0.01692, "lr": 0.00000}
[03/08 22:54:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.60477, "dt_data": 0.02529, "dt_net": 3.57948, "epoch": "50/55", "eta": "1:55:21", "gpu_mem": "17.37G", "iter": "330/375", "loss": 0.01819, "lr": 0.00000}
[03/08 22:55:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.54443, "dt_data": 0.02516, "dt_net": 3.51927, "epoch": "50/55", "eta": "1:52:49", "gpu_mem": "17.37G", "iter": "340/375", "loss": 0.01548, "lr": 0.00000}
[03/08 22:55:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.29931, "dt_data": 0.02551, "dt_net": 4.27379, "epoch": "50/55", "eta": "2:16:08", "gpu_mem": "17.37G", "iter": "350/375", "loss": 0.01656, "lr": 0.00000}
[03/08 22:56:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.23448, "dt_data": 0.02522, "dt_net": 4.20925, "epoch": "50/55", "eta": "2:13:23", "gpu_mem": "17.37G", "iter": "360/375", "loss": 0.01766, "lr": 0.00000}
[03/08 22:57:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 3.90752, "dt_data": 0.02542, "dt_net": 3.88210, "epoch": "50/55", "eta": "2:02:26", "gpu_mem": "17.37G", "iter": "370/375", "loss": 0.01668, "lr": 0.00000}
[03/08 22:57:24][INFO] logging.py:  99: json_stats: {"RAM": "44.43/251.55G", "_type": "train_epoch", "dt": 0.00045, "dt_data": 0.00045, "dt_net": 3.06259, "epoch": "50/55", "eta": "0:00:00", "gpu_mem": "17.37G", "lr": 0.00000}
[03/08 22:57:24][INFO] train_net.py: 478: Epoch 49 takes 1370.74s. Epochs from 42 to 49 take 1365.37s in average and 1367.56s in median.
[03/08 22:57:24][INFO] train_net.py: 484: For epoch 49, each iteraction takes 3.66s in average. From epoch 42 to 49, each iteraction takes 3.64s in average.
[03/08 22:57:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:02:42", "gpu_mem": "17.37G", "iter": "10/96", "time_diff": 1.88887}
[03/08 22:57:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:02:04", "gpu_mem": "17.37G", "iter": "20/96", "time_diff": 1.63422}
[03/08 22:58:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:01:55", "gpu_mem": "17.37G", "iter": "30/96", "time_diff": 1.74604}
[03/08 22:58:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:01:48", "gpu_mem": "17.37G", "iter": "40/96", "time_diff": 1.94567}
[03/08 22:58:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:01:30", "gpu_mem": "17.37G", "iter": "50/96", "time_diff": 1.96584}
[03/08 22:59:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:01:10", "gpu_mem": "17.37G", "iter": "60/96", "time_diff": 1.96376}
[03/08 22:59:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:00:45", "gpu_mem": "17.37G", "iter": "70/96", "time_diff": 1.75317}
[03/08 22:59:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:00:29", "gpu_mem": "17.37G", "iter": "80/96", "time_diff": 1.84053}
[03/08 23:00:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "50/55", "eta": "0:00:12", "gpu_mem": "17.37G", "iter": "90/96", "time_diff": 2.05149}
[03/08 23:00:16][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/08 23:00:16][INFO] logging.py:  99: json_stats: {"RAM": "43.39/251.55G", "_type": "val_epoch", "epoch": "50/55", "gpu_mem": "17.37G", "map": 0.60610, "time_diff": 0.00011}
[03/08 23:00:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 4.04011, "dt_data": 0.49903, "dt_net": 3.54108, "epoch": "51/55", "eta": "2:05:34", "gpu_mem": "17.37G", "iter": "10/375", "loss": 0.01714, "lr": 0.00000}
[03/09 09:28:28][INFO] train_net.py: 396: Train with config:
[03/09 09:28:28][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics_sparse', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/mZ/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/image/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': True, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/09 09:28:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:28][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:28][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:28][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:28:29][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:28:29][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/09 09:28:29][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/09 09:28:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:28:29][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/09 09:28:33][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/09 09:28:33][INFO] uniformerv2_model.py: 334: Init center: True
[03/09 09:28:35][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/09 09:28:35][INFO] misc.py: 185: Params: 133,343,372
[03/09 09:28:35][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/09 09:28:35][INFO] misc.py: 187: Flops: 0 G
[03/09 09:28:35][INFO] misc.py: 192: Activations: 0 M
[03/09 09:28:35][INFO] misc.py: 197: nvidia-smi
[03/09 09:28:36][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/09 09:28:36][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/09 09:28:36][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/09 09:28:36][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/09 09:28:38][INFO] charades.py:  71: Constructing Charades train...
[03/09 09:30:03][INFO] train_net.py: 396: Train with config:
[03/09 09:30:03][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/image/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': True, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:03][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:03][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:03][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:30:04][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:30:04][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/09 09:30:04][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/09 09:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:30:04][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/09 09:30:05][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/09 09:30:05][INFO] uniformerv2_model.py: 334: Init center: True
[03/09 09:30:06][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/09 09:30:06][INFO] misc.py: 185: Params: 133,343,372
[03/09 09:30:06][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/09 09:30:06][INFO] misc.py: 187: Flops: 0 G
[03/09 09:30:06][INFO] misc.py: 192: Activations: 0 M
[03/09 09:30:06][INFO] misc.py: 197: nvidia-smi
[03/09 09:30:07][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/09 09:30:07][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/09 09:30:07][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/09 09:30:07][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/09 09:33:31][INFO] train_net.py: 396: Train with config:
[03/09 09:33:31][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/image/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': True, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/09 09:33:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:33:32][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:33:32][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/09 09:33:32][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/09 09:33:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:33:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:33:33][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/09 09:33:33][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/09 09:33:33][INFO] uniformerv2_model.py: 334: Init center: True
[03/09 09:33:34][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/09 09:33:34][INFO] misc.py: 185: Params: 133,343,372
[03/09 09:33:34][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/09 09:33:34][INFO] misc.py: 187: Flops: 0 G
[03/09 09:33:34][INFO] misc.py: 192: Activations: 0 M
[03/09 09:33:34][INFO] misc.py: 197: nvidia-smi
[03/09 09:33:35][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/09 09:33:35][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/09 09:33:35][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/09 09:33:35][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/09 09:34:30][INFO] train_net.py: 396: Train with config:
[03/09 09:34:30][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/image/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': True, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/09 09:34:30][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:30][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:30][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:30][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:30][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:30][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:30][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:30][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:30][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:30][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:30][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:30][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:30][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:34:31][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:34:31][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/09 09:34:31][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/09 09:34:31][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:34:31][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:34:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:34:32][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:34:32][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/09 09:34:32][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/09 09:34:32][INFO] uniformerv2_model.py: 334: Init center: True
[03/09 09:34:34][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/09 09:34:34][INFO] misc.py: 185: Params: 133,343,372
[03/09 09:34:34][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/09 09:34:34][INFO] misc.py: 187: Flops: 0 G
[03/09 09:34:34][INFO] misc.py: 192: Activations: 0 M
[03/09 09:34:34][INFO] misc.py: 197: nvidia-smi
[03/09 09:34:35][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/09 09:34:35][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/09 09:34:35][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/09 09:34:35][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/09 09:35:44][INFO] train_net.py: 396: Train with config:
[03/09 09:35:44][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/image/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': True, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/09 09:35:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:44][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:44][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:44][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:44][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:44][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:35:45][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:35:45][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:35:45][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/09 09:35:45][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/09 09:35:45][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:35:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:35:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:35:46][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:35:46][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/09 09:35:46][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/09 09:35:46][INFO] uniformerv2_model.py: 334: Init center: True
[03/09 09:35:47][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/09 09:35:47][INFO] misc.py: 185: Params: 133,343,372
[03/09 09:35:47][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/09 09:35:47][INFO] misc.py: 187: Flops: 0 G
[03/09 09:35:47][INFO] misc.py: 192: Activations: 0 M
[03/09 09:35:47][INFO] misc.py: 197: nvidia-smi
[03/09 09:35:48][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/09 09:35:48][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/09 09:35:48][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/09 09:35:48][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/09 09:35:50][INFO] charades.py:  71: Constructing Charades train...
[03/09 09:36:04][INFO] charades.py: 107: Charades dataloader constructed (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/train.csv
[03/09 09:36:04][INFO] charades.py:  71: Constructing Charades val...
[03/09 09:36:07][INFO] charades.py: 107: Charades dataloader constructed (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/val.csv
[03/09 09:36:07][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./exp/animal/bce_logits/runs-charades`
[03/09 09:36:07][INFO] train_net.py: 439: Start epoch: 43
[03/09 09:39:10][INFO] train_net.py: 396: Train with config:
[03/09 09:39:10][INFO] train_net.py: 397: CfgNode({'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1}), 'TRAIN': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'EVAL_PERIOD': 1, 'CHECKPOINT_PERIOD': 100, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'SAVE_LATEST': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.0, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': False, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'charades', 'BATCH_SIZE': 64, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 4, 'NUM_SPATIAL_CROPS': 3, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'TEST_BEST': True, 'ADD_SOFTMAX': True, 'INTERVAL': 2000}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'uniformerv2', 'MODEL_NAME': 'Uniformerv2', 'NUM_CLASSES': 140, 'NUM_CLASSES_LIST': [400, 600, 700], 'LOSS_FUNC': 'bce_logit', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'uniformerv2'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'USE_CHECKPOINT': False, 'CHECKPOINT_NUM': [0], 'EMA_DECAY': 0.9999, 'EMA_EPOCH': -1}), 'MVIT': CfgNode({'MODE': 'conv', 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [2, 4, 4], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [], 'HEAD_MUL': [], 'POOL_KV_STRIDE': [], 'POOL_Q_STRIDE': [], 'POOL_KVQ_KERNEL': None, 'ZERO_DECAY_POS_CLS': True, 'NORM_STEM': False, 'SEP_POS_EMBED': False, 'DROPOUT_RATE': 0.0}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'UNIFORMER': CfgNode({'EMBED_DIM': [64, 128, 320, 512], 'DEPTH': [3, 4, 8, 3], 'NUM_HEADS': [1, 2, 5, 8], 'HEAD_DIM': 64, 'MLP_RATIO': [4.0, 4.0, 4.0, 4.0], 'QKV_BIAS': True, 'QKV_SCALE': None, 'REPRESENTATION_SIZE': None, 'DROPOUT_RATE': 0, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'SPLIT': False, 'STAGE_TYPE': [0, 0, 1, 1], 'STD': False, 'KS': 5, 'DPE': True, 'RATIO': 1, 'MBCONV': False, 'ADD_MLP': True, 'TAU': 3, 'PRUNE_RATIO': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'TRADE_OFF': [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 'INIT_VALUE': 1.0}), 'VIP': CfgNode({'LAYERS': [4, 3, 8, 3], 'TRANSITIONS': [True, False, False, False], 'SEGMENT_DIM': [32, 16, 16, 16], 'T_STRIDE': 1, 'MLP_RATIOS': [3, 3, 3, 3], 'EMBED_DIMS': [192, 384, 384, 384], 'PATCH_SIZE': 7, 'QKV_SCALE': None, 'QKV_BIAS': True, 'ATTENTION_DROPOUT_RATE': 0, 'DROP_DEPTH_RATE': 0.1, 'PRETRAIN_NAME': None, 'ST_TYPE': 'st_skip'}), 'UNIFORMERV2': CfgNode({'BACKBONE': 'uniformerv2_b16', 'N_LAYERS': 4, 'N_DIM': 768, 'N_HEAD': 12, 'MLP_FACTOR': 4.0, 'BACKBONE_DROP_PATH_RATE': 0.0, 'DROP_PATH_RATE': 0.0, 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5], 'CLS_DROPOUT': 0.5, 'RETURN_LIST': [8, 9, 10, 11], 'DW_REDUCTION': 1.5, 'TEMPORAL_DOWNSAMPLE': False, 'NO_LMHRA': False, 'DOUBLE_LMHRA': True, 'PRETRAIN': '', 'DELETE_SPECIAL_HEAD': False, 'FROZEN': False}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/', 'EXTRA_PATH_TO_DATA_DIR': '', 'PATH_TO_DATA_DIR_LIST': [''], 'PATH_LABEL_SEPARATOR': ' ', 'PATH_PREFIX': '/mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/dataset/image/', 'PATH_PREFIX_LIST': [''], 'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt', 'IMAGE_TEMPLATE': '{:05d}.jpg', 'NUM_FRAMES': 8, 'SAMPLING_RATE': 16, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'DECODING_BACKEND': 'decord', 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': True, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'MC': False}), 'SOLVER': CfgNode({'BASE_LR': 1e-05, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 55, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 5.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRADIENT': 20, 'BACKBONE_LR_RATIO': 0.1, 'SPECIAL_LIST': [], 'SPECIAL_RATIO': 1.0}), 'NUM_GPUS': 4, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './exp/animal/bce_logits', 'RNG_SEED': 6666, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 1, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': True, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1}), 'VIDEO_PATH': ''})
[03/09 09:39:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:10][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:10][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:10][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  71: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py:  75: No L_MHRA: False
[03/09 09:39:11][INFO] uniformerv2_model.py:  76: Double L_MHRA: True
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py:  54: Init zero for Conv in pos_emb
[03/09 09:39:11][INFO] uniformerv2_model.py: 213: Use checkpoint: False
[03/09 09:39:11][INFO] uniformerv2_model.py: 214: Checkpoint number: [0]
[03/09 09:39:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py: 139: Drop path rate: 0.0
[03/09 09:39:11][INFO] uniformerv2_model.py: 398: load pretrained weights
[03/09 09:39:12][INFO] uniformerv2_model.py: 353: Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
[03/09 09:39:12][INFO] uniformerv2_model.py: 334: Init center: True
[03/09 09:39:12][INFO] misc.py: 184: Model:
DistributedDataParallel(
  (module): Uniformerv2(
    (backbone): VisionTransformer(
      (conv1): Conv3d(3, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): ModuleList(
          (0-11): 12 x ResidualAttentionBlock(
            (drop_path): Identity()
            (lmhra1): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (lmhra2): Local_MHRA(
              (pos_embed): Sequential(
                (0): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (1): Conv3d(768, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))
                (2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), groups=512)
                (3): Conv3d(512, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1))
              )
            )
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (dpe): ModuleList(
          (0-3): 4 x Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768)
        )
        (dec): ModuleList(
          (0-3): 4 x Extractor(
            (drop_path): Identity()
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (dropout): Dropout(p=0.5, inplace=False)
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ln_3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj): Sequential(
          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Linear(in_features=768, out_features=140, bias=True)
        )
        (sigmoid): Sigmoid()
      )
    )
  )
)
[03/09 09:39:12][INFO] misc.py: 185: Params: 133,343,372
[03/09 09:39:12][INFO] misc.py: 186: Mem: 0.9990062713623047 MB
[03/09 09:39:13][INFO] misc.py: 187: Flops: 0 G
[03/09 09:39:13][INFO] misc.py: 192: Activations: 0 M
[03/09 09:39:13][INFO] misc.py: 197: nvidia-smi
[03/09 09:39:13][INFO] optimizer.py:  71: bn 48, non bn 144, zero 219
[03/09 09:39:13][INFO] checkpoint_amp.py: 555: ./exp/animal/bce_logits
[03/09 09:39:13][INFO] checkpoint_amp.py: 567: Load from best checkpoint file.
[03/09 09:39:13][INFO] checkpoint_amp.py: 268: Loading network weights from ./exp/animal/bce_logits/best.pyth.
[03/09 09:39:15][INFO] charades.py:  71: Constructing Charades train...
[03/09 09:39:27][INFO] charades.py: 107: Charades dataloader constructed (size: 24004) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/train.csv
[03/09 09:39:27][INFO] charades.py:  71: Constructing Charades val...
[03/09 09:39:31][INFO] charades.py: 107: Charades dataloader constructed (size: 6096) from /mount/ccai_nas/yunzhu/Animal_Kingdom/action_recognition/annotation/val.csv
[03/09 09:39:31][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./exp/animal/bce_logits/runs-charades`
[03/09 09:39:31][INFO] train_net.py: 439: Start epoch: 43
[03/09 09:39:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:02:03", "gpu_mem": "3.53G", "iter": "10/96", "time_diff": 1.43880}
[03/09 09:40:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:51", "gpu_mem": "3.53G", "iter": "20/96", "time_diff": 1.46070}
[03/09 09:40:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:37", "gpu_mem": "3.53G", "iter": "30/96", "time_diff": 1.47085}
[03/09 09:40:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:19", "gpu_mem": "3.53G", "iter": "40/96", "time_diff": 1.42286}
[03/09 09:40:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:01:03", "gpu_mem": "3.53G", "iter": "50/96", "time_diff": 1.37260}
[03/09 09:41:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:53", "gpu_mem": "3.53G", "iter": "60/96", "time_diff": 1.47460}
[03/09 09:41:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:38", "gpu_mem": "3.53G", "iter": "70/96", "time_diff": 1.49847}
[03/09 09:41:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:26", "gpu_mem": "3.53G", "iter": "80/96", "time_diff": 1.64347}
[03/09 09:41:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "43/55", "eta": "0:00:09", "gpu_mem": "3.53G", "iter": "90/96", "time_diff": 1.64167}
[03/09 09:42:02][INFO] meters.py: 773: Getting mAP for 1524 examples
[03/09 09:42:02][INFO] logging.py:  99: json_stats: {"RAM": "44.78/251.55G", "_type": "val_epoch", "epoch": "43/55", "gpu_mem": "3.53G", "map": 0.37838, "time_diff": 0.00007}
[03/09 09:42:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.21390, "dt_data": 0.02554, "dt_net": 2.18836, "epoch": "43/55", "eta": "2:59:30", "gpu_mem": "17.36G", "iter": "10/375", "loss": 0.02533, "lr": 0.00000}
[03/09 09:42:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 2.01082, "dt_data": 0.02511, "dt_net": 1.98571, "epoch": "43/55", "eta": "2:42:42", "gpu_mem": "17.36G", "iter": "20/375", "loss": 0.02413, "lr": 0.00000}
[03/09 09:43:10][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 1.60896, "dt_data": 0.02519, "dt_net": 1.58377, "epoch": "43/55", "eta": "2:09:55", "gpu_mem": "17.36G", "iter": "30/375", "loss": 0.02220, "lr": 0.00000}
[03/09 09:43:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 1.65810, "dt_data": 0.02510, "dt_net": 1.63299, "epoch": "43/55", "eta": "2:13:36", "gpu_mem": "17.36G", "iter": "40/375", "loss": 0.02075, "lr": 0.00000}
